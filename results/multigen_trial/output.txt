Beginning trial described in ./config/multigen_trial.json.
Experiment type: multiple generators each corresponding to 1 key.
Experiment settings:
	byte: 0
	keys: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
	key_dataset_kwargs:
		keep_data_in_memory: True
		data_path: ./data
		download: True
		extract: True
		preprocess: True
		delete_download_after_extraction: False
		delete_extracted_after_preprocess: False
		samples_to_use: 500
	dataloader_kwargs:
		batch_size: 16
		shuffle: True
	dataset_prop_for_validation: 0.2
	trace_map_constructor: None
	trace_map_kwargs:
		layers: [256]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	plaintext_map_constructor: None
	plaintext_map_kwargs:
		layers: [64]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	key_map_constructor: <function get_mlp_map at 0x7f67f6443700>
	key_map_kwargs:
		layers: [64, 256]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	cumulative_map_constructor: None
	cumulative_map_kwargs:
		layers: [256]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	discriminator_constructor: <function get_xdeepsca_discriminator at 0x7f67f64438b0>
	discriminator_kwargs:
	discriminator_loss_constructor: <class 'torch.nn.modules.loss.CrossEntropyLoss'>
	discriminator_loss_kwargs:
	discriminator_optimizer_constructor: <class 'torch.optim.adam.Adam'>
	discriminator_optimizer_kwargs:
	generator_loss_constructor: <class 'loss_functions.BatchStdLoss'>
	generator_loss_kwargs:
	generator_optimizer_constructor: <class 'torch.optim.adam.Adam'>
	generator_optimizer_kwargs:
	device: cuda
	discriminator_pretraining_epochs: 0
	generator_pretraining_epochs: 0
	gan_training_epochs: 100
	discriminator_posttraining_epochs: 100
	seed: 0
Loading datasets.
AesKeyGroupDataset:
	Available keys: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
	Key transform: Compose(
    IntToBinary()
    ToTensor1D()
)
	Byte: 0
	Number of samples available: 10112
	Trace size: torch.Size([1, 500])
	Key size: torch.Size([1, 8])
	Plaintext size: torch.Size([1, 8])
	Key index size: ()
Constructing generator.
KeyOnlyGenerator(
  (key_trace_map): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=8, out_features=64, bias=True)
    (2): ReLU()
    (3): Linear(in_features=64, out_features=256, bias=True)
    (4): ReLU()
    (5): Linear(in_features=256, out_features=500, bias=True)
    (6): Unflatten(dim=-1, unflattened_size=torch.Size([1, 500]))
  )
)

Constructing discriminator.
Discriminator(
  (model): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=500, out_features=200, bias=True)
    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): ReLU()
    (4): Dropout(p=0.2, inplace=False)
    (5): Linear(in_features=200, out_features=200, bias=True)
    (6): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): ReLU()
    (8): Linear(in_features=200, out_features=256, bias=True)
  )
)

Calculating initial results.
Training results:
gen_loss: 0.020652138
disc_loss: 5.5611715
disc_acc: 0.0

Validation results:
gen_loss: 0.019758703
disc_loss: 5.5615115
disc_acc: 0.0


Training discriminator and generator simultaneously.
	Epoch 1
Training results:
gen_loss: 3.0688076
disc_loss: 0.5122117
disc_acc: 0.9107673267326732

Validation results:
gen_loss: 2.6411147
disc_loss: 0.077750735
disc_acc: 0.9945436507936508


	Epoch 2
Training results:
gen_loss: 4.900911
disc_loss: 0.20857859
disc_acc: 0.9392326732673267

Validation results:
gen_loss: 3.1119452
disc_loss: 0.07745773
disc_acc: 0.9945436507936508


	Epoch 3
Training results:
gen_loss: 5.9410787
disc_loss: 0.25897297
disc_acc: 0.9195544554455446

Validation results:
gen_loss: 3.0379894
disc_loss: 0.059568536
disc_acc: 1.0


	Epoch 4
Training results:
gen_loss: 6.730286
disc_loss: 0.18551418
disc_acc: 0.9428217821782178

Validation results:
gen_loss: 4.446616
disc_loss: 0.032126322
disc_acc: 1.0


	Epoch 5
Training results:
gen_loss: 7.2411695
disc_loss: 0.14322616
disc_acc: 0.9539603960396039

Validation results:
gen_loss: 5.8129144
disc_loss: 0.008640942
disc_acc: 1.0


	Epoch 6
Training results:
gen_loss: 7.720818
disc_loss: 0.10184222
disc_acc: 0.9648514851485148

Validation results:
gen_loss: 3.7220652
disc_loss: 0.03824953
disc_acc: 0.9930555555555556


	Epoch 7
Training results:
gen_loss: 8.032492
disc_loss: 0.07461764
disc_acc: 0.9764851485148515

Validation results:
gen_loss: 4.304258
disc_loss: 0.009407168
disc_acc: 1.0


	Epoch 8
Training results:
gen_loss: 8.5523815
disc_loss: 0.0762715
disc_acc: 0.9763613861386139

Validation results:
gen_loss: 4.680233
disc_loss: 0.007300833
disc_acc: 1.0


	Epoch 9
Training results:
gen_loss: 8.921854
disc_loss: 0.05843197
disc_acc: 0.9819306930693069

Validation results:
gen_loss: 4.2561417
disc_loss: 0.0018765159
disc_acc: 1.0


	Epoch 10
Training results:
gen_loss: 9.0501
disc_loss: 0.043697204
disc_acc: 0.9873762376237624

Validation results:
gen_loss: 5.286981
disc_loss: 0.006072243
disc_acc: 1.0


	Epoch 11
Training results:
gen_loss: 9.398312
disc_loss: 0.05679878
disc_acc: 0.9814356435643564

Validation results:
gen_loss: 6.5177603
disc_loss: 0.005910879
disc_acc: 1.0


	Epoch 12
Training results:
gen_loss: 9.307827
disc_loss: 0.050208855
disc_acc: 0.9827970297029703

Validation results:
gen_loss: 11.465573
disc_loss: 0.018906549
disc_acc: 1.0


	Epoch 13
Training results:
gen_loss: 9.808648
disc_loss: 0.068154134
disc_acc: 0.9784653465346534

Validation results:
gen_loss: 7.2426443
disc_loss: 0.18007264
disc_acc: 0.8953373015873016


	Epoch 14
Training results:
gen_loss: 10.259366
disc_loss: 0.04341007
disc_acc: 0.9853960396039604

Validation results:
gen_loss: 7.6639624
disc_loss: 0.0018160786
disc_acc: 1.0


	Epoch 15
Training results:
gen_loss: 10.618273
disc_loss: 0.042633288
disc_acc: 0.9860148514851486

Validation results:
gen_loss: 5.9599094
disc_loss: 0.0013028682
disc_acc: 1.0


	Epoch 16
Training results:
gen_loss: 10.278083
disc_loss: 0.053714316
disc_acc: 0.9818069306930693

Validation results:
gen_loss: 6.2430515
disc_loss: 0.0037740539
disc_acc: 1.0


	Epoch 17
Training results:
gen_loss: 10.952094
disc_loss: 0.035776448
disc_acc: 0.9873762376237624

Validation results:
gen_loss: 5.682639
disc_loss: 0.0021901114
disc_acc: 1.0


	Epoch 18
Training results:
gen_loss: 11.39966
disc_loss: 0.04612996
disc_acc: 0.9818069306930693

Validation results:
gen_loss: 8.061711
disc_loss: 0.00060490996
disc_acc: 1.0


	Epoch 19
Training results:
gen_loss: 11.653527
disc_loss: 0.022880033
disc_acc: 0.9918316831683168

Validation results:
gen_loss: 5.115519
disc_loss: 0.00012024039
disc_acc: 1.0


	Epoch 20
Training results:
gen_loss: 12.32338
disc_loss: 0.022485487
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 7.602053
disc_loss: 0.0016348085
disc_acc: 1.0


	Epoch 21
Training results:
gen_loss: 12.804258
disc_loss: 0.022125036
disc_acc: 0.9925742574257426

Validation results:
gen_loss: 11.865521
disc_loss: 0.51128525
disc_acc: 0.8864087301587301


	Epoch 22
Training results:
gen_loss: 13.040118
disc_loss: 0.023154344
disc_acc: 0.9915841584158416

Validation results:
gen_loss: 6.216358
disc_loss: 0.027276522
disc_acc: 1.0


	Epoch 23
Training results:
gen_loss: 13.303512
disc_loss: 0.025273398
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 7.4382505
disc_loss: 0.0002274733
disc_acc: 1.0


	Epoch 24
Training results:
gen_loss: 14.01391
disc_loss: 0.011717273
disc_acc: 0.9955445544554455

Validation results:
gen_loss: 7.729998
disc_loss: 0.00018384792
disc_acc: 1.0


	Epoch 25
Training results:
gen_loss: 14.745846
disc_loss: 0.027514422
disc_acc: 0.9910891089108911

Validation results:
gen_loss: 11.954341
disc_loss: 0.14107521
disc_acc: 0.9424603174603174


	Epoch 26
Training results:
gen_loss: 15.604823
disc_loss: 0.019634213
disc_acc: 0.9931930693069307

Validation results:
gen_loss: 8.779384
disc_loss: 0.00029409517
disc_acc: 1.0


	Epoch 27
Training results:
gen_loss: 15.621905
disc_loss: 0.015802871
disc_acc: 0.996039603960396

Validation results:
gen_loss: 13.0213995
disc_loss: 0.00044802262
disc_acc: 1.0


	Epoch 28
Training results:
gen_loss: 16.605251
disc_loss: 0.016036035
disc_acc: 0.9955445544554455

Validation results:
gen_loss: 8.492714
disc_loss: 6.8594534e-05
disc_acc: 1.0


	Epoch 29
Training results:
gen_loss: 16.968435
disc_loss: 0.018104056
disc_acc: 0.9943069306930693

Validation results:
gen_loss: 7.433298
disc_loss: 0.0009948219
disc_acc: 1.0


	Epoch 30
Training results:
gen_loss: 17.977219
disc_loss: 0.018031191
disc_acc: 0.9948019801980198

Validation results:
gen_loss: 7.770406
disc_loss: 5.9970327e-05
disc_acc: 1.0


	Epoch 31
Training results:
gen_loss: 17.75999
disc_loss: 0.01130297
disc_acc: 0.996039603960396

Validation results:
gen_loss: 9.917009
disc_loss: 0.0007715634
disc_acc: 1.0


	Epoch 32
Training results:
gen_loss: 18.605621
disc_loss: 0.013146137
disc_acc: 0.995420792079208

Validation results:
gen_loss: 9.691946
disc_loss: 0.0005937475
disc_acc: 1.0


	Epoch 33
Training results:
gen_loss: 19.791819
disc_loss: 0.008856899
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 8.682157
disc_loss: 0.00018734089
disc_acc: 1.0


	Epoch 34
Training results:
gen_loss: 20.041506
disc_loss: 0.010108042
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 9.619574
disc_loss: 0.00016059607
disc_acc: 1.0


	Epoch 35
Training results:
gen_loss: 19.861341
disc_loss: 0.008617019
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 9.926307
disc_loss: 0.00012606454
disc_acc: 1.0


	Epoch 36
Training results:
gen_loss: 20.533895
disc_loss: 0.004607048
disc_acc: 0.9987623762376238

Validation results:
gen_loss: 14.08135
disc_loss: 0.0001778013
disc_acc: 1.0


	Epoch 37
Training results:
gen_loss: 19.817343
disc_loss: 0.0076604798
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 10.322397
disc_loss: 0.00010512716
disc_acc: 1.0


	Epoch 38
Training results:
gen_loss: 21.173744
disc_loss: 0.009684525
disc_acc: 0.9971534653465347

Validation results:
gen_loss: 10.394581
disc_loss: 3.7328056e-05
disc_acc: 1.0


	Epoch 39
Training results:
gen_loss: 21.924215
disc_loss: 0.012640387
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 9.286358
disc_loss: 3.9313392e-05
disc_acc: 1.0


	Epoch 40
Training results:
gen_loss: 21.820736
disc_loss: 0.0068310387
disc_acc: 0.9977722772277228

Validation results:
gen_loss: 11.353717
disc_loss: 0.0001137213
disc_acc: 1.0


	Epoch 41
Training results:
gen_loss: 21.437132
disc_loss: 0.0023873616
disc_acc: 0.9993811881188119

Validation results:
gen_loss: 10.777244
disc_loss: 4.5450717e-05
disc_acc: 1.0


	Epoch 42
Training results:
gen_loss: 21.5346
disc_loss: 0.004852511
disc_acc: 0.9986386138613862

Validation results:
gen_loss: 17.1766
disc_loss: 0.00029637734
disc_acc: 1.0


	Epoch 43
Training results:
gen_loss: 22.66438
disc_loss: 0.0038386995
disc_acc: 0.999009900990099

Validation results:
gen_loss: 6.917303
disc_loss: 6.759674e-06
disc_acc: 1.0


	Epoch 44
Training results:
gen_loss: 23.53719
disc_loss: 0.0048238407
disc_acc: 0.9982673267326733

Validation results:
gen_loss: 19.221758
disc_loss: 0.0019702096
disc_acc: 1.0


	Epoch 45
Training results:
gen_loss: 23.153042
disc_loss: 0.0064422335
disc_acc: 0.998019801980198

Validation results:
gen_loss: 18.335686
disc_loss: 0.00020784678
disc_acc: 1.0


	Epoch 46
Training results:
gen_loss: 24.267366
disc_loss: 0.009660865
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 12.339654
disc_loss: 0.00029355503
disc_acc: 1.0


	Epoch 47
Training results:
gen_loss: 23.74468
disc_loss: 0.008469212
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 12.805579
disc_loss: 0.00012363443
disc_acc: 1.0


	Epoch 48
Training results:
gen_loss: 24.317543
disc_loss: 0.009117013
disc_acc: 0.9972772277227723

Validation results:
gen_loss: 9.272402
disc_loss: 7.806568e-06
disc_acc: 1.0


	Epoch 49
Training results:
gen_loss: 24.419598
disc_loss: 0.0014238225
disc_acc: 0.9996287128712872

Validation results:
gen_loss: 12.707017
disc_loss: 3.19429e-05
disc_acc: 1.0


	Epoch 50
Training results:
gen_loss: 25.155235
disc_loss: 0.0018158281
disc_acc: 0.9993811881188119

Validation results:
gen_loss: 11.942009
disc_loss: 2.1663049e-05
disc_acc: 1.0


	Epoch 51
Training results:
gen_loss: 24.280775
disc_loss: 0.0010788625
disc_acc: 0.9995049504950495

Validation results:
gen_loss: 16.091774
disc_loss: 2.138249e-05
disc_acc: 1.0


	Epoch 52
Training results:
gen_loss: 25.33212
disc_loss: 0.0021286148
disc_acc: 0.999009900990099

Validation results:
gen_loss: 15.429879
disc_loss: 4.3754437e-05
disc_acc: 1.0


	Epoch 53
Training results:
gen_loss: 24.921352
disc_loss: 0.00072560005
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 19.69678
disc_loss: 0.00026191483
disc_acc: 1.0


	Epoch 54
Training results:
gen_loss: 25.087221
disc_loss: 0.0046705557
disc_acc: 0.9986386138613862

Validation results:
gen_loss: 18.202187
disc_loss: 0.0011108518
disc_acc: 1.0


	Epoch 55
Training results:
gen_loss: 25.590637
disc_loss: 0.0043259645
disc_acc: 0.9988861386138614

Validation results:
gen_loss: 15.410263
disc_loss: 7.467334e-05
disc_acc: 1.0


	Epoch 56
Training results:
gen_loss: 25.086914
disc_loss: 0.006063701
disc_acc: 0.9981435643564357

Validation results:
gen_loss: 10.490431
disc_loss: 2.3710107e-05
disc_acc: 1.0


	Epoch 57
Training results:
gen_loss: 24.731386
disc_loss: 0.005403701
disc_acc: 0.9985148514851485

Validation results:
gen_loss: 13.024472
disc_loss: 1.908584e-05
disc_acc: 1.0


	Epoch 58
Training results:
gen_loss: 25.111282
disc_loss: 0.0047282963
disc_acc: 0.999009900990099

Validation results:
gen_loss: 12.561502
disc_loss: 3.2262316e-05
disc_acc: 1.0


	Epoch 59
Training results:
gen_loss: 24.495424
disc_loss: 0.0025898141
disc_acc: 0.9992574257425743

Validation results:
gen_loss: 9.108266
disc_loss: 1.1469629e-05
disc_acc: 1.0


	Epoch 60
Training results:
gen_loss: 25.254173
disc_loss: 0.0044526868
disc_acc: 0.998391089108911

Validation results:
gen_loss: 9.983175
disc_loss: 2.664509e-06
disc_acc: 1.0


	Epoch 61
Training results:
gen_loss: 25.682829
disc_loss: 0.0013174126
disc_acc: 0.9995049504950495

Validation results:
gen_loss: 12.08148
disc_loss: 6.3382877e-06
disc_acc: 1.0


	Epoch 62
Training results:
gen_loss: 25.445951
disc_loss: 0.0023315982
disc_acc: 0.9995049504950495

Validation results:
gen_loss: 16.361462
disc_loss: 7.466181e-06
disc_acc: 1.0


	Epoch 63
Training results:
gen_loss: 26.299788
disc_loss: 0.0031612387
disc_acc: 0.9987623762376238

Validation results:
gen_loss: 9.25034
disc_loss: 4.430058e-05
disc_acc: 1.0


	Epoch 64
Training results:
gen_loss: 26.567442
disc_loss: 0.009877171
disc_acc: 0.9977722772277228

Validation results:
gen_loss: 11.811234
disc_loss: 1.7150426e-06
disc_acc: 1.0


	Epoch 65
Training results:
gen_loss: 27.038855
disc_loss: 0.006072585
disc_acc: 0.9991336633663367

Validation results:
gen_loss: 14.345364
disc_loss: 4.680352e-06
disc_acc: 1.0


	Epoch 66
Training results:
gen_loss: 26.871569
disc_loss: 0.00038556522
disc_acc: 1.0

Validation results:
gen_loss: 10.219139
disc_loss: 1.5253131e-05
disc_acc: 1.0


	Epoch 67
Training results:
gen_loss: 27.069838
disc_loss: 0.0018128917
disc_acc: 0.9995049504950495

Validation results:
gen_loss: 15.645705
disc_loss: 1.165834e-06
disc_acc: 1.0


	Epoch 68
Training results:
gen_loss: 26.790955
disc_loss: 0.001182403
disc_acc: 0.9996287128712872

Validation results:
gen_loss: 15.191483
disc_loss: 3.0112358e-06
disc_acc: 1.0


	Epoch 69
Training results:
gen_loss: 26.998573
disc_loss: 0.00059999456
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 15.686722
disc_loss: 6.30613e-06
disc_acc: 1.0


	Epoch 70
Training results:
gen_loss: 26.801128
disc_loss: 0.0013322243
disc_acc: 0.9995049504950495

Validation results:
gen_loss: 16.16812
disc_loss: 1.6201376e-06
disc_acc: 1.0


	Epoch 71
Training results:
gen_loss: 27.347445
disc_loss: 0.0021303224
disc_acc: 0.9993811881188119

Validation results:
gen_loss: 36.191387
disc_loss: 4.5364823e-06
disc_acc: 1.0


	Epoch 72
Training results:
gen_loss: 27.772127
disc_loss: 0.0015727452
disc_acc: 0.9995049504950495

Validation results:
gen_loss: 19.119564
disc_loss: 1.2159782e-06
disc_acc: 1.0


	Epoch 73
Training results:
gen_loss: 27.159971
disc_loss: 0.0053303167
disc_acc: 0.9985148514851485

Validation results:
gen_loss: 20.005606
disc_loss: 1.0631826e-06
disc_acc: 1.0


	Epoch 74
Training results:
gen_loss: 27.70548
disc_loss: 0.006028541
disc_acc: 0.9988861386138614

Validation results:
gen_loss: 12.942223
disc_loss: 2.1594105e-06
disc_acc: 1.0


	Epoch 75
Training results:
gen_loss: 27.62852
disc_loss: 0.0042226566
disc_acc: 0.9985148514851485

Validation results:
gen_loss: 10.226024
disc_loss: 8.5799925e-08
disc_acc: 1.0


	Epoch 76
Training results:
gen_loss: 27.54835
disc_loss: 0.0026942862
disc_acc: 0.9991336633663367

Validation results:
gen_loss: 14.446469
disc_loss: 3.7483488e-07
disc_acc: 1.0


	Epoch 77
Training results:
gen_loss: 27.202433
disc_loss: 0.0054216716
disc_acc: 0.9986386138613862

Validation results:
gen_loss: 11.964831
disc_loss: 1.8573226e-07
disc_acc: 1.0


	Epoch 78
Training results:
gen_loss: 26.772038
disc_loss: 0.0016561527
disc_acc: 0.9996287128712872

Validation results:
gen_loss: 11.460821
disc_loss: 2.4811595e-07
disc_acc: 1.0


	Epoch 79
Training results:
gen_loss: 27.18862
disc_loss: 0.00017565326
disc_acc: 1.0

Validation results:
gen_loss: 12.286625
disc_loss: 9.52018e-08
disc_acc: 1.0


	Epoch 80
Training results:
gen_loss: 26.903597
disc_loss: 0.0019172193
disc_acc: 0.9991336633663367

Validation results:
gen_loss: 11.336455
disc_loss: 1.1246132e-06
disc_acc: 1.0


	Epoch 81
Training results:
gen_loss: 26.994724
disc_loss: 0.00016553528
disc_acc: 1.0

Validation results:
gen_loss: 11.700575
disc_loss: 1.3109465e-07
disc_acc: 1.0


	Epoch 82
Training results:
gen_loss: 27.311834
disc_loss: 0.0026813678
disc_acc: 0.9991336633663367

Validation results:
gen_loss: 11.69056
disc_loss: 8.260682e-08
disc_acc: 1.0


	Epoch 83
Training results:
gen_loss: 27.003538
disc_loss: 0.00015765775
disc_acc: 1.0

Validation results:
gen_loss: 12.419482
disc_loss: 4.8428767e-08
disc_acc: 1.0


	Epoch 84
Training results:
gen_loss: 27.4602
disc_loss: 0.0064733233
disc_acc: 0.9977722772277228

Validation results:
gen_loss: 12.508894
disc_loss: 1.2535892e-07
disc_acc: 1.0


	Epoch 85
Training results:
gen_loss: 27.54314
disc_loss: 0.00040399618
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 11.041588
disc_loss: 9.2659164e-08
disc_acc: 1.0


	Epoch 86
Training results:
gen_loss: 27.776068
disc_loss: 0.0020124472
disc_acc: 0.9993811881188119

Validation results:
gen_loss: 23.631622
disc_loss: 2.369993e-07
disc_acc: 1.0


	Epoch 87
Training results:
gen_loss: 27.88597
disc_loss: 0.002059913
disc_acc: 0.999009900990099

Validation results:
gen_loss: 14.341649
disc_loss: 5.6038937e-07
disc_acc: 1.0


	Epoch 88
Training results:
gen_loss: 27.795568
disc_loss: 0.0003394199
disc_acc: 1.0

Validation results:
gen_loss: 14.531545
disc_loss: 6.8888276e-08
disc_acc: 1.0


	Epoch 89
Training results:
gen_loss: 27.656845
disc_loss: 0.002896267
disc_acc: 0.9995049504950495

Validation results:
gen_loss: 11.294324
disc_loss: 1.7331456e-07
disc_acc: 1.0


	Epoch 90
Training results:
gen_loss: 27.748795
disc_loss: 0.00655305
disc_acc: 0.9991336633663367

Validation results:
gen_loss: 13.807808
disc_loss: 3.9677293e-08
disc_acc: 1.0


	Epoch 91
Training results:
gen_loss: 27.321459
disc_loss: 6.978542e-05
disc_acc: 1.0

Validation results:
gen_loss: 16.539917
disc_loss: 1.1175863e-07
disc_acc: 1.0


	Epoch 92
Training results:
gen_loss: 27.373344
disc_loss: 0.00043558885
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 23.14185
disc_loss: 1.1589787e-07
disc_acc: 1.0


	Epoch 93
Training results:
gen_loss: 27.50904
disc_loss: 0.0013230367
disc_acc: 0.9996287128712872

Validation results:
gen_loss: 9.1135435
disc_loss: 1.2535896e-08
disc_acc: 1.0


	Epoch 94
Training results:
gen_loss: 27.642246
disc_loss: 0.00057056826
disc_acc: 0.9997524752475248

Validation results:
gen_loss: 15.723137
disc_loss: 1.3085815e-07
disc_acc: 1.0


	Epoch 95
Training results:
gen_loss: 27.635967
disc_loss: 0.0023050832
disc_acc: 0.9995049504950495

Validation results:
gen_loss: 10.781958
disc_loss: 2.0045608e-08
disc_acc: 1.0


	Epoch 96
Training results:
gen_loss: 27.531977
disc_loss: 0.0002615065
disc_acc: 1.0

Validation results:
gen_loss: 12.977536
disc_loss: 7.2554435e-08
disc_acc: 1.0


	Epoch 97
Training results:
gen_loss: 27.37888
disc_loss: 5.547328e-05
disc_acc: 1.0

Validation results:
gen_loss: 12.513364
disc_loss: 6.681869e-09
disc_acc: 1.0


	Epoch 98
Training results:
gen_loss: 28.043926
disc_loss: 0.0025336666
disc_acc: 0.9995049504950495

Validation results:
gen_loss: 10.807241
disc_loss: 3.2936292e-08
disc_acc: 1.0


	Epoch 99
Training results:
gen_loss: 28.531073
disc_loss: 0.0010804735
disc_acc: 0.9996287128712872

Validation results:
gen_loss: 12.594146
disc_loss: 3.8258136e-08
disc_acc: 1.0


	Epoch 100
Training results:
gen_loss: 29.20333
disc_loss: 0.0023031947
disc_acc: 0.9993811881188119

Validation results:
gen_loss: 9.771464
disc_loss: 6.5636057e-09
disc_acc: 1.0



Training new discriminator on static trained discriminator.
	Initial performance
Training results:
gen_loss: 0.73057747
disc_loss: 5.575994
disc_acc: 0.05965346534653465

Validation results:
gen_loss: 0.75544715
disc_loss: 5.5695558
disc_acc: 0.07390873015873016


	Epoch 1
Training results:
gen_loss: 2.7779226
disc_loss: 0.22397512
disc_acc: 0.9845297029702971

Validation results:
gen_loss: 2.2356637
disc_loss: 0.0037381214
disc_acc: 1.0


	Epoch 2
Training results:
gen_loss: 3.2708182
disc_loss: 0.009703333
disc_acc: 0.9988861386138614

Validation results:
gen_loss: 2.6335359
disc_loss: 0.00038571126
disc_acc: 1.0


	Epoch 3
Training results:
gen_loss: 3.4474576
disc_loss: 0.0017146614
disc_acc: 1.0

Validation results:
gen_loss: 2.7027392
disc_loss: 0.0002536321
disc_acc: 1.0


	Epoch 4
Training results:
gen_loss: 3.5424592
disc_loss: 0.00094447914
disc_acc: 1.0

Validation results:
gen_loss: 2.5412188
disc_loss: 6.543422e-05
disc_acc: 1.0


	Epoch 5
Training results:
gen_loss: 4.163602
disc_loss: 0.0119920205
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 3.7383657
disc_loss: 8.293682e-05
disc_acc: 1.0


	Epoch 6
Training results:
gen_loss: 4.676849
disc_loss: 0.00083688775
disc_acc: 1.0

Validation results:
gen_loss: 4.0533514
disc_loss: 2.1573855e-05
disc_acc: 1.0


	Epoch 7
Training results:
gen_loss: 5.024178
disc_loss: 0.0049728383
disc_acc: 0.9987623762376238

Validation results:
gen_loss: 4.6623487
disc_loss: 5.5672634e-05
disc_acc: 1.0


	Epoch 8
Training results:
gen_loss: 5.716104
disc_loss: 0.0067785135
disc_acc: 0.9981435643564357

Validation results:
gen_loss: 4.275085
disc_loss: 2.7766764e-05
disc_acc: 1.0


	Epoch 9
Training results:
gen_loss: 5.943478
disc_loss: 0.00142119
disc_acc: 0.9997524752475248

Validation results:
gen_loss: 4.4272723
disc_loss: 1.2321903e-05
disc_acc: 1.0


	Epoch 10
Training results:
gen_loss: 5.9409227
disc_loss: 0.00030440858
disc_acc: 1.0

Validation results:
gen_loss: 4.3122697
disc_loss: 7.092884e-06
disc_acc: 1.0


	Epoch 11
Training results:
gen_loss: 6.1862326
disc_loss: 0.0049908934
disc_acc: 0.9985148514851485

Validation results:
gen_loss: 4.6678867
disc_loss: 1.4083235e-05
disc_acc: 1.0


	Epoch 12
Training results:
gen_loss: 6.5754333
disc_loss: 0.004892172
disc_acc: 0.998391089108911

Validation results:
gen_loss: 4.9763126
disc_loss: 3.1179276e-05
disc_acc: 1.0


	Epoch 13
Training results:
gen_loss: 6.9122458
disc_loss: 0.00096849725
disc_acc: 0.9997524752475248

Validation results:
gen_loss: 5.3341002
disc_loss: 7.372807e-06
disc_acc: 1.0


	Epoch 14
Training results:
gen_loss: 7.402808
disc_loss: 0.000491242
disc_acc: 1.0

Validation results:
gen_loss: 6.0402403
disc_loss: 2.7824744e-06
disc_acc: 1.0


	Epoch 15
Training results:
gen_loss: 7.254368
disc_loss: 0.0010880185
disc_acc: 0.9996287128712872

Validation results:
gen_loss: 5.4108915
disc_loss: 1.9995885e-05
disc_acc: 1.0


	Epoch 16
Training results:
gen_loss: 7.208675
disc_loss: 0.0021558567
disc_acc: 0.9996287128712872

Validation results:
gen_loss: 5.846806
disc_loss: 2.467588e-06
disc_acc: 1.0


	Epoch 17
Training results:
gen_loss: 7.1429467
disc_loss: 0.0003122543
disc_acc: 1.0

Validation results:
gen_loss: 4.3890743
disc_loss: 1.1701532e-06
disc_acc: 1.0


	Epoch 18
Training results:
gen_loss: 7.4805737
disc_loss: 0.0018047356
disc_acc: 0.9993811881188119

Validation results:
gen_loss: 5.5068765
disc_loss: 0.00014484244
disc_acc: 1.0


	Epoch 19
Training results:
gen_loss: 8.572699
disc_loss: 0.00496174
disc_acc: 0.998019801980198

Validation results:
gen_loss: 6.547218
disc_loss: 3.0336107e-06
disc_acc: 1.0


	Epoch 20
Training results:
gen_loss: 8.687278
disc_loss: 0.00034872067
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 6.7086415
disc_loss: 7.4978766e-07
disc_acc: 1.0


	Epoch 21
Training results:
gen_loss: 8.679935
disc_loss: 0.00026683422
disc_acc: 1.0

Validation results:
gen_loss: 7.4257145
disc_loss: 6.1479034e-07
disc_acc: 1.0


	Epoch 22
Training results:
gen_loss: 9.188217
disc_loss: 0.00037667638
disc_acc: 1.0

Validation results:
gen_loss: 6.8988605
disc_loss: 4.1575333e-07
disc_acc: 1.0


	Epoch 23
Training results:
gen_loss: 9.02457
disc_loss: 3.9308663e-05
disc_acc: 1.0

Validation results:
gen_loss: 7.0444098
disc_loss: 2.3611224e-07
disc_acc: 1.0


	Epoch 24
Training results:
gen_loss: 9.239476
disc_loss: 0.0020009826
disc_acc: 0.9992574257425743

Validation results:
gen_loss: 8.274451
disc_loss: 3.550354e-06
disc_acc: 1.0


	Epoch 25
Training results:
gen_loss: 9.7481365
disc_loss: 0.004903212
disc_acc: 0.9986386138613862

Validation results:
gen_loss: 7.1759257
disc_loss: 4.776044e-07
disc_acc: 1.0


	Epoch 26
Training results:
gen_loss: 9.874684
disc_loss: 0.00012503639
disc_acc: 1.0

Validation results:
gen_loss: 7.218032
disc_loss: 1.5527954e-07
disc_acc: 1.0


	Epoch 27
Training results:
gen_loss: 9.989573
disc_loss: 0.0017890431
disc_acc: 0.9991336633663367

Validation results:
gen_loss: 7.510013
disc_loss: 8.4055387e-07
disc_acc: 1.0


	Epoch 28
Training results:
gen_loss: 10.282968
disc_loss: 0.0021915485
disc_acc: 0.9996287128712872

Validation results:
gen_loss: 7.9893565
disc_loss: 3.4704297e-07
disc_acc: 1.0


	Epoch 29
Training results:
gen_loss: 10.404163
disc_loss: 0.004334061
disc_acc: 0.9985148514851485

Validation results:
gen_loss: 8.184084
disc_loss: 1.0981869e-06
disc_acc: 1.0


	Epoch 30
Training results:
gen_loss: 9.89672
disc_loss: 0.00040799295
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 6.4276905
disc_loss: 4.528292e-07
disc_acc: 1.0


	Epoch 31
Training results:
gen_loss: 9.863184
disc_loss: 4.622104e-05
disc_acc: 1.0

Validation results:
gen_loss: 7.3265676
disc_loss: 1.5320987e-07
disc_acc: 1.0


	Epoch 32
Training results:
gen_loss: 9.999861
disc_loss: 3.2992597e-05
disc_acc: 1.0

Validation results:
gen_loss: 6.9594975
disc_loss: 4.414158e-07
disc_acc: 1.0


	Epoch 33
Training results:
gen_loss: 11.050143
disc_loss: 0.0013112021
disc_acc: 0.9996287128712872

Validation results:
gen_loss: 9.460898
disc_loss: 2.866104e-07
disc_acc: 1.0


	Epoch 34
Training results:
gen_loss: 11.947732
disc_loss: 0.0005952073
disc_acc: 0.9997524752475248

Validation results:
gen_loss: 7.7968836
disc_loss: 6.427602e-08
disc_acc: 1.0


	Epoch 35
Training results:
gen_loss: 12.149928
disc_loss: 0.0016315957
disc_acc: 0.9993811881188119

Validation results:
gen_loss: 11.063459
disc_loss: 6.5434796e-07
disc_acc: 1.0


	Epoch 36
Training results:
gen_loss: 13.060889
disc_loss: 0.0024591784
disc_acc: 0.999009900990099

Validation results:
gen_loss: 11.564793
disc_loss: 2.805201e-07
disc_acc: 1.0


	Epoch 37
Training results:
gen_loss: 12.37021
disc_loss: 7.80752e-05
disc_acc: 1.0

Validation results:
gen_loss: 10.703239
disc_loss: 2.760851e-07
disc_acc: 1.0


	Epoch 38
Training results:
gen_loss: 12.426103
disc_loss: 0.0013754639
disc_acc: 0.9996287128712872

Validation results:
gen_loss: 10.181035
disc_loss: 3.0435007e-07
disc_acc: 1.0


	Epoch 39
Training results:
gen_loss: 12.05088
disc_loss: 0.00021617408
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 9.2958975
disc_loss: 5.0853163e-08
disc_acc: 1.0


	Epoch 40
Training results:
gen_loss: 12.322423
disc_loss: 0.00016245176
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 9.148449
disc_loss: 2.3569828e-07
disc_acc: 1.0


	Epoch 41
Training results:
gen_loss: 11.858118
disc_loss: 0.0004887387
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 8.498633
disc_loss: 9.999151e-08
disc_acc: 1.0


	Epoch 42
Training results:
gen_loss: 12.527555
disc_loss: 0.0015244132
disc_acc: 0.9996287128712872

Validation results:
gen_loss: 10.725287
disc_loss: 1.0513595e-07
disc_acc: 1.0


	Epoch 43
Training results:
gen_loss: 12.99643
disc_loss: 1.809253e-05
disc_acc: 1.0

Validation results:
gen_loss: 8.544814
disc_loss: 9.839494e-08
disc_acc: 1.0


	Epoch 44
Training results:
gen_loss: 12.651974
disc_loss: 1.4173491e-05
disc_acc: 1.0

Validation results:
gen_loss: 8.189278
disc_loss: 9.242265e-08
disc_acc: 1.0


	Epoch 45
Training results:
gen_loss: 12.548302
disc_loss: 0.000329677
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 8.628718
disc_loss: 1.2535891e-07
disc_acc: 1.0


	Epoch 46
Training results:
gen_loss: 12.856269
disc_loss: 0.002770791
disc_acc: 0.9996287128712872

Validation results:
gen_loss: 9.273656
disc_loss: 5.108969e-08
disc_acc: 1.0


	Epoch 47
Training results:
gen_loss: 12.49212
disc_loss: 4.76003e-05
disc_acc: 1.0

Validation results:
gen_loss: 9.917421
disc_loss: 1.6095605e-07
disc_acc: 1.0


	Epoch 48
Training results:
gen_loss: 13.199042
disc_loss: 0.00025815587
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 12.071165
disc_loss: 1.04840275e-07
disc_acc: 1.0


	Epoch 49
Training results:
gen_loss: 14.861473
disc_loss: 0.0049706833
disc_acc: 0.999009900990099

Validation results:
gen_loss: 10.822443
disc_loss: 1.270737e-07
disc_acc: 1.0


	Epoch 50
Training results:
gen_loss: 15.218309
disc_loss: 9.027811e-05
disc_acc: 1.0

Validation results:
gen_loss: 11.304817
disc_loss: 7.4505797e-09
disc_acc: 1.0


	Epoch 51
Training results:
gen_loss: 15.0762205
disc_loss: 0.00021211973
disc_acc: 1.0

Validation results:
gen_loss: 10.944142
disc_loss: 5.913159e-11
disc_acc: 1.0


	Epoch 52
Training results:
gen_loss: 14.55052
disc_loss: 0.0006140403
disc_acc: 0.9997524752475248

Validation results:
gen_loss: 9.6179695
disc_loss: 2.3179581e-08
disc_acc: 1.0


	Epoch 53
Training results:
gen_loss: 14.172544
disc_loss: 0.002764176
disc_acc: 0.999009900990099

Validation results:
gen_loss: 11.574793
disc_loss: 1.4901159e-08
disc_acc: 1.0


	Epoch 54
Training results:
gen_loss: 14.149316
disc_loss: 0.00036959426
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 8.627737
disc_loss: 1.5965528e-08
disc_acc: 1.0


	Epoch 55
Training results:
gen_loss: 14.312473
disc_loss: 0.00072269875
disc_acc: 0.9997524752475248

Validation results:
gen_loss: 11.216791
disc_loss: 5.913159e-11
disc_acc: 1.0


	Epoch 56
Training results:
gen_loss: 14.873864
disc_loss: 1.8835919e-05
disc_acc: 1.0

Validation results:
gen_loss: 10.844871
disc_loss: 0.0
disc_acc: 1.0


	Epoch 57
Training results:
gen_loss: 14.897784
disc_loss: 1.8101136e-05
disc_acc: 1.0

Validation results:
gen_loss: 10.322175
disc_loss: 0.0
disc_acc: 1.0


	Epoch 58
Training results:
gen_loss: 15.02236
disc_loss: 0.00014137039
disc_acc: 1.0

Validation results:
gen_loss: 10.600091
disc_loss: 7.2140534e-09
disc_acc: 1.0


	Epoch 59
Training results:
gen_loss: 15.347678
disc_loss: 1.9968222e-05
disc_acc: 1.0

Validation results:
gen_loss: 10.737214
disc_loss: 0.0
disc_acc: 1.0


	Epoch 60
Training results:
gen_loss: 15.443308
disc_loss: 0.0037506619
disc_acc: 0.999009900990099

Validation results:
gen_loss: 11.634894
disc_loss: 6.634563e-08
disc_acc: 1.0


	Epoch 61
Training results:
gen_loss: 15.314459
disc_loss: 0.00080036966
disc_acc: 0.9997524752475248

Validation results:
gen_loss: 10.625218
disc_loss: 5.966374e-08
disc_acc: 1.0


	Epoch 62
Training results:
gen_loss: 15.212103
disc_loss: 0.0008813126
disc_acc: 0.9997524752475248

Validation results:
gen_loss: 9.879668
disc_loss: 4.0682522e-08
disc_acc: 1.0


	Epoch 63
Training results:
gen_loss: 15.429744
disc_loss: 0.0047119292
disc_acc: 0.9991336633663367

Validation results:
gen_loss: 11.431674
disc_loss: 1.5427415e-07
disc_acc: 1.0


	Epoch 64
Training results:
gen_loss: 16.22531
disc_loss: 9.8273245e-05
disc_acc: 1.0

Validation results:
gen_loss: 10.565121
disc_loss: 2.8560555e-08
disc_acc: 1.0


	Epoch 65
Training results:
gen_loss: 16.22852
disc_loss: 5.1323528e-05
disc_acc: 1.0

Validation results:
gen_loss: 10.4802
disc_loss: 6.6227375e-09
disc_acc: 1.0


	Epoch 66
Training results:
gen_loss: 16.40659
disc_loss: 5.281478e-06
disc_acc: 1.0

Validation results:
gen_loss: 10.534189
disc_loss: 1.1235002e-09
disc_acc: 1.0


	Epoch 67
Training results:
gen_loss: 16.026121
disc_loss: 0.0011584766
disc_acc: 0.9995049504950495

Validation results:
gen_loss: 7.9096956
disc_loss: 6.563606e-09
disc_acc: 1.0


	Epoch 68
Training results:
gen_loss: 14.542221
disc_loss: 0.00034196608
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 8.061446
disc_loss: 0.0
disc_acc: 1.0


	Epoch 69
Training results:
gen_loss: 14.651858
disc_loss: 0.00011432516
disc_acc: 1.0

Validation results:
gen_loss: 9.495326
disc_loss: 1.3363738e-08
disc_acc: 1.0


	Epoch 70
Training results:
gen_loss: 15.516982
disc_loss: 0.0005627983
disc_acc: 0.9997524752475248

Validation results:
gen_loss: 11.5781145
disc_loss: 1.980908e-08
disc_acc: 1.0


	Epoch 71
Training results:
gen_loss: 15.76536
disc_loss: 2.87769e-05
disc_acc: 1.0

Validation results:
gen_loss: 9.932615
disc_loss: 0.0
disc_acc: 1.0


	Epoch 72
Training results:
gen_loss: 15.728243
disc_loss: 1.2163215e-05
disc_acc: 1.0

Validation results:
gen_loss: 9.641766
disc_loss: 0.0
disc_acc: 1.0


	Epoch 73
Training results:
gen_loss: 15.802177
disc_loss: 0.00067268306
disc_acc: 0.9997524752475248

Validation results:
gen_loss: 11.368552
disc_loss: 1.2417634e-09
disc_acc: 1.0


	Epoch 74
Training results:
gen_loss: 15.948814
disc_loss: 0.00035302283
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 10.910443
disc_loss: 5.913159e-10
disc_acc: 1.0


	Epoch 75
Training results:
gen_loss: 16.170656
disc_loss: 6.1002797e-06
disc_acc: 1.0

Validation results:
gen_loss: 11.362387
disc_loss: 0.0
disc_acc: 1.0


	Epoch 76
Training results:
gen_loss: 16.256592
disc_loss: 6.056532e-06
disc_acc: 1.0

Validation results:
gen_loss: 9.879557
disc_loss: 3.8317264e-08
disc_acc: 1.0


	Epoch 77
Training results:
gen_loss: 16.084774
disc_loss: 0.00194337
disc_acc: 0.9992574257425743

Validation results:
gen_loss: 11.588785
disc_loss: 1.3127211e-08
disc_acc: 1.0


	Epoch 78
Training results:
gen_loss: 15.822713
disc_loss: 5.7323872e-05
disc_acc: 1.0

Validation results:
gen_loss: 10.192452
disc_loss: 1.1826318e-10
disc_acc: 1.0


	Epoch 79
Training results:
gen_loss: 15.544297
disc_loss: 0.0006553913
disc_acc: 0.9996287128712872

Validation results:
gen_loss: 10.552072
disc_loss: 0.0
disc_acc: 1.0


	Epoch 80
Training results:
gen_loss: 15.824153
disc_loss: 1.6074988e-05
disc_acc: 1.0

Validation results:
gen_loss: 10.297327
disc_loss: 0.0
disc_acc: 1.0


	Epoch 81
Training results:
gen_loss: 16.700577
disc_loss: 0.0007736755
disc_acc: 0.9996287128712872

Validation results:
gen_loss: 11.486722
disc_loss: 2.60179e-09
disc_acc: 1.0


	Epoch 82
Training results:
gen_loss: 17.324608
disc_loss: 0.0002619404
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 12.296174
disc_loss: 3.0157108e-09
disc_acc: 1.0


	Epoch 83
Training results:
gen_loss: 17.100573
disc_loss: 2.1360152e-05
disc_acc: 1.0

Validation results:
gen_loss: 12.27283
disc_loss: 0.0
disc_acc: 1.0


	Epoch 84
Training results:
gen_loss: 17.149168
disc_loss: 9.017667e-06
disc_acc: 1.0

Validation results:
gen_loss: 10.991533
disc_loss: 0.0
disc_acc: 1.0


	Epoch 85
Training results:
gen_loss: 17.03482
disc_loss: 2.1277678e-05
disc_acc: 1.0

Validation results:
gen_loss: 10.990201
disc_loss: 0.0
disc_acc: 1.0


	Epoch 86
Training results:
gen_loss: 16.79577
disc_loss: 5.8301184e-06
disc_acc: 1.0

Validation results:
gen_loss: 11.137267
disc_loss: 0.0
disc_acc: 1.0


	Epoch 87
Training results:
gen_loss: 16.767769
disc_loss: 1.9012479e-06
disc_acc: 1.0

Validation results:
gen_loss: 12.317692
disc_loss: 0.0
disc_acc: 1.0


	Epoch 88
Training results:
gen_loss: 16.625599
disc_loss: 1.6023208e-05
disc_acc: 1.0

Validation results:
gen_loss: 11.320172
disc_loss: 0.0
disc_acc: 1.0


	Epoch 89
Training results:
gen_loss: 17.025183
disc_loss: 0.0003828102
disc_acc: 0.9998762376237624

Validation results:
gen_loss: 12.429166
disc_loss: 0.0
disc_acc: 1.0


	Epoch 90
Training results:
gen_loss: 16.8911
disc_loss: 2.060837e-06
disc_acc: 1.0

Validation results:
gen_loss: 11.24404
disc_loss: 0.0
disc_acc: 1.0


	Epoch 91
Training results:
gen_loss: 17.02056
disc_loss: 1.4794271e-05
disc_acc: 1.0

Validation results:
gen_loss: 10.918765
disc_loss: 8.751475e-09
disc_acc: 1.0


	Epoch 92
Training results:
gen_loss: 16.668236
disc_loss: 0.0013994535
disc_acc: 0.9995049504950495

Validation results:
gen_loss: 10.2930975
disc_loss: 0.0
disc_acc: 1.0


	Epoch 93
Training results:
gen_loss: 16.86177
disc_loss: 0.0032936917
disc_acc: 0.9991336633663367

Validation results:
gen_loss: 11.843816
disc_loss: 4.4940002e-08
disc_acc: 1.0


	Epoch 94
Training results:
gen_loss: 16.63118
disc_loss: 0.0015534004
disc_acc: 0.9995049504950495

Validation results:
gen_loss: 13.282678
disc_loss: 0.0
disc_acc: 1.0


	Epoch 95
Training results:
gen_loss: 17.756495
disc_loss: 7.6544224e-05
disc_acc: 1.0

Validation results:
gen_loss: 11.414964
disc_loss: 1.7739477e-10
disc_acc: 1.0


	Epoch 96
Training results:
gen_loss: 17.336924
disc_loss: 1.7424582e-06
disc_acc: 1.0

Validation results:
gen_loss: 10.617872
disc_loss: 0.0
disc_acc: 1.0


	Epoch 97
Training results:
gen_loss: 17.380493
disc_loss: 5.0730483e-05
disc_acc: 1.0

Validation results:
gen_loss: 11.670338
disc_loss: 0.0
disc_acc: 1.0


	Epoch 98
Training results:
gen_loss: 17.384699
disc_loss: 6.463378e-06
disc_acc: 1.0

Validation results:
gen_loss: 11.215808
disc_loss: 0.0
disc_acc: 1.0


	Epoch 99
Training results:
gen_loss: 17.192852
disc_loss: 0.00023221194
disc_acc: 1.0

Validation results:
gen_loss: 12.42023
disc_loss: 0.0
disc_acc: 1.0


	Epoch 100
Training results:
gen_loss: 16.60732
disc_loss: 3.0599127e-05
disc_acc: 1.0

Validation results:
gen_loss: 9.241955
disc_loss: 5.913159e-11
disc_acc: 1.0



gen_train_loss: 0.020652138, 3.0688076, 4.900911, 5.9410787, 6.730286, 7.2411695, 7.720818, 8.032492, 8.5523815, 8.921854, 9.0501, 9.398312, 9.307827, 9.808648, 10.259366, 10.618273, 10.278083, 10.952094, 11.39966, 11.653527, 12.32338, 12.804258, 13.040118, 13.303512, 14.01391, 14.745846, 15.604823, 15.621905, 16.605251, 16.968435, 17.977219, 17.75999, 18.605621, 19.791819, 20.041506, 19.861341, 20.533895, 19.817343, 21.173744, 21.924215, 21.820736, 21.437132, 21.5346, 22.66438, 23.53719, 23.153042, 24.267366, 23.74468, 24.317543, 24.419598, 25.155235, 24.280775, 25.33212, 24.921352, 25.087221, 25.590637, 25.086914, 24.731386, 25.111282, 24.495424, 25.254173, 25.682829, 25.445951, 26.299788, 26.567442, 27.038855, 26.871569, 27.069838, 26.790955, 26.998573, 26.801128, 27.347445, 27.772127, 27.159971, 27.70548, 27.62852, 27.54835, 27.202433, 26.772038, 27.18862, 26.903597, 26.994724, 27.311834, 27.003538, 27.4602, 27.54314, 27.776068, 27.88597, 27.795568, 27.656845, 27.748795, 27.321459, 27.373344, 27.50904, 27.642246, 27.635967, 27.531977, 27.37888, 28.043926, 28.531073, 29.20333, 0.73057747, 2.7779226, 3.2708182, 3.4474576, 3.5424592, 4.163602, 4.676849, 5.024178, 5.716104, 5.943478, 5.9409227, 6.1862326, 6.5754333, 6.9122458, 7.402808, 7.254368, 7.208675, 7.1429467, 7.4805737, 8.572699, 8.687278, 8.679935, 9.188217, 9.02457, 9.239476, 9.7481365, 9.874684, 9.989573, 10.282968, 10.404163, 9.89672, 9.863184, 9.999861, 11.050143, 11.947732, 12.149928, 13.060889, 12.37021, 12.426103, 12.05088, 12.322423, 11.858118, 12.527555, 12.99643, 12.651974, 12.548302, 12.856269, 12.49212, 13.199042, 14.861473, 15.218309, 15.0762205, 14.55052, 14.172544, 14.149316, 14.312473, 14.873864, 14.897784, 15.02236, 15.347678, 15.443308, 15.314459, 15.212103, 15.429744, 16.22531, 16.22852, 16.40659, 16.026121, 14.542221, 14.651858, 15.516982, 15.76536, 15.728243, 15.802177, 15.948814, 16.170656, 16.256592, 16.084774, 15.822713, 15.544297, 15.824153, 16.700577, 17.324608, 17.100573, 17.149168, 17.03482, 16.79577, 16.767769, 16.625599, 17.025183, 16.8911, 17.02056, 16.668236, 16.86177, 16.63118, 17.756495, 17.336924, 17.380493, 17.384699, 17.192852, 16.60732
disc_train_loss: 5.5611715, 0.5122117, 0.20857859, 0.25897297, 0.18551418, 0.14322616, 0.10184222, 0.07461764, 0.0762715, 0.05843197, 0.043697204, 0.05679878, 0.050208855, 0.068154134, 0.04341007, 0.042633288, 0.053714316, 0.035776448, 0.04612996, 0.022880033, 0.022485487, 0.022125036, 0.023154344, 0.025273398, 0.011717273, 0.027514422, 0.019634213, 0.015802871, 0.016036035, 0.018104056, 0.018031191, 0.01130297, 0.013146137, 0.008856899, 0.010108042, 0.008617019, 0.004607048, 0.0076604798, 0.009684525, 0.012640387, 0.0068310387, 0.0023873616, 0.004852511, 0.0038386995, 0.0048238407, 0.0064422335, 0.009660865, 0.008469212, 0.009117013, 0.0014238225, 0.0018158281, 0.0010788625, 0.0021286148, 0.00072560005, 0.0046705557, 0.0043259645, 0.006063701, 0.005403701, 0.0047282963, 0.0025898141, 0.0044526868, 0.0013174126, 0.0023315982, 0.0031612387, 0.009877171, 0.006072585, 0.00038556522, 0.0018128917, 0.001182403, 0.00059999456, 0.0013322243, 0.0021303224, 0.0015727452, 0.0053303167, 0.006028541, 0.0042226566, 0.0026942862, 0.0054216716, 0.0016561527, 0.00017565326, 0.0019172193, 0.00016553528, 0.0026813678, 0.00015765775, 0.0064733233, 0.00040399618, 0.0020124472, 0.002059913, 0.0003394199, 0.002896267, 0.00655305, 6.978542e-05, 0.00043558885, 0.0013230367, 0.00057056826, 0.0023050832, 0.0002615065, 5.547328e-05, 0.0025336666, 0.0010804735, 0.0023031947, 5.575994, 0.22397512, 0.009703333, 0.0017146614, 0.00094447914, 0.0119920205, 0.00083688775, 0.0049728383, 0.0067785135, 0.00142119, 0.00030440858, 0.0049908934, 0.004892172, 0.00096849725, 0.000491242, 0.0010880185, 0.0021558567, 0.0003122543, 0.0018047356, 0.00496174, 0.00034872067, 0.00026683422, 0.00037667638, 3.9308663e-05, 0.0020009826, 0.004903212, 0.00012503639, 0.0017890431, 0.0021915485, 0.004334061, 0.00040799295, 4.622104e-05, 3.2992597e-05, 0.0013112021, 0.0005952073, 0.0016315957, 0.0024591784, 7.80752e-05, 0.0013754639, 0.00021617408, 0.00016245176, 0.0004887387, 0.0015244132, 1.809253e-05, 1.4173491e-05, 0.000329677, 0.002770791, 4.76003e-05, 0.00025815587, 0.0049706833, 9.027811e-05, 0.00021211973, 0.0006140403, 0.002764176, 0.00036959426, 0.00072269875, 1.8835919e-05, 1.8101136e-05, 0.00014137039, 1.9968222e-05, 0.0037506619, 0.00080036966, 0.0008813126, 0.0047119292, 9.8273245e-05, 5.1323528e-05, 5.281478e-06, 0.0011584766, 0.00034196608, 0.00011432516, 0.0005627983, 2.87769e-05, 1.2163215e-05, 0.00067268306, 0.00035302283, 6.1002797e-06, 6.056532e-06, 0.00194337, 5.7323872e-05, 0.0006553913, 1.6074988e-05, 0.0007736755, 0.0002619404, 2.1360152e-05, 9.017667e-06, 2.1277678e-05, 5.8301184e-06, 1.9012479e-06, 1.6023208e-05, 0.0003828102, 2.060837e-06, 1.4794271e-05, 0.0013994535, 0.0032936917, 0.0015534004, 7.6544224e-05, 1.7424582e-06, 5.0730483e-05, 6.463378e-06, 0.00023221194, 3.0599127e-05
disc_train_acc: 0.0, 0.9107673267326732, 0.9392326732673267, 0.9195544554455446, 0.9428217821782178, 0.9539603960396039, 0.9648514851485148, 0.9764851485148515, 0.9763613861386139, 0.9819306930693069, 0.9873762376237624, 0.9814356435643564, 0.9827970297029703, 0.9784653465346534, 0.9853960396039604, 0.9860148514851486, 0.9818069306930693, 0.9873762376237624, 0.9818069306930693, 0.9918316831683168, 0.9917079207920793, 0.9925742574257426, 0.9915841584158416, 0.9917079207920793, 0.9955445544554455, 0.9910891089108911, 0.9931930693069307, 0.996039603960396, 0.9955445544554455, 0.9943069306930693, 0.9948019801980198, 0.996039603960396, 0.995420792079208, 0.9969059405940595, 0.9967821782178218, 0.9976485148514852, 0.9987623762376238, 0.9976485148514852, 0.9971534653465347, 0.9969059405940595, 0.9977722772277228, 0.9993811881188119, 0.9986386138613862, 0.999009900990099, 0.9982673267326733, 0.998019801980198, 0.9969059405940595, 0.9969059405940595, 0.9972772277227723, 0.9996287128712872, 0.9993811881188119, 0.9995049504950495, 0.999009900990099, 0.9998762376237624, 0.9986386138613862, 0.9988861386138614, 0.9981435643564357, 0.9985148514851485, 0.999009900990099, 0.9992574257425743, 0.998391089108911, 0.9995049504950495, 0.9995049504950495, 0.9987623762376238, 0.9977722772277228, 0.9991336633663367, 1.0, 0.9995049504950495, 0.9996287128712872, 0.9998762376237624, 0.9995049504950495, 0.9993811881188119, 0.9995049504950495, 0.9985148514851485, 0.9988861386138614, 0.9985148514851485, 0.9991336633663367, 0.9986386138613862, 0.9996287128712872, 1.0, 0.9991336633663367, 1.0, 0.9991336633663367, 1.0, 0.9977722772277228, 0.9998762376237624, 0.9993811881188119, 0.999009900990099, 1.0, 0.9995049504950495, 0.9991336633663367, 1.0, 0.9998762376237624, 0.9996287128712872, 0.9997524752475248, 0.9995049504950495, 1.0, 1.0, 0.9995049504950495, 0.9996287128712872, 0.9993811881188119, 0.05965346534653465, 0.9845297029702971, 0.9988861386138614, 1.0, 1.0, 0.9969059405940595, 1.0, 0.9987623762376238, 0.9981435643564357, 0.9997524752475248, 1.0, 0.9985148514851485, 0.998391089108911, 0.9997524752475248, 1.0, 0.9996287128712872, 0.9996287128712872, 1.0, 0.9993811881188119, 0.998019801980198, 0.9998762376237624, 1.0, 1.0, 1.0, 0.9992574257425743, 0.9986386138613862, 1.0, 0.9991336633663367, 0.9996287128712872, 0.9985148514851485, 0.9998762376237624, 1.0, 1.0, 0.9996287128712872, 0.9997524752475248, 0.9993811881188119, 0.999009900990099, 1.0, 0.9996287128712872, 0.9998762376237624, 0.9998762376237624, 0.9998762376237624, 0.9996287128712872, 1.0, 1.0, 0.9998762376237624, 0.9996287128712872, 1.0, 0.9998762376237624, 0.999009900990099, 1.0, 1.0, 0.9997524752475248, 0.999009900990099, 0.9998762376237624, 0.9997524752475248, 1.0, 1.0, 1.0, 1.0, 0.999009900990099, 0.9997524752475248, 0.9997524752475248, 0.9991336633663367, 1.0, 1.0, 1.0, 0.9995049504950495, 0.9998762376237624, 1.0, 0.9997524752475248, 1.0, 1.0, 0.9997524752475248, 0.9998762376237624, 1.0, 1.0, 0.9992574257425743, 1.0, 0.9996287128712872, 1.0, 0.9996287128712872, 0.9998762376237624, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9998762376237624, 1.0, 1.0, 0.9995049504950495, 0.9991336633663367, 0.9995049504950495, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0
gen_val_loss: 0.019758703, 2.6411147, 3.1119452, 3.0379894, 4.446616, 5.8129144, 3.7220652, 4.304258, 4.680233, 4.2561417, 5.286981, 6.5177603, 11.465573, 7.2426443, 7.6639624, 5.9599094, 6.2430515, 5.682639, 8.061711, 5.115519, 7.602053, 11.865521, 6.216358, 7.4382505, 7.729998, 11.954341, 8.779384, 13.0213995, 8.492714, 7.433298, 7.770406, 9.917009, 9.691946, 8.682157, 9.619574, 9.926307, 14.08135, 10.322397, 10.394581, 9.286358, 11.353717, 10.777244, 17.1766, 6.917303, 19.221758, 18.335686, 12.339654, 12.805579, 9.272402, 12.707017, 11.942009, 16.091774, 15.429879, 19.69678, 18.202187, 15.410263, 10.490431, 13.024472, 12.561502, 9.108266, 9.983175, 12.08148, 16.361462, 9.25034, 11.811234, 14.345364, 10.219139, 15.645705, 15.191483, 15.686722, 16.16812, 36.191387, 19.119564, 20.005606, 12.942223, 10.226024, 14.446469, 11.964831, 11.460821, 12.286625, 11.336455, 11.700575, 11.69056, 12.419482, 12.508894, 11.041588, 23.631622, 14.341649, 14.531545, 11.294324, 13.807808, 16.539917, 23.14185, 9.1135435, 15.723137, 10.781958, 12.977536, 12.513364, 10.807241, 12.594146, 9.771464, 0.75544715, 2.2356637, 2.6335359, 2.7027392, 2.5412188, 3.7383657, 4.0533514, 4.6623487, 4.275085, 4.4272723, 4.3122697, 4.6678867, 4.9763126, 5.3341002, 6.0402403, 5.4108915, 5.846806, 4.3890743, 5.5068765, 6.547218, 6.7086415, 7.4257145, 6.8988605, 7.0444098, 8.274451, 7.1759257, 7.218032, 7.510013, 7.9893565, 8.184084, 6.4276905, 7.3265676, 6.9594975, 9.460898, 7.7968836, 11.063459, 11.564793, 10.703239, 10.181035, 9.2958975, 9.148449, 8.498633, 10.725287, 8.544814, 8.189278, 8.628718, 9.273656, 9.917421, 12.071165, 10.822443, 11.304817, 10.944142, 9.6179695, 11.574793, 8.627737, 11.216791, 10.844871, 10.322175, 10.600091, 10.737214, 11.634894, 10.625218, 9.879668, 11.431674, 10.565121, 10.4802, 10.534189, 7.9096956, 8.061446, 9.495326, 11.5781145, 9.932615, 9.641766, 11.368552, 10.910443, 11.362387, 9.879557, 11.588785, 10.192452, 10.552072, 10.297327, 11.486722, 12.296174, 12.27283, 10.991533, 10.990201, 11.137267, 12.317692, 11.320172, 12.429166, 11.24404, 10.918765, 10.2930975, 11.843816, 13.282678, 11.414964, 10.617872, 11.670338, 11.215808, 12.42023, 9.241955
disc_val_loss: 5.5615115, 0.077750735, 0.07745773, 0.059568536, 0.032126322, 0.008640942, 0.03824953, 0.009407168, 0.007300833, 0.0018765159, 0.006072243, 0.005910879, 0.018906549, 0.18007264, 0.0018160786, 0.0013028682, 0.0037740539, 0.0021901114, 0.00060490996, 0.00012024039, 0.0016348085, 0.51128525, 0.027276522, 0.0002274733, 0.00018384792, 0.14107521, 0.00029409517, 0.00044802262, 6.8594534e-05, 0.0009948219, 5.9970327e-05, 0.0007715634, 0.0005937475, 0.00018734089, 0.00016059607, 0.00012606454, 0.0001778013, 0.00010512716, 3.7328056e-05, 3.9313392e-05, 0.0001137213, 4.5450717e-05, 0.00029637734, 6.759674e-06, 0.0019702096, 0.00020784678, 0.00029355503, 0.00012363443, 7.806568e-06, 3.19429e-05, 2.1663049e-05, 2.138249e-05, 4.3754437e-05, 0.00026191483, 0.0011108518, 7.467334e-05, 2.3710107e-05, 1.908584e-05, 3.2262316e-05, 1.1469629e-05, 2.664509e-06, 6.3382877e-06, 7.466181e-06, 4.430058e-05, 1.7150426e-06, 4.680352e-06, 1.5253131e-05, 1.165834e-06, 3.0112358e-06, 6.30613e-06, 1.6201376e-06, 4.5364823e-06, 1.2159782e-06, 1.0631826e-06, 2.1594105e-06, 8.5799925e-08, 3.7483488e-07, 1.8573226e-07, 2.4811595e-07, 9.52018e-08, 1.1246132e-06, 1.3109465e-07, 8.260682e-08, 4.8428767e-08, 1.2535892e-07, 9.2659164e-08, 2.369993e-07, 5.6038937e-07, 6.8888276e-08, 1.7331456e-07, 3.9677293e-08, 1.1175863e-07, 1.1589787e-07, 1.2535896e-08, 1.3085815e-07, 2.0045608e-08, 7.2554435e-08, 6.681869e-09, 3.2936292e-08, 3.8258136e-08, 6.5636057e-09, 5.5695558, 0.0037381214, 0.00038571126, 0.0002536321, 6.543422e-05, 8.293682e-05, 2.1573855e-05, 5.5672634e-05, 2.7766764e-05, 1.2321903e-05, 7.092884e-06, 1.4083235e-05, 3.1179276e-05, 7.372807e-06, 2.7824744e-06, 1.9995885e-05, 2.467588e-06, 1.1701532e-06, 0.00014484244, 3.0336107e-06, 7.4978766e-07, 6.1479034e-07, 4.1575333e-07, 2.3611224e-07, 3.550354e-06, 4.776044e-07, 1.5527954e-07, 8.4055387e-07, 3.4704297e-07, 1.0981869e-06, 4.528292e-07, 1.5320987e-07, 4.414158e-07, 2.866104e-07, 6.427602e-08, 6.5434796e-07, 2.805201e-07, 2.760851e-07, 3.0435007e-07, 5.0853163e-08, 2.3569828e-07, 9.999151e-08, 1.0513595e-07, 9.839494e-08, 9.242265e-08, 1.2535891e-07, 5.108969e-08, 1.6095605e-07, 1.04840275e-07, 1.270737e-07, 7.4505797e-09, 5.913159e-11, 2.3179581e-08, 1.4901159e-08, 1.5965528e-08, 5.913159e-11, 0.0, 0.0, 7.2140534e-09, 0.0, 6.634563e-08, 5.966374e-08, 4.0682522e-08, 1.5427415e-07, 2.8560555e-08, 6.6227375e-09, 1.1235002e-09, 6.563606e-09, 0.0, 1.3363738e-08, 1.980908e-08, 0.0, 0.0, 1.2417634e-09, 5.913159e-10, 0.0, 3.8317264e-08, 1.3127211e-08, 1.1826318e-10, 0.0, 0.0, 2.60179e-09, 3.0157108e-09, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 8.751475e-09, 0.0, 4.4940002e-08, 0.0, 1.7739477e-10, 0.0, 0.0, 0.0, 0.0, 5.913159e-11
disc_val_acc: 0.0, 0.9945436507936508, 0.9945436507936508, 1.0, 1.0, 1.0, 0.9930555555555556, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8953373015873016, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8864087301587301, 1.0, 1.0, 1.0, 0.9424603174603174, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07390873015873016, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0

