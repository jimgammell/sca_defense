Beginning trial described in ./config/multigen_trial.json.
Experiment type: multiple generators each corresponding to 1 key.
Experiment settings:
	byte: 0
	keys: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
	key_dataset_kwargs:
		keep_data_in_memory: True
		data_path: ./data
		download: True
		extract: True
		preprocess: True
		delete_download_after_extraction: False
		delete_extracted_after_preprocess: False
		samples_to_use: 500
	dataloader_kwargs:
		batch_size: 16
		shuffle: True
	dataset_prop_for_validation: 0.2
	trace_map_constructor: None
	trace_map_kwargs:
		layers: [256]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	plaintext_map_constructor: None
	plaintext_map_kwargs:
		layers: [64]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	key_map_constructor: <function get_zero_map at 0x7fc7107113a0>
	key_map_kwargs:
	cumulative_map_constructor: None
	cumulative_map_kwargs:
		layers: [256]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	discriminator_constructor: <function get_xdeepsca_discriminator at 0x7fc70d2648b0>
	discriminator_kwargs:
	discriminator_loss_constructor: <class 'torch.nn.modules.loss.CrossEntropyLoss'>
	discriminator_loss_kwargs:
	discriminator_optimizer_constructor: <class 'torch.optim.adam.Adam'>
	discriminator_optimizer_kwargs:
	generator_loss_constructor: <class 'loss_functions.BatchStdLoss'>
	generator_loss_kwargs:
	generator_optimizer_constructor: <class 'torch.optim.adam.Adam'>
	generator_optimizer_kwargs:
	device: cuda
	discriminator_pretraining_epochs: 0
	generator_pretraining_epochs: 0
	gan_training_epochs: 100
	discriminator_posttraining_epochs: 100
	seed: 0
Loading datasets.
AesKeyGroupDataset:
	Available keys: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
	Key transform: Compose(
    IntToBinary()
    ToTensor1D()
)
	Byte: 0
	Number of samples available: 10112
	Trace size: torch.Size([1, 500])
	Key size: torch.Size([1, 8])
	Plaintext size: torch.Size([1, 8])
	Key index size: ()
Constructing generator.
KeyOnlyGenerator(
  (key_trace_map): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=8, out_features=8, bias=False)
    (2): Linear(in_features=8, out_features=500, bias=False)
    (3): Unflatten(dim=-1, unflattened_size=torch.Size([1, 500]))
  )
)

Constructing discriminator.
Discriminator(
  (model): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=500, out_features=200, bias=True)
    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): ReLU()
    (4): Dropout(p=0.2, inplace=False)
    (5): Linear(in_features=200, out_features=200, bias=True)
    (6): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): ReLU()
    (8): Linear(in_features=200, out_features=256, bias=True)
  )
)

Calculating initial results.
Training results:
gen_loss: 0.017465893
disc_loss: 5.549591
disc_acc: 0.0

Validation results:
gen_loss: 0.016667297
disc_loss: 5.5523176
disc_acc: 0.0


Training discriminator and generator simultaneously.
	Epoch 1
Training results:
gen_loss: 3.915103
disc_loss: 1.3360267
disc_acc: 0.5897277227722773

Validation results:
gen_loss: 4.925635
disc_loss: 2.5600905
disc_acc: 0.2698412698412698


	Epoch 2
Training results:
gen_loss: 5.359791
disc_loss: 0.47511926
disc_acc: 0.8474009900990099

Validation results:
gen_loss: 4.2505674
disc_loss: 0.8639209
disc_acc: 0.7063492063492064


	Epoch 3
Training results:
gen_loss: 6.1232867
disc_loss: 0.3436792
disc_acc: 0.8851485148514852

Validation results:
gen_loss: 8.210184
disc_loss: 1.3382838
disc_acc: 0.6036706349206349


	Epoch 4
Training results:
gen_loss: 6.422283
disc_loss: 0.27859452
disc_acc: 0.9110148514851485

Validation results:
gen_loss: 5.1402287
disc_loss: 0.74151844
disc_acc: 0.7395833333333334


	Epoch 5
Training results:
gen_loss: 6.778576
disc_loss: 0.26534748
disc_acc: 0.9090346534653465

Validation results:
gen_loss: 5.8560047
disc_loss: 1.4709806
disc_acc: 0.5629960317460317


	Epoch 6
Training results:
gen_loss: 7.0762687
disc_loss: 0.23966871
disc_acc: 0.9201732673267327

Validation results:
gen_loss: 8.014394
disc_loss: 1.1345569
disc_acc: 0.6423611111111112


	Epoch 7
Training results:
gen_loss: 7.385945
disc_loss: 0.21985598
disc_acc: 0.9262376237623763

Validation results:
gen_loss: 6.1189947
disc_loss: 1.5772299
disc_acc: 0.5024801587301587


	Epoch 8
Training results:
gen_loss: 7.511315
disc_loss: 0.22690952
disc_acc: 0.9246287128712871

Validation results:
gen_loss: 5.7750382
disc_loss: 0.40081233
disc_acc: 0.8467261904761905


	Epoch 9
Training results:
gen_loss: 7.5624566
disc_loss: 0.18341644
disc_acc: 0.9352722772277228

Validation results:
gen_loss: 9.759907
disc_loss: 3.4698524
disc_acc: 0.3343253968253968


	Epoch 10
Training results:
gen_loss: 7.7609596
disc_loss: 0.19174926
disc_acc: 0.9327970297029703

Validation results:
gen_loss: 8.911359
disc_loss: 0.7623847
disc_acc: 0.7366071428571429


	Epoch 11
Training results:
gen_loss: 7.970894
disc_loss: 0.19230376
disc_acc: 0.93490099009901

Validation results:
gen_loss: 10.480018
disc_loss: 4.508161
disc_acc: 0.27728174603174605


	Epoch 12
Training results:
gen_loss: 8.125742
disc_loss: 0.17956884
disc_acc: 0.94009900990099

Validation results:
gen_loss: 7.5078
disc_loss: 0.57705307
disc_acc: 0.7931547619047619


	Epoch 13
Training results:
gen_loss: 8.725919
disc_loss: 0.16799966
disc_acc: 0.9446782178217822

Validation results:
gen_loss: 6.7395844
disc_loss: 0.13639009
disc_acc: 0.9588293650793651


	Epoch 14
Training results:
gen_loss: 9.2088585
disc_loss: 0.14860587
disc_acc: 0.9523514851485149

Validation results:
gen_loss: 7.723098
disc_loss: 0.9461669
disc_acc: 0.7058531746031746


	Epoch 15
Training results:
gen_loss: 9.3916855
disc_loss: 0.13126352
disc_acc: 0.9548267326732673

Validation results:
gen_loss: 6.3017983
disc_loss: 2.3974693
disc_acc: 0.5114087301587301


	Epoch 16
Training results:
gen_loss: 9.883738
disc_loss: 0.15552475
disc_acc: 0.9443069306930693

Validation results:
gen_loss: 7.0546823
disc_loss: 0.41815588
disc_acc: 0.8308531746031746


	Epoch 17
Training results:
gen_loss: 10.020084
disc_loss: 0.15761939
disc_acc: 0.9475247524752475

Validation results:
gen_loss: 8.821914
disc_loss: 0.56746906
disc_acc: 0.7941468253968254


	Epoch 18
Training results:
gen_loss: 10.356579
disc_loss: 0.13105054
disc_acc: 0.9560643564356436

Validation results:
gen_loss: 7.139569
disc_loss: 0.42741773
disc_acc: 0.8377976190476191


	Epoch 19
Training results:
gen_loss: 10.497956
disc_loss: 0.13568904
disc_acc: 0.9560643564356436

Validation results:
gen_loss: 11.046736
disc_loss: 0.49227577
disc_acc: 0.8283730158730159


	Epoch 20
Training results:
gen_loss: 11.149219
disc_loss: 0.13098845
disc_acc: 0.9573019801980198

Validation results:
gen_loss: 10.75118
disc_loss: 0.3081923
disc_acc: 0.8705357142857143


	Epoch 21
Training results:
gen_loss: 11.9213295
disc_loss: 0.1315735
disc_acc: 0.9537128712871287

Validation results:
gen_loss: 12.579869
disc_loss: 1.3629926
disc_acc: 0.621031746031746


	Epoch 22
Training results:
gen_loss: 12.468105
disc_loss: 0.1290503
disc_acc: 0.9577970297029703

Validation results:
gen_loss: 12.234857
disc_loss: 0.20846026
disc_acc: 0.9131944444444444


	Epoch 23
Training results:
gen_loss: 12.399582
disc_loss: 0.116363235
disc_acc: 0.9601485148514851

Validation results:
gen_loss: 13.592762
disc_loss: 0.5603758
disc_acc: 0.7976190476190477


	Epoch 24
Training results:
gen_loss: 12.615928
disc_loss: 0.12276954
disc_acc: 0.9594059405940594

Validation results:
gen_loss: 12.686326
disc_loss: 0.6530965
disc_acc: 0.7658730158730159


	Epoch 25
Training results:
gen_loss: 13.380621
disc_loss: 0.123682804
disc_acc: 0.9591584158415841

Validation results:
gen_loss: 21.630947
disc_loss: 2.1543024
disc_acc: 0.6413690476190477


	Epoch 26
Training results:
gen_loss: 13.648167
disc_loss: 0.1115701
disc_acc: 0.9606435643564356

Validation results:
gen_loss: 13.631503
disc_loss: 0.40881288
disc_acc: 0.847718253968254


	Epoch 27
Training results:
gen_loss: 13.526952
disc_loss: 0.11749535
disc_acc: 0.9587871287128713

Validation results:
gen_loss: 13.36135
disc_loss: 0.6401487
disc_acc: 0.8010912698412699


	Epoch 28
Training results:
gen_loss: 14.93153
disc_loss: 0.10924785
disc_acc: 0.9641089108910891

Validation results:
gen_loss: 9.400121
disc_loss: 0.14914691
disc_acc: 0.9389880952380952


	Epoch 29
Training results:
gen_loss: 15.466533
disc_loss: 0.11100927
disc_acc: 0.9613861386138614

Validation results:
gen_loss: 13.927616
disc_loss: 0.08537866
disc_acc: 0.96875


	Epoch 30
Training results:
gen_loss: 16.517145
disc_loss: 0.1018547
disc_acc: 0.9647277227722773

Validation results:
gen_loss: 15.655143
disc_loss: 0.16256449
disc_acc: 0.9444444444444444


	Epoch 31
Training results:
gen_loss: 16.794031
disc_loss: 0.111782566
disc_acc: 0.9638613861386138

Validation results:
gen_loss: 14.579443
disc_loss: 0.15835121
disc_acc: 0.9424603174603174


	Epoch 32
Training results:
gen_loss: 16.444252
disc_loss: 0.11344695
disc_acc: 0.9594059405940594

Validation results:
gen_loss: 15.031311
disc_loss: 0.7205155
disc_acc: 0.7316468253968254


	Epoch 33
Training results:
gen_loss: 16.057573
disc_loss: 0.095632516
disc_acc: 0.9655940594059406

Validation results:
gen_loss: 12.956967
disc_loss: 0.04790979
disc_acc: 0.9816468253968254


	Epoch 34
Training results:
gen_loss: 16.227089
disc_loss: 0.09177675
disc_acc: 0.968069306930693

Validation results:
gen_loss: 15.0595045
disc_loss: 0.22643448
disc_acc: 0.9161706349206349


	Epoch 35
Training results:
gen_loss: 16.450352
disc_loss: 0.09777222
disc_acc: 0.9665841584158416

Validation results:
gen_loss: 15.201976
disc_loss: 0.15851073
disc_acc: 0.939484126984127


	Epoch 36
Training results:
gen_loss: 17.43786
disc_loss: 0.092829846
disc_acc: 0.9641089108910891

Validation results:
gen_loss: 16.752146
disc_loss: 0.21819052
disc_acc: 0.9171626984126984


	Epoch 37
Training results:
gen_loss: 17.86974
disc_loss: 0.088303745
disc_acc: 0.9685643564356435

Validation results:
gen_loss: 20.767643
disc_loss: 0.66081953
disc_acc: 0.8194444444444444


	Epoch 38
Training results:
gen_loss: 17.687178
disc_loss: 0.0904583
disc_acc: 0.968069306930693

Validation results:
gen_loss: 21.772957
disc_loss: 2.2278516
disc_acc: 0.6101190476190477


	Epoch 39
Training results:
gen_loss: 18.021996
disc_loss: 0.09177679
disc_acc: 0.9676980198019802

Validation results:
gen_loss: 12.74014
disc_loss: 0.0629691
disc_acc: 0.9751984126984127


	Epoch 40
Training results:
gen_loss: 17.66883
disc_loss: 0.08424382
disc_acc: 0.9701732673267327

Validation results:
gen_loss: 19.233583
disc_loss: 0.8247781
disc_acc: 0.7862103174603174


	Epoch 41
Training results:
gen_loss: 17.855276
disc_loss: 0.07714309
disc_acc: 0.9702970297029703

Validation results:
gen_loss: 12.198323
disc_loss: 0.11515096
disc_acc: 0.9538690476190477


	Epoch 42
Training results:
gen_loss: 17.653025
disc_loss: 0.0878833
disc_acc: 0.968069306930693

Validation results:
gen_loss: 15.33354
disc_loss: 0.12843736
disc_acc: 0.9538690476190477


	Epoch 43
Training results:
gen_loss: 17.574366
disc_loss: 0.08168051
disc_acc: 0.9714108910891089

Validation results:
gen_loss: 20.955286
disc_loss: 1.4283112
disc_acc: 0.6815476190476191


	Epoch 44
Training results:
gen_loss: 17.520292
disc_loss: 0.08340695
disc_acc: 0.9709158415841584

Validation results:
gen_loss: 17.959387
disc_loss: 1.5619378
disc_acc: 0.6096230158730159


	Epoch 45
Training results:
gen_loss: 17.981894
disc_loss: 0.075717665
disc_acc: 0.9721534653465347

Validation results:
gen_loss: 13.658522
disc_loss: 0.23354764
disc_acc: 0.9087301587301587


	Epoch 46
Training results:
gen_loss: 18.033323
disc_loss: 0.08185212
disc_acc: 0.9731435643564357

Validation results:
gen_loss: 21.317303
disc_loss: 3.9428723
disc_acc: 0.4826388888888889


	Epoch 47
Training results:
gen_loss: 18.254786
disc_loss: 0.086831495
disc_acc: 0.9711633663366337

Validation results:
gen_loss: 12.064492
disc_loss: 0.030870495
disc_acc: 0.9895833333333334


	Epoch 48
Training results:
gen_loss: 18.506
disc_loss: 0.07580806
disc_acc: 0.974009900990099

Validation results:
gen_loss: 15.982727
disc_loss: 0.14934266
disc_acc: 0.9439484126984127


	Epoch 49
Training results:
gen_loss: 18.84505
disc_loss: 0.07287904
disc_acc: 0.9726485148514852

Validation results:
gen_loss: 21.675825
disc_loss: 3.3645415
disc_acc: 0.6130952380952381


	Epoch 50
Training results:
gen_loss: 18.591366
disc_loss: 0.07870535
disc_acc: 0.9717821782178218

Validation results:
gen_loss: 13.708792
disc_loss: 0.047056098
disc_acc: 0.9811507936507936


	Epoch 51
Training results:
gen_loss: 18.864815
disc_loss: 0.06637685
disc_acc: 0.9761138613861386

Validation results:
gen_loss: 23.016771
disc_loss: 0.38575518
disc_acc: 0.8581349206349206


	Epoch 52
Training results:
gen_loss: 19.249887
disc_loss: 0.08220758
disc_acc: 0.9715346534653465

Validation results:
gen_loss: 15.166815
disc_loss: 0.16763252
disc_acc: 0.935515873015873


	Epoch 53
Training results:
gen_loss: 19.485132
disc_loss: 0.07103909
disc_acc: 0.9761138613861386

Validation results:
gen_loss: 19.146696
disc_loss: 0.22243059
disc_acc: 0.9161706349206349


	Epoch 54
Training results:
gen_loss: 19.74276
disc_loss: 0.07222977
disc_acc: 0.9741336633663367

Validation results:
gen_loss: 15.063337
disc_loss: 0.11697554
disc_acc: 0.9523809523809523


	Epoch 55
Training results:
gen_loss: 19.103647
disc_loss: 0.07354433
disc_acc: 0.9752475247524752

Validation results:
gen_loss: 15.439414
disc_loss: 0.026392309
disc_acc: 0.9915674603174603


	Epoch 56
Training results:
gen_loss: 19.36562
disc_loss: 0.0694536
disc_acc: 0.9764851485148515

Validation results:
gen_loss: 17.898617
disc_loss: 0.1330982
disc_acc: 0.9499007936507936


	Epoch 57
Training results:
gen_loss: 19.534061
disc_loss: 0.07657911
disc_acc: 0.9726485148514852

Validation results:
gen_loss: 17.723343
disc_loss: 0.26791123
disc_acc: 0.9087301587301587


	Epoch 58
Training results:
gen_loss: 19.725288
disc_loss: 0.06857457
disc_acc: 0.9764851485148515

Validation results:
gen_loss: 15.837041
disc_loss: 0.04905136
disc_acc: 0.9831349206349206


	Epoch 59
Training results:
gen_loss: 20.054394
disc_loss: 0.07217313
disc_acc: 0.9751237623762377

Validation results:
gen_loss: 17.214922
disc_loss: 0.101452805
disc_acc: 0.9652777777777778


	Epoch 60
Training results:
gen_loss: 21.176226
disc_loss: 0.07333897
disc_acc: 0.9745049504950495

Validation results:
gen_loss: 16.194221
disc_loss: 0.14022027
disc_acc: 0.9459325396825397


	Epoch 61
Training results:
gen_loss: 20.390657
disc_loss: 0.06694848
disc_acc: 0.9767326732673267

Validation results:
gen_loss: 18.668812
disc_loss: 0.14336905
disc_acc: 0.9469246031746031


	Epoch 62
Training results:
gen_loss: 20.88933
disc_loss: 0.07235697
disc_acc: 0.9746287128712872

Validation results:
gen_loss: 23.07856
disc_loss: 0.325764
disc_acc: 0.8784722222222222


	Epoch 63
Training results:
gen_loss: 21.049458
disc_loss: 0.055669274
disc_acc: 0.9794554455445544

Validation results:
gen_loss: 19.576004
disc_loss: 0.53220934
disc_acc: 0.8288690476190477


	Epoch 64
Training results:
gen_loss: 21.361412
disc_loss: 0.07463365
disc_acc: 0.9737623762376237

Validation results:
gen_loss: 16.060272
disc_loss: 0.2036549
disc_acc: 0.9250992063492064


	Epoch 65
Training results:
gen_loss: 21.219856
disc_loss: 0.05937065
disc_acc: 0.9782178217821782

Validation results:
gen_loss: 12.234263
disc_loss: 0.17797801
disc_acc: 0.9350198412698413


	Epoch 66
Training results:
gen_loss: 21.031046
disc_loss: 0.06810823
disc_acc: 0.9773514851485149

Validation results:
gen_loss: 24.239513
disc_loss: 1.2972687
disc_acc: 0.6845238095238095


	Epoch 67
Training results:
gen_loss: 20.823439
disc_loss: 0.0752082
disc_acc: 0.9737623762376237

Validation results:
gen_loss: 20.610504
disc_loss: 1.2463837
disc_acc: 0.7271825396825397


	Epoch 68
Training results:
gen_loss: 20.571106
disc_loss: 0.05757061
disc_acc: 0.9795792079207921

Validation results:
gen_loss: 28.314623
disc_loss: 2.5032573
disc_acc: 0.5927579365079365


	Epoch 69
Training results:
gen_loss: 20.62096
disc_loss: 0.061033342
disc_acc: 0.9780940594059406

Validation results:
gen_loss: 15.69535
disc_loss: 0.029343836
disc_acc: 0.9880952380952381


	Epoch 70
Training results:
gen_loss: 21.473932
disc_loss: 0.06529443
disc_acc: 0.9782178217821782

Validation results:
gen_loss: 14.804232
disc_loss: 0.09428618
disc_acc: 0.9627976190476191


	Epoch 71
Training results:
gen_loss: 20.86941
disc_loss: 0.061487306
disc_acc: 0.9793316831683169

Validation results:
gen_loss: 12.705679
disc_loss: 0.23913613
disc_acc: 0.9057539682539683


	Epoch 72
Training results:
gen_loss: 20.60384
disc_loss: 0.06143135
disc_acc: 0.9775990099009901

Validation results:
gen_loss: 15.992057
disc_loss: 0.09051301
disc_acc: 0.9637896825396826


	Epoch 73
Training results:
gen_loss: 20.650803
disc_loss: 0.047937457
disc_acc: 0.9832920792079208

Validation results:
gen_loss: 17.136566
disc_loss: 0.03850209
disc_acc: 0.9846230158730159


	Epoch 74
Training results:
gen_loss: 20.291166
disc_loss: 0.07449291
disc_acc: 0.9746287128712872

Validation results:
gen_loss: 22.67824
disc_loss: 0.339486
disc_acc: 0.8923611111111112


	Epoch 75
Training results:
gen_loss: 20.748623
disc_loss: 0.059174106
disc_acc: 0.9792079207920792

Validation results:
gen_loss: 19.446482
disc_loss: 0.069458425
disc_acc: 0.9722222222222222


	Epoch 76
Training results:
gen_loss: 20.656572
disc_loss: 0.06326708
disc_acc: 0.9778465346534654

Validation results:
gen_loss: 15.522743
disc_loss: 0.06313546
disc_acc: 0.9791666666666666


	Epoch 77
Training results:
gen_loss: 20.607208
disc_loss: 0.05487957
disc_acc: 0.9805693069306931

Validation results:
gen_loss: 17.416601
disc_loss: 0.066069424
disc_acc: 0.9747023809523809


	Epoch 78
Training results:
gen_loss: 21.058195
disc_loss: 0.06473869
disc_acc: 0.9771039603960396

Validation results:
gen_loss: 20.567953
disc_loss: 0.7743636
disc_acc: 0.8660714285714286


	Epoch 79
Training results:
gen_loss: 21.022537
disc_loss: 0.0532951
disc_acc: 0.9801980198019802

Validation results:
gen_loss: 20.338623
disc_loss: 0.15323383
disc_acc: 0.935515873015873


	Epoch 80
Training results:
gen_loss: 21.382975
disc_loss: 0.070082605
disc_acc: 0.9768564356435644

Validation results:
gen_loss: 18.065365
disc_loss: 0.06127911
disc_acc: 0.9776785714285714


	Epoch 81
Training results:
gen_loss: 21.38699
disc_loss: 0.05883564
disc_acc: 0.9793316831683169

Validation results:
gen_loss: 15.811594
disc_loss: 0.23533577
disc_acc: 0.9151785714285714


	Epoch 82
Training results:
gen_loss: 21.40211
disc_loss: 0.063105196
disc_acc: 0.9788366336633664

Validation results:
gen_loss: 24.228315
disc_loss: 0.7749133
disc_acc: 0.8452380952380952


	Epoch 83
Training results:
gen_loss: 21.182783
disc_loss: 0.05076837
disc_acc: 0.9824257425742574

Validation results:
gen_loss: 22.461933
disc_loss: 1.3148426
disc_acc: 0.7390873015873016


	Epoch 84
Training results:
gen_loss: 20.824425
disc_loss: 0.055332772
disc_acc: 0.9793316831683169

Validation results:
gen_loss: 22.997303
disc_loss: 0.9198271
disc_acc: 0.7415674603174603


	Epoch 85
Training results:
gen_loss: 21.041313
disc_loss: 0.052032016
disc_acc: 0.9818069306930693

Validation results:
gen_loss: 15.098549
disc_loss: 0.062348757
disc_acc: 0.9836309523809523


	Epoch 86
Training results:
gen_loss: 20.831566
disc_loss: 0.056849528
disc_acc: 0.9778465346534654

Validation results:
gen_loss: 24.904915
disc_loss: 0.91776097
disc_acc: 0.8020833333333334


	Epoch 87
Training results:
gen_loss: 20.677591
disc_loss: 0.053410932
disc_acc: 0.9804455445544554

Validation results:
gen_loss: 20.91807
disc_loss: 0.06267202
disc_acc: 0.9781746031746031


	Epoch 88
Training results:
gen_loss: 21.086899
disc_loss: 0.058384992
disc_acc: 0.9805693069306931

Validation results:
gen_loss: 14.493197
disc_loss: 0.121269576
disc_acc: 0.9593253968253969


	Epoch 89
Training results:
gen_loss: 21.289839
disc_loss: 0.051421855
disc_acc: 0.9821782178217822

Validation results:
gen_loss: 16.364115
disc_loss: 0.040895786
disc_acc: 0.9861111111111112


	Epoch 90
Training results:
gen_loss: 21.238892
disc_loss: 0.059696026
disc_acc: 0.9774752475247525

Validation results:
gen_loss: 23.633938
disc_loss: 0.523134
disc_acc: 0.8363095238095238


	Epoch 91
Training results:
gen_loss: 20.484928
disc_loss: 0.050160673
disc_acc: 0.9816831683168317

Validation results:
gen_loss: 16.074224
disc_loss: 0.7766852
disc_acc: 0.873015873015873


	Epoch 92
Training results:
gen_loss: 21.053051
disc_loss: 0.049992785
disc_acc: 0.9820544554455446

Validation results:
gen_loss: 16.08741
disc_loss: 0.07745434
disc_acc: 0.9717261904761905


	Epoch 93
Training results:
gen_loss: 20.85598
disc_loss: 0.055234745
disc_acc: 0.9821782178217822

Validation results:
gen_loss: 16.837143
disc_loss: 0.1671921
disc_acc: 0.9360119047619048


	Epoch 94
Training results:
gen_loss: 20.268553
disc_loss: 0.05950347
disc_acc: 0.9793316831683169

Validation results:
gen_loss: 15.64648
disc_loss: 0.030203601
disc_acc: 0.9875992063492064


	Epoch 95
Training results:
gen_loss: 20.33169
disc_loss: 0.051932737
disc_acc: 0.9816831683168317

Validation results:
gen_loss: 18.557882
disc_loss: 0.6331275
disc_acc: 0.8343253968253969


	Epoch 96
Training results:
gen_loss: 20.447805
disc_loss: 0.05023499
disc_acc: 0.9820544554455446

Validation results:
gen_loss: 16.7631
disc_loss: 0.03768678
disc_acc: 0.9866071428571429


	Epoch 97
Training results:
gen_loss: 20.80666
disc_loss: 0.05354743
disc_acc: 0.9815594059405941

Validation results:
gen_loss: 17.686737
disc_loss: 0.018571863
disc_acc: 0.9930555555555556


	Epoch 98
Training results:
gen_loss: 21.002544
disc_loss: 0.03839709
disc_acc: 0.9853960396039604

Validation results:
gen_loss: 14.795434
disc_loss: 0.020616729
disc_acc: 0.9940476190476191


	Epoch 99
Training results:
gen_loss: 20.440088
disc_loss: 0.0503911
disc_acc: 0.9842821782178218

Validation results:
gen_loss: 14.404691
disc_loss: 0.030198231
disc_acc: 0.9885912698412699


	Epoch 100
Training results:
gen_loss: 20.262842
disc_loss: 0.056449525
disc_acc: 0.9810643564356436

Validation results:
gen_loss: 29.89829
disc_loss: 0.59615976
disc_acc: 0.8571428571428571



Training new discriminator on static trained discriminator.
	Initial performance
Training results:
gen_loss: 0.018100196
disc_loss: 5.542061
disc_acc: 0.0

Validation results:
gen_loss: 0.017171964
disc_loss: 5.5420732
disc_acc: 0.0


	Epoch 1
Training results:
gen_loss: 3.6775413
disc_loss: 1.3224822
disc_acc: 0.5935643564356435

Validation results:
gen_loss: 5.079787
disc_loss: 2.492341
disc_acc: 0.28422619047619047


	Epoch 2
Training results:
gen_loss: 4.908653
disc_loss: 0.47654638
disc_acc: 0.8422029702970297

Validation results:
gen_loss: 6.986336
disc_loss: 1.9154705
disc_acc: 0.4801587301587302


	Epoch 3
Training results:
gen_loss: 5.5429354
disc_loss: 0.3379635
disc_acc: 0.8902227722772277

Validation results:
gen_loss: 6.808677
disc_loss: 1.9603481
disc_acc: 0.44246031746031744


	Epoch 4
Training results:
gen_loss: 5.7819376
disc_loss: 0.29153284
disc_acc: 0.9042079207920792

Validation results:
gen_loss: 5.6960187
disc_loss: 0.9328407
disc_acc: 0.6641865079365079


	Epoch 5
Training results:
gen_loss: 6.070267
disc_loss: 0.2529349
disc_acc: 0.9157178217821782

Validation results:
gen_loss: 7.8110633
disc_loss: 3.2532477
disc_acc: 0.310515873015873


	Epoch 6
Training results:
gen_loss: 6.728553
disc_loss: 0.25708795
disc_acc: 0.9173267326732674

Validation results:
gen_loss: 4.8258457
disc_loss: 2.0045009
disc_acc: 0.42212301587301587


	Epoch 7
Training results:
gen_loss: 7.0716615
disc_loss: 0.2201324
disc_acc: 0.925990099009901

Validation results:
gen_loss: 6.9699264
disc_loss: 0.9249822
disc_acc: 0.6463293650793651


	Epoch 8
Training results:
gen_loss: 7.1919746
disc_loss: 0.19715099
disc_acc: 0.9371287128712872

Validation results:
gen_loss: 7.6939235
disc_loss: 3.4847202
disc_acc: 0.33779761904761907


	Epoch 9
Training results:
gen_loss: 7.496708
disc_loss: 0.1942019
disc_acc: 0.9330445544554455

Validation results:
gen_loss: 8.085631
disc_loss: 1.3541857
disc_acc: 0.5739087301587301


	Epoch 10
Training results:
gen_loss: 7.477155
disc_loss: 0.19003154
disc_acc: 0.9393564356435643

Validation results:
gen_loss: 5.877345
disc_loss: 0.4233324
disc_acc: 0.8263888888888888


	Epoch 11
Training results:
gen_loss: 7.16317
disc_loss: 0.16112779
disc_acc: 0.943069306930693

Validation results:
gen_loss: 8.51126
disc_loss: 0.729473
disc_acc: 0.716765873015873


	Epoch 12
Training results:
gen_loss: 7.5851293
disc_loss: 0.1756617
disc_acc: 0.9405940594059405

Validation results:
gen_loss: 6.2680345
disc_loss: 0.63950545
disc_acc: 0.7490079365079365


	Epoch 13
Training results:
gen_loss: 7.6821494
disc_loss: 0.1547248
disc_acc: 0.9516089108910891

Validation results:
gen_loss: 6.3179665
disc_loss: 2.2228146
disc_acc: 0.47619047619047616


	Epoch 14
Training results:
gen_loss: 8.099609
disc_loss: 0.16331747
disc_acc: 0.9466584158415842

Validation results:
gen_loss: 6.2138553
disc_loss: 0.59125
disc_acc: 0.7663690476190477


	Epoch 15
Training results:
gen_loss: 8.43827
disc_loss: 0.15213937
disc_acc: 0.948019801980198

Validation results:
gen_loss: 10.97687
disc_loss: 3.3948758
disc_acc: 0.46130952380952384


	Epoch 16
Training results:
gen_loss: 8.41461
disc_loss: 0.14647096
disc_acc: 0.9488861386138614

Validation results:
gen_loss: 11.619981
disc_loss: 1.468594
disc_acc: 0.6641865079365079


	Epoch 17
Training results:
gen_loss: 8.960338
disc_loss: 0.14539066
disc_acc: 0.9507425742574257

Validation results:
gen_loss: 8.781651
disc_loss: 1.220788
disc_acc: 0.6865079365079365


	Epoch 18
Training results:
gen_loss: 9.1525955
disc_loss: 0.14366414
disc_acc: 0.9521039603960396

Validation results:
gen_loss: 9.902598
disc_loss: 1.4914796
disc_acc: 0.5763888888888888


	Epoch 19
Training results:
gen_loss: 9.435323
disc_loss: 0.13019374
disc_acc: 0.9563118811881188

Validation results:
gen_loss: 11.296499
disc_loss: 4.28534
disc_acc: 0.35813492063492064


	Epoch 20
Training results:
gen_loss: 9.897832
disc_loss: 0.13004716
disc_acc: 0.9577970297029703

Validation results:
gen_loss: 11.630225
disc_loss: 3.6923
disc_acc: 0.3551587301587302


	Epoch 21
Training results:
gen_loss: 10.108103
disc_loss: 0.13275065
disc_acc: 0.9551980198019802

Validation results:
gen_loss: 7.791545
disc_loss: 0.317091
disc_acc: 0.8953373015873016


	Epoch 22
Training results:
gen_loss: 9.910032
disc_loss: 0.11928067
disc_acc: 0.9586633663366336

Validation results:
gen_loss: 13.007236
disc_loss: 1.2913477
disc_acc: 0.6795634920634921


	Epoch 23
Training results:
gen_loss: 9.973559
disc_loss: 0.11813701
disc_acc: 0.9616336633663366

Validation results:
gen_loss: 11.910486
disc_loss: 1.3895314
disc_acc: 0.6185515873015873


	Epoch 24
Training results:
gen_loss: 10.027574
disc_loss: 0.12735133
disc_acc: 0.9597772277227723

Validation results:
gen_loss: 9.595809
disc_loss: 1.0472003
disc_acc: 0.6691468253968254


	Epoch 25
Training results:
gen_loss: 10.473286
disc_loss: 0.11588082
disc_acc: 0.9603960396039604

Validation results:
gen_loss: 9.870242
disc_loss: 1.8711388
disc_acc: 0.5694444444444444


	Epoch 26
Training results:
gen_loss: 11.020243
disc_loss: 0.12076815
disc_acc: 0.9585396039603961

Validation results:
gen_loss: 10.053329
disc_loss: 0.73439246
disc_acc: 0.7217261904761905


	Epoch 27
Training results:
gen_loss: 11.226613
disc_loss: 0.10822381
disc_acc: 0.9625

Validation results:
gen_loss: 13.828928
disc_loss: 1.9993641
disc_acc: 0.5952380952380952


	Epoch 28
Training results:
gen_loss: 11.61745
disc_loss: 0.1068441
disc_acc: 0.9638613861386138

Validation results:
gen_loss: 14.298131
disc_loss: 1.459912
disc_acc: 0.6438492063492064


	Epoch 29
Training results:
gen_loss: 11.487653
disc_loss: 0.1027333
disc_acc: 0.9662128712871287

Validation results:
gen_loss: 8.988095
disc_loss: 0.6173007
disc_acc: 0.8115079365079365


	Epoch 30
Training results:
gen_loss: 11.6286335
disc_loss: 0.10100211
disc_acc: 0.968069306930693

Validation results:
gen_loss: 11.624245
disc_loss: 0.23342036
disc_acc: 0.9171626984126984


	Epoch 31
Training results:
gen_loss: 11.678376
disc_loss: 0.1026367
disc_acc: 0.9629950495049505

Validation results:
gen_loss: 12.891351
disc_loss: 3.115723
disc_acc: 0.4513888888888889


	Epoch 32
Training results:
gen_loss: 11.709267
disc_loss: 0.101743795
disc_acc: 0.9637376237623763

Validation results:
gen_loss: 11.186227
disc_loss: 1.1140757
disc_acc: 0.6666666666666666


	Epoch 33
Training results:
gen_loss: 11.823549
disc_loss: 0.10020211
disc_acc: 0.9659653465346535

Validation results:
gen_loss: 10.847013
disc_loss: 0.26643237
disc_acc: 0.9002976190476191


	Epoch 34
Training results:
gen_loss: 12.1685295
disc_loss: 0.10051834
disc_acc: 0.9650990099009901

Validation results:
gen_loss: 16.806074
disc_loss: 1.6423099
disc_acc: 0.6443452380952381


	Epoch 35
Training results:
gen_loss: 12.635714
disc_loss: 0.09183855
disc_acc: 0.9683168316831683

Validation results:
gen_loss: 9.7276945
disc_loss: 1.5568159
disc_acc: 0.6364087301587301


	Epoch 36
Training results:
gen_loss: 12.72229
disc_loss: 0.09860909
disc_acc: 0.9676980198019802

Validation results:
gen_loss: 9.394194
disc_loss: 0.29970846
disc_acc: 0.8834325396825397


	Epoch 37
Training results:
gen_loss: 13.011059
disc_loss: 0.095389955
disc_acc: 0.9673267326732673

Validation results:
gen_loss: 11.835873
disc_loss: 0.77591723
disc_acc: 0.7574404761904762


	Epoch 38
Training results:
gen_loss: 13.172666
disc_loss: 0.087962344
disc_acc: 0.970049504950495

Validation results:
gen_loss: 14.718118
disc_loss: 1.526123
disc_acc: 0.6964285714285714


	Epoch 39
Training results:
gen_loss: 13.456501
disc_loss: 0.09293946
disc_acc: 0.9662128712871287

Validation results:
gen_loss: 13.502487
disc_loss: 2.4837754
disc_acc: 0.5357142857142857


	Epoch 40
Training results:
gen_loss: 13.608423
disc_loss: 0.09531117
disc_acc: 0.9683168316831683

Validation results:
gen_loss: 16.644705
disc_loss: 4.1713505
disc_acc: 0.4677579365079365


	Epoch 41
Training results:
gen_loss: 13.781542
disc_loss: 0.08074074
disc_acc: 0.9714108910891089

Validation results:
gen_loss: 16.840199
disc_loss: 1.528488
disc_acc: 0.6096230158730159


	Epoch 42
Training results:
gen_loss: 13.882265
disc_loss: 0.079260774
disc_acc: 0.971039603960396

Validation results:
gen_loss: 14.16997
disc_loss: 0.6503049
disc_acc: 0.8571428571428571


	Epoch 43
Training results:
gen_loss: 14.224946
disc_loss: 0.07382814
disc_acc: 0.9733910891089109

Validation results:
gen_loss: 15.598033
disc_loss: 0.368101
disc_acc: 0.878968253968254


	Epoch 44
Training results:
gen_loss: 14.885089
disc_loss: 0.086060695
disc_acc: 0.9717821782178218

Validation results:
gen_loss: 14.008818
disc_loss: 2.1890466
disc_acc: 0.5719246031746031


	Epoch 45
Training results:
gen_loss: 14.99759
disc_loss: 0.078832954
disc_acc: 0.9709158415841584

Validation results:
gen_loss: 16.82114
disc_loss: 1.7502352
disc_acc: 0.6011904761904762


	Epoch 46
Training results:
gen_loss: 14.948076
disc_loss: 0.084601946
disc_acc: 0.9695544554455445

Validation results:
gen_loss: 13.976321
disc_loss: 0.061735407
disc_acc: 0.9791666666666666


	Epoch 47
Training results:
gen_loss: 14.899067
disc_loss: 0.08294546
disc_acc: 0.9702970297029703

Validation results:
gen_loss: 14.714953
disc_loss: 0.70227665
disc_acc: 0.7886904761904762


	Epoch 48
Training results:
gen_loss: 15.079775
disc_loss: 0.08519772
disc_acc: 0.9699257425742575

Validation results:
gen_loss: 10.181169
disc_loss: 0.05804385
disc_acc: 0.9816468253968254


	Epoch 49
Training results:
gen_loss: 15.148202
disc_loss: 0.06757698
disc_acc: 0.9764851485148515

Validation results:
gen_loss: 14.546229
disc_loss: 2.6339216
disc_acc: 0.5982142857142857


	Epoch 50
Training results:
gen_loss: 14.830742
disc_loss: 0.0765766
disc_acc: 0.9726485148514852

Validation results:
gen_loss: 23.52714
disc_loss: 1.7337476
disc_acc: 0.6607142857142857


	Epoch 51
Training results:
gen_loss: 15.558085
disc_loss: 0.0842904
disc_acc: 0.9705445544554455

Validation results:
gen_loss: 17.130285
disc_loss: 1.2182968
disc_acc: 0.7311507936507936


	Epoch 52
Training results:
gen_loss: 15.610873
disc_loss: 0.08889053
disc_acc: 0.9686881188118812

Validation results:
gen_loss: 14.978234
disc_loss: 0.45830742
disc_acc: 0.8511904761904762


	Epoch 53
Training results:
gen_loss: 15.0033045
disc_loss: 0.068607785
disc_acc: 0.9751237623762377

Validation results:
gen_loss: 13.617295
disc_loss: 1.2025967
disc_acc: 0.6478174603174603


	Epoch 54
Training results:
gen_loss: 15.501172
disc_loss: 0.07058113
disc_acc: 0.9751237623762377

Validation results:
gen_loss: 17.357208
disc_loss: 1.8203973
disc_acc: 0.6205357142857143


	Epoch 55
Training results:
gen_loss: 15.892296
disc_loss: 0.073746316
disc_acc: 0.9742574257425742

Validation results:
gen_loss: 18.948835
disc_loss: 1.1591312
disc_acc: 0.7579365079365079


	Epoch 56
Training results:
gen_loss: 16.065472
disc_loss: 0.08466522
disc_acc: 0.9705445544554455

Validation results:
gen_loss: 21.826996
disc_loss: 3.997149
disc_acc: 0.5610119047619048


	Epoch 57
Training results:
gen_loss: 16.002419
disc_loss: 0.07165548
disc_acc: 0.9724009900990099

Validation results:
gen_loss: 16.726349
disc_loss: 0.10086407
disc_acc: 0.964781746031746


	Epoch 58
Training results:
gen_loss: 16.503017
disc_loss: 0.08000068
disc_acc: 0.9737623762376237

Validation results:
gen_loss: 17.763517
disc_loss: 1.2513291
disc_acc: 0.7028769841269841


	Epoch 59
Training results:
gen_loss: 16.62633
disc_loss: 0.06591437
disc_acc: 0.9774752475247525

Validation results:
gen_loss: 16.38169
disc_loss: 0.25518063
disc_acc: 0.9122023809523809


	Epoch 60
Training results:
gen_loss: 17.029787
disc_loss: 0.067491144
disc_acc: 0.9763613861386139

Validation results:
gen_loss: 14.495442
disc_loss: 0.66822064
disc_acc: 0.7693452380952381


	Epoch 61
Training results:
gen_loss: 17.19856
disc_loss: 0.06546803
disc_acc: 0.977970297029703

Validation results:
gen_loss: 15.034926
disc_loss: 0.88068306
disc_acc: 0.7108134920634921


	Epoch 62
Training results:
gen_loss: 17.028044
disc_loss: 0.07510448
disc_acc: 0.9738861386138614

Validation results:
gen_loss: 13.98712
disc_loss: 0.40414992
disc_acc: 0.8591269841269841


	Epoch 63
Training results:
gen_loss: 17.391851
disc_loss: 0.06215241
disc_acc: 0.9789603960396039

Validation results:
gen_loss: 15.693606
disc_loss: 0.16367717
disc_acc: 0.9305555555555556


	Epoch 64
Training results:
gen_loss: 16.851025
disc_loss: 0.07288318
disc_acc: 0.9735148514851485

Validation results:
gen_loss: 26.744875
disc_loss: 5.6373124
disc_acc: 0.49503968253968256


	Epoch 65
Training results:
gen_loss: 17.273287
disc_loss: 0.06861835
disc_acc: 0.9773514851485149

Validation results:
gen_loss: 15.173442
disc_loss: 0.03356161
disc_acc: 0.9866071428571429


	Epoch 66
Training results:
gen_loss: 16.938627
disc_loss: 0.066655785
disc_acc: 0.975

Validation results:
gen_loss: 13.456769
disc_loss: 0.45558226
disc_acc: 0.8551587301587301


	Epoch 67
Training results:
gen_loss: 16.940191
disc_loss: 0.06297522
disc_acc: 0.9778465346534654

Validation results:
gen_loss: 13.486574
disc_loss: 0.20294914
disc_acc: 0.9260912698412699


	Epoch 68
Training results:
gen_loss: 17.14416
disc_loss: 0.05531746
disc_acc: 0.9819306930693069

Validation results:
gen_loss: 10.6769705
disc_loss: 0.11769337
disc_acc: 0.9533730158730159


	Epoch 69
Training results:
gen_loss: 17.293352
disc_loss: 0.053213805
disc_acc: 0.9798267326732674

Validation results:
gen_loss: 14.285483
disc_loss: 0.069810525
disc_acc: 0.9766865079365079


	Epoch 70
Training results:
gen_loss: 17.517384
disc_loss: 0.057234984
disc_acc: 0.9800742574257426

Validation results:
gen_loss: 20.415022
disc_loss: 2.617886
disc_acc: 0.5178571428571429


	Epoch 71
Training results:
gen_loss: 17.518677
disc_loss: 0.07056617
disc_acc: 0.9756188118811882

Validation results:
gen_loss: 20.394487
disc_loss: 3.0577254
disc_acc: 0.529265873015873


	Epoch 72
Training results:
gen_loss: 17.82297
disc_loss: 0.0639454
disc_acc: 0.9775990099009901

Validation results:
gen_loss: 14.774529
disc_loss: 0.45125297
disc_acc: 0.8492063492063492


	Epoch 73
Training results:
gen_loss: 18.081526
disc_loss: 0.058249697
disc_acc: 0.977970297029703

Validation results:
gen_loss: 14.914551
disc_loss: 1.8139049
disc_acc: 0.5902777777777778


	Epoch 74
Training results:
gen_loss: 18.139631
disc_loss: 0.0693912
disc_acc: 0.9756188118811882

Validation results:
gen_loss: 29.775814
disc_loss: 3.1697388
disc_acc: 0.6532738095238095


	Epoch 75
Training results:
gen_loss: 18.055534
disc_loss: 0.059809882
disc_acc: 0.9795792079207921

Validation results:
gen_loss: 17.234312
disc_loss: 0.07314877
disc_acc: 0.9751984126984127


	Epoch 76
Training results:
gen_loss: 18.551283
disc_loss: 0.05800519
disc_acc: 0.9788366336633664

Validation results:
gen_loss: 15.4533415
disc_loss: 0.738486
disc_acc: 0.8273809523809523


	Epoch 77
Training results:
gen_loss: 18.903831
disc_loss: 0.05473149
disc_acc: 0.9809405940594059

Validation results:
gen_loss: 24.663437
disc_loss: 2.8589792
disc_acc: 0.5793650793650794


	Epoch 78
Training results:
gen_loss: 19.12416
disc_loss: 0.056421638
disc_acc: 0.9805693069306931

Validation results:
gen_loss: 12.275533
disc_loss: 0.0341536
disc_acc: 0.9871031746031746


	Epoch 79
Training results:
gen_loss: 18.65429
disc_loss: 0.054352183
disc_acc: 0.9804455445544554

Validation results:
gen_loss: 19.047237
disc_loss: 1.4338789
disc_acc: 0.6319444444444444


	Epoch 80
Training results:
gen_loss: 19.177088
disc_loss: 0.06044199
disc_acc: 0.9784653465346534

Validation results:
gen_loss: 16.529366
disc_loss: 0.024847707
disc_acc: 0.9925595238095238


	Epoch 81
Training results:
gen_loss: 19.239477
disc_loss: 0.053925283
disc_acc: 0.9806930693069307

Validation results:
gen_loss: 22.552298
disc_loss: 0.18894225
disc_acc: 0.9315476190476191


	Epoch 82
Training results:
gen_loss: 19.724628
disc_loss: 0.06707309
disc_acc: 0.9763613861386139

Validation results:
gen_loss: 16.884804
disc_loss: 0.27940613
disc_acc: 0.9057539682539683


	Epoch 83
Training results:
gen_loss: 19.193012
disc_loss: 0.051393457
disc_acc: 0.9829207920792079

Validation results:
gen_loss: 15.858965
disc_loss: 0.12148713
disc_acc: 0.9548611111111112


	Epoch 84
Training results:
gen_loss: 19.001272
disc_loss: 0.0736997
disc_acc: 0.9758663366336634

Validation results:
gen_loss: 12.600036
disc_loss: 0.021512048
disc_acc: 0.9925595238095238


	Epoch 85
Training results:
gen_loss: 18.712399
disc_loss: 0.054351293
disc_acc: 0.9814356435643564

Validation results:
gen_loss: 15.272546
disc_loss: 0.024957595
disc_acc: 0.9915674603174603


	Epoch 86
Training results:
gen_loss: 19.041534
disc_loss: 0.048786685
disc_acc: 0.9831683168316832

Validation results:
gen_loss: 24.447742
disc_loss: 0.8878342
disc_acc: 0.7703373015873016


	Epoch 87
Training results:
gen_loss: 19.042456
disc_loss: 0.05291152
disc_acc: 0.9804455445544554

Validation results:
gen_loss: 14.528476
disc_loss: 0.25300393
disc_acc: 0.8953373015873016


	Epoch 88
Training results:
gen_loss: 19.550924
disc_loss: 0.056511827
disc_acc: 0.9798267326732674

Validation results:
gen_loss: 13.739999
disc_loss: 0.19184764
disc_acc: 0.9300595238095238


	Epoch 89
Training results:
gen_loss: 20.339365
disc_loss: 0.058299094
disc_acc: 0.9788366336633664

Validation results:
gen_loss: 19.401731
disc_loss: 7.548406
disc_acc: 0.44345238095238093


	Epoch 90
Training results:
gen_loss: 19.613447
disc_loss: 0.05245138
disc_acc: 0.9806930693069307

Validation results:
gen_loss: 25.519735
disc_loss: 0.93056196
disc_acc: 0.7559523809523809


	Epoch 91
Training results:
gen_loss: 19.646832
disc_loss: 0.05702391
disc_acc: 0.9788366336633664

Validation results:
gen_loss: 19.462234
disc_loss: 2.380777
disc_acc: 0.6031746031746031


	Epoch 92
Training results:
gen_loss: 20.032444
disc_loss: 0.050050125
disc_acc: 0.9825495049504951

Validation results:
gen_loss: 16.839592
disc_loss: 0.06942803
disc_acc: 0.9761904761904762


	Epoch 93
Training results:
gen_loss: 20.366669
disc_loss: 0.047528084
disc_acc: 0.9820544554455446

Validation results:
gen_loss: 20.348606
disc_loss: 1.1594847
disc_acc: 0.7390873015873016


	Epoch 94
Training results:
gen_loss: 20.375034
disc_loss: 0.04844359
disc_acc: 0.9818069306930693

Validation results:
gen_loss: 19.967907
disc_loss: 0.15433232
disc_acc: 0.9518849206349206


	Epoch 95
Training results:
gen_loss: 19.541836
disc_loss: 0.045889586
disc_acc: 0.9835396039603961

Validation results:
gen_loss: 17.555328
disc_loss: 0.049555402
disc_acc: 0.9816468253968254


	Epoch 96
Training results:
gen_loss: 20.04105
disc_loss: 0.052165236
disc_acc: 0.9819306930693069

Validation results:
gen_loss: 19.340406
disc_loss: 0.34994215
disc_acc: 0.8849206349206349


	Epoch 97
Training results:
gen_loss: 19.637276
disc_loss: 0.050020184
disc_acc: 0.9814356435643564

Validation results:
gen_loss: 18.806381
disc_loss: 1.4266353
disc_acc: 0.6830357142857143


	Epoch 98
Training results:
gen_loss: 19.834742
disc_loss: 0.05779043
disc_acc: 0.9784653465346534

Validation results:
gen_loss: 15.449928
disc_loss: 0.08820534
disc_acc: 0.9652777777777778


	Epoch 99
Training results:
gen_loss: 19.952255
disc_loss: 0.050415967
disc_acc: 0.9820544554455446

Validation results:
gen_loss: 20.146816
disc_loss: 3.742765
disc_acc: 0.5104166666666666


	Epoch 100
Training results:
gen_loss: 19.908754
disc_loss: 0.045768913
disc_acc: 0.9831683168316832

Validation results:
gen_loss: 23.076326
disc_loss: 1.8966055
disc_acc: 0.652281746031746



gen_train_loss: 0.017465893, 3.915103, 5.359791, 6.1232867, 6.422283, 6.778576, 7.0762687, 7.385945, 7.511315, 7.5624566, 7.7609596, 7.970894, 8.125742, 8.725919, 9.2088585, 9.3916855, 9.883738, 10.020084, 10.356579, 10.497956, 11.149219, 11.9213295, 12.468105, 12.399582, 12.615928, 13.380621, 13.648167, 13.526952, 14.93153, 15.466533, 16.517145, 16.794031, 16.444252, 16.057573, 16.227089, 16.450352, 17.43786, 17.86974, 17.687178, 18.021996, 17.66883, 17.855276, 17.653025, 17.574366, 17.520292, 17.981894, 18.033323, 18.254786, 18.506, 18.84505, 18.591366, 18.864815, 19.249887, 19.485132, 19.74276, 19.103647, 19.36562, 19.534061, 19.725288, 20.054394, 21.176226, 20.390657, 20.88933, 21.049458, 21.361412, 21.219856, 21.031046, 20.823439, 20.571106, 20.62096, 21.473932, 20.86941, 20.60384, 20.650803, 20.291166, 20.748623, 20.656572, 20.607208, 21.058195, 21.022537, 21.382975, 21.38699, 21.40211, 21.182783, 20.824425, 21.041313, 20.831566, 20.677591, 21.086899, 21.289839, 21.238892, 20.484928, 21.053051, 20.85598, 20.268553, 20.33169, 20.447805, 20.80666, 21.002544, 20.440088, 20.262842, 0.018100196, 3.6775413, 4.908653, 5.5429354, 5.7819376, 6.070267, 6.728553, 7.0716615, 7.1919746, 7.496708, 7.477155, 7.16317, 7.5851293, 7.6821494, 8.099609, 8.43827, 8.41461, 8.960338, 9.1525955, 9.435323, 9.897832, 10.108103, 9.910032, 9.973559, 10.027574, 10.473286, 11.020243, 11.226613, 11.61745, 11.487653, 11.6286335, 11.678376, 11.709267, 11.823549, 12.1685295, 12.635714, 12.72229, 13.011059, 13.172666, 13.456501, 13.608423, 13.781542, 13.882265, 14.224946, 14.885089, 14.99759, 14.948076, 14.899067, 15.079775, 15.148202, 14.830742, 15.558085, 15.610873, 15.0033045, 15.501172, 15.892296, 16.065472, 16.002419, 16.503017, 16.62633, 17.029787, 17.19856, 17.028044, 17.391851, 16.851025, 17.273287, 16.938627, 16.940191, 17.14416, 17.293352, 17.517384, 17.518677, 17.82297, 18.081526, 18.139631, 18.055534, 18.551283, 18.903831, 19.12416, 18.65429, 19.177088, 19.239477, 19.724628, 19.193012, 19.001272, 18.712399, 19.041534, 19.042456, 19.550924, 20.339365, 19.613447, 19.646832, 20.032444, 20.366669, 20.375034, 19.541836, 20.04105, 19.637276, 19.834742, 19.952255, 19.908754
disc_train_loss: 5.549591, 1.3360267, 0.47511926, 0.3436792, 0.27859452, 0.26534748, 0.23966871, 0.21985598, 0.22690952, 0.18341644, 0.19174926, 0.19230376, 0.17956884, 0.16799966, 0.14860587, 0.13126352, 0.15552475, 0.15761939, 0.13105054, 0.13568904, 0.13098845, 0.1315735, 0.1290503, 0.116363235, 0.12276954, 0.123682804, 0.1115701, 0.11749535, 0.10924785, 0.11100927, 0.1018547, 0.111782566, 0.11344695, 0.095632516, 0.09177675, 0.09777222, 0.092829846, 0.088303745, 0.0904583, 0.09177679, 0.08424382, 0.07714309, 0.0878833, 0.08168051, 0.08340695, 0.075717665, 0.08185212, 0.086831495, 0.07580806, 0.07287904, 0.07870535, 0.06637685, 0.08220758, 0.07103909, 0.07222977, 0.07354433, 0.0694536, 0.07657911, 0.06857457, 0.07217313, 0.07333897, 0.06694848, 0.07235697, 0.055669274, 0.07463365, 0.05937065, 0.06810823, 0.0752082, 0.05757061, 0.061033342, 0.06529443, 0.061487306, 0.06143135, 0.047937457, 0.07449291, 0.059174106, 0.06326708, 0.05487957, 0.06473869, 0.0532951, 0.070082605, 0.05883564, 0.063105196, 0.05076837, 0.055332772, 0.052032016, 0.056849528, 0.053410932, 0.058384992, 0.051421855, 0.059696026, 0.050160673, 0.049992785, 0.055234745, 0.05950347, 0.051932737, 0.05023499, 0.05354743, 0.03839709, 0.0503911, 0.056449525, 5.542061, 1.3224822, 0.47654638, 0.3379635, 0.29153284, 0.2529349, 0.25708795, 0.2201324, 0.19715099, 0.1942019, 0.19003154, 0.16112779, 0.1756617, 0.1547248, 0.16331747, 0.15213937, 0.14647096, 0.14539066, 0.14366414, 0.13019374, 0.13004716, 0.13275065, 0.11928067, 0.11813701, 0.12735133, 0.11588082, 0.12076815, 0.10822381, 0.1068441, 0.1027333, 0.10100211, 0.1026367, 0.101743795, 0.10020211, 0.10051834, 0.09183855, 0.09860909, 0.095389955, 0.087962344, 0.09293946, 0.09531117, 0.08074074, 0.079260774, 0.07382814, 0.086060695, 0.078832954, 0.084601946, 0.08294546, 0.08519772, 0.06757698, 0.0765766, 0.0842904, 0.08889053, 0.068607785, 0.07058113, 0.073746316, 0.08466522, 0.07165548, 0.08000068, 0.06591437, 0.067491144, 0.06546803, 0.07510448, 0.06215241, 0.07288318, 0.06861835, 0.066655785, 0.06297522, 0.05531746, 0.053213805, 0.057234984, 0.07056617, 0.0639454, 0.058249697, 0.0693912, 0.059809882, 0.05800519, 0.05473149, 0.056421638, 0.054352183, 0.06044199, 0.053925283, 0.06707309, 0.051393457, 0.0736997, 0.054351293, 0.048786685, 0.05291152, 0.056511827, 0.058299094, 0.05245138, 0.05702391, 0.050050125, 0.047528084, 0.04844359, 0.045889586, 0.052165236, 0.050020184, 0.05779043, 0.050415967, 0.045768913
disc_train_acc: 0.0, 0.5897277227722773, 0.8474009900990099, 0.8851485148514852, 0.9110148514851485, 0.9090346534653465, 0.9201732673267327, 0.9262376237623763, 0.9246287128712871, 0.9352722772277228, 0.9327970297029703, 0.93490099009901, 0.94009900990099, 0.9446782178217822, 0.9523514851485149, 0.9548267326732673, 0.9443069306930693, 0.9475247524752475, 0.9560643564356436, 0.9560643564356436, 0.9573019801980198, 0.9537128712871287, 0.9577970297029703, 0.9601485148514851, 0.9594059405940594, 0.9591584158415841, 0.9606435643564356, 0.9587871287128713, 0.9641089108910891, 0.9613861386138614, 0.9647277227722773, 0.9638613861386138, 0.9594059405940594, 0.9655940594059406, 0.968069306930693, 0.9665841584158416, 0.9641089108910891, 0.9685643564356435, 0.968069306930693, 0.9676980198019802, 0.9701732673267327, 0.9702970297029703, 0.968069306930693, 0.9714108910891089, 0.9709158415841584, 0.9721534653465347, 0.9731435643564357, 0.9711633663366337, 0.974009900990099, 0.9726485148514852, 0.9717821782178218, 0.9761138613861386, 0.9715346534653465, 0.9761138613861386, 0.9741336633663367, 0.9752475247524752, 0.9764851485148515, 0.9726485148514852, 0.9764851485148515, 0.9751237623762377, 0.9745049504950495, 0.9767326732673267, 0.9746287128712872, 0.9794554455445544, 0.9737623762376237, 0.9782178217821782, 0.9773514851485149, 0.9737623762376237, 0.9795792079207921, 0.9780940594059406, 0.9782178217821782, 0.9793316831683169, 0.9775990099009901, 0.9832920792079208, 0.9746287128712872, 0.9792079207920792, 0.9778465346534654, 0.9805693069306931, 0.9771039603960396, 0.9801980198019802, 0.9768564356435644, 0.9793316831683169, 0.9788366336633664, 0.9824257425742574, 0.9793316831683169, 0.9818069306930693, 0.9778465346534654, 0.9804455445544554, 0.9805693069306931, 0.9821782178217822, 0.9774752475247525, 0.9816831683168317, 0.9820544554455446, 0.9821782178217822, 0.9793316831683169, 0.9816831683168317, 0.9820544554455446, 0.9815594059405941, 0.9853960396039604, 0.9842821782178218, 0.9810643564356436, 0.0, 0.5935643564356435, 0.8422029702970297, 0.8902227722772277, 0.9042079207920792, 0.9157178217821782, 0.9173267326732674, 0.925990099009901, 0.9371287128712872, 0.9330445544554455, 0.9393564356435643, 0.943069306930693, 0.9405940594059405, 0.9516089108910891, 0.9466584158415842, 0.948019801980198, 0.9488861386138614, 0.9507425742574257, 0.9521039603960396, 0.9563118811881188, 0.9577970297029703, 0.9551980198019802, 0.9586633663366336, 0.9616336633663366, 0.9597772277227723, 0.9603960396039604, 0.9585396039603961, 0.9625, 0.9638613861386138, 0.9662128712871287, 0.968069306930693, 0.9629950495049505, 0.9637376237623763, 0.9659653465346535, 0.9650990099009901, 0.9683168316831683, 0.9676980198019802, 0.9673267326732673, 0.970049504950495, 0.9662128712871287, 0.9683168316831683, 0.9714108910891089, 0.971039603960396, 0.9733910891089109, 0.9717821782178218, 0.9709158415841584, 0.9695544554455445, 0.9702970297029703, 0.9699257425742575, 0.9764851485148515, 0.9726485148514852, 0.9705445544554455, 0.9686881188118812, 0.9751237623762377, 0.9751237623762377, 0.9742574257425742, 0.9705445544554455, 0.9724009900990099, 0.9737623762376237, 0.9774752475247525, 0.9763613861386139, 0.977970297029703, 0.9738861386138614, 0.9789603960396039, 0.9735148514851485, 0.9773514851485149, 0.975, 0.9778465346534654, 0.9819306930693069, 0.9798267326732674, 0.9800742574257426, 0.9756188118811882, 0.9775990099009901, 0.977970297029703, 0.9756188118811882, 0.9795792079207921, 0.9788366336633664, 0.9809405940594059, 0.9805693069306931, 0.9804455445544554, 0.9784653465346534, 0.9806930693069307, 0.9763613861386139, 0.9829207920792079, 0.9758663366336634, 0.9814356435643564, 0.9831683168316832, 0.9804455445544554, 0.9798267326732674, 0.9788366336633664, 0.9806930693069307, 0.9788366336633664, 0.9825495049504951, 0.9820544554455446, 0.9818069306930693, 0.9835396039603961, 0.9819306930693069, 0.9814356435643564, 0.9784653465346534, 0.9820544554455446, 0.9831683168316832
gen_val_loss: 0.016667297, 4.925635, 4.2505674, 8.210184, 5.1402287, 5.8560047, 8.014394, 6.1189947, 5.7750382, 9.759907, 8.911359, 10.480018, 7.5078, 6.7395844, 7.723098, 6.3017983, 7.0546823, 8.821914, 7.139569, 11.046736, 10.75118, 12.579869, 12.234857, 13.592762, 12.686326, 21.630947, 13.631503, 13.36135, 9.400121, 13.927616, 15.655143, 14.579443, 15.031311, 12.956967, 15.0595045, 15.201976, 16.752146, 20.767643, 21.772957, 12.74014, 19.233583, 12.198323, 15.33354, 20.955286, 17.959387, 13.658522, 21.317303, 12.064492, 15.982727, 21.675825, 13.708792, 23.016771, 15.166815, 19.146696, 15.063337, 15.439414, 17.898617, 17.723343, 15.837041, 17.214922, 16.194221, 18.668812, 23.07856, 19.576004, 16.060272, 12.234263, 24.239513, 20.610504, 28.314623, 15.69535, 14.804232, 12.705679, 15.992057, 17.136566, 22.67824, 19.446482, 15.522743, 17.416601, 20.567953, 20.338623, 18.065365, 15.811594, 24.228315, 22.461933, 22.997303, 15.098549, 24.904915, 20.91807, 14.493197, 16.364115, 23.633938, 16.074224, 16.08741, 16.837143, 15.64648, 18.557882, 16.7631, 17.686737, 14.795434, 14.404691, 29.89829, 0.017171964, 5.079787, 6.986336, 6.808677, 5.6960187, 7.8110633, 4.8258457, 6.9699264, 7.6939235, 8.085631, 5.877345, 8.51126, 6.2680345, 6.3179665, 6.2138553, 10.97687, 11.619981, 8.781651, 9.902598, 11.296499, 11.630225, 7.791545, 13.007236, 11.910486, 9.595809, 9.870242, 10.053329, 13.828928, 14.298131, 8.988095, 11.624245, 12.891351, 11.186227, 10.847013, 16.806074, 9.7276945, 9.394194, 11.835873, 14.718118, 13.502487, 16.644705, 16.840199, 14.16997, 15.598033, 14.008818, 16.82114, 13.976321, 14.714953, 10.181169, 14.546229, 23.52714, 17.130285, 14.978234, 13.617295, 17.357208, 18.948835, 21.826996, 16.726349, 17.763517, 16.38169, 14.495442, 15.034926, 13.98712, 15.693606, 26.744875, 15.173442, 13.456769, 13.486574, 10.6769705, 14.285483, 20.415022, 20.394487, 14.774529, 14.914551, 29.775814, 17.234312, 15.4533415, 24.663437, 12.275533, 19.047237, 16.529366, 22.552298, 16.884804, 15.858965, 12.600036, 15.272546, 24.447742, 14.528476, 13.739999, 19.401731, 25.519735, 19.462234, 16.839592, 20.348606, 19.967907, 17.555328, 19.340406, 18.806381, 15.449928, 20.146816, 23.076326
disc_val_loss: 5.5523176, 2.5600905, 0.8639209, 1.3382838, 0.74151844, 1.4709806, 1.1345569, 1.5772299, 0.40081233, 3.4698524, 0.7623847, 4.508161, 0.57705307, 0.13639009, 0.9461669, 2.3974693, 0.41815588, 0.56746906, 0.42741773, 0.49227577, 0.3081923, 1.3629926, 0.20846026, 0.5603758, 0.6530965, 2.1543024, 0.40881288, 0.6401487, 0.14914691, 0.08537866, 0.16256449, 0.15835121, 0.7205155, 0.04790979, 0.22643448, 0.15851073, 0.21819052, 0.66081953, 2.2278516, 0.0629691, 0.8247781, 0.11515096, 0.12843736, 1.4283112, 1.5619378, 0.23354764, 3.9428723, 0.030870495, 0.14934266, 3.3645415, 0.047056098, 0.38575518, 0.16763252, 0.22243059, 0.11697554, 0.026392309, 0.1330982, 0.26791123, 0.04905136, 0.101452805, 0.14022027, 0.14336905, 0.325764, 0.53220934, 0.2036549, 0.17797801, 1.2972687, 1.2463837, 2.5032573, 0.029343836, 0.09428618, 0.23913613, 0.09051301, 0.03850209, 0.339486, 0.069458425, 0.06313546, 0.066069424, 0.7743636, 0.15323383, 0.06127911, 0.23533577, 0.7749133, 1.3148426, 0.9198271, 0.062348757, 0.91776097, 0.06267202, 0.121269576, 0.040895786, 0.523134, 0.7766852, 0.07745434, 0.1671921, 0.030203601, 0.6331275, 0.03768678, 0.018571863, 0.020616729, 0.030198231, 0.59615976, 5.5420732, 2.492341, 1.9154705, 1.9603481, 0.9328407, 3.2532477, 2.0045009, 0.9249822, 3.4847202, 1.3541857, 0.4233324, 0.729473, 0.63950545, 2.2228146, 0.59125, 3.3948758, 1.468594, 1.220788, 1.4914796, 4.28534, 3.6923, 0.317091, 1.2913477, 1.3895314, 1.0472003, 1.8711388, 0.73439246, 1.9993641, 1.459912, 0.6173007, 0.23342036, 3.115723, 1.1140757, 0.26643237, 1.6423099, 1.5568159, 0.29970846, 0.77591723, 1.526123, 2.4837754, 4.1713505, 1.528488, 0.6503049, 0.368101, 2.1890466, 1.7502352, 0.061735407, 0.70227665, 0.05804385, 2.6339216, 1.7337476, 1.2182968, 0.45830742, 1.2025967, 1.8203973, 1.1591312, 3.997149, 0.10086407, 1.2513291, 0.25518063, 0.66822064, 0.88068306, 0.40414992, 0.16367717, 5.6373124, 0.03356161, 0.45558226, 0.20294914, 0.11769337, 0.069810525, 2.617886, 3.0577254, 0.45125297, 1.8139049, 3.1697388, 0.07314877, 0.738486, 2.8589792, 0.0341536, 1.4338789, 0.024847707, 0.18894225, 0.27940613, 0.12148713, 0.021512048, 0.024957595, 0.8878342, 0.25300393, 0.19184764, 7.548406, 0.93056196, 2.380777, 0.06942803, 1.1594847, 0.15433232, 0.049555402, 0.34994215, 1.4266353, 0.08820534, 3.742765, 1.8966055
disc_val_acc: 0.0, 0.2698412698412698, 0.7063492063492064, 0.6036706349206349, 0.7395833333333334, 0.5629960317460317, 0.6423611111111112, 0.5024801587301587, 0.8467261904761905, 0.3343253968253968, 0.7366071428571429, 0.27728174603174605, 0.7931547619047619, 0.9588293650793651, 0.7058531746031746, 0.5114087301587301, 0.8308531746031746, 0.7941468253968254, 0.8377976190476191, 0.8283730158730159, 0.8705357142857143, 0.621031746031746, 0.9131944444444444, 0.7976190476190477, 0.7658730158730159, 0.6413690476190477, 0.847718253968254, 0.8010912698412699, 0.9389880952380952, 0.96875, 0.9444444444444444, 0.9424603174603174, 0.7316468253968254, 0.9816468253968254, 0.9161706349206349, 0.939484126984127, 0.9171626984126984, 0.8194444444444444, 0.6101190476190477, 0.9751984126984127, 0.7862103174603174, 0.9538690476190477, 0.9538690476190477, 0.6815476190476191, 0.6096230158730159, 0.9087301587301587, 0.4826388888888889, 0.9895833333333334, 0.9439484126984127, 0.6130952380952381, 0.9811507936507936, 0.8581349206349206, 0.935515873015873, 0.9161706349206349, 0.9523809523809523, 0.9915674603174603, 0.9499007936507936, 0.9087301587301587, 0.9831349206349206, 0.9652777777777778, 0.9459325396825397, 0.9469246031746031, 0.8784722222222222, 0.8288690476190477, 0.9250992063492064, 0.9350198412698413, 0.6845238095238095, 0.7271825396825397, 0.5927579365079365, 0.9880952380952381, 0.9627976190476191, 0.9057539682539683, 0.9637896825396826, 0.9846230158730159, 0.8923611111111112, 0.9722222222222222, 0.9791666666666666, 0.9747023809523809, 0.8660714285714286, 0.935515873015873, 0.9776785714285714, 0.9151785714285714, 0.8452380952380952, 0.7390873015873016, 0.7415674603174603, 0.9836309523809523, 0.8020833333333334, 0.9781746031746031, 0.9593253968253969, 0.9861111111111112, 0.8363095238095238, 0.873015873015873, 0.9717261904761905, 0.9360119047619048, 0.9875992063492064, 0.8343253968253969, 0.9866071428571429, 0.9930555555555556, 0.9940476190476191, 0.9885912698412699, 0.8571428571428571, 0.0, 0.28422619047619047, 0.4801587301587302, 0.44246031746031744, 0.6641865079365079, 0.310515873015873, 0.42212301587301587, 0.6463293650793651, 0.33779761904761907, 0.5739087301587301, 0.8263888888888888, 0.716765873015873, 0.7490079365079365, 0.47619047619047616, 0.7663690476190477, 0.46130952380952384, 0.6641865079365079, 0.6865079365079365, 0.5763888888888888, 0.35813492063492064, 0.3551587301587302, 0.8953373015873016, 0.6795634920634921, 0.6185515873015873, 0.6691468253968254, 0.5694444444444444, 0.7217261904761905, 0.5952380952380952, 0.6438492063492064, 0.8115079365079365, 0.9171626984126984, 0.4513888888888889, 0.6666666666666666, 0.9002976190476191, 0.6443452380952381, 0.6364087301587301, 0.8834325396825397, 0.7574404761904762, 0.6964285714285714, 0.5357142857142857, 0.4677579365079365, 0.6096230158730159, 0.8571428571428571, 0.878968253968254, 0.5719246031746031, 0.6011904761904762, 0.9791666666666666, 0.7886904761904762, 0.9816468253968254, 0.5982142857142857, 0.6607142857142857, 0.7311507936507936, 0.8511904761904762, 0.6478174603174603, 0.6205357142857143, 0.7579365079365079, 0.5610119047619048, 0.964781746031746, 0.7028769841269841, 0.9122023809523809, 0.7693452380952381, 0.7108134920634921, 0.8591269841269841, 0.9305555555555556, 0.49503968253968256, 0.9866071428571429, 0.8551587301587301, 0.9260912698412699, 0.9533730158730159, 0.9766865079365079, 0.5178571428571429, 0.529265873015873, 0.8492063492063492, 0.5902777777777778, 0.6532738095238095, 0.9751984126984127, 0.8273809523809523, 0.5793650793650794, 0.9871031746031746, 0.6319444444444444, 0.9925595238095238, 0.9315476190476191, 0.9057539682539683, 0.9548611111111112, 0.9925595238095238, 0.9915674603174603, 0.7703373015873016, 0.8953373015873016, 0.9300595238095238, 0.44345238095238093, 0.7559523809523809, 0.6031746031746031, 0.9761904761904762, 0.7390873015873016, 0.9518849206349206, 0.9816468253968254, 0.8849206349206349, 0.6830357142857143, 0.9652777777777778, 0.5104166666666666, 0.652281746031746

