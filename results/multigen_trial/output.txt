Beginning trial described in ./config/multigen_trial.json.
Experiment type: multiple generators each corresponding to 1 key.
Experiment settings:
	byte: 0
	keys: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
	key_dataset_kwargs:
		keep_data_in_memory: True
		data_path: ./data
		download: True
		extract: True
		preprocess: True
		delete_download_after_extraction: False
		delete_extracted_after_preprocess: False
	dataloader_kwargs:
		batch_size: 16
		shuffle: True
	dataset_prop_for_validation: 0.2
	trace_map_constructor: None
	trace_map_kwargs:
		layers: [256]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	plaintext_map_constructor: None
	plaintext_map_kwargs:
		layers: [64]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	key_map_constructor: <function get_mlp_map at 0x7f25ae1145e0>
	key_map_kwargs:
		layers: [64, 256]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	cumulative_map_constructor: None
	cumulative_map_kwargs:
		layers: [256]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	discriminator_constructor: <function get_google_style_resnet_discriminator at 0x7f25ae114790>
	discriminator_kwargs:
	discriminator_loss_constructor: <class 'torch.nn.modules.loss.CrossEntropyLoss'>
	discriminator_loss_kwargs:
	discriminator_optimizer_constructor: <class 'torch.optim.adam.Adam'>
	discriminator_optimizer_kwargs:
	generator_loss_constructor: <class 'torch.nn.modules.loss.CrossEntropyLoss'>
	generator_loss_kwargs:
	generator_optimizer_constructor: <class 'torch.optim.adam.Adam'>
	generator_optimizer_kwargs:
	device: cuda
	discriminator_pretraining_epochs: 0
	generator_pretraining_epochs: 0
	gan_training_epochs: 500
	discriminator_posttraining_epochs: 500
	seed: 0
Loading datasets.
AesKeyGroupDataset:
	Available keys: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
	Key transform: Compose(
    IntToBinary()
    ToTensor1D()
)
	Byte: 0
	Number of samples available: 10112
	Trace size: torch.Size([1, 3000])
	Key size: torch.Size([1, 8])
	Plaintext size: torch.Size([1, 8])
	Key index size: ()
Constructing generator.
KeyOnlyGenerator(
  (key_trace_map): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=8, out_features=64, bias=True)
    (2): ReLU()
    (3): Linear(in_features=64, out_features=256, bias=True)
    (4): ReLU()
    (5): Linear(in_features=256, out_features=3000, bias=True)
    (6): Unflatten(dim=-1, unflattened_size=torch.Size([1, 3000]))
  )
)

Constructing discriminator.
Discriminator(
  (model): Sequential(
    (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    (1): Stack(
      (F): Sequential(
        (0): Block(
          (F): Sequential(
            (0): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(1, 16, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(16, 64, kernel_size=(1,), stride=(1,))
          )
          (Id): Conv1d(1, 64, kernel_size=(1,), stride=(1,))
        )
        (1): Block(
          (F): Sequential(
            (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(64, 16, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(16, 64, kernel_size=(1,), stride=(1,))
          )
          (Id): Identity()
        )
        (2): Block(
          (F): Sequential(
            (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(64, 16, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(16, 16, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
            (6): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(16, 64, kernel_size=(1,), stride=(1,))
          )
          (Id): MaxPool1d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)
        )
      )
    )
    (2): Stack(
      (F): Sequential(
        (0): Block(
          (F): Sequential(
            (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(64, 32, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
          )
          (Id): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
        )
        (1): Block(
          (F): Sequential(
            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
          )
          (Id): Identity()
        )
        (2): Block(
          (F): Sequential(
            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
          )
          (Id): Identity()
        )
        (3): Block(
          (F): Sequential(
            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(32, 32, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
            (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
          )
          (Id): MaxPool1d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)
        )
      )
    )
    (3): Stack(
      (F): Sequential(
        (0): Block(
          (F): Sequential(
            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
          )
          (Id): Conv1d(128, 256, kernel_size=(1,), stride=(1,))
        )
        (1): Block(
          (F): Sequential(
            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
          )
          (Id): Identity()
        )
        (2): Block(
          (F): Sequential(
            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
          )
          (Id): Identity()
        )
        (3): Block(
          (F): Sequential(
            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
            (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
          )
          (Id): MaxPool1d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)
        )
      )
    )
    (4): Stack(
      (F): Sequential(
        (0): Block(
          (F): Sequential(
            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
          )
          (Id): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
        )
        (1): Block(
          (F): Sequential(
            (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
          )
          (Id): Identity()
        )
        (2): Block(
          (F): Sequential(
            (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
            (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
          )
          (Id): MaxPool1d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)
        )
      )
    )
    (5): Flatten(start_dim=1, end_dim=-1)
    (6): LazyLinear(in_features=0, out_features=256, bias=True)
  )
)

Calculating initial results.
Training results:
gen_loss: -5.53727
disc_loss: 5.53727
disc_acc: 0.002103960396039604

Validation results:
gen_loss: -5.5387955
disc_loss: 5.5387955
disc_acc: 0.004464285714285714


Training discriminator and generator simultaneously.
	Epoch 1
Training results:
gen_loss: -2.7251005
disc_loss: 2.7251005
disc_acc: 0.2829207920792079

Validation results:
gen_loss: -1.8456204
disc_loss: 1.8456204
disc_acc: 0.3645833333333333


	Epoch 2
Training results:
gen_loss: -2.5890434
disc_loss: 2.5890434
disc_acc: 0.22685643564356436

Validation results:
gen_loss: -2.2531445
disc_loss: 2.2531445
disc_acc: 0.26785714285714285


	Epoch 3
Training results:
gen_loss: -2.1565492
disc_loss: 2.1565492
disc_acc: 0.24653465346534653

Validation results:
gen_loss: -1.9039419
disc_loss: 1.9039419
disc_acc: 0.3030753968253968


	Epoch 4
Training results:
gen_loss: -2.071932
disc_loss: 2.071932
disc_acc: 0.23849009900990098

Validation results:
gen_loss: -2.2546418
disc_loss: 2.2546418
disc_acc: 0.16567460317460317


	Epoch 5
Training results:
gen_loss: -2.156711
disc_loss: 2.156711
disc_acc: 0.16175742574257426

Validation results:
gen_loss: -2.1324432
disc_loss: 2.1324432
disc_acc: 0.12152777777777778


	Epoch 6
Training results:
gen_loss: -2.1561751
disc_loss: 2.1561751
disc_acc: 0.14913366336633663

Validation results:
gen_loss: -2.1419933
disc_loss: 2.1419933
disc_acc: 0.13442460317460317


	Epoch 7
Training results:
gen_loss: -2.230742
disc_loss: 2.230742
disc_acc: 0.15804455445544555

Validation results:
gen_loss: -2.1022446
disc_loss: 2.1022446
disc_acc: 0.16865079365079366


	Epoch 8
Training results:
gen_loss: -2.160218
disc_loss: 2.160218
disc_acc: 0.12314356435643564

Validation results:
gen_loss: -2.1365902
disc_loss: 2.1365902
disc_acc: 0.10962301587301587


	Epoch 9
Training results:
gen_loss: -2.1657603
disc_loss: 2.1657603
disc_acc: 0.15247524752475247

Validation results:
gen_loss: -2.4493008
disc_loss: 2.4493008
disc_acc: 0.2113095238095238


	Epoch 10
Training results:
gen_loss: -2.2203355
disc_loss: 2.2203355
disc_acc: 0.20544554455445543

Validation results:
gen_loss: -1.9383608
disc_loss: 1.9383608
disc_acc: 0.2822420634920635


	Epoch 11
Training results:
gen_loss: -2.2472143
disc_loss: 2.2472143
disc_acc: 0.1943069306930693

Validation results:
gen_loss: -2.2011626
disc_loss: 2.2011626
disc_acc: 0.17410714285714285


	Epoch 12
Training results:
gen_loss: -2.0960872
disc_loss: 2.0960872
disc_acc: 0.2125

Validation results:
gen_loss: -2.317465
disc_loss: 2.317465
disc_acc: 0.19146825396825398


	Epoch 13
Training results:
gen_loss: -2.083834
disc_loss: 2.083834
disc_acc: 0.19554455445544555

Validation results:
gen_loss: -2.1447294
disc_loss: 2.1447294
disc_acc: 0.11557539682539683


	Epoch 14
Training results:
gen_loss: -2.1319017
disc_loss: 2.1319017
disc_acc: 0.1422029702970297

Validation results:
gen_loss: -2.124371
disc_loss: 2.124371
disc_acc: 0.16567460317460317


	Epoch 15
Training results:
gen_loss: -2.1234715
disc_loss: 2.1234715
disc_acc: 0.13551980198019803

Validation results:
gen_loss: -2.1105452
disc_loss: 2.1105452
disc_acc: 0.12202380952380952


	Epoch 16
Training results:
gen_loss: -2.1336594
disc_loss: 2.1336594
disc_acc: 0.13836633663366338

Validation results:
gen_loss: -2.2123837
disc_loss: 2.2123837
disc_acc: 0.12946428571428573


	Epoch 17
Training results:
gen_loss: -2.1364896
disc_loss: 2.1364896
disc_acc: 0.1275990099009901

Validation results:
gen_loss: -2.1280057
disc_loss: 2.1280057
disc_acc: 0.1195436507936508


	Epoch 18
Training results:
gen_loss: -2.1283855
disc_loss: 2.1283855
disc_acc: 0.1311881188118812

Validation results:
gen_loss: -2.1010349
disc_loss: 2.1010349
disc_acc: 0.12549603174603174


	Epoch 19
Training results:
gen_loss: -2.1581597
disc_loss: 2.1581597
disc_acc: 0.1504950495049505

Validation results:
gen_loss: -2.5000684
disc_loss: 2.5000684
disc_acc: 0.1259920634920635


	Epoch 20
Training results:
gen_loss: -2.6646993
disc_loss: 2.6646993
disc_acc: 0.14294554455445543

Validation results:
gen_loss: -1.9985459
disc_loss: 1.9985459
disc_acc: 0.2544642857142857


	Epoch 21
Training results:
gen_loss: -2.3120537
disc_loss: 2.3120537
disc_acc: 0.17487623762376237

Validation results:
gen_loss: -2.0665965
disc_loss: 2.0665965
disc_acc: 0.19642857142857142


	Epoch 22
Training results:
gen_loss: -2.0566354
disc_loss: 2.0566354
disc_acc: 0.22871287128712872

Validation results:
gen_loss: -1.85668
disc_loss: 1.85668
disc_acc: 0.27132936507936506


	Epoch 23
Training results:
gen_loss: -1.9850467
disc_loss: 1.9850467
disc_acc: 0.22314356435643565

Validation results:
gen_loss: -2.033308
disc_loss: 2.033308
disc_acc: 0.2088293650793651


	Epoch 24
Training results:
gen_loss: -2.0523767
disc_loss: 2.0523767
disc_acc: 0.24245049504950494

Validation results:
gen_loss: -2.2767012
disc_loss: 2.2767012
disc_acc: 0.17410714285714285


	Epoch 25
Training results:
gen_loss: -2.0360959
disc_loss: 2.0360959
disc_acc: 0.235519801980198

Validation results:
gen_loss: -2.131386
disc_loss: 2.131386
disc_acc: 0.18700396825396826


	Epoch 26
Training results:
gen_loss: -2.0786393
disc_loss: 2.0786393
disc_acc: 0.21794554455445544

Validation results:
gen_loss: -2.1155474
disc_loss: 2.1155474
disc_acc: 0.23759920634920634


	Epoch 27
Training results:
gen_loss: -2.1559744
disc_loss: 2.1559744
disc_acc: 0.21435643564356435

Validation results:
gen_loss: -2.1419997
disc_loss: 2.1419997
disc_acc: 0.18898809523809523


	Epoch 28
Training results:
gen_loss: -2.0298772
disc_loss: 2.0298772
disc_acc: 0.2295792079207921

Validation results:
gen_loss: -1.9412495
disc_loss: 1.9412495
disc_acc: 0.19444444444444445


	Epoch 29
Training results:
gen_loss: -1.8962908
disc_loss: 1.8962908
disc_acc: 0.2396039603960396

Validation results:
gen_loss: -1.8594198
disc_loss: 1.8594198
disc_acc: 0.2524801587301587


	Epoch 30
Training results:
gen_loss: -2.0012991
disc_loss: 2.0012991
disc_acc: 0.250990099009901

Validation results:
gen_loss: -1.7953107
disc_loss: 1.7953107
disc_acc: 0.25396825396825395


	Epoch 31
Training results:
gen_loss: -2.0815158
disc_loss: 2.0815158
disc_acc: 0.201980198019802

Validation results:
gen_loss: -1.9452198
disc_loss: 1.9452198
disc_acc: 0.22123015873015872


	Epoch 32
Training results:
gen_loss: -2.1481006
disc_loss: 2.1481006
disc_acc: 0.14826732673267326

Validation results:
gen_loss: -2.1220741
disc_loss: 2.1220741
disc_acc: 0.10119047619047619


	Epoch 33
Training results:
gen_loss: -2.1244788
disc_loss: 2.1244788
disc_acc: 0.1400990099009901

Validation results:
gen_loss: -2.118636
disc_loss: 2.118636
disc_acc: 0.1488095238095238


	Epoch 34
Training results:
gen_loss: -2.142833
disc_loss: 2.142833
disc_acc: 0.13626237623762377

Validation results:
gen_loss: -2.1991365
disc_loss: 2.1991365
disc_acc: 0.12053571428571429


	Epoch 35
Training results:
gen_loss: -3.148554
disc_loss: 3.148554
disc_acc: 0.14492574257425742

Validation results:
gen_loss: -2.6186962
disc_loss: 2.6186962
disc_acc: 0.18551587301587302


	Epoch 36
Training results:
gen_loss: -1.9598194
disc_loss: 1.9598194
disc_acc: 0.19381188118811882

Validation results:
gen_loss: -1.8281316
disc_loss: 1.8281316
disc_acc: 0.19246031746031747


	Epoch 37
Training results:
gen_loss: -2.0606441
disc_loss: 2.0606441
disc_acc: 0.1948019801980198

Validation results:
gen_loss: -2.207206
disc_loss: 2.207206
disc_acc: 0.1597222222222222


	Epoch 38
Training results:
gen_loss: -2.1025264
disc_loss: 2.1025264
disc_acc: 0.19146039603960396

Validation results:
gen_loss: -2.1840668
disc_loss: 2.1840668
disc_acc: 0.12103174603174603


	Epoch 39
Training results:
gen_loss: -2.133006
disc_loss: 2.133006
disc_acc: 0.14579207920792078

Validation results:
gen_loss: -2.1096165
disc_loss: 2.1096165
disc_acc: 0.125


	Epoch 40
Training results:
gen_loss: -2.134203
disc_loss: 2.134203
disc_acc: 0.12141089108910891

Validation results:
gen_loss: -2.1425474
disc_loss: 2.1425474
disc_acc: 0.11160714285714286


	Epoch 41
Training results:
gen_loss: -2.1360495
disc_loss: 2.1360495
disc_acc: 0.12413366336633663

Validation results:
gen_loss: -2.122908
disc_loss: 2.122908
disc_acc: 0.11706349206349206


	Epoch 42
Training results:
gen_loss: -2.1425843
disc_loss: 2.1425843
disc_acc: 0.12524752475247525

Validation results:
gen_loss: -2.1282413
disc_loss: 2.1282413
disc_acc: 0.13392857142857142


	Epoch 43
Training results:
gen_loss: -2.1430767
disc_loss: 2.1430767
disc_acc: 0.1245049504950495

Validation results:
gen_loss: -2.1434166
disc_loss: 2.1434166
disc_acc: 0.11160714285714286


	Epoch 44
Training results:
gen_loss: -2.1487696
disc_loss: 2.1487696
disc_acc: 0.21027227722772276

Validation results:
gen_loss: -2.1285632
disc_loss: 2.1285632
disc_acc: 0.13392857142857142


	Epoch 45
Training results:
gen_loss: -2.1442585
disc_loss: 2.1442585
disc_acc: 0.19071782178217822

Validation results:
gen_loss: -2.111273
disc_loss: 2.111273
disc_acc: 0.17410714285714285


	Epoch 46
Training results:
gen_loss: -2.1383774
disc_loss: 2.1383774
disc_acc: 0.12883663366336634

Validation results:
gen_loss: -2.1092658
disc_loss: 2.1092658
disc_acc: 0.15873015873015872


	Epoch 47
Training results:
gen_loss: -2.0870845
disc_loss: 2.0870845
disc_acc: 0.19653465346534654

Validation results:
gen_loss: -1.9337374
disc_loss: 1.9337374
disc_acc: 0.27331349206349204


	Epoch 48
Training results:
gen_loss: -1.999492
disc_loss: 1.999492
disc_acc: 0.24455445544554455

Validation results:
gen_loss: -1.8378156
disc_loss: 1.8378156
disc_acc: 0.27827380952380953


	Epoch 49
Training results:
gen_loss: -2.0067945
disc_loss: 2.0067945
disc_acc: 0.23155940594059407

Validation results:
gen_loss: -1.996102
disc_loss: 1.996102
disc_acc: 0.2465277777777778


	Epoch 50
Training results:
gen_loss: -1.8663415
disc_loss: 1.8663415
disc_acc: 0.27772277227722775

Validation results:
gen_loss: -1.7916478
disc_loss: 1.7916478
disc_acc: 0.28521825396825395


	Epoch 51
Training results:
gen_loss: -2.0839362
disc_loss: 2.0839362
disc_acc: 0.20445544554455444

Validation results:
gen_loss: -2.0894113
disc_loss: 2.0894113
disc_acc: 0.14087301587301587


	Epoch 52
Training results:
gen_loss: -2.1214576
disc_loss: 2.1214576
disc_acc: 0.15284653465346534

Validation results:
gen_loss: -2.1173995
disc_loss: 2.1173995
disc_acc: 0.12698412698412698


	Epoch 53
Training results:
gen_loss: -2.1300466
disc_loss: 2.1300466
disc_acc: 0.125

Validation results:
gen_loss: -2.1208549
disc_loss: 2.1208549
disc_acc: 0.12797619047619047


	Epoch 54
Training results:
gen_loss: -2.1416185
disc_loss: 2.1416185
disc_acc: 0.13650990099009902

Validation results:
gen_loss: -2.4382377
disc_loss: 2.4382377
disc_acc: 0.13343253968253968


	Epoch 55
Training results:
gen_loss: -2.1057756
disc_loss: 2.1057756
disc_acc: 0.2349009900990099

Validation results:
gen_loss: -1.6979438
disc_loss: 1.6979438
disc_acc: 0.26884920634920634


	Epoch 56
Training results:
gen_loss: -1.8360944
disc_loss: 1.8360944
disc_acc: 0.26683168316831685

Validation results:
gen_loss: -1.9877533
disc_loss: 1.9877533
disc_acc: 0.2584325396825397


	Epoch 57
Training results:
gen_loss: -1.9061491
disc_loss: 1.9061491
disc_acc: 0.2474009900990099

Validation results:
gen_loss: -2.0000384
disc_loss: 2.0000384
disc_acc: 0.20238095238095238


	Epoch 58
Training results:
gen_loss: -1.9152063
disc_loss: 1.9152063
disc_acc: 0.25853960396039605

Validation results:
gen_loss: -2.245339
disc_loss: 2.245339
disc_acc: 0.13541666666666666


	Epoch 59
Training results:
gen_loss: -2.1465883
disc_loss: 2.1465883
disc_acc: 0.1568069306930693

Validation results:
gen_loss: -2.211377
disc_loss: 2.211377
disc_acc: 0.11607142857142858


	Epoch 60
Training results:
gen_loss: -2.121797
disc_loss: 2.121797
disc_acc: 0.13353960396039605

Validation results:
gen_loss: -2.1924863
disc_loss: 2.1924863
disc_acc: 0.16220238095238096


	Epoch 61
Training results:
gen_loss: -2.1774356
disc_loss: 2.1774356
disc_acc: 0.14888613861386138

Validation results:
gen_loss: -2.1585376
disc_loss: 2.1585376
disc_acc: 0.12053571428571429


	Epoch 62
Training results:
gen_loss: -2.198678
disc_loss: 2.198678
disc_acc: 0.15222772277227722

Validation results:
gen_loss: -2.1373634
disc_loss: 2.1373634
disc_acc: 0.12748015873015872


	Epoch 63
Training results:
gen_loss: -2.1229348
disc_loss: 2.1229348
disc_acc: 0.12834158415841584

Validation results:
gen_loss: -2.1031454
disc_loss: 2.1031454
disc_acc: 0.11259920634920635


	Epoch 64
Training results:
gen_loss: -2.1174703
disc_loss: 2.1174703
disc_acc: 0.12685643564356436

Validation results:
gen_loss: -2.0902123
disc_loss: 2.0902123
disc_acc: 0.11507936507936507


	Epoch 65
Training results:
gen_loss: -2.1281176
disc_loss: 2.1281176
disc_acc: 0.1297029702970297

Validation results:
gen_loss: -2.1557422
disc_loss: 2.1557422
disc_acc: 0.11607142857142858


	Epoch 66
Training results:
gen_loss: -2.1353478
disc_loss: 2.1353478
disc_acc: 0.12017326732673267

Validation results:
gen_loss: -2.184194
disc_loss: 2.184194
disc_acc: 0.12400793650793651


	Epoch 67
Training results:
gen_loss: -2.1815696
disc_loss: 2.1815696
disc_acc: 0.15334158415841584

Validation results:
gen_loss: -2.0658839
disc_loss: 2.0658839
disc_acc: 0.22321428571428573


	Epoch 68
Training results:
gen_loss: -2.0233443
disc_loss: 2.0233443
disc_acc: 0.2412128712871287

Validation results:
gen_loss: -1.9272935
disc_loss: 1.9272935
disc_acc: 0.20634920634920634


	Epoch 69
Training results:
gen_loss: -1.9646906
disc_loss: 1.9646906
disc_acc: 0.25594059405940595

Validation results:
gen_loss: -1.8387926
disc_loss: 1.8387926
disc_acc: 0.2648809523809524


	Epoch 70
Training results:
gen_loss: -1.9692959
disc_loss: 1.9692959
disc_acc: 0.24938118811881188

Validation results:
gen_loss: -2.0529823
disc_loss: 2.0529823
disc_acc: 0.21478174603174602


	Epoch 71
Training results:
gen_loss: -1.8175793
disc_loss: 1.8175793
disc_acc: 0.2957920792079208

Validation results:
gen_loss: -1.7873132
disc_loss: 1.7873132
disc_acc: 0.3005952380952381


	Epoch 72
Training results:
gen_loss: -2.0776758
disc_loss: 2.0776758
disc_acc: 0.22314356435643565

Validation results:
gen_loss: -1.7943645
disc_loss: 1.7943645
disc_acc: 0.2802579365079365


	Epoch 73
Training results:
gen_loss: -2.0101378
disc_loss: 2.0101378
disc_acc: 0.24108910891089108

Validation results:
gen_loss: -2.2036996
disc_loss: 2.2036996
disc_acc: 0.18204365079365079


	Epoch 74
Training results:
gen_loss: -2.0687153
disc_loss: 2.0687153
disc_acc: 0.21262376237623762

Validation results:
gen_loss: -2.0995154
disc_loss: 2.0995154
disc_acc: 0.28125


	Epoch 75
Training results:
gen_loss: -2.0121608
disc_loss: 2.0121608
disc_acc: 0.24826732673267327

Validation results:
gen_loss: -2.129629
disc_loss: 2.129629
disc_acc: 0.2058531746031746


	Epoch 76
Training results:
gen_loss: -2.2475188
disc_loss: 2.2475188
disc_acc: 0.15655940594059406

Validation results:
gen_loss: -2.2205086
disc_loss: 2.2205086
disc_acc: 0.16319444444444445


	Epoch 77
Training results:
gen_loss: -2.2540097
disc_loss: 2.2540097
disc_acc: 0.12821782178217822

Validation results:
gen_loss: -2.2870219
disc_loss: 2.2870219
disc_acc: 0.1284722222222222


	Epoch 78
Training results:
gen_loss: -2.25918
disc_loss: 2.25918
disc_acc: 0.1275990099009901

Validation results:
gen_loss: -2.3020864
disc_loss: 2.3020864
disc_acc: 0.12450396825396826


	Epoch 79
Training results:
gen_loss: -2.253107
disc_loss: 2.253107
disc_acc: 0.13873762376237625

Validation results:
gen_loss: -2.2617126
disc_loss: 2.2617126
disc_acc: 0.17162698412698413


	Epoch 80
Training results:
gen_loss: -2.2709575
disc_loss: 2.2709575
disc_acc: 0.14492574257425742

Validation results:
gen_loss: -2.3141112
disc_loss: 2.3141112
disc_acc: 0.15823412698412698


	Epoch 81
Training results:
gen_loss: -2.2657619
disc_loss: 2.2657619
disc_acc: 0.13316831683168318

Validation results:
gen_loss: -2.2254517
disc_loss: 2.2254517
disc_acc: 0.14434523809523808


	Epoch 82
Training results:
gen_loss: -2.252832
disc_loss: 2.252832
disc_acc: 0.13032178217821783

Validation results:
gen_loss: -2.1844575
disc_loss: 2.1844575
disc_acc: 0.18601190476190477


	Epoch 83
Training results:
gen_loss: -2.2665842
disc_loss: 2.2665842
disc_acc: 0.1342821782178218

Validation results:
gen_loss: -2.2660809
disc_loss: 2.2660809
disc_acc: 0.12996031746031747


	Epoch 84
Training results:
gen_loss: -2.2511463
disc_loss: 2.2511463
disc_acc: 0.12277227722772277

Validation results:
gen_loss: -2.237853
disc_loss: 2.237853
disc_acc: 0.13640873015873015


	Epoch 85
Training results:
gen_loss: -2.246231
disc_loss: 2.246231
disc_acc: 0.12425742574257426

Validation results:
gen_loss: -2.2368073
disc_loss: 2.2368073
disc_acc: 0.1259920634920635


	Epoch 86
Training results:
gen_loss: -2.2639494
disc_loss: 2.2639494
disc_acc: 0.1264851485148515

Validation results:
gen_loss: -2.2849963
disc_loss: 2.2849963
disc_acc: 0.12053571428571429


	Epoch 87
Training results:
gen_loss: -2.2559423
disc_loss: 2.2559423
disc_acc: 0.125

Validation results:
gen_loss: -2.271974
disc_loss: 2.271974
disc_acc: 0.13740079365079366


	Epoch 88
Training results:
gen_loss: -2.2824316
disc_loss: 2.2824316
disc_acc: 0.12945544554455446

Validation results:
gen_loss: -2.3635476
disc_loss: 2.3635476
disc_acc: 0.11755952380952381


	Epoch 89
Training results:
gen_loss: -2.2757053
disc_loss: 2.2757053
disc_acc: 0.12685643564356436

Validation results:
gen_loss: -2.2535505
disc_loss: 2.2535505
disc_acc: 0.10962301587301587


	Epoch 90
Training results:
gen_loss: -2.2597106
disc_loss: 2.2597106
disc_acc: 0.12871287128712872

Validation results:
gen_loss: -2.2950304
disc_loss: 2.2950304
disc_acc: 0.12946428571428573


	Epoch 91
Training results:
gen_loss: -2.2646456
disc_loss: 2.2646456
disc_acc: 0.13131188118811882

Validation results:
gen_loss: -2.2676787
disc_loss: 2.2676787
disc_acc: 0.11507936507936507


	Epoch 92
Training results:
gen_loss: -2.2561722
disc_loss: 2.2561722
disc_acc: 0.12623762376237624

Validation results:
gen_loss: -2.2180696
disc_loss: 2.2180696
disc_acc: 0.14682539682539683


	Epoch 93
Training results:
gen_loss: -2.2618322
disc_loss: 2.2618322
disc_acc: 0.1342821782178218

Validation results:
gen_loss: -2.252806
disc_loss: 2.252806
disc_acc: 0.12251984126984126


	Epoch 94
Training results:
gen_loss: -2.2635663
disc_loss: 2.2635663
disc_acc: 0.12797029702970297

Validation results:
gen_loss: -2.2638528
disc_loss: 2.2638528
disc_acc: 0.12152777777777778


	Epoch 95
Training results:
gen_loss: -2.2379148
disc_loss: 2.2379148
disc_acc: 0.1297029702970297

Validation results:
gen_loss: -2.2519412
disc_loss: 2.2519412
disc_acc: 0.12003968253968254


	Epoch 96
Training results:
gen_loss: -2.3093827
disc_loss: 2.3093827
disc_acc: 0.12153465346534653

Validation results:
gen_loss: -2.2709422
disc_loss: 2.2709422
disc_acc: 0.1527777777777778


	Epoch 97
Training results:
gen_loss: -2.2698922
disc_loss: 2.2698922
disc_acc: 0.13465346534653466

Validation results:
gen_loss: -2.2609618
disc_loss: 2.2609618
disc_acc: 0.11805555555555555


	Epoch 98
Training results:
gen_loss: -2.2665865
disc_loss: 2.2665865
disc_acc: 0.13366336633663367

Validation results:
gen_loss: -2.2859979
disc_loss: 2.2859979
disc_acc: 0.13442460317460317


	Epoch 99
Training results:
gen_loss: -2.2985451
disc_loss: 2.2985451
disc_acc: 0.12846534653465347

Validation results:
gen_loss: -2.2296774
disc_loss: 2.2296774
disc_acc: 0.1259920634920635


	Epoch 100
Training results:
gen_loss: -2.255351
disc_loss: 2.255351
disc_acc: 0.1292079207920792

Validation results:
gen_loss: -2.2631233
disc_loss: 2.2631233
disc_acc: 0.1185515873015873


	Epoch 101
Training results:
gen_loss: -2.2469547
disc_loss: 2.2469547
disc_acc: 0.12141089108910891

Validation results:
gen_loss: -2.2495835
disc_loss: 2.2495835
disc_acc: 0.11557539682539683


	Epoch 102
Training results:
gen_loss: -2.2578776
disc_loss: 2.2578776
disc_acc: 0.1271039603960396

Validation results:
gen_loss: -2.2190256
disc_loss: 2.2190256
disc_acc: 0.1453373015873016


	Epoch 103
Training results:
gen_loss: -2.292301
disc_loss: 2.292301
disc_acc: 0.12883663366336634

Validation results:
gen_loss: -2.2573614
disc_loss: 2.2573614
disc_acc: 0.12549603174603174


	Epoch 104
Training results:
gen_loss: -2.2413058
disc_loss: 2.2413058
disc_acc: 0.1290841584158416

Validation results:
gen_loss: -2.2957544
disc_loss: 2.2957544
disc_acc: 0.12053571428571429


	Epoch 105
Training results:
gen_loss: -2.2650952
disc_loss: 2.2650952
disc_acc: 0.15655940594059406

Validation results:
gen_loss: -2.0131488
disc_loss: 2.0131488
disc_acc: 0.22916666666666666


	Epoch 106
Training results:
gen_loss: -2.0329013
disc_loss: 2.0329013
disc_acc: 0.2316831683168317

Validation results:
gen_loss: -1.9533912
disc_loss: 1.9533912
disc_acc: 0.21279761904761904


	Epoch 107
Training results:
gen_loss: -1.9764037
disc_loss: 1.9764037
disc_acc: 0.23193069306930694

Validation results:
gen_loss: -1.8333818
disc_loss: 1.8333818
disc_acc: 0.25744047619047616


	Epoch 108
Training results:
gen_loss: -1.925542
disc_loss: 1.925542
disc_acc: 0.24084158415841583

Validation results:
gen_loss: -2.1223276
disc_loss: 2.1223276
disc_acc: 0.20684523809523808


	Epoch 109
Training results:
gen_loss: -2.0715673
disc_loss: 2.0715673
disc_acc: 0.1650990099009901

Validation results:
gen_loss: -1.8192651
disc_loss: 1.8192651
disc_acc: 0.24107142857142858


	Epoch 110
Training results:
gen_loss: -2.0934052
disc_loss: 2.0934052
disc_acc: 0.15346534653465346

Validation results:
gen_loss: -2.1327229
disc_loss: 2.1327229
disc_acc: 0.12698412698412698


	Epoch 111
Training results:
gen_loss: -2.127186
disc_loss: 2.127186
disc_acc: 0.13836633663366338

Validation results:
gen_loss: -2.256093
disc_loss: 2.256093
disc_acc: 0.10367063492063493


	Epoch 112
Training results:
gen_loss: -2.134402
disc_loss: 2.134402
disc_acc: 0.14665841584158415

Validation results:
gen_loss: -2.2019548
disc_loss: 2.2019548
disc_acc: 0.11160714285714286


	Epoch 113
Training results:
gen_loss: -2.142781
disc_loss: 2.142781
disc_acc: 0.13452970297029704

Validation results:
gen_loss: -2.1039774
disc_loss: 2.1039774
disc_acc: 0.13640873015873015


	Epoch 114
Training results:
gen_loss: -2.1221273
disc_loss: 2.1221273
disc_acc: 0.12314356435643564

Validation results:
gen_loss: -2.100022
disc_loss: 2.100022
disc_acc: 0.12748015873015872


	Epoch 115
Training results:
gen_loss: -2.1389213
disc_loss: 2.1389213
disc_acc: 0.11794554455445544

Validation results:
gen_loss: -2.1421678
disc_loss: 2.1421678
disc_acc: 0.13690476190476192


	Epoch 116
Training results:
gen_loss: -2.132754
disc_loss: 2.132754
disc_acc: 0.12586633663366337

Validation results:
gen_loss: -2.1073902
disc_loss: 2.1073902
disc_acc: 0.1314484126984127


	Epoch 117
Training results:
gen_loss: -2.1327157
disc_loss: 2.1327157
disc_acc: 0.1349009900990099

Validation results:
gen_loss: -2.0552983
disc_loss: 2.0552983
disc_acc: 0.19295634920634921


	Epoch 118
Training results:
gen_loss: -2.168422
disc_loss: 2.168422
disc_acc: 0.13551980198019803

Validation results:
gen_loss: -2.1528559
disc_loss: 2.1528559
disc_acc: 0.11607142857142858


	Epoch 119
Training results:
gen_loss: -2.1317785
disc_loss: 2.1317785
disc_acc: 0.1219059405940594

Validation results:
gen_loss: -2.1283996
disc_loss: 2.1283996
disc_acc: 0.12946428571428573


	Epoch 120
Training results:
gen_loss: -2.1331065
disc_loss: 2.1331065
disc_acc: 0.1275990099009901

Validation results:
gen_loss: -2.1332595
disc_loss: 2.1332595
disc_acc: 0.1185515873015873


	Epoch 121
Training results:
gen_loss: -2.1477954
disc_loss: 2.1477954
disc_acc: 0.12252475247524752

Validation results:
gen_loss: -2.1489205
disc_loss: 2.1489205
disc_acc: 0.12103174603174603


	Epoch 122
Training results:
gen_loss: -2.1578946
disc_loss: 2.1578946
disc_acc: 0.12165841584158416

Validation results:
gen_loss: -2.0987024
disc_loss: 2.0987024
disc_acc: 0.11706349206349206


	Epoch 123
Training results:
gen_loss: -2.1467419
disc_loss: 2.1467419
disc_acc: 0.12351485148514851

Validation results:
gen_loss: -2.1140654
disc_loss: 2.1140654
disc_acc: 0.14434523809523808


	Epoch 124
Training results:
gen_loss: -2.1355119
disc_loss: 2.1355119
disc_acc: 0.1280940594059406

Validation results:
gen_loss: -2.1076806
disc_loss: 2.1076806
disc_acc: 0.13392857142857142


	Epoch 125
Training results:
gen_loss: -2.1358933
disc_loss: 2.1358933
disc_acc: 0.12363861386138614

Validation results:
gen_loss: -2.0949535
disc_loss: 2.0949535
disc_acc: 0.12400793650793651


	Epoch 126
Training results:
gen_loss: -2.1417418
disc_loss: 2.1417418
disc_acc: 0.12747524752475248

Validation results:
gen_loss: -2.1690097
disc_loss: 2.1690097
disc_acc: 0.11557539682539683


	Epoch 127
Training results:
gen_loss: -2.1204216
disc_loss: 2.1204216
disc_acc: 0.125990099009901

Validation results:
gen_loss: -2.0906255
disc_loss: 2.0906255
disc_acc: 0.12400793650793651


	Epoch 128
Training results:
gen_loss: -2.139558
disc_loss: 2.139558
disc_acc: 0.1297029702970297

Validation results:
gen_loss: -2.102058
disc_loss: 2.102058
disc_acc: 0.1349206349206349


	Epoch 129
Training results:
gen_loss: -2.1336489
disc_loss: 2.1336489
disc_acc: 0.12091584158415841

Validation results:
gen_loss: -2.1475542
disc_loss: 2.1475542
disc_acc: 0.12103174603174603


	Epoch 130
Training results:
gen_loss: -2.1259336
disc_loss: 2.1259336
disc_acc: 0.12933168316831684

Validation results:
gen_loss: -2.1406562
disc_loss: 2.1406562
disc_acc: 0.1453373015873016


	Epoch 131
Training results:
gen_loss: -2.1495237
disc_loss: 2.1495237
disc_acc: 0.13551980198019803

Validation results:
gen_loss: -2.240926
disc_loss: 2.240926
disc_acc: 0.11259920634920635


	Epoch 132
Training results:
gen_loss: -2.129426
disc_loss: 2.129426
disc_acc: 0.12314356435643564

Validation results:
gen_loss: -2.1559935
disc_loss: 2.1559935
disc_acc: 0.1185515873015873


	Epoch 133
Training results:
gen_loss: -2.124746
disc_loss: 2.124746
disc_acc: 0.12326732673267327

Validation results:
gen_loss: -2.0976365
disc_loss: 2.0976365
disc_acc: 0.13392857142857142


	Epoch 134
Training results:
gen_loss: -2.1303046
disc_loss: 2.1303046
disc_acc: 0.12896039603960396

Validation results:
gen_loss: -2.114877
disc_loss: 2.114877
disc_acc: 0.12748015873015872


	Epoch 135
Training results:
gen_loss: -2.1377976
disc_loss: 2.1377976
disc_acc: 0.11893564356435643

Validation results:
gen_loss: -2.15567
disc_loss: 2.15567
disc_acc: 0.1314484126984127


	Epoch 136
Training results:
gen_loss: -2.1438756
disc_loss: 2.1438756
disc_acc: 0.12116336633663366

Validation results:
gen_loss: -2.1686625
disc_loss: 2.1686625
disc_acc: 0.12053571428571429


	Epoch 137
Training results:
gen_loss: -2.1374142
disc_loss: 2.1374142
disc_acc: 0.12821782178217822

Validation results:
gen_loss: -2.1094947
disc_loss: 2.1094947
disc_acc: 0.13343253968253968


	Epoch 138
Training results:
gen_loss: -2.1397233
disc_loss: 2.1397233
disc_acc: 0.14975247524752475

Validation results:
gen_loss: -1.9515847
disc_loss: 1.9515847
disc_acc: 0.3030753968253968


	Epoch 139
Training results:
gen_loss: -1.790997
disc_loss: 1.790997
disc_acc: 0.27561881188118814

Validation results:
gen_loss: -1.6301502
disc_loss: 1.6301502
disc_acc: 0.3343253968253968


	Epoch 140
Training results:
gen_loss: -2.9521525
disc_loss: 2.9521525
disc_acc: 0.23626237623762375

Validation results:
gen_loss: -1.6820496
disc_loss: 1.6820496
disc_acc: 0.2748015873015873


	Epoch 141
Training results:
gen_loss: -1.8757553
disc_loss: 1.8757553
disc_acc: 0.23886138613861385

Validation results:
gen_loss: -1.8137329
disc_loss: 1.8137329
disc_acc: 0.2544642857142857


	Epoch 142
Training results:
gen_loss: -1.881932
disc_loss: 1.881932
disc_acc: 0.22896039603960397

Validation results:
gen_loss: -1.8755562
disc_loss: 1.8755562
disc_acc: 0.20982142857142858


	Epoch 143
Training results:
gen_loss: -1.784115
disc_loss: 1.784115
disc_acc: 0.27512376237623765

Validation results:
gen_loss: -1.5853956
disc_loss: 1.5853956
disc_acc: 0.3958333333333333


	Epoch 144
Training results:
gen_loss: -1.6291845
disc_loss: 1.6291845
disc_acc: 0.3097772277227723

Validation results:
gen_loss: -1.6703023
disc_loss: 1.6703023
disc_acc: 0.310515873015873


	Epoch 145
Training results:
gen_loss: -1.6303774
disc_loss: 1.6303774
disc_acc: 0.31472772277227723

Validation results:
gen_loss: -1.4774214
disc_loss: 1.4774214
disc_acc: 0.37797619047619047


	Epoch 146
Training results:
gen_loss: -1.7396917
disc_loss: 1.7396917
disc_acc: 0.2912128712871287

Validation results:
gen_loss: -1.6000248
disc_loss: 1.6000248
disc_acc: 0.31299603174603174


	Epoch 147
Training results:
gen_loss: -1.7525951
disc_loss: 1.7525951
disc_acc: 0.299009900990099

Validation results:
gen_loss: -1.7694088
disc_loss: 1.7694088
disc_acc: 0.27132936507936506


	Epoch 148
Training results:
gen_loss: -1.830805
disc_loss: 1.830805
disc_acc: 0.25655940594059407

Validation results:
gen_loss: -1.9760422
disc_loss: 1.9760422
disc_acc: 0.2867063492063492


	Epoch 149
Training results:
gen_loss: -1.7789757
disc_loss: 1.7789757
disc_acc: 0.2727722772277228

Validation results:
gen_loss: -1.4919628
disc_loss: 1.4919628
disc_acc: 0.34375


	Epoch 150
Training results:
gen_loss: -1.9449475
disc_loss: 1.9449475
disc_acc: 0.2131188118811881

Validation results:
gen_loss: -1.6884587
disc_loss: 1.6884587
disc_acc: 0.3100198412698413


	Epoch 151
Training results:
gen_loss: -1.7548574
disc_loss: 1.7548574
disc_acc: 0.2918316831683168

Validation results:
gen_loss: -1.7531519
disc_loss: 1.7531519
disc_acc: 0.28273809523809523


	Epoch 152
Training results:
gen_loss: -1.7654396
disc_loss: 1.7654396
disc_acc: 0.29257425742574256

Validation results:
gen_loss: -1.5217212
disc_loss: 1.5217212
disc_acc: 0.3318452380952381


	Epoch 153
Training results:
gen_loss: -1.7123555
disc_loss: 1.7123555
disc_acc: 0.30185643564356435

Validation results:
gen_loss: -1.3883313
disc_loss: 1.3883313
disc_acc: 0.3655753968253968


	Epoch 154
Training results:
gen_loss: -1.5400335
disc_loss: 1.5400335
disc_acc: 0.27363861386138616

Validation results:
gen_loss: -1.4500105
disc_loss: 1.4500105
disc_acc: 0.2683531746031746


	Epoch 155
Training results:
gen_loss: -1.4847863
disc_loss: 1.4847863
disc_acc: 0.25742574257425743

Validation results:
gen_loss: -1.5865953
disc_loss: 1.5865953
disc_acc: 0.2435515873015873


	Epoch 156
Training results:
gen_loss: -1.7866939
disc_loss: 1.7866939
disc_acc: 0.21633663366336633

Validation results:
gen_loss: -1.9340388
disc_loss: 1.9340388
disc_acc: 0.18700396825396826


	Epoch 157
Training results:
gen_loss: -1.817796
disc_loss: 1.817796
disc_acc: 0.1889851485148515

Validation results:
gen_loss: -1.8535311
disc_loss: 1.8535311
disc_acc: 0.21825396825396826


	Epoch 158
Training results:
gen_loss: -1.8545167
disc_loss: 1.8545167
disc_acc: 0.2030940594059406

Validation results:
gen_loss: -1.8316596
disc_loss: 1.8316596
disc_acc: 0.1884920634920635


	Epoch 159
Training results:
gen_loss: -1.8067751
disc_loss: 1.8067751
disc_acc: 0.2321782178217822

Validation results:
gen_loss: -1.8139157
disc_loss: 1.8139157
disc_acc: 0.22817460317460317


	Epoch 160
Training results:
gen_loss: -1.7955003
disc_loss: 1.7955003
disc_acc: 0.22995049504950496

Validation results:
gen_loss: -1.7855022
disc_loss: 1.7855022
disc_acc: 0.27827380952380953


	Epoch 161
Training results:
gen_loss: -1.7953918
disc_loss: 1.7953918
disc_acc: 0.2459158415841584

Validation results:
gen_loss: -1.8983731
disc_loss: 1.8983731
disc_acc: 0.18154761904761904


	Epoch 162
Training results:
gen_loss: -1.7830588
disc_loss: 1.7830588
disc_acc: 0.23688118811881187

Validation results:
gen_loss: -1.7973698
disc_loss: 1.7973698
disc_acc: 0.23015873015873015


	Epoch 163
Training results:
gen_loss: -1.8234836
disc_loss: 1.8234836
disc_acc: 0.19071782178217822

Validation results:
gen_loss: -1.8380128
disc_loss: 1.8380128
disc_acc: 0.1974206349206349


	Epoch 164
Training results:
gen_loss: -1.8100477
disc_loss: 1.8100477
disc_acc: 0.18688118811881188

Validation results:
gen_loss: -1.8021375
disc_loss: 1.8021375
disc_acc: 0.18799603174603174


	Epoch 165
Training results:
gen_loss: -1.7874577
disc_loss: 1.7874577
disc_acc: 0.18725247524752475

Validation results:
gen_loss: -1.785052
disc_loss: 1.785052
disc_acc: 0.1884920634920635


	Epoch 166
Training results:
gen_loss: -1.8448445
disc_loss: 1.8448445
disc_acc: 0.18935643564356436

Validation results:
gen_loss: -1.833322
disc_loss: 1.833322
disc_acc: 0.19593253968253968


	Epoch 167
Training results:
gen_loss: -1.8187449
disc_loss: 1.8187449
disc_acc: 0.18935643564356436

Validation results:
gen_loss: -1.7920169
disc_loss: 1.7920169
disc_acc: 0.18898809523809523


	Epoch 168
Training results:
gen_loss: -1.8676597
disc_loss: 1.8676597
disc_acc: 0.20804455445544554

Validation results:
gen_loss: -1.7733921
disc_loss: 1.7733921
disc_acc: 0.20238095238095238


	Epoch 169
Training results:
gen_loss: -1.8161227
disc_loss: 1.8161227
disc_acc: 0.18712871287128713

Validation results:
gen_loss: -1.8279445
disc_loss: 1.8279445
disc_acc: 0.19642857142857142


	Epoch 170
Training results:
gen_loss: -1.8168678
disc_loss: 1.8168678
disc_acc: 0.1806930693069307

Validation results:
gen_loss: -1.7800528
disc_loss: 1.7800528
disc_acc: 0.20188492063492064


	Epoch 171
Training results:
gen_loss: -1.8464894
disc_loss: 1.8464894
disc_acc: 0.1860148514851485

Validation results:
gen_loss: -1.7975553
disc_loss: 1.7975553
disc_acc: 0.17261904761904762


	Epoch 172
Training results:
gen_loss: -1.7817036
disc_loss: 1.7817036
disc_acc: 0.17809405940594059

Validation results:
gen_loss: -1.8206965
disc_loss: 1.8206965
disc_acc: 0.20734126984126985


	Epoch 173
Training results:
gen_loss: -1.8034042
disc_loss: 1.8034042
disc_acc: 0.19975247524752476

Validation results:
gen_loss: -1.7807901
disc_loss: 1.7807901
disc_acc: 0.19940476190476192


	Epoch 174
Training results:
gen_loss: -1.8317443
disc_loss: 1.8317443
disc_acc: 0.23688118811881187

Validation results:
gen_loss: -2.023608
disc_loss: 2.023608
disc_acc: 0.1765873015873016


	Epoch 175
Training results:
gen_loss: -1.8390162
disc_loss: 1.8390162
disc_acc: 0.19517326732673268

Validation results:
gen_loss: -1.766512
disc_loss: 1.766512
disc_acc: 0.20238095238095238


	Epoch 176
Training results:
gen_loss: -1.7886544
disc_loss: 1.7886544
disc_acc: 0.1870049504950495

Validation results:
gen_loss: -1.877569
disc_loss: 1.877569
disc_acc: 0.17807539682539683


	Epoch 177
Training results:
gen_loss: -1.8026457
disc_loss: 1.8026457
disc_acc: 0.18056930693069306

Validation results:
gen_loss: -1.7946762
disc_loss: 1.7946762
disc_acc: 0.17807539682539683


	Epoch 178
Training results:
gen_loss: -1.9136523
disc_loss: 1.9136523
disc_acc: 0.22883663366336635

Validation results:
gen_loss: -1.8913925
disc_loss: 1.8913925
disc_acc: 0.30257936507936506


	Epoch 179
Training results:
gen_loss: -1.917561
disc_loss: 1.917561
disc_acc: 0.2620049504950495

Validation results:
gen_loss: -1.9648174
disc_loss: 1.9648174
disc_acc: 0.18601190476190477


	Epoch 180
Training results:
gen_loss: -1.8418795
disc_loss: 1.8418795
disc_acc: 0.2662128712871287

Validation results:
gen_loss: -1.7946131
disc_loss: 1.7946131
disc_acc: 0.28720238095238093


	Epoch 181
Training results:
gen_loss: -1.844174
disc_loss: 1.844174
disc_acc: 0.2801980198019802

Validation results:
gen_loss: -1.7633244
disc_loss: 1.7633244
disc_acc: 0.3040674603174603


	Epoch 182
Training results:
gen_loss: -2.2676094
disc_loss: 2.2676094
disc_acc: 0.26212871287128714

Validation results:
gen_loss: -1.7281188
disc_loss: 1.7281188
disc_acc: 0.22023809523809523


	Epoch 183
Training results:
gen_loss: -1.8951426
disc_loss: 1.8951426
disc_acc: 0.25742574257425743

Validation results:
gen_loss: -2.0587308
disc_loss: 2.0587308
disc_acc: 0.14037698412698413


	Epoch 184
Training results:
gen_loss: -1.8659058
disc_loss: 1.8659058
disc_acc: 0.27202970297029705

Validation results:
gen_loss: -2.1995726
disc_loss: 2.1995726
disc_acc: 0.27728174603174605


	Epoch 185
Training results:
gen_loss: -2.0838044
disc_loss: 2.0838044
disc_acc: 0.25544554455445545

Validation results:
gen_loss: -2.096671
disc_loss: 2.096671
disc_acc: 0.2594246031746032


	Epoch 186
Training results:
gen_loss: -1.9957159
disc_loss: 1.9957159
disc_acc: 0.2332920792079208

Validation results:
gen_loss: -2.0138526
disc_loss: 2.0138526
disc_acc: 0.22172619047619047


	Epoch 187
Training results:
gen_loss: -2.207981
disc_loss: 2.207981
disc_acc: 0.21806930693069307

Validation results:
gen_loss: -2.28165
disc_loss: 2.28165
disc_acc: 0.23412698412698413


	Epoch 188
Training results:
gen_loss: -2.2850597
disc_loss: 2.2850597
disc_acc: 0.21472772277227722

Validation results:
gen_loss: -1.871936
disc_loss: 1.871936
disc_acc: 0.26686507936507936


	Epoch 189
Training results:
gen_loss: -1.9936328
disc_loss: 1.9936328
disc_acc: 0.23230198019801981

Validation results:
gen_loss: -1.8536814
disc_loss: 1.8536814
disc_acc: 0.3318452380952381


	Epoch 190
Training results:
gen_loss: -1.9130511
disc_loss: 1.9130511
disc_acc: 0.2680693069306931

Validation results:
gen_loss: -2.060189
disc_loss: 2.060189
disc_acc: 0.19196428571428573


	Epoch 191
Training results:
gen_loss: -2.031769
disc_loss: 2.031769
disc_acc: 0.252970297029703

Validation results:
gen_loss: -2.178283
disc_loss: 2.178283
disc_acc: 0.1865079365079365


	Epoch 192
Training results:
gen_loss: -2.1348815
disc_loss: 2.1348815
disc_acc: 0.2228960396039604

Validation results:
gen_loss: -2.0365481
disc_loss: 2.0365481
disc_acc: 0.2435515873015873


	Epoch 193
Training results:
gen_loss: -2.0617537
disc_loss: 2.0617537
disc_acc: 0.2311881188118812

Validation results:
gen_loss: -1.9856907
disc_loss: 1.9856907
disc_acc: 0.2261904761904762


	Epoch 194
Training results:
gen_loss: -2.0657744
disc_loss: 2.0657744
disc_acc: 0.22636138613861387

Validation results:
gen_loss: -2.1306987
disc_loss: 2.1306987
disc_acc: 0.19692460317460317


	Epoch 195
Training results:
gen_loss: -1.9333346
disc_loss: 1.9333346
disc_acc: 0.2592821782178218

Validation results:
gen_loss: -2.076415
disc_loss: 2.076415
disc_acc: 0.20982142857142858


	Epoch 196
Training results:
gen_loss: -2.0361402
disc_loss: 2.0361402
disc_acc: 0.20408415841584157

Validation results:
gen_loss: -2.0427842
disc_loss: 2.0427842
disc_acc: 0.17063492063492064


	Epoch 197
Training results:
gen_loss: -2.08565
disc_loss: 2.08565
disc_acc: 0.16225247524752476

Validation results:
gen_loss: -2.0840156
disc_loss: 2.0840156
disc_acc: 0.12748015873015872


	Epoch 198
Training results:
gen_loss: -2.098012
disc_loss: 2.098012
disc_acc: 0.15173267326732673

Validation results:
gen_loss: -2.1238618
disc_loss: 2.1238618
disc_acc: 0.17162698412698413


	Epoch 199
Training results:
gen_loss: -2.1246207
disc_loss: 2.1246207
disc_acc: 0.1290841584158416

Validation results:
gen_loss: -2.1250696
disc_loss: 2.1250696
disc_acc: 0.1324404761904762


	Epoch 200
Training results:
gen_loss: -2.1274858
disc_loss: 2.1274858
disc_acc: 0.13415841584158417

Validation results:
gen_loss: -2.1005795
disc_loss: 2.1005795
disc_acc: 0.13988095238095238


	Epoch 201
Training results:
gen_loss: -2.1339483
disc_loss: 2.1339483
disc_acc: 0.12586633663366337

Validation results:
gen_loss: -2.133733
disc_loss: 2.133733
disc_acc: 0.12351190476190477


	Epoch 202
Training results:
gen_loss: -2.141649
disc_loss: 2.141649
disc_acc: 0.12128712871287128

Validation results:
gen_loss: -2.128595
disc_loss: 2.128595
disc_acc: 0.13343253968253968


	Epoch 203
Training results:
gen_loss: -2.1531816
disc_loss: 2.1531816
disc_acc: 0.1297029702970297

Validation results:
gen_loss: -2.126978
disc_loss: 2.126978
disc_acc: 0.11706349206349206


	Epoch 204
Training results:
gen_loss: -2.1299374
disc_loss: 2.1299374
disc_acc: 0.1219059405940594

Validation results:
gen_loss: -2.1236389
disc_loss: 2.1236389
disc_acc: 0.11557539682539683


	Epoch 205
Training results:
gen_loss: -2.1462066
disc_loss: 2.1462066
disc_acc: 0.12982673267326733

Validation results:
gen_loss: -2.1775217
disc_loss: 2.1775217
disc_acc: 0.12251984126984126


	Epoch 206
Training results:
gen_loss: -2.147144
disc_loss: 2.147144
disc_acc: 0.13267326732673268

Validation results:
gen_loss: -2.2583776
disc_loss: 2.2583776
disc_acc: 0.15079365079365079


	Epoch 207
Training results:
gen_loss: -2.144747
disc_loss: 2.144747
disc_acc: 0.12797029702970297

Validation results:
gen_loss: -2.1284506
disc_loss: 2.1284506
disc_acc: 0.14434523809523808


	Epoch 208
Training results:
gen_loss: -2.1228535
disc_loss: 2.1228535
disc_acc: 0.12871287128712872

Validation results:
gen_loss: -2.1308215
disc_loss: 2.1308215
disc_acc: 0.12946428571428573


	Epoch 209
Training results:
gen_loss: -2.144629
disc_loss: 2.144629
disc_acc: 0.12363861386138614

Validation results:
gen_loss: -2.143695
disc_loss: 2.143695
disc_acc: 0.11805555555555555


	Epoch 210
Training results:
gen_loss: -2.1028197
disc_loss: 2.1028197
disc_acc: 0.23353960396039605

Validation results:
gen_loss: -1.8849286
disc_loss: 1.8849286
disc_acc: 0.2673611111111111


	Epoch 211
Training results:
gen_loss: -2.022173
disc_loss: 2.022173
disc_acc: 0.2426980198019802

Validation results:
gen_loss: -1.8764426
disc_loss: 1.8764426
disc_acc: 0.33283730158730157


	Epoch 212
Training results:
gen_loss: -1.9981766
disc_loss: 1.9981766
disc_acc: 0.2459158415841584

Validation results:
gen_loss: -1.9163841
disc_loss: 1.9163841
disc_acc: 0.24751984126984128


	Epoch 213
Training results:
gen_loss: -1.9940763
disc_loss: 1.9940763
disc_acc: 0.24133663366336633

Validation results:
gen_loss: -2.065509
disc_loss: 2.065509
disc_acc: 0.24454365079365079


	Epoch 214
Training results:
gen_loss: -2.0334163
disc_loss: 2.0334163
disc_acc: 0.23613861386138613

Validation results:
gen_loss: -2.0637946
disc_loss: 2.0637946
disc_acc: 0.2251984126984127


	Epoch 215
Training results:
gen_loss: -2.0533025
disc_loss: 2.0533025
disc_acc: 0.24702970297029703

Validation results:
gen_loss: -2.0776896
disc_loss: 2.0776896
disc_acc: 0.21478174603174602


	Epoch 216
Training results:
gen_loss: -2.024048
disc_loss: 2.024048
disc_acc: 0.22252475247524753

Validation results:
gen_loss: -3.4099247
disc_loss: 3.4099247
disc_acc: 0.06448412698412699


	Epoch 217
Training results:
gen_loss: -2.184671
disc_loss: 2.184671
disc_acc: 0.20965346534653465

Validation results:
gen_loss: -1.9652139
disc_loss: 1.9652139
disc_acc: 0.23065476190476192


	Epoch 218
Training results:
gen_loss: -2.277644
disc_loss: 2.277644
disc_acc: 0.1962871287128713

Validation results:
gen_loss: -2.025233
disc_loss: 2.025233
disc_acc: 0.18055555555555555


	Epoch 219
Training results:
gen_loss: -2.2076705
disc_loss: 2.2076705
disc_acc: 0.19084158415841584

Validation results:
gen_loss: -2.3438218
disc_loss: 2.3438218
disc_acc: 0.19890873015873015


	Epoch 220
Training results:
gen_loss: -2.3254626
disc_loss: 2.3254626
disc_acc: 0.19504950495049506

Validation results:
gen_loss: -2.3998039
disc_loss: 2.3998039
disc_acc: 0.14434523809523808


	Epoch 221
Training results:
gen_loss: -2.2356055
disc_loss: 2.2356055
disc_acc: 0.2014851485148515

Validation results:
gen_loss: -2.1527693
disc_loss: 2.1527693
disc_acc: 0.22123015873015872


	Epoch 222
Training results:
gen_loss: -2.3045511
disc_loss: 2.3045511
disc_acc: 0.19554455445544555

Validation results:
gen_loss: -2.5406442
disc_loss: 2.5406442
disc_acc: 0.19047619047619047


	Epoch 223
Training results:
gen_loss: -2.235909
disc_loss: 2.235909
disc_acc: 0.18626237623762376

Validation results:
gen_loss: -2.0223625
disc_loss: 2.0223625
disc_acc: 0.25297619047619047


	Epoch 224
Training results:
gen_loss: -2.0504332
disc_loss: 2.0504332
disc_acc: 0.2214108910891089

Validation results:
gen_loss: -2.3176851
disc_loss: 2.3176851
disc_acc: 0.20238095238095238


	Epoch 225
Training results:
gen_loss: -2.0755103
disc_loss: 2.0755103
disc_acc: 0.23316831683168318

Validation results:
gen_loss: -1.9964082
disc_loss: 1.9964082
disc_acc: 0.22668650793650794


	Epoch 226
Training results:
gen_loss: -2.0690053
disc_loss: 2.0690053
disc_acc: 0.2280940594059406

Validation results:
gen_loss: -2.1419625
disc_loss: 2.1419625
disc_acc: 0.2251984126984127


	Epoch 227
Training results:
gen_loss: -1.9936646
disc_loss: 1.9936646
disc_acc: 0.23638613861386137

Validation results:
gen_loss: -1.8581315
disc_loss: 1.8581315
disc_acc: 0.2316468253968254


	Epoch 228
Training results:
gen_loss: -2.0330844
disc_loss: 2.0330844
disc_acc: 0.2125

Validation results:
gen_loss: -2.233475
disc_loss: 2.233475
disc_acc: 0.1875


	Epoch 229
Training results:
gen_loss: -2.063377
disc_loss: 2.063377
disc_acc: 0.2047029702970297

Validation results:
gen_loss: -2.1459584
disc_loss: 2.1459584
disc_acc: 0.17113095238095238


	Epoch 230
Training results:
gen_loss: -2.1383882
disc_loss: 2.1383882
disc_acc: 0.15185643564356435

Validation results:
gen_loss: -2.1514237
disc_loss: 2.1514237
disc_acc: 0.13690476190476192


	Epoch 231
Training results:
gen_loss: -2.121785
disc_loss: 2.121785
disc_acc: 0.13391089108910892

Validation results:
gen_loss: -2.1553354
disc_loss: 2.1553354
disc_acc: 0.11507936507936507


	Epoch 232
Training results:
gen_loss: -2.1357048
disc_loss: 2.1357048
disc_acc: 0.12487623762376238

Validation results:
gen_loss: -2.125396
disc_loss: 2.125396
disc_acc: 0.13293650793650794


	Epoch 233
Training results:
gen_loss: -2.1387625
disc_loss: 2.1387625
disc_acc: 0.12326732673267327

Validation results:
gen_loss: -2.1269958
disc_loss: 2.1269958
disc_acc: 0.12202380952380952


	Epoch 234
Training results:
gen_loss: -2.1297257
disc_loss: 2.1297257
disc_acc: 0.12153465346534653

Validation results:
gen_loss: -2.1102512
disc_loss: 2.1102512
disc_acc: 0.12152777777777778


	Epoch 235
Training results:
gen_loss: -2.1431267
disc_loss: 2.1431267
disc_acc: 0.1301980198019802

Validation results:
gen_loss: -2.1282527
disc_loss: 2.1282527
disc_acc: 0.11755952380952381


	Epoch 236
Training results:
gen_loss: -2.1392744
disc_loss: 2.1392744
disc_acc: 0.12425742574257426

Validation results:
gen_loss: -2.1104074
disc_loss: 2.1104074
disc_acc: 0.1259920634920635


	Epoch 237
Training results:
gen_loss: -2.1283534
disc_loss: 2.1283534
disc_acc: 0.12314356435643564

Validation results:
gen_loss: -2.1186075
disc_loss: 2.1186075
disc_acc: 0.11507936507936507


	Epoch 238
Training results:
gen_loss: -2.136435
disc_loss: 2.136435
disc_acc: 0.12425742574257426

Validation results:
gen_loss: -2.1167047
disc_loss: 2.1167047
disc_acc: 0.1378968253968254


	Epoch 239
Training results:
gen_loss: -2.1361454
disc_loss: 2.1361454
disc_acc: 0.12227722772277227

Validation results:
gen_loss: -2.175357
disc_loss: 2.175357
disc_acc: 0.13640873015873015


	Epoch 240
Training results:
gen_loss: -2.1413476
disc_loss: 2.1413476
disc_acc: 0.13044554455445545

Validation results:
gen_loss: -2.1699963
disc_loss: 2.1699963
disc_acc: 0.12251984126984126


	Epoch 241
Training results:
gen_loss: -2.168248
disc_loss: 2.168248
disc_acc: 0.15222772277227722

Validation results:
gen_loss: -2.166929
disc_loss: 2.166929
disc_acc: 0.21279761904761904


	Epoch 242
Training results:
gen_loss: -2.1388469
disc_loss: 2.1388469
disc_acc: 0.18118811881188118

Validation results:
gen_loss: -2.0965931
disc_loss: 2.0965931
disc_acc: 0.22023809523809523


	Epoch 243
Training results:
gen_loss: -2.0902617
disc_loss: 2.0902617
disc_acc: 0.1827970297029703

Validation results:
gen_loss: -2.3395352
disc_loss: 2.3395352
disc_acc: 0.13194444444444445


	Epoch 244
Training results:
gen_loss: -2.0978804
disc_loss: 2.0978804
disc_acc: 0.1792079207920792

Validation results:
gen_loss: -2.1700535
disc_loss: 2.1700535
disc_acc: 0.1195436507936508


	Epoch 245
Training results:
gen_loss: -2.1193025
disc_loss: 2.1193025
disc_acc: 0.14245049504950494

Validation results:
gen_loss: -2.241927
disc_loss: 2.241927
disc_acc: 0.1284722222222222


	Epoch 246
Training results:
gen_loss: -2.1132967
disc_loss: 2.1132967
disc_acc: 0.139480198019802

Validation results:
gen_loss: -1.9266816
disc_loss: 1.9266816
disc_acc: 0.20436507936507936


	Epoch 247
Training results:
gen_loss: -2.0350025
disc_loss: 2.0350025
disc_acc: 0.21448019801980198

Validation results:
gen_loss: -1.70943
disc_loss: 1.70943
disc_acc: 0.28521825396825395


	Epoch 248
Training results:
gen_loss: -1.826167
disc_loss: 1.826167
disc_acc: 0.27933168316831686

Validation results:
gen_loss: -1.6862444
disc_loss: 1.6862444
disc_acc: 0.28869047619047616


	Epoch 249
Training results:
gen_loss: -1.8607761
disc_loss: 1.8607761
disc_acc: 0.27821782178217824

Validation results:
gen_loss: -1.5710672
disc_loss: 1.5710672
disc_acc: 0.3209325396825397


	Epoch 250
Training results:
gen_loss: -1.747367
disc_loss: 1.747367
disc_acc: 0.27413366336633666

Validation results:
gen_loss: -1.5758712
disc_loss: 1.5758712
disc_acc: 0.24801587301587302


	Epoch 251
Training results:
gen_loss: -1.6151175
disc_loss: 1.6151175
disc_acc: 0.261509900990099

Validation results:
gen_loss: -1.6887977
disc_loss: 1.6887977
disc_acc: 0.27232142857142855


	Epoch 252
Training results:
gen_loss: -1.7261841
disc_loss: 1.7261841
disc_acc: 0.27091584158415843

Validation results:
gen_loss: -1.4859324
disc_loss: 1.4859324
disc_acc: 0.29811507936507936


	Epoch 253
Training results:
gen_loss: -1.8070363
disc_loss: 1.8070363
disc_acc: 0.2214108910891089

Validation results:
gen_loss: -2.0322936
disc_loss: 2.0322936
disc_acc: 0.18551587301587302


	Epoch 254
Training results:
gen_loss: -2.0428894
disc_loss: 2.0428894
disc_acc: 0.1735148514851485

Validation results:
gen_loss: -1.9197538
disc_loss: 1.9197538
disc_acc: 0.20833333333333334


	Epoch 255
Training results:
gen_loss: -1.9918641
disc_loss: 1.9918641
disc_acc: 0.18576732673267327

Validation results:
gen_loss: -1.896421
disc_loss: 1.896421
disc_acc: 0.1884920634920635


	Epoch 256
Training results:
gen_loss: -1.876973
disc_loss: 1.876973
disc_acc: 0.22586633663366337

Validation results:
gen_loss: -1.9061828
disc_loss: 1.9061828
disc_acc: 0.21378968253968253


	Epoch 257
Training results:
gen_loss: -1.845575
disc_loss: 1.845575
disc_acc: 0.2448019801980198

Validation results:
gen_loss: -1.9265567
disc_loss: 1.9265567
disc_acc: 0.2534722222222222


	Epoch 258
Training results:
gen_loss: -1.8523232
disc_loss: 1.8523232
disc_acc: 0.23452970297029702

Validation results:
gen_loss: -1.9104061
disc_loss: 1.9104061
disc_acc: 0.24057539682539683


	Epoch 259
Training results:
gen_loss: -1.8243179
disc_loss: 1.8243179
disc_acc: 0.2561881188118812

Validation results:
gen_loss: -1.6825126
disc_loss: 1.6825126
disc_acc: 0.3125


	Epoch 260
Training results:
gen_loss: -1.7347635
disc_loss: 1.7347635
disc_acc: 0.26831683168316833

Validation results:
gen_loss: -1.5933774
disc_loss: 1.5933774
disc_acc: 0.35367063492063494


	Epoch 261
Training results:
gen_loss: -1.709367
disc_loss: 1.709367
disc_acc: 0.27673267326732676

Validation results:
gen_loss: -1.8448362
disc_loss: 1.8448362
disc_acc: 0.2286706349206349


	Epoch 262
Training results:
gen_loss: -1.645668
disc_loss: 1.645668
disc_acc: 0.2995049504950495

Validation results:
gen_loss: -1.8391188
disc_loss: 1.8391188
disc_acc: 0.3169642857142857


	Epoch 263
Training results:
gen_loss: -1.6052873
disc_loss: 1.6052873
disc_acc: 0.32165841584158417

Validation results:
gen_loss: -1.722304
disc_loss: 1.722304
disc_acc: 0.25892857142857145


	Epoch 264
Training results:
gen_loss: -1.5424422
disc_loss: 1.5424422
disc_acc: 0.31163366336633663

Validation results:
gen_loss: -1.4807662
disc_loss: 1.4807662
disc_acc: 0.35119047619047616


	Epoch 265
Training results:
gen_loss: -1.5661187
disc_loss: 1.5661187
disc_acc: 0.3100247524752475

Validation results:
gen_loss: -1.5807453
disc_loss: 1.5807453
disc_acc: 0.29910714285714285


	Epoch 266
Training results:
gen_loss: -1.4631835
disc_loss: 1.4631835
disc_acc: 0.3165841584158416

Validation results:
gen_loss: -1.3781668
disc_loss: 1.3781668
disc_acc: 0.34424603174603174


	Epoch 267
Training results:
gen_loss: -1.5578063
disc_loss: 1.5578063
disc_acc: 0.3224009900990099

Validation results:
gen_loss: -1.9490826
disc_loss: 1.9490826
disc_acc: 0.2614087301587302


	Epoch 268
Training results:
gen_loss: -1.520009
disc_loss: 1.520009
disc_acc: 0.29777227722772276

Validation results:
gen_loss: -1.4095782
disc_loss: 1.4095782
disc_acc: 0.35912698412698413


	Epoch 269
Training results:
gen_loss: -1.5108614
disc_loss: 1.5108614
disc_acc: 0.33304455445544556

Validation results:
gen_loss: -1.7068851
disc_loss: 1.7068851
disc_acc: 0.24057539682539683


	Epoch 270
Training results:
gen_loss: -1.4934467
disc_loss: 1.4934467
disc_acc: 0.30915841584158416

Validation results:
gen_loss: -1.4202745
disc_loss: 1.4202745
disc_acc: 0.3070436507936508


	Epoch 271
Training results:
gen_loss: -1.4716555
disc_loss: 1.4716555
disc_acc: 0.275

Validation results:
gen_loss: -1.5335965
disc_loss: 1.5335965
disc_acc: 0.23412698412698413


	Epoch 272
Training results:
gen_loss: -1.50013
disc_loss: 1.50013
disc_acc: 0.25185643564356436

Validation results:
gen_loss: -1.4546381
disc_loss: 1.4546381
disc_acc: 0.24553571428571427


	Epoch 273
Training results:
gen_loss: -1.5555589
disc_loss: 1.5555589
disc_acc: 0.313490099009901

Validation results:
gen_loss: -1.6022217
disc_loss: 1.6022217
disc_acc: 0.24156746031746032


	Epoch 274
Training results:
gen_loss: -1.478038
disc_loss: 1.478038
disc_acc: 0.28898514851485146

Validation results:
gen_loss: -1.5707039
disc_loss: 1.5707039
disc_acc: 0.2837301587301587


	Epoch 275
Training results:
gen_loss: -1.4718558
disc_loss: 1.4718558
disc_acc: 0.27710396039603963

Validation results:
gen_loss: -1.5426493
disc_loss: 1.5426493
disc_acc: 0.27529761904761907


	Epoch 276
Training results:
gen_loss: -1.4996606
disc_loss: 1.4996606
disc_acc: 0.263490099009901

Validation results:
gen_loss: -1.3813447
disc_loss: 1.3813447
disc_acc: 0.3551587301587302


	Epoch 277
Training results:
gen_loss: -1.4614435
disc_loss: 1.4614435
disc_acc: 0.2556930693069307

Validation results:
gen_loss: -1.4213191
disc_loss: 1.4213191
disc_acc: 0.27976190476190477


	Epoch 278
Training results:
gen_loss: -1.4416982
disc_loss: 1.4416982
disc_acc: 0.24715346534653465

Validation results:
gen_loss: -1.4337889
disc_loss: 1.4337889
disc_acc: 0.2544642857142857


	Epoch 279
Training results:
gen_loss: -1.5014682
disc_loss: 1.5014682
disc_acc: 0.3481435643564356

Validation results:
gen_loss: -1.8233947
disc_loss: 1.8233947
disc_acc: 0.27529761904761907


	Epoch 280
Training results:
gen_loss: -1.6427261
disc_loss: 1.6427261
disc_acc: 0.3157178217821782

Validation results:
gen_loss: -1.6284349
disc_loss: 1.6284349
disc_acc: 0.29563492063492064


	Epoch 281
Training results:
gen_loss: -1.5844891
disc_loss: 1.5844891
disc_acc: 0.3378712871287129

Validation results:
gen_loss: -1.49121
disc_loss: 1.49121
disc_acc: 0.39037698412698413


	Epoch 282
Training results:
gen_loss: -1.6188003
disc_loss: 1.6188003
disc_acc: 0.3409653465346535

Validation results:
gen_loss: -1.6117817
disc_loss: 1.6117817
disc_acc: 0.33134920634920634


	Epoch 283
Training results:
gen_loss: -1.589244
disc_loss: 1.589244
disc_acc: 0.30086633663366336

Validation results:
gen_loss: -1.5869839
disc_loss: 1.5869839
disc_acc: 0.3030753968253968


	Epoch 284
Training results:
gen_loss: -1.6382748
disc_loss: 1.6382748
disc_acc: 0.2962871287128713

Validation results:
gen_loss: -1.8483435
disc_loss: 1.8483435
disc_acc: 0.2867063492063492


	Epoch 285
Training results:
gen_loss: -1.6035398
disc_loss: 1.6035398
disc_acc: 0.3110148514851485

Validation results:
gen_loss: -1.9282702
disc_loss: 1.9282702
disc_acc: 0.24751984126984128


	Epoch 286
Training results:
gen_loss: -1.6298866
disc_loss: 1.6298866
disc_acc: 0.3209158415841584

Validation results:
gen_loss: -1.624495
disc_loss: 1.624495
disc_acc: 0.29464285714285715


	Epoch 287
Training results:
gen_loss: -1.6300573
disc_loss: 1.6300573
disc_acc: 0.2957920792079208

Validation results:
gen_loss: -1.6054065
disc_loss: 1.6054065
disc_acc: 0.30505952380952384


	Epoch 288
Training results:
gen_loss: -1.5888798
disc_loss: 1.5888798
disc_acc: 0.2952970297029703

Validation results:
gen_loss: -1.5576446
disc_loss: 1.5576446
disc_acc: 0.30505952380952384


	Epoch 289
Training results:
gen_loss: -1.6306854
disc_loss: 1.6306854
disc_acc: 0.3012376237623762

Validation results:
gen_loss: -1.646585
disc_loss: 1.646585
disc_acc: 0.2926587301587302


	Epoch 290
Training results:
gen_loss: -1.6227046
disc_loss: 1.6227046
disc_acc: 0.2887376237623762

Validation results:
gen_loss: -1.5882409
disc_loss: 1.5882409
disc_acc: 0.29712301587301587


	Epoch 291
Training results:
gen_loss: -1.7657151
disc_loss: 1.7657151
disc_acc: 0.30866336633663366

Validation results:
gen_loss: -1.7808518
disc_loss: 1.7808518
disc_acc: 0.2986111111111111


	Epoch 292
Training results:
gen_loss: -1.5459136
disc_loss: 1.5459136
disc_acc: 0.3507425742574257

Validation results:
gen_loss: -1.4577211
disc_loss: 1.4577211
disc_acc: 0.40327380952380953


	Epoch 293
Training results:
gen_loss: -1.6669047
disc_loss: 1.6669047
disc_acc: 0.28465346534653463

Validation results:
gen_loss: -1.7502524
disc_loss: 1.7502524
disc_acc: 0.24950396825396826


	Epoch 294
Training results:
gen_loss: -1.6553802
disc_loss: 1.6553802
disc_acc: 0.2535891089108911

Validation results:
gen_loss: -1.6407405
disc_loss: 1.6407405
disc_acc: 0.2197420634920635


	Epoch 295
Training results:
gen_loss: -1.6342024
disc_loss: 1.6342024
disc_acc: 0.24752475247524752

Validation results:
gen_loss: -1.5257311
disc_loss: 1.5257311
disc_acc: 0.28273809523809523


	Epoch 296
Training results:
gen_loss: -1.6307212
disc_loss: 1.6307212
disc_acc: 0.2608910891089109

Validation results:
gen_loss: -1.6015278
disc_loss: 1.6015278
disc_acc: 0.2594246031746032


	Epoch 297
Training results:
gen_loss: -1.669597
disc_loss: 1.669597
disc_acc: 0.2573019801980198

Validation results:
gen_loss: -1.5720168
disc_loss: 1.5720168
disc_acc: 0.2876984126984127


	Epoch 298
Training results:
gen_loss: -1.6277112
disc_loss: 1.6277112
disc_acc: 0.3069306930693069

Validation results:
gen_loss: -1.6872534
disc_loss: 1.6872534
disc_acc: 0.3219246031746032


	Epoch 299
Training results:
gen_loss: -1.595324
disc_loss: 1.595324
disc_acc: 0.328960396039604

Validation results:
gen_loss: -1.6756644
disc_loss: 1.6756644
disc_acc: 0.30853174603174605


	Epoch 300
Training results:
gen_loss: -1.7054818
disc_loss: 1.7054818
disc_acc: 0.3261138613861386

Validation results:
gen_loss: -1.6119806
disc_loss: 1.6119806
disc_acc: 0.32936507936507936


	Epoch 301
Training results:
gen_loss: -1.6490873
disc_loss: 1.6490873
disc_acc: 0.3073019801980198

Validation results:
gen_loss: -1.5601517
disc_loss: 1.5601517
disc_acc: 0.3090277777777778


	Epoch 302
Training results:
gen_loss: -1.5943589
disc_loss: 1.5943589
disc_acc: 0.2954207920792079

Validation results:
gen_loss: -1.547819
disc_loss: 1.547819
disc_acc: 0.3030753968253968


	Epoch 303
Training results:
gen_loss: -1.5953046
disc_loss: 1.5953046
disc_acc: 0.3150990099009901

Validation results:
gen_loss: -1.581002
disc_loss: 1.581002
disc_acc: 0.3566468253968254


	Epoch 304
Training results:
gen_loss: -1.5518999
disc_loss: 1.5518999
disc_acc: 0.3527227722772277

Validation results:
gen_loss: -1.5497441
disc_loss: 1.5497441
disc_acc: 0.3189484126984127


	Epoch 305
Training results:
gen_loss: -1.5908607
disc_loss: 1.5908607
disc_acc: 0.3436881188118812

Validation results:
gen_loss: -2.0175524
disc_loss: 2.0175524
disc_acc: 0.27232142857142855


	Epoch 306
Training results:
gen_loss: -1.7524967
disc_loss: 1.7524967
disc_acc: 0.25965346534653466

Validation results:
gen_loss: -1.7248677
disc_loss: 1.7248677
disc_acc: 0.28125


	Epoch 307
Training results:
gen_loss: -1.6579317
disc_loss: 1.6579317
disc_acc: 0.2681930693069307

Validation results:
gen_loss: -1.5675405
disc_loss: 1.5675405
disc_acc: 0.25396825396825395


	Epoch 308
Training results:
gen_loss: -1.6650484
disc_loss: 1.6650484
disc_acc: 0.2988861386138614

Validation results:
gen_loss: -1.5691725
disc_loss: 1.5691725
disc_acc: 0.34226190476190477


	Epoch 309
Training results:
gen_loss: -1.6461334
disc_loss: 1.6461334
disc_acc: 0.3238861386138614

Validation results:
gen_loss: -1.9467824
disc_loss: 1.9467824
disc_acc: 0.2698412698412698


	Epoch 310
Training results:
gen_loss: -1.6601845
disc_loss: 1.6601845
disc_acc: 0.31027227722772277

Validation results:
gen_loss: -1.845994
disc_loss: 1.845994
disc_acc: 0.18948412698412698


	Epoch 311
Training results:
gen_loss: -1.8463337
disc_loss: 1.8463337
disc_acc: 0.18576732673267327

Validation results:
gen_loss: -1.76581
disc_loss: 1.76581
disc_acc: 0.19642857142857142


	Epoch 312
Training results:
gen_loss: -1.8041608
disc_loss: 1.8041608
disc_acc: 0.1896039603960396

Validation results:
gen_loss: -1.769411
disc_loss: 1.769411
disc_acc: 0.2113095238095238


	Epoch 313
Training results:
gen_loss: -1.8026685
disc_loss: 1.8026685
disc_acc: 0.20123762376237625

Validation results:
gen_loss: -1.816697
disc_loss: 1.816697
disc_acc: 0.1661706349206349


	Epoch 314
Training results:
gen_loss: -1.8452034
disc_loss: 1.8452034
disc_acc: 0.19641089108910892

Validation results:
gen_loss: -1.830165
disc_loss: 1.830165
disc_acc: 0.24603174603174602


	Epoch 315
Training results:
gen_loss: -1.815262
disc_loss: 1.815262
disc_acc: 0.2084158415841584

Validation results:
gen_loss: -1.8565224
disc_loss: 1.8565224
disc_acc: 0.1765873015873016


	Epoch 316
Training results:
gen_loss: -1.7994359
disc_loss: 1.7994359
disc_acc: 0.1875

Validation results:
gen_loss: -1.7850956
disc_loss: 1.7850956
disc_acc: 0.17559523809523808


	Epoch 317
Training results:
gen_loss: -1.7865237
disc_loss: 1.7865237
disc_acc: 0.18688118811881188

Validation results:
gen_loss: -1.7815894
disc_loss: 1.7815894
disc_acc: 0.19642857142857142


	Epoch 318
Training results:
gen_loss: -1.813377
disc_loss: 1.813377
disc_acc: 0.19096534653465347

Validation results:
gen_loss: -1.8844332
disc_loss: 1.8844332
disc_acc: 0.17956349206349206


	Epoch 319
Training results:
gen_loss: -1.8164285
disc_loss: 1.8164285
disc_acc: 0.18935643564356436

Validation results:
gen_loss: -1.845371
disc_loss: 1.845371
disc_acc: 0.19196428571428573


	Epoch 320
Training results:
gen_loss: -1.8216612
disc_loss: 1.8216612
disc_acc: 0.18415841584158416

Validation results:
gen_loss: -1.8099828
disc_loss: 1.8099828
disc_acc: 0.1909722222222222


	Epoch 321
Training results:
gen_loss: -1.7813556
disc_loss: 1.7813556
disc_acc: 0.1941831683168317

Validation results:
gen_loss: -1.7554667
disc_loss: 1.7554667
disc_acc: 0.18353174603174602


	Epoch 322
Training results:
gen_loss: -1.801971
disc_loss: 1.801971
disc_acc: 0.19603960396039605

Validation results:
gen_loss: -1.8379554
disc_loss: 1.8379554
disc_acc: 0.1865079365079365


	Epoch 323
Training results:
gen_loss: -1.8546305
disc_loss: 1.8546305
disc_acc: 0.19653465346534654

Validation results:
gen_loss: -1.8190523
disc_loss: 1.8190523
disc_acc: 0.1939484126984127


	Epoch 324
Training results:
gen_loss: -1.81627
disc_loss: 1.81627
disc_acc: 0.18638613861386139

Validation results:
gen_loss: -1.7452756
disc_loss: 1.7452756
disc_acc: 0.20287698412698413


	Epoch 325
Training results:
gen_loss: -1.7909936
disc_loss: 1.7909936
disc_acc: 0.1860148514851485

Validation results:
gen_loss: -1.7594533
disc_loss: 1.7594533
disc_acc: 0.19047619047619047


	Epoch 326
Training results:
gen_loss: -1.797611
disc_loss: 1.797611
disc_acc: 0.19034653465346535

Validation results:
gen_loss: -1.816929
disc_loss: 1.816929
disc_acc: 0.1875


	Epoch 327
Training results:
gen_loss: -1.8297822
disc_loss: 1.8297822
disc_acc: 0.1879950495049505

Validation results:
gen_loss: -1.8742013
disc_loss: 1.8742013
disc_acc: 0.1775793650793651


	Epoch 328
Training results:
gen_loss: -1.8082201
disc_loss: 1.8082201
disc_acc: 0.18452970297029703

Validation results:
gen_loss: -1.9837003
disc_loss: 1.9837003
disc_acc: 0.17609126984126985


	Epoch 329
Training results:
gen_loss: -1.8020532
disc_loss: 1.8020532
disc_acc: 0.18787128712871287

Validation results:
gen_loss: -1.7490876
disc_loss: 1.7490876
disc_acc: 0.21031746031746032


	Epoch 330
Training results:
gen_loss: -1.8171433
disc_loss: 1.8171433
disc_acc: 0.19752475247524753

Validation results:
gen_loss: -1.8473687
disc_loss: 1.8473687
disc_acc: 0.17708333333333334


	Epoch 331
Training results:
gen_loss: -1.7756011
disc_loss: 1.7756011
disc_acc: 0.18663366336633663

Validation results:
gen_loss: -1.8507895
disc_loss: 1.8507895
disc_acc: 0.17261904761904762


	Epoch 332
Training results:
gen_loss: -1.8067836
disc_loss: 1.8067836
disc_acc: 0.18923267326732673

Validation results:
gen_loss: -1.9477854
disc_loss: 1.9477854
disc_acc: 0.1800595238095238


	Epoch 333
Training results:
gen_loss: -1.7995683
disc_loss: 1.7995683
disc_acc: 0.18923267326732673

Validation results:
gen_loss: -1.8283014
disc_loss: 1.8283014
disc_acc: 0.2088293650793651


	Epoch 334
Training results:
gen_loss: -1.8104384
disc_loss: 1.8104384
disc_acc: 0.18712871287128713

Validation results:
gen_loss: -1.8587447
disc_loss: 1.8587447
disc_acc: 0.18501984126984128


	Epoch 335
Training results:
gen_loss: -1.810846
disc_loss: 1.810846
disc_acc: 0.18886138613861386

Validation results:
gen_loss: -1.7834455
disc_loss: 1.7834455
disc_acc: 0.18700396825396826


	Epoch 336
Training results:
gen_loss: -1.8389581
disc_loss: 1.8389581
disc_acc: 0.18366336633663366

Validation results:
gen_loss: -1.865225
disc_loss: 1.865225
disc_acc: 0.17906746031746032


	Epoch 337
Training results:
gen_loss: -1.9274925
disc_loss: 1.9274925
disc_acc: 0.18948019801980198

Validation results:
gen_loss: -1.8212078
disc_loss: 1.8212078
disc_acc: 0.1909722222222222


	Epoch 338
Training results:
gen_loss: -1.7931381
disc_loss: 1.7931381
disc_acc: 0.18465346534653465

Validation results:
gen_loss: -1.7857609
disc_loss: 1.7857609
disc_acc: 0.19345238095238096


	Epoch 339
Training results:
gen_loss: -1.7824801
disc_loss: 1.7824801
disc_acc: 0.18663366336633663

Validation results:
gen_loss: -1.8034204
disc_loss: 1.8034204
disc_acc: 0.1840277777777778


	Epoch 340
Training results:
gen_loss: -1.7879295
disc_loss: 1.7879295
disc_acc: 0.19393564356435644

Validation results:
gen_loss: -1.803171
disc_loss: 1.803171
disc_acc: 0.17956349206349206


	Epoch 341
Training results:
gen_loss: -1.7944344
disc_loss: 1.7944344
disc_acc: 0.1860148514851485

Validation results:
gen_loss: -1.7794788
disc_loss: 1.7794788
disc_acc: 0.23115079365079366


	Epoch 342
Training results:
gen_loss: -1.7972575
disc_loss: 1.7972575
disc_acc: 0.2162128712871287

Validation results:
gen_loss: -1.8027656
disc_loss: 1.8027656
disc_acc: 0.1765873015873016


	Epoch 343
Training results:
gen_loss: -1.7999908
disc_loss: 1.7999908
disc_acc: 0.18712871287128713

Validation results:
gen_loss: -1.8641187
disc_loss: 1.8641187
disc_acc: 0.1909722222222222


	Epoch 344
Training results:
gen_loss: -1.785269
disc_loss: 1.785269
disc_acc: 0.19022277227722773

Validation results:
gen_loss: -1.7979746
disc_loss: 1.7979746
disc_acc: 0.1949404761904762


	Epoch 345
Training results:
gen_loss: -1.8157755
disc_loss: 1.8157755
disc_acc: 0.1922029702970297

Validation results:
gen_loss: -1.8519396
disc_loss: 1.8519396
disc_acc: 0.1746031746031746


	Epoch 346
Training results:
gen_loss: -1.797538
disc_loss: 1.797538
disc_acc: 0.2004950495049505

Validation results:
gen_loss: -1.7649264
disc_loss: 1.7649264
disc_acc: 0.20734126984126985


	Epoch 347
Training results:
gen_loss: -1.8100772
disc_loss: 1.8100772
disc_acc: 0.19146039603960396

Validation results:
gen_loss: -1.8126086
disc_loss: 1.8126086
disc_acc: 0.1775793650793651


	Epoch 348
Training results:
gen_loss: -1.8677701
disc_loss: 1.8677701
disc_acc: 0.22227722772277228

Validation results:
gen_loss: -1.8373939
disc_loss: 1.8373939
disc_acc: 0.26537698412698413


	Epoch 349
Training results:
gen_loss: -1.7492293
disc_loss: 1.7492293
disc_acc: 0.2830445544554455

Validation results:
gen_loss: -1.6691266
disc_loss: 1.6691266
disc_acc: 0.2638888888888889


	Epoch 350
Training results:
gen_loss: -1.6989546
disc_loss: 1.6989546
disc_acc: 0.28836633663366334

Validation results:
gen_loss: -1.5985495
disc_loss: 1.5985495
disc_acc: 0.35267857142857145


	Epoch 351
Training results:
gen_loss: -1.6900673
disc_loss: 1.6900673
disc_acc: 0.31027227722772277

Validation results:
gen_loss: -1.7931461
disc_loss: 1.7931461
disc_acc: 0.2663690476190476


	Epoch 352
Training results:
gen_loss: -1.8220972
disc_loss: 1.8220972
disc_acc: 0.2146039603960396

Validation results:
gen_loss: -1.7217572
disc_loss: 1.7217572
disc_acc: 0.29017857142857145


	Epoch 353
Training results:
gen_loss: -1.7943226
disc_loss: 1.7943226
disc_acc: 0.2422029702970297

Validation results:
gen_loss: -1.7731323
disc_loss: 1.7731323
disc_acc: 0.25793650793650796


	Epoch 354
Training results:
gen_loss: -1.8031683
disc_loss: 1.8031683
disc_acc: 0.22524752475247525

Validation results:
gen_loss: -1.7115408
disc_loss: 1.7115408
disc_acc: 0.23214285714285715


	Epoch 355
Training results:
gen_loss: -1.7715023
disc_loss: 1.7715023
disc_acc: 0.24554455445544554

Validation results:
gen_loss: -1.7484034
disc_loss: 1.7484034
disc_acc: 0.22916666666666666


	Epoch 356
Training results:
gen_loss: -1.7410953
disc_loss: 1.7410953
disc_acc: 0.2660891089108911

Validation results:
gen_loss: -1.755933
disc_loss: 1.755933
disc_acc: 0.2286706349206349


	Epoch 357
Training results:
gen_loss: -1.7657065
disc_loss: 1.7657065
disc_acc: 0.2478960396039604

Validation results:
gen_loss: -1.7028488
disc_loss: 1.7028488
disc_acc: 0.24950396825396826


	Epoch 358
Training results:
gen_loss: -1.7402775
disc_loss: 1.7402775
disc_acc: 0.25866336633663367

Validation results:
gen_loss: -1.8498838
disc_loss: 1.8498838
disc_acc: 0.23214285714285715


	Epoch 359
Training results:
gen_loss: -1.7092648
disc_loss: 1.7092648
disc_acc: 0.25705445544554456

Validation results:
gen_loss: -1.6160191
disc_loss: 1.6160191
disc_acc: 0.28422619047619047


	Epoch 360
Training results:
gen_loss: -1.7321095
disc_loss: 1.7321095
disc_acc: 0.26262376237623763

Validation results:
gen_loss: -1.5348759
disc_loss: 1.5348759
disc_acc: 0.3447420634920635


	Epoch 361
Training results:
gen_loss: -1.6572022
disc_loss: 1.6572022
disc_acc: 0.2830445544554455

Validation results:
gen_loss: -1.7289352
disc_loss: 1.7289352
disc_acc: 0.25892857142857145


	Epoch 362
Training results:
gen_loss: -1.6646966
disc_loss: 1.6646966
disc_acc: 0.282549504950495

Validation results:
gen_loss: -1.5051526
disc_loss: 1.5051526
disc_acc: 0.3715277777777778


	Epoch 363
Training results:
gen_loss: -1.5364004
disc_loss: 1.5364004
disc_acc: 0.3491336633663366

Validation results:
gen_loss: -1.5717114
disc_loss: 1.5717114
disc_acc: 0.31994047619047616


	Epoch 364
Training results:
gen_loss: -1.6335998
disc_loss: 1.6335998
disc_acc: 0.32215346534653466

Validation results:
gen_loss: -1.542636
disc_loss: 1.542636
disc_acc: 0.38244047619047616


	Epoch 365
Training results:
gen_loss: -1.6098641
disc_loss: 1.6098641
disc_acc: 0.33824257425742577

Validation results:
gen_loss: -1.5328672
disc_loss: 1.5328672
disc_acc: 0.36259920634920634


	Epoch 366
Training results:
gen_loss: -1.6307158
disc_loss: 1.6307158
disc_acc: 0.33502475247524754

Validation results:
gen_loss: -2.0003998
disc_loss: 2.0003998
disc_acc: 0.26091269841269843


	Epoch 367
Training results:
gen_loss: -1.6982819
disc_loss: 1.6982819
disc_acc: 0.2975247524752475

Validation results:
gen_loss: -1.713064
disc_loss: 1.713064
disc_acc: 0.2663690476190476


	Epoch 368
Training results:
gen_loss: -1.6287587
disc_loss: 1.6287587
disc_acc: 0.30383663366336633

Validation results:
gen_loss: -1.6320301
disc_loss: 1.6320301
disc_acc: 0.26884920634920634


	Epoch 369
Training results:
gen_loss: -1.6183625
disc_loss: 1.6183625
disc_acc: 0.32116336633663367

Validation results:
gen_loss: -1.6470928
disc_loss: 1.6470928
disc_acc: 0.3353174603174603


	Epoch 370
Training results:
gen_loss: -1.6318609
disc_loss: 1.6318609
disc_acc: 0.33044554455445546

Validation results:
gen_loss: -1.508557
disc_loss: 1.508557
disc_acc: 0.3541666666666667


	Epoch 371
Training results:
gen_loss: -1.613425
disc_loss: 1.613425
disc_acc: 0.33564356435643566

Validation results:
gen_loss: -1.6714324
disc_loss: 1.6714324
disc_acc: 0.28422619047619047


	Epoch 372
Training results:
gen_loss: -1.6586587
disc_loss: 1.6586587
disc_acc: 0.3235148514851485

Validation results:
gen_loss: -1.7830625
disc_loss: 1.7830625
disc_acc: 0.30456349206349204


	Epoch 373
Training results:
gen_loss: -1.7016292
disc_loss: 1.7016292
disc_acc: 0.32784653465346536

Validation results:
gen_loss: -1.8416624
disc_loss: 1.8416624
disc_acc: 0.27827380952380953


	Epoch 374
Training results:
gen_loss: -1.6400999
disc_loss: 1.6400999
disc_acc: 0.2954207920792079

Validation results:
gen_loss: -1.7254989
disc_loss: 1.7254989
disc_acc: 0.30357142857142855


	Epoch 375
Training results:
gen_loss: -1.6939502
disc_loss: 1.6939502
disc_acc: 0.29455445544554454

Validation results:
gen_loss: -1.6776278
disc_loss: 1.6776278
disc_acc: 0.24603174603174602


	Epoch 376
Training results:
gen_loss: -1.7038432
disc_loss: 1.7038432
disc_acc: 0.26534653465346536

Validation results:
gen_loss: -1.8061274
disc_loss: 1.8061274
disc_acc: 0.32242063492063494


	Epoch 377
Training results:
gen_loss: -1.694001
disc_loss: 1.694001
disc_acc: 0.3341584158415842

Validation results:
gen_loss: -1.7092267
disc_loss: 1.7092267
disc_acc: 0.34077380952380953


	Epoch 378
Training results:
gen_loss: -1.670246
disc_loss: 1.670246
disc_acc: 0.3160891089108911

Validation results:
gen_loss: -1.6939033
disc_loss: 1.6939033
disc_acc: 0.30009920634920634


	Epoch 379
Training results:
gen_loss: -1.6669371
disc_loss: 1.6669371
disc_acc: 0.33242574257425744

Validation results:
gen_loss: -2.1702325
disc_loss: 2.1702325
disc_acc: 0.25049603174603174


	Epoch 380
Training results:
gen_loss: -1.879112
disc_loss: 1.879112
disc_acc: 0.2584158415841584

Validation results:
gen_loss: -1.6541001
disc_loss: 1.6541001
disc_acc: 0.31994047619047616


	Epoch 381
Training results:
gen_loss: -1.8486375
disc_loss: 1.8486375
disc_acc: 0.2733910891089109

Validation results:
gen_loss: -1.8207316
disc_loss: 1.8207316
disc_acc: 0.26438492063492064


	Epoch 382
Training results:
gen_loss: -1.8389121
disc_loss: 1.8389121
disc_acc: 0.2775990099009901

Validation results:
gen_loss: -1.6878619
disc_loss: 1.6878619
disc_acc: 0.2996031746031746


	Epoch 383
Training results:
gen_loss: -1.7461678
disc_loss: 1.7461678
disc_acc: 0.31893564356435644

Validation results:
gen_loss: -1.6746336
disc_loss: 1.6746336
disc_acc: 0.3194444444444444


	Epoch 384
Training results:
gen_loss: -1.8487542
disc_loss: 1.8487542
disc_acc: 0.27722772277227725

Validation results:
gen_loss: -2.0461705
disc_loss: 2.0461705
disc_acc: 0.22668650793650794


	Epoch 385
Training results:
gen_loss: -1.9169866
disc_loss: 1.9169866
disc_acc: 0.25804455445544555

Validation results:
gen_loss: -1.7476215
disc_loss: 1.7476215
disc_acc: 0.3100198412698413


	Epoch 386
Training results:
gen_loss: -1.8101614
disc_loss: 1.8101614
disc_acc: 0.28935643564356434

Validation results:
gen_loss: -1.821947
disc_loss: 1.821947
disc_acc: 0.31746031746031744


	Epoch 387
Training results:
gen_loss: -1.8513027
disc_loss: 1.8513027
disc_acc: 0.28329207920792077

Validation results:
gen_loss: -1.582801
disc_loss: 1.582801
disc_acc: 0.3323412698412698


	Epoch 388
Training results:
gen_loss: -1.8862363
disc_loss: 1.8862363
disc_acc: 0.24133663366336633

Validation results:
gen_loss: -1.7346413
disc_loss: 1.7346413
disc_acc: 0.30357142857142855


	Epoch 389
Training results:
gen_loss: -1.9407365
disc_loss: 1.9407365
disc_acc: 0.2641089108910891

Validation results:
gen_loss: -1.677903
disc_loss: 1.677903
disc_acc: 0.2822420634920635


	Epoch 390
Training results:
gen_loss: -1.8128415
disc_loss: 1.8128415
disc_acc: 0.2962871287128713

Validation results:
gen_loss: -1.9211535
disc_loss: 1.9211535
disc_acc: 0.2673611111111111


	Epoch 391
Training results:
gen_loss: -1.876354
disc_loss: 1.876354
disc_acc: 0.23094059405940595

Validation results:
gen_loss: -1.8250456
disc_loss: 1.8250456
disc_acc: 0.24503968253968253


	Epoch 392
Training results:
gen_loss: -1.8647734
disc_loss: 1.8647734
disc_acc: 0.2129950495049505

Validation results:
gen_loss: -1.855937
disc_loss: 1.855937
disc_acc: 0.18055555555555555


	Epoch 393
Training results:
gen_loss: -1.8585852
disc_loss: 1.8585852
disc_acc: 0.2592821782178218

Validation results:
gen_loss: -1.8587565
disc_loss: 1.8587565
disc_acc: 0.28720238095238093


	Epoch 394
Training results:
gen_loss: -1.755554
disc_loss: 1.755554
disc_acc: 0.2928217821782178

Validation results:
gen_loss: -1.7649134
disc_loss: 1.7649134
disc_acc: 0.3010912698412698


	Epoch 395
Training results:
gen_loss: -1.8052232
disc_loss: 1.8052232
disc_acc: 0.2745049504950495

Validation results:
gen_loss: -1.9340273
disc_loss: 1.9340273
disc_acc: 0.20634920634920634


	Epoch 396
Training results:
gen_loss: -1.8408942
disc_loss: 1.8408942
disc_acc: 0.23081683168316833

Validation results:
gen_loss: -1.9470724
disc_loss: 1.9470724
disc_acc: 0.20932539682539683


	Epoch 397
Training results:
gen_loss: -1.9599519
disc_loss: 1.9599519
disc_acc: 0.1948019801980198

Validation results:
gen_loss: -1.9980795
disc_loss: 1.9980795
disc_acc: 0.18898809523809523


	Epoch 398
Training results:
gen_loss: -1.9471911
disc_loss: 1.9471911
disc_acc: 0.1875

Validation results:
gen_loss: -1.8267497
disc_loss: 1.8267497
disc_acc: 0.2509920634920635


	Epoch 399
Training results:
gen_loss: -1.9146554
disc_loss: 1.9146554
disc_acc: 0.26212871287128714

Validation results:
gen_loss: -2.0304198
disc_loss: 2.0304198
disc_acc: 0.19246031746031747


	Epoch 400
Training results:
gen_loss: -1.8178861
disc_loss: 1.8178861
disc_acc: 0.23948019801980197

Validation results:
gen_loss: -2.1271298
disc_loss: 2.1271298
disc_acc: 0.23809523809523808


	Epoch 401
Training results:
gen_loss: -1.7137154
disc_loss: 1.7137154
disc_acc: 0.3149752475247525

Validation results:
gen_loss: -1.7130185
disc_loss: 1.7130185
disc_acc: 0.32043650793650796


	Epoch 402
Training results:
gen_loss: -1.7258193
disc_loss: 1.7258193
disc_acc: 0.296039603960396

Validation results:
gen_loss: -1.631518
disc_loss: 1.631518
disc_acc: 0.3318452380952381


	Epoch 403
Training results:
gen_loss: -1.7408673
disc_loss: 1.7408673
disc_acc: 0.2745049504950495

Validation results:
gen_loss: -1.9751865
disc_loss: 1.9751865
disc_acc: 0.29464285714285715


	Epoch 404
Training results:
gen_loss: -1.7470893
disc_loss: 1.7470893
disc_acc: 0.2680693069306931

Validation results:
gen_loss: -1.7343614
disc_loss: 1.7343614
disc_acc: 0.24603174603174602


	Epoch 405
Training results:
gen_loss: -1.7638612
disc_loss: 1.7638612
disc_acc: 0.24047029702970296

Validation results:
gen_loss: -1.7551059
disc_loss: 1.7551059
disc_acc: 0.22916666666666666


	Epoch 406
Training results:
gen_loss: -1.7694906
disc_loss: 1.7694906
disc_acc: 0.25383663366336634

Validation results:
gen_loss: -1.7916126
disc_loss: 1.7916126
disc_acc: 0.1909722222222222


	Epoch 407
Training results:
gen_loss: -1.7947787
disc_loss: 1.7947787
disc_acc: 0.22623762376237624

Validation results:
gen_loss: -1.8008953
disc_loss: 1.8008953
disc_acc: 0.2113095238095238


	Epoch 408
Training results:
gen_loss: -1.7907968
disc_loss: 1.7907968
disc_acc: 0.23316831683168318

Validation results:
gen_loss: -1.794658
disc_loss: 1.794658
disc_acc: 0.20684523809523808


	Epoch 409
Training results:
gen_loss: -1.7489899
disc_loss: 1.7489899
disc_acc: 0.25173267326732673

Validation results:
gen_loss: -1.9025865
disc_loss: 1.9025865
disc_acc: 0.28621031746031744


	Epoch 410
Training results:
gen_loss: -1.7819505
disc_loss: 1.7819505
disc_acc: 0.23737623762376237

Validation results:
gen_loss: -2.0404456
disc_loss: 2.0404456
disc_acc: 0.16765873015873015


	Epoch 411
Training results:
gen_loss: -1.7560167
disc_loss: 1.7560167
disc_acc: 0.2375

Validation results:
gen_loss: -1.7067276
disc_loss: 1.7067276
disc_acc: 0.28869047619047616


	Epoch 412
Training results:
gen_loss: -1.6648815
disc_loss: 1.6648815
disc_acc: 0.29294554455445543

Validation results:
gen_loss: -1.5019176
disc_loss: 1.5019176
disc_acc: 0.34871031746031744


	Epoch 413
Training results:
gen_loss: -1.6192138
disc_loss: 1.6192138
disc_acc: 0.31274752475247525

Validation results:
gen_loss: -1.9253782
disc_loss: 1.9253782
disc_acc: 0.21031746031746032


	Epoch 414
Training results:
gen_loss: -1.7766141
disc_loss: 1.7766141
disc_acc: 0.21584158415841584

Validation results:
gen_loss: -1.6677314
disc_loss: 1.6677314
disc_acc: 0.31845238095238093


	Epoch 415
Training results:
gen_loss: -1.7589314
disc_loss: 1.7589314
disc_acc: 0.263490099009901

Validation results:
gen_loss: -1.7464529
disc_loss: 1.7464529
disc_acc: 0.18303571428571427


	Epoch 416
Training results:
gen_loss: -1.7434505
disc_loss: 1.7434505
disc_acc: 0.22995049504950496

Validation results:
gen_loss: -1.4814823
disc_loss: 1.4814823
disc_acc: 0.31994047619047616


	Epoch 417
Training results:
gen_loss: -1.644981
disc_loss: 1.644981
disc_acc: 0.29554455445544553

Validation results:
gen_loss: -1.9846553
disc_loss: 1.9846553
disc_acc: 0.19940476190476192


	Epoch 418
Training results:
gen_loss: -1.6841172
disc_loss: 1.6841172
disc_acc: 0.29777227722772276

Validation results:
gen_loss: -1.9417074
disc_loss: 1.9417074
disc_acc: 0.2490079365079365


	Epoch 419
Training results:
gen_loss: -1.7234133
disc_loss: 1.7234133
disc_acc: 0.2469059405940594

Validation results:
gen_loss: -1.7400719
disc_loss: 1.7400719
disc_acc: 0.1984126984126984


	Epoch 420
Training results:
gen_loss: -1.6870579
disc_loss: 1.6870579
disc_acc: 0.26014851485148516

Validation results:
gen_loss: -1.4406585
disc_loss: 1.4406585
disc_acc: 0.3194444444444444


	Epoch 421
Training results:
gen_loss: -1.617149
disc_loss: 1.617149
disc_acc: 0.30396039603960395

Validation results:
gen_loss: -1.3777405
disc_loss: 1.3777405
disc_acc: 0.37648809523809523


	Epoch 422
Training results:
gen_loss: -1.604015
disc_loss: 1.604015
disc_acc: 0.32363861386138615

Validation results:
gen_loss: -1.425053
disc_loss: 1.425053
disc_acc: 0.41617063492063494


	Epoch 423
Training results:
gen_loss: -1.7153053
disc_loss: 1.7153053
disc_acc: 0.2670792079207921

Validation results:
gen_loss: -1.6501675
disc_loss: 1.6501675
disc_acc: 0.3864087301587302


	Epoch 424
Training results:
gen_loss: -1.5777708
disc_loss: 1.5777708
disc_acc: 0.32301980198019803

Validation results:
gen_loss: -1.5921308
disc_loss: 1.5921308
disc_acc: 0.3080357142857143


	Epoch 425
Training results:
gen_loss: -1.6996778
disc_loss: 1.6996778
disc_acc: 0.2801980198019802

Validation results:
gen_loss: -1.8269202
disc_loss: 1.8269202
disc_acc: 0.3611111111111111


	Epoch 426
Training results:
gen_loss: -1.5830842
disc_loss: 1.5830842
disc_acc: 0.3074257425742574

Validation results:
gen_loss: -1.3740356
disc_loss: 1.3740356
disc_acc: 0.33035714285714285


	Epoch 427
Training results:
gen_loss: -1.6373895
disc_loss: 1.6373895
disc_acc: 0.30705445544554455

Validation results:
gen_loss: -1.5425041
disc_loss: 1.5425041
disc_acc: 0.2996031746031746


	Epoch 428
Training results:
gen_loss: -1.6386807
disc_loss: 1.6386807
disc_acc: 0.2908415841584158

Validation results:
gen_loss: -1.6505347
disc_loss: 1.6505347
disc_acc: 0.27529761904761907


	Epoch 429
Training results:
gen_loss: -1.6198231
disc_loss: 1.6198231
disc_acc: 0.3089108910891089

Validation results:
gen_loss: -1.7842146
disc_loss: 1.7842146
disc_acc: 0.22172619047619047


	Epoch 430
Training results:
gen_loss: -1.5568463
disc_loss: 1.5568463
disc_acc: 0.31163366336633663

Validation results:
gen_loss: -1.5516757
disc_loss: 1.5516757
disc_acc: 0.35119047619047616


	Epoch 431
Training results:
gen_loss: -1.5686018
disc_loss: 1.5686018
disc_acc: 0.33353960396039606

Validation results:
gen_loss: -1.2865908
disc_loss: 1.2865908
disc_acc: 0.4126984126984127


	Epoch 432
Training results:
gen_loss: -1.5223916
disc_loss: 1.5223916
disc_acc: 0.3264851485148515

Validation results:
gen_loss: -1.3604425
disc_loss: 1.3604425
disc_acc: 0.3586309523809524


	Epoch 433
Training results:
gen_loss: -1.4492385
disc_loss: 1.4492385
disc_acc: 0.3025990099009901

Validation results:
gen_loss: -1.2854816
disc_loss: 1.2854816
disc_acc: 0.3373015873015873


	Epoch 434
Training results:
gen_loss: -1.4179425
disc_loss: 1.4179425
disc_acc: 0.2849009900990099

Validation results:
gen_loss: -1.151045
disc_loss: 1.151045
disc_acc: 0.44146825396825395


	Epoch 435
Training results:
gen_loss: -1.4109223
disc_loss: 1.4109223
disc_acc: 0.31844059405940595

Validation results:
gen_loss: -1.5032837
disc_loss: 1.5032837
disc_acc: 0.2916666666666667


	Epoch 436
Training results:
gen_loss: -1.4018179
disc_loss: 1.4018179
disc_acc: 0.30643564356435643

Validation results:
gen_loss: -1.2927078
disc_loss: 1.2927078
disc_acc: 0.3854166666666667


	Epoch 437
Training results:
gen_loss: -1.4479511
disc_loss: 1.4479511
disc_acc: 0.3022277227722772

Validation results:
gen_loss: -1.4339513
disc_loss: 1.4339513
disc_acc: 0.2961309523809524


	Epoch 438
Training results:
gen_loss: -1.4095597
disc_loss: 1.4095597
disc_acc: 0.3301980198019802

Validation results:
gen_loss: -1.5862098
disc_loss: 1.5862098
disc_acc: 0.26438492063492064


	Epoch 439
Training results:
gen_loss: -1.4837799
disc_loss: 1.4837799
disc_acc: 0.29146039603960394

Validation results:
gen_loss: -1.3537121
disc_loss: 1.3537121
disc_acc: 0.37103174603174605


	Epoch 440
Training results:
gen_loss: -1.4768001
disc_loss: 1.4768001
disc_acc: 0.2886138613861386

Validation results:
gen_loss: -1.4339085
disc_loss: 1.4339085
disc_acc: 0.27331349206349204


	Epoch 441
Training results:
gen_loss: -1.4264426
disc_loss: 1.4264426
disc_acc: 0.3014851485148515

Validation results:
gen_loss: -1.3169299
disc_loss: 1.3169299
disc_acc: 0.34226190476190477


	Epoch 442
Training results:
gen_loss: -1.5210241
disc_loss: 1.5210241
disc_acc: 0.296039603960396

Validation results:
gen_loss: -1.6905047
disc_loss: 1.6905047
disc_acc: 0.23115079365079366


	Epoch 443
Training results:
gen_loss: -1.7408135
disc_loss: 1.7408135
disc_acc: 0.24678217821782178

Validation results:
gen_loss: -1.7273179
disc_loss: 1.7273179
disc_acc: 0.2251984126984127


	Epoch 444
Training results:
gen_loss: -1.7650422
disc_loss: 1.7650422
disc_acc: 0.2448019801980198

Validation results:
gen_loss: -1.7694694
disc_loss: 1.7694694
disc_acc: 0.1671626984126984


	Epoch 445
Training results:
gen_loss: -1.7474518
disc_loss: 1.7474518
disc_acc: 0.2407178217821782

Validation results:
gen_loss: -1.9481248
disc_loss: 1.9481248
disc_acc: 0.1865079365079365


	Epoch 446
Training results:
gen_loss: -1.7603103
disc_loss: 1.7603103
disc_acc: 0.22004950495049505

Validation results:
gen_loss: -1.9887155
disc_loss: 1.9887155
disc_acc: 0.17559523809523808


	Epoch 447
Training results:
gen_loss: -1.6818702
disc_loss: 1.6818702
disc_acc: 0.27660891089108913

Validation results:
gen_loss: -2.1723757
disc_loss: 2.1723757
disc_acc: 0.18501984126984128


	Epoch 448
Training results:
gen_loss: -1.6762122
disc_loss: 1.6762122
disc_acc: 0.2784653465346535

Validation results:
gen_loss: -1.6027304
disc_loss: 1.6027304
disc_acc: 0.30357142857142855


	Epoch 449
Training results:
gen_loss: -1.6575034
disc_loss: 1.6575034
disc_acc: 0.27363861386138616

Validation results:
gen_loss: -1.9887608
disc_loss: 1.9887608
disc_acc: 0.2088293650793651


	Epoch 450
Training results:
gen_loss: -1.5916096
disc_loss: 1.5916096
disc_acc: 0.30816831683168316

Validation results:
gen_loss: -1.5836912
disc_loss: 1.5836912
disc_acc: 0.32787698412698413


	Epoch 451
Training results:
gen_loss: -1.5214908
disc_loss: 1.5214908
disc_acc: 0.3175742574257426

Validation results:
gen_loss: -1.2792583
disc_loss: 1.2792583
disc_acc: 0.39732142857142855


	Epoch 452
Training results:
gen_loss: -1.5411053
disc_loss: 1.5411053
disc_acc: 0.3264851485148515

Validation results:
gen_loss: -1.4313624
disc_loss: 1.4313624
disc_acc: 0.3492063492063492


	Epoch 453
Training results:
gen_loss: -1.5638734
disc_loss: 1.5638734
disc_acc: 0.30247524752475247

Validation results:
gen_loss: -1.46116
disc_loss: 1.46116
disc_acc: 0.36755952380952384


	Epoch 454
Training results:
gen_loss: -1.5951952
disc_loss: 1.5951952
disc_acc: 0.3061881188118812

Validation results:
gen_loss: -1.6125568
disc_loss: 1.6125568
disc_acc: 0.2837301587301587


	Epoch 455
Training results:
gen_loss: -1.519327
disc_loss: 1.519327
disc_acc: 0.3198019801980198

Validation results:
gen_loss: -1.6053226
disc_loss: 1.6053226
disc_acc: 0.2628968253968254


	Epoch 456
Training results:
gen_loss: -1.5175873
disc_loss: 1.5175873
disc_acc: 0.32821782178217823

Validation results:
gen_loss: -1.4627213
disc_loss: 1.4627213
disc_acc: 0.2926587301587302


	Epoch 457
Training results:
gen_loss: -1.6052985
disc_loss: 1.6052985
disc_acc: 0.3032178217821782

Validation results:
gen_loss: -1.3643295
disc_loss: 1.3643295
disc_acc: 0.34871031746031744


	Epoch 458
Training results:
gen_loss: -1.5067438
disc_loss: 1.5067438
disc_acc: 0.32215346534653466

Validation results:
gen_loss: -1.6721137
disc_loss: 1.6721137
disc_acc: 0.2614087301587302


	Epoch 459
Training results:
gen_loss: -1.6262276
disc_loss: 1.6262276
disc_acc: 0.29158415841584157

Validation results:
gen_loss: -1.6756501
disc_loss: 1.6756501
disc_acc: 0.31994047619047616


	Epoch 460
Training results:
gen_loss: -1.5635326
disc_loss: 1.5635326
disc_acc: 0.30334158415841583

Validation results:
gen_loss: -1.6445295
disc_loss: 1.6445295
disc_acc: 0.33581349206349204


	Epoch 461
Training results:
gen_loss: -1.5090733
disc_loss: 1.5090733
disc_acc: 0.3131188118811881

Validation results:
gen_loss: -1.9384128
disc_loss: 1.9384128
disc_acc: 0.2177579365079365


	Epoch 462
Training results:
gen_loss: -1.5859349
disc_loss: 1.5859349
disc_acc: 0.28539603960396037

Validation results:
gen_loss: -1.5398897
disc_loss: 1.5398897
disc_acc: 0.28918650793650796


	Epoch 463
Training results:
gen_loss: -1.4867114
disc_loss: 1.4867114
disc_acc: 0.31943069306930694

Validation results:
gen_loss: -1.2896514
disc_loss: 1.2896514
disc_acc: 0.38244047619047616


	Epoch 464
Training results:
gen_loss: -1.4102936
disc_loss: 1.4102936
disc_acc: 0.31014851485148515

Validation results:
gen_loss: -1.4318805
disc_loss: 1.4318805
disc_acc: 0.2708333333333333


	Epoch 465
Training results:
gen_loss: -1.3916284
disc_loss: 1.3916284
disc_acc: 0.3136138613861386

Validation results:
gen_loss: -1.3574326
disc_loss: 1.3574326
disc_acc: 0.3273809523809524


	Epoch 466
Training results:
gen_loss: -1.3834052
disc_loss: 1.3834052
disc_acc: 0.3172029702970297

Validation results:
gen_loss: -1.3111805
disc_loss: 1.3111805
disc_acc: 0.3333333333333333


	Epoch 467
Training results:
gen_loss: -1.3734908
disc_loss: 1.3734908
disc_acc: 0.3175742574257426

Validation results:
gen_loss: -1.543542
disc_loss: 1.543542
disc_acc: 0.3040674603174603


	Epoch 468
Training results:
gen_loss: -1.3797898
disc_loss: 1.3797898
disc_acc: 0.3186881188118812

Validation results:
gen_loss: -1.4493494
disc_loss: 1.4493494
disc_acc: 0.36408730158730157


	Epoch 469
Training results:
gen_loss: -1.4213884
disc_loss: 1.4213884
disc_acc: 0.3073019801980198

Validation results:
gen_loss: -1.480579
disc_loss: 1.480579
disc_acc: 0.34077380952380953


	Epoch 470
Training results:
gen_loss: -1.478116
disc_loss: 1.478116
disc_acc: 0.30024752475247524

Validation results:
gen_loss: -1.3217386
disc_loss: 1.3217386
disc_acc: 0.3373015873015873


	Epoch 471
Training results:
gen_loss: -1.4449531
disc_loss: 1.4449531
disc_acc: 0.3108910891089109

Validation results:
gen_loss: -1.378052
disc_loss: 1.378052
disc_acc: 0.37996031746031744


	Epoch 472
Training results:
gen_loss: -1.4270717
disc_loss: 1.4270717
disc_acc: 0.31076732673267327

Validation results:
gen_loss: -1.3499763
disc_loss: 1.3499763
disc_acc: 0.3149801587301587


	Epoch 473
Training results:
gen_loss: -1.4063514
disc_loss: 1.4063514
disc_acc: 0.33564356435643566

Validation results:
gen_loss: -1.346961
disc_loss: 1.346961
disc_acc: 0.33035714285714285


	Epoch 474
Training results:
gen_loss: -1.3670614
disc_loss: 1.3670614
disc_acc: 0.3284653465346535

Validation results:
gen_loss: -1.5217947
disc_loss: 1.5217947
disc_acc: 0.31845238095238093


	Epoch 475
Training results:
gen_loss: -1.4042406
disc_loss: 1.4042406
disc_acc: 0.3318069306930693

Validation results:
gen_loss: -1.2970505
disc_loss: 1.2970505
disc_acc: 0.38392857142857145


	Epoch 476
Training results:
gen_loss: -1.3474599
disc_loss: 1.3474599
disc_acc: 0.341460396039604

Validation results:
gen_loss: -1.2363123
disc_loss: 1.2363123
disc_acc: 0.4146825396825397


	Epoch 477
Training results:
gen_loss: -1.3948504
disc_loss: 1.3948504
disc_acc: 0.3214108910891089

Validation results:
gen_loss: -1.2562495
disc_loss: 1.2562495
disc_acc: 0.3333333333333333


	Epoch 478
Training results:
gen_loss: -1.3572742
disc_loss: 1.3572742
disc_acc: 0.3551980198019802

Validation results:
gen_loss: -1.2804116
disc_loss: 1.2804116
disc_acc: 0.3601190476190476


	Epoch 479
Training results:
gen_loss: -1.4551163
disc_loss: 1.4551163
disc_acc: 0.33353960396039606

Validation results:
gen_loss: -1.2583641
disc_loss: 1.2583641
disc_acc: 0.3368055555555556


	Epoch 480
Training results:
gen_loss: -1.43845
disc_loss: 1.43845
disc_acc: 0.3349009900990099

Validation results:
gen_loss: -1.3867713
disc_loss: 1.3867713
disc_acc: 0.3055555555555556


	Epoch 481
Training results:
gen_loss: -1.428499
disc_loss: 1.428499
disc_acc: 0.3110148514851485

Validation results:
gen_loss: -1.4288183
disc_loss: 1.4288183
disc_acc: 0.29216269841269843


	Epoch 482
Training results:
gen_loss: -1.4522954
disc_loss: 1.4522954
disc_acc: 0.3047029702970297

Validation results:
gen_loss: -1.267465
disc_loss: 1.267465
disc_acc: 0.29910714285714285


	Epoch 483
Training results:
gen_loss: -1.4010471
disc_loss: 1.4010471
disc_acc: 0.33452970297029705

Validation results:
gen_loss: -1.303739
disc_loss: 1.303739
disc_acc: 0.3630952380952381


	Epoch 484
Training results:
gen_loss: -1.3845979
disc_loss: 1.3845979
disc_acc: 0.3295792079207921

Validation results:
gen_loss: -1.2798673
disc_loss: 1.2798673
disc_acc: 0.36061507936507936


	Epoch 485
Training results:
gen_loss: -1.4000559
disc_loss: 1.4000559
disc_acc: 0.3149752475247525

Validation results:
gen_loss: -1.526867
disc_loss: 1.526867
disc_acc: 0.2614087301587302


	Epoch 486
Training results:
gen_loss: -1.3633549
disc_loss: 1.3633549
disc_acc: 0.3315594059405941

Validation results:
gen_loss: -1.2107121
disc_loss: 1.2107121
disc_acc: 0.4568452380952381


	Epoch 487
Training results:
gen_loss: -1.4398539
disc_loss: 1.4398539
disc_acc: 0.3181930693069307

Validation results:
gen_loss: -1.3528858
disc_loss: 1.3528858
disc_acc: 0.3288690476190476


	Epoch 488
Training results:
gen_loss: -1.3752627
disc_loss: 1.3752627
disc_acc: 0.35148514851485146

Validation results:
gen_loss: -1.4697922
disc_loss: 1.4697922
disc_acc: 0.3506944444444444


	Epoch 489
Training results:
gen_loss: -1.43069
disc_loss: 1.43069
disc_acc: 0.3120049504950495

Validation results:
gen_loss: -1.2289392
disc_loss: 1.2289392
disc_acc: 0.3998015873015873


	Epoch 490
Training results:
gen_loss: -1.3802607
disc_loss: 1.3802607
disc_acc: 0.35457920792079206

Validation results:
gen_loss: -1.5696632
disc_loss: 1.5696632
disc_acc: 0.2896825396825397


	Epoch 491
Training results:
gen_loss: -1.3988798
disc_loss: 1.3988798
disc_acc: 0.35247524752475246

Validation results:
gen_loss: -1.3777668
disc_loss: 1.3777668
disc_acc: 0.3695436507936508


	Epoch 492
Training results:
gen_loss: -1.3804562
disc_loss: 1.3804562
disc_acc: 0.34888613861386136

Validation results:
gen_loss: -1.2181654
disc_loss: 1.2181654
disc_acc: 0.4642857142857143


	Epoch 493
Training results:
gen_loss: -1.3892171
disc_loss: 1.3892171
disc_acc: 0.3327970297029703

Validation results:
gen_loss: -1.4198205
disc_loss: 1.4198205
disc_acc: 0.30853174603174605


	Epoch 494
Training results:
gen_loss: -1.4131991
disc_loss: 1.4131991
disc_acc: 0.3120049504950495

Validation results:
gen_loss: -1.3141847
disc_loss: 1.3141847
disc_acc: 0.3531746031746032


	Epoch 495
Training results:
gen_loss: -1.4373577
disc_loss: 1.4373577
disc_acc: 0.3113861386138614

Validation results:
gen_loss: -1.445682
disc_loss: 1.445682
disc_acc: 0.2619047619047619


	Epoch 496
Training results:
gen_loss: -1.409653
disc_loss: 1.409653
disc_acc: 0.33663366336633666

Validation results:
gen_loss: -1.4271299
disc_loss: 1.4271299
disc_acc: 0.30654761904761907


	Epoch 497
Training results:
gen_loss: -1.349
disc_loss: 1.349
disc_acc: 0.33762376237623765

Validation results:
gen_loss: -1.4353839
disc_loss: 1.4353839
disc_acc: 0.33978174603174605


	Epoch 498
Training results:
gen_loss: -1.3661172
disc_loss: 1.3661172
disc_acc: 0.3459158415841584

Validation results:
gen_loss: -1.097942
disc_loss: 1.097942
disc_acc: 0.4618055555555556


	Epoch 499
Training results:
gen_loss: -1.3309664
disc_loss: 1.3309664
disc_acc: 0.34628712871287126

Validation results:
gen_loss: -1.2605577
disc_loss: 1.2605577
disc_acc: 0.3630952380952381


	Epoch 500
Training results:
gen_loss: -1.3943357
disc_loss: 1.3943357
disc_acc: 0.341460396039604

Validation results:
gen_loss: -1.7660481
disc_loss: 1.7660481
disc_acc: 0.34672619047619047



Training new discriminator on static trained discriminator.
	Initial performance
Training results:
gen_loss: -5.7154927
disc_loss: 5.7154927
disc_acc: 0.0023514851485148514

Validation results:
gen_loss: -5.701759
disc_loss: 5.701759
disc_acc: 0.001488095238095238


	Epoch 1
Training results:
gen_loss: -2.1569734
disc_loss: 2.1569734
disc_acc: 0.2243811881188119

Validation results:
gen_loss: -1.7179042
disc_loss: 1.7179042
disc_acc: 0.24702380952380953


	Epoch 2
Training results:
gen_loss: -1.7437778
disc_loss: 1.7437778
disc_acc: 0.24975247524752475

Validation results:
gen_loss: -1.6084311
disc_loss: 1.6084311
disc_acc: 0.26785714285714285


	Epoch 3
Training results:
gen_loss: -1.7154473
disc_loss: 1.7154473
disc_acc: 0.26064356435643565

Validation results:
gen_loss: -1.5431874
disc_loss: 1.5431874
disc_acc: 0.29662698412698413


	Epoch 4
Training results:
gen_loss: -1.5785937
disc_loss: 1.5785937
disc_acc: 0.2952970297029703

Validation results:
gen_loss: -1.4304436
disc_loss: 1.4304436
disc_acc: 0.30257936507936506


	Epoch 5
Training results:
gen_loss: -1.4985594
disc_loss: 1.4985594
disc_acc: 0.3349009900990099

Validation results:
gen_loss: -1.5423734
disc_loss: 1.5423734
disc_acc: 0.3229166666666667


	Epoch 6
Training results:
gen_loss: -1.4519703
disc_loss: 1.4519703
disc_acc: 0.36076732673267325

Validation results:
gen_loss: -1.4557594
disc_loss: 1.4557594
disc_acc: 0.3263888888888889


	Epoch 7
Training results:
gen_loss: -1.3216434
disc_loss: 1.3216434
disc_acc: 0.4064356435643564

Validation results:
gen_loss: -1.3074996
disc_loss: 1.3074996
disc_acc: 0.3531746031746032


	Epoch 8
Training results:
gen_loss: -1.1239977
disc_loss: 1.1239977
disc_acc: 0.49764851485148515

Validation results:
gen_loss: -1.0741827
disc_loss: 1.0741827
disc_acc: 0.45436507936507936


	Epoch 9
Training results:
gen_loss: -1.0678568
disc_loss: 1.0678568
disc_acc: 0.5214108910891089

Validation results:
gen_loss: -1.0217333
disc_loss: 1.0217333
disc_acc: 0.5411706349206349


	Epoch 10
Training results:
gen_loss: -1.0320927
disc_loss: 1.0320927
disc_acc: 0.5488861386138614

Validation results:
gen_loss: -0.75660163
disc_loss: 0.75660163
disc_acc: 0.6870039682539683


	Epoch 11
Training results:
gen_loss: -0.7831516
disc_loss: 0.7831516
disc_acc: 0.6452970297029703

Validation results:
gen_loss: -0.7347325
disc_loss: 0.7347325
disc_acc: 0.7028769841269841


	Epoch 12
Training results:
gen_loss: -0.6868841
disc_loss: 0.6868841
disc_acc: 0.6981435643564357

Validation results:
gen_loss: -0.671023
disc_loss: 0.671023
disc_acc: 0.7336309523809523


	Epoch 13
Training results:
gen_loss: -0.7232311
disc_loss: 0.7232311
disc_acc: 0.6922029702970297

Validation results:
gen_loss: -0.54441583
disc_loss: 0.54441583
disc_acc: 0.7455357142857143


	Epoch 14
Training results:
gen_loss: -0.63086796
disc_loss: 0.63086796
disc_acc: 0.7363861386138614

Validation results:
gen_loss: -0.63902503
disc_loss: 0.63902503
disc_acc: 0.6537698412698413


	Epoch 15
Training results:
gen_loss: -0.5825474
disc_loss: 0.5825474
disc_acc: 0.7566831683168317

Validation results:
gen_loss: -0.5046317
disc_loss: 0.5046317
disc_acc: 0.7708333333333334


	Epoch 16
Training results:
gen_loss: -0.536956
disc_loss: 0.536956
disc_acc: 0.7663366336633664

Validation results:
gen_loss: -0.9287793
disc_loss: 0.9287793
disc_acc: 0.6349206349206349


	Epoch 17
Training results:
gen_loss: -0.54428387
disc_loss: 0.54428387
disc_acc: 0.781559405940594

Validation results:
gen_loss: -0.27608505
disc_loss: 0.27608505
disc_acc: 0.8700396825396826


	Epoch 18
Training results:
gen_loss: -0.3619415
disc_loss: 0.3619415
disc_acc: 0.8481435643564357

Validation results:
gen_loss: -0.26879337
disc_loss: 0.26879337
disc_acc: 0.8779761904761905


	Epoch 19
Training results:
gen_loss: -0.28039932
disc_loss: 0.28039932
disc_acc: 0.8772277227722772

Validation results:
gen_loss: -0.26873246
disc_loss: 0.26873246
disc_acc: 0.8804563492063492


	Epoch 20
Training results:
gen_loss: -0.4567445
disc_loss: 0.4567445
disc_acc: 0.813490099009901

Validation results:
gen_loss: -0.3471503
disc_loss: 0.3471503
disc_acc: 0.8735119047619048


	Epoch 21
Training results:
gen_loss: -0.487098
disc_loss: 0.487098
disc_acc: 0.8021039603960396

Validation results:
gen_loss: -0.39858857
disc_loss: 0.39858857
disc_acc: 0.8209325396825397


	Epoch 22
Training results:
gen_loss: -0.34372953
disc_loss: 0.34372953
disc_acc: 0.8587871287128713

Validation results:
gen_loss: -0.2670414
disc_loss: 0.2670414
disc_acc: 0.8998015873015873


	Epoch 23
Training results:
gen_loss: -0.45134962
disc_loss: 0.45134962
disc_acc: 0.8356435643564356

Validation results:
gen_loss: -0.8163431
disc_loss: 0.8163431
disc_acc: 0.7708333333333334


	Epoch 24
Training results:
gen_loss: -0.34072575
disc_loss: 0.34072575
disc_acc: 0.8521039603960396

Validation results:
gen_loss: -0.2829779
disc_loss: 0.2829779
disc_acc: 0.8754960317460317


	Epoch 25
Training results:
gen_loss: -0.25641146
disc_loss: 0.25641146
disc_acc: 0.8914603960396039

Validation results:
gen_loss: -0.5206138
disc_loss: 0.5206138
disc_acc: 0.7797619047619048


	Epoch 26
Training results:
gen_loss: -0.43941116
disc_loss: 0.43941116
disc_acc: 0.825

Validation results:
gen_loss: -0.25647113
disc_loss: 0.25647113
disc_acc: 0.9255952380952381


	Epoch 27
Training results:
gen_loss: -0.28849554
disc_loss: 0.28849554
disc_acc: 0.8834158415841584

Validation results:
gen_loss: -0.4201277
disc_loss: 0.4201277
disc_acc: 0.8556547619047619


	Epoch 28
Training results:
gen_loss: -0.36180753
disc_loss: 0.36180753
disc_acc: 0.8525990099009901

Validation results:
gen_loss: -0.3613172
disc_loss: 0.3613172
disc_acc: 0.8938492063492064


	Epoch 29
Training results:
gen_loss: -0.35297796
disc_loss: 0.35297796
disc_acc: 0.8543316831683169

Validation results:
gen_loss: -0.20703767
disc_loss: 0.20703767
disc_acc: 0.9419642857142857


	Epoch 30
Training results:
gen_loss: -0.35820478
disc_loss: 0.35820478
disc_acc: 0.861509900990099

Validation results:
gen_loss: -0.19506545
disc_loss: 0.19506545
disc_acc: 0.9454365079365079


	Epoch 31
Training results:
gen_loss: -0.16344777
disc_loss: 0.16344777
disc_acc: 0.9235148514851486

Validation results:
gen_loss: -0.11368534
disc_loss: 0.11368534
disc_acc: 0.9786706349206349


	Epoch 32
Training results:
gen_loss: -0.43198544
disc_loss: 0.43198544
disc_acc: 0.8400990099009901

Validation results:
gen_loss: -0.20995358
disc_loss: 0.20995358
disc_acc: 0.8740079365079365


	Epoch 33
Training results:
gen_loss: -0.2519095
disc_loss: 0.2519095
disc_acc: 0.8966584158415841

Validation results:
gen_loss: -0.16218324
disc_loss: 0.16218324
disc_acc: 0.9315476190476191


	Epoch 34
Training results:
gen_loss: -0.335027
disc_loss: 0.335027
disc_acc: 0.8659653465346535

Validation results:
gen_loss: -0.30539984
disc_loss: 0.30539984
disc_acc: 0.8804563492063492


	Epoch 35
Training results:
gen_loss: -0.239541
disc_loss: 0.239541
disc_acc: 0.8949257425742574

Validation results:
gen_loss: -0.15425694
disc_loss: 0.15425694
disc_acc: 0.8784722222222222


	Epoch 36
Training results:
gen_loss: -0.45451766
disc_loss: 0.45451766
disc_acc: 0.8352722772277228

Validation results:
gen_loss: -0.15606803
disc_loss: 0.15606803
disc_acc: 0.9623015873015873


	Epoch 37
Training results:
gen_loss: -0.26878214
disc_loss: 0.26878214
disc_acc: 0.8923267326732673

Validation results:
gen_loss: -0.1449
disc_loss: 0.1449
disc_acc: 0.9002976190476191


	Epoch 38
Training results:
gen_loss: -0.20053801
disc_loss: 0.20053801
disc_acc: 0.9122524752475247

Validation results:
gen_loss: -0.20450486
disc_loss: 0.20450486
disc_acc: 0.9290674603174603


	Epoch 39
Training results:
gen_loss: -0.19866055
disc_loss: 0.19866055
disc_acc: 0.9103960396039604

Validation results:
gen_loss: -0.121026225
disc_loss: 0.121026225
disc_acc: 0.9503968253968254


	Epoch 40
Training results:
gen_loss: -0.4496548
disc_loss: 0.4496548
disc_acc: 0.847029702970297

Validation results:
gen_loss: -0.3342289
disc_loss: 0.3342289
disc_acc: 0.8849206349206349


	Epoch 41
Training results:
gen_loss: -0.18146667
disc_loss: 0.18146667
disc_acc: 0.9236386138613861

Validation results:
gen_loss: -0.14165896
disc_loss: 0.14165896
disc_acc: 0.8948412698412699


	Epoch 42
Training results:
gen_loss: -0.17924397
disc_loss: 0.17924397
disc_acc: 0.9185643564356436

Validation results:
gen_loss: -0.1351345
disc_loss: 0.1351345
disc_acc: 0.9623015873015873


	Epoch 43
Training results:
gen_loss: -0.48798573
disc_loss: 0.48798573
disc_acc: 0.8295792079207921

Validation results:
gen_loss: -0.23850659
disc_loss: 0.23850659
disc_acc: 0.8556547619047619


	Epoch 44
Training results:
gen_loss: -0.1754378
disc_loss: 0.1754378
disc_acc: 0.9207920792079208

Validation results:
gen_loss: -0.15630002
disc_loss: 0.15630002
disc_acc: 0.9424603174603174


	Epoch 45
Training results:
gen_loss: -0.20171699
disc_loss: 0.20171699
disc_acc: 0.9224009900990099

Validation results:
gen_loss: -0.24870183
disc_loss: 0.24870183
disc_acc: 0.9017857142857143


	Epoch 46
Training results:
gen_loss: -0.18665798
disc_loss: 0.18665798
disc_acc: 0.9288366336633663

Validation results:
gen_loss: -0.2126224
disc_loss: 0.2126224
disc_acc: 0.9161706349206349


	Epoch 47
Training results:
gen_loss: -0.17493887
disc_loss: 0.17493887
disc_acc: 0.9272277227722773

Validation results:
gen_loss: -0.4028581
disc_loss: 0.4028581
disc_acc: 0.8561507936507936


	Epoch 48
Training results:
gen_loss: -0.23802872
disc_loss: 0.23802872
disc_acc: 0.9071782178217822

Validation results:
gen_loss: -0.15662447
disc_loss: 0.15662447
disc_acc: 0.9196428571428571


	Epoch 49
Training results:
gen_loss: -0.29423276
disc_loss: 0.29423276
disc_acc: 0.8952970297029703

Validation results:
gen_loss: -0.27803424
disc_loss: 0.27803424
disc_acc: 0.8541666666666666


	Epoch 50
Training results:
gen_loss: -0.31689766
disc_loss: 0.31689766
disc_acc: 0.8910891089108911

Validation results:
gen_loss: -0.1284227
disc_loss: 0.1284227
disc_acc: 0.9598214285714286


	Epoch 51
Training results:
gen_loss: -0.16538328
disc_loss: 0.16538328
disc_acc: 0.9297029702970298

Validation results:
gen_loss: -0.11190555
disc_loss: 0.11190555
disc_acc: 0.9494047619047619


	Epoch 52
Training results:
gen_loss: -0.31442717
disc_loss: 0.31442717
disc_acc: 0.8997524752475248

Validation results:
gen_loss: -1.1728419
disc_loss: 1.1728419
disc_acc: 0.7242063492063492


	Epoch 53
Training results:
gen_loss: -0.22671336
disc_loss: 0.22671336
disc_acc: 0.9206683168316832

Validation results:
gen_loss: -0.06898111
disc_loss: 0.06898111
disc_acc: 0.9826388888888888


	Epoch 54
Training results:
gen_loss: -0.13025972
disc_loss: 0.13025972
disc_acc: 0.9516089108910891

Validation results:
gen_loss: -0.31999022
disc_loss: 0.31999022
disc_acc: 0.9122023809523809


	Epoch 55
Training results:
gen_loss: -0.22079854
disc_loss: 0.22079854
disc_acc: 0.9247524752475248

Validation results:
gen_loss: -0.12304763
disc_loss: 0.12304763
disc_acc: 0.9588293650793651


	Epoch 56
Training results:
gen_loss: -0.11239371
disc_loss: 0.11239371
disc_acc: 0.9533415841584159

Validation results:
gen_loss: -0.24438377
disc_loss: 0.24438377
disc_acc: 0.9409722222222222


	Epoch 57
Training results:
gen_loss: -0.16463926
disc_loss: 0.16463926
disc_acc: 0.9474009900990099

Validation results:
gen_loss: -0.07163566
disc_loss: 0.07163566
disc_acc: 0.9677579365079365


	Epoch 58
Training results:
gen_loss: -0.22712497
disc_loss: 0.22712497
disc_acc: 0.9186881188118812

Validation results:
gen_loss: -0.36310628
disc_loss: 0.36310628
disc_acc: 0.8764880952380952


	Epoch 59
Training results:
gen_loss: -0.53926384
disc_loss: 0.53926384
disc_acc: 0.8511138613861386

Validation results:
gen_loss: -0.21154298
disc_loss: 0.21154298
disc_acc: 0.8690476190476191


	Epoch 60
Training results:
gen_loss: -0.21379572
disc_loss: 0.21379572
disc_acc: 0.925990099009901

Validation results:
gen_loss: -0.25815174
disc_loss: 0.25815174
disc_acc: 0.8759920634920635


	Epoch 61
Training results:
gen_loss: -0.12953454
disc_loss: 0.12953454
disc_acc: 0.9443069306930693

Validation results:
gen_loss: -0.08855412
disc_loss: 0.08855412
disc_acc: 0.9806547619047619


	Epoch 62
Training results:
gen_loss: -0.15539059
disc_loss: 0.15539059
disc_acc: 0.9465346534653465

Validation results:
gen_loss: -0.11352852
disc_loss: 0.11352852
disc_acc: 0.9409722222222222


	Epoch 63
Training results:
gen_loss: -0.20631409
disc_loss: 0.20631409
disc_acc: 0.9251237623762376

Validation results:
gen_loss: -0.18067837
disc_loss: 0.18067837
disc_acc: 0.9246031746031746


	Epoch 64
Training results:
gen_loss: -0.199712
disc_loss: 0.199712
disc_acc: 0.9285891089108911

Validation results:
gen_loss: -0.11777721
disc_loss: 0.11777721
disc_acc: 0.9523809523809523


	Epoch 65
Training results:
gen_loss: -0.31470302
disc_loss: 0.31470302
disc_acc: 0.9148514851485149

Validation results:
gen_loss: -0.2532354
disc_loss: 0.2532354
disc_acc: 0.9310515873015873


	Epoch 66
Training results:
gen_loss: -0.1396297
disc_loss: 0.1396297
disc_acc: 0.9532178217821782

Validation results:
gen_loss: -0.13553973
disc_loss: 0.13553973
disc_acc: 0.9632936507936508


	Epoch 67
Training results:
gen_loss: -0.052758984
disc_loss: 0.052758984
disc_acc: 0.9834158415841584

Validation results:
gen_loss: -0.004112084
disc_loss: 0.004112084
disc_acc: 1.0


	Epoch 68
Training results:
gen_loss: -0.3297161
disc_loss: 0.3297161
disc_acc: 0.9178217821782179

Validation results:
gen_loss: -0.14792995
disc_loss: 0.14792995
disc_acc: 0.9270833333333334


	Epoch 69
Training results:
gen_loss: -0.14323771
disc_loss: 0.14323771
disc_acc: 0.9580445544554456

Validation results:
gen_loss: -0.16200107
disc_loss: 0.16200107
disc_acc: 0.9305555555555556


	Epoch 70
Training results:
gen_loss: -0.01171961
disc_loss: 0.01171961
disc_acc: 0.9969059405940595

Validation results:
gen_loss: -0.001388964
disc_loss: 0.001388964
disc_acc: 1.0


	Epoch 71
Training results:
gen_loss: -0.20509824
disc_loss: 0.20509824
disc_acc: 0.932920792079208

Validation results:
gen_loss: -0.03374321
disc_loss: 0.03374321
disc_acc: 0.998015873015873


	Epoch 72
Training results:
gen_loss: -0.10373695
disc_loss: 0.10373695
disc_acc: 0.9701732673267327

Validation results:
gen_loss: -0.1601914
disc_loss: 0.1601914
disc_acc: 0.9494047619047619


	Epoch 73
Training results:
gen_loss: -0.1087377
disc_loss: 0.1087377
disc_acc: 0.965470297029703

Validation results:
gen_loss: -0.12348393
disc_loss: 0.12348393
disc_acc: 0.9176587301587301


	Epoch 74
Training results:
gen_loss: -0.22163777
disc_loss: 0.22163777
disc_acc: 0.9405940594059405

Validation results:
gen_loss: -0.06671694
disc_loss: 0.06671694
disc_acc: 0.9697420634920635


	Epoch 75
Training results:
gen_loss: -0.017409123
disc_loss: 0.017409123
disc_acc: 0.9957920792079208

Validation results:
gen_loss: -0.0023373037
disc_loss: 0.0023373037
disc_acc: 0.9995039682539683


	Epoch 76
Training results:
gen_loss: -0.25362656
disc_loss: 0.25362656
disc_acc: 0.9292079207920793

Validation results:
gen_loss: -0.48907405
disc_loss: 0.48907405
disc_acc: 0.8472222222222222


	Epoch 77
Training results:
gen_loss: -0.13398537
disc_loss: 0.13398537
disc_acc: 0.9612623762376238

Validation results:
gen_loss: -0.028425027
disc_loss: 0.028425027
disc_acc: 0.9945436507936508


	Epoch 78
Training results:
gen_loss: -0.07670936
disc_loss: 0.07670936
disc_acc: 0.9764851485148515

Validation results:
gen_loss: -0.0012785045
disc_loss: 0.0012785045
disc_acc: 1.0


	Epoch 79
Training results:
gen_loss: -0.0056417114
disc_loss: 0.0056417114
disc_acc: 0.999009900990099

Validation results:
gen_loss: -0.0003552587
disc_loss: 0.0003552587
disc_acc: 1.0


	Epoch 80
Training results:
gen_loss: -0.05786776
disc_loss: 0.05786776
disc_acc: 0.986509900990099

Validation results:
gen_loss: -0.03070236
disc_loss: 0.03070236
disc_acc: 0.9885912698412699


	Epoch 81
Training results:
gen_loss: -0.5264505
disc_loss: 0.5264505
disc_acc: 0.9099009900990099

Validation results:
gen_loss: -0.006645516
disc_loss: 0.006645516
disc_acc: 0.9995039682539683


	Epoch 82
Training results:
gen_loss: -0.08431212
disc_loss: 0.08431212
disc_acc: 0.9842821782178218

Validation results:
gen_loss: -0.61438334
disc_loss: 0.61438334
disc_acc: 0.8779761904761905


	Epoch 83
Training results:
gen_loss: -0.06544067
disc_loss: 0.06544067
disc_acc: 0.9805693069306931

Validation results:
gen_loss: -0.00082295213
disc_loss: 0.00082295213
disc_acc: 1.0


	Epoch 84
Training results:
gen_loss: -0.001966619
disc_loss: 0.001966619
disc_acc: 0.9998762376237624

Validation results:
gen_loss: -0.00093148695
disc_loss: 0.00093148695
disc_acc: 1.0


	Epoch 85
Training results:
gen_loss: -0.086972594
disc_loss: 0.086972594
disc_acc: 0.9775990099009901

Validation results:
gen_loss: -0.0011759432
disc_loss: 0.0011759432
disc_acc: 0.9995039682539683


	Epoch 86
Training results:
gen_loss: -0.15570208
disc_loss: 0.15570208
disc_acc: 0.9597772277227723

Validation results:
gen_loss: -0.087300815
disc_loss: 0.087300815
disc_acc: 0.9821428571428571


	Epoch 87
Training results:
gen_loss: -0.0667239
disc_loss: 0.0667239
disc_acc: 0.9790841584158416

Validation results:
gen_loss: -0.0068451497
disc_loss: 0.0068451497
disc_acc: 0.9990079365079365


	Epoch 88
Training results:
gen_loss: -0.22581789
disc_loss: 0.22581789
disc_acc: 0.9429455445544555

Validation results:
gen_loss: -0.07877863
disc_loss: 0.07877863
disc_acc: 0.972718253968254


	Epoch 89
Training results:
gen_loss: -0.029057903
disc_loss: 0.029057903
disc_acc: 0.9908415841584158

Validation results:
gen_loss: -0.0005080385
disc_loss: 0.0005080385
disc_acc: 1.0


	Epoch 90
Training results:
gen_loss: -0.01157707
disc_loss: 0.01157707
disc_acc: 0.9975247524752475

Validation results:
gen_loss: -0.00034865376
disc_loss: 0.00034865376
disc_acc: 1.0


	Epoch 91
Training results:
gen_loss: -0.2395026
disc_loss: 0.2395026
disc_acc: 0.9441831683168317

Validation results:
gen_loss: -0.15698756
disc_loss: 0.15698756
disc_acc: 0.9315476190476191


	Epoch 92
Training results:
gen_loss: -0.016327702
disc_loss: 0.016327702
disc_acc: 0.9943069306930693

Validation results:
gen_loss: -0.0068738344
disc_loss: 0.0068738344
disc_acc: 0.9990079365079365


	Epoch 93
Training results:
gen_loss: -0.00037294254
disc_loss: 0.00037294254
disc_acc: 1.0

Validation results:
gen_loss: -0.00019798856
disc_loss: 0.00019798856
disc_acc: 1.0


	Epoch 94
Training results:
gen_loss: -0.6753586
disc_loss: 0.6753586
disc_acc: 0.8831683168316832

Validation results:
gen_loss: -0.03134578
disc_loss: 0.03134578
disc_acc: 0.9965277777777778


	Epoch 95
Training results:
gen_loss: -0.0260856
disc_loss: 0.0260856
disc_acc: 0.9913366336633663

Validation results:
gen_loss: -0.012030008
disc_loss: 0.012030008
disc_acc: 0.9970238095238095


	Epoch 96
Training results:
gen_loss: -0.0015403205
disc_loss: 0.0015403205
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -0.001160253
disc_loss: 0.001160253
disc_acc: 1.0


	Epoch 97
Training results:
gen_loss: -0.00046481585
disc_loss: 0.00046481585
disc_acc: 1.0

Validation results:
gen_loss: -0.00020644152
disc_loss: 0.00020644152
disc_acc: 1.0


	Epoch 98
Training results:
gen_loss: -0.00014650101
disc_loss: 0.00014650101
disc_acc: 1.0

Validation results:
gen_loss: -0.00013066133
disc_loss: 0.00013066133
disc_acc: 1.0


	Epoch 99
Training results:
gen_loss: -0.15357368
disc_loss: 0.15357368
disc_acc: 0.9584158415841584

Validation results:
gen_loss: -0.19219655
disc_loss: 0.19219655
disc_acc: 0.9389880952380952


	Epoch 100
Training results:
gen_loss: -0.074837014
disc_loss: 0.074837014
disc_acc: 0.976980198019802

Validation results:
gen_loss: -0.013912729
disc_loss: 0.013912729
disc_acc: 1.0


	Epoch 101
Training results:
gen_loss: -0.050283417
disc_loss: 0.050283417
disc_acc: 0.9832920792079208

Validation results:
gen_loss: -0.0013653695
disc_loss: 0.0013653695
disc_acc: 1.0


	Epoch 102
Training results:
gen_loss: -0.031787805
disc_loss: 0.031787805
disc_acc: 0.9903465346534653

Validation results:
gen_loss: -0.079524964
disc_loss: 0.079524964
disc_acc: 0.9756944444444444


	Epoch 103
Training results:
gen_loss: -0.24361934
disc_loss: 0.24361934
disc_acc: 0.9412128712871287

Validation results:
gen_loss: -0.0019195979
disc_loss: 0.0019195979
disc_acc: 0.9995039682539683


	Epoch 104
Training results:
gen_loss: -0.0039059394
disc_loss: 0.0039059394
disc_acc: 0.9992574257425743

Validation results:
gen_loss: -0.0031998283
disc_loss: 0.0031998283
disc_acc: 0.9995039682539683


	Epoch 105
Training results:
gen_loss: -0.00039916753
disc_loss: 0.00039916753
disc_acc: 1.0

Validation results:
gen_loss: -0.00015836101
disc_loss: 0.00015836101
disc_acc: 1.0


	Epoch 106
Training results:
gen_loss: -0.00017960949
disc_loss: 0.00017960949
disc_acc: 1.0

Validation results:
gen_loss: -0.00010051481
disc_loss: 0.00010051481
disc_acc: 1.0


	Epoch 107
Training results:
gen_loss: -9.83847e-05
disc_loss: 9.83847e-05
disc_acc: 1.0

Validation results:
gen_loss: -5.374305e-05
disc_loss: 5.374305e-05
disc_acc: 1.0


	Epoch 108
Training results:
gen_loss: -4.4373064e-05
disc_loss: 4.4373064e-05
disc_acc: 1.0

Validation results:
gen_loss: -4.0541378e-05
disc_loss: 4.0541378e-05
disc_acc: 1.0


	Epoch 109
Training results:
gen_loss: -0.9357059
disc_loss: 0.9357059
disc_acc: 0.884529702970297

Validation results:
gen_loss: -0.0074947802
disc_loss: 0.0074947802
disc_acc: 1.0


	Epoch 110
Training results:
gen_loss: -0.02165622
disc_loss: 0.02165622
disc_acc: 0.994430693069307

Validation results:
gen_loss: -0.15963364
disc_loss: 0.15963364
disc_acc: 0.9454365079365079


	Epoch 111
Training results:
gen_loss: -0.089066446
disc_loss: 0.089066446
disc_acc: 0.9753712871287129

Validation results:
gen_loss: -0.32223117
disc_loss: 0.32223117
disc_acc: 0.9255952380952381


	Epoch 112
Training results:
gen_loss: -0.109716915
disc_loss: 0.109716915
disc_acc: 0.9719059405940594

Validation results:
gen_loss: -0.0039024751
disc_loss: 0.0039024751
disc_acc: 0.9995039682539683


	Epoch 113
Training results:
gen_loss: -0.0014182886
disc_loss: 0.0014182886
disc_acc: 1.0

Validation results:
gen_loss: -0.0012376178
disc_loss: 0.0012376178
disc_acc: 1.0


	Epoch 114
Training results:
gen_loss: -0.047236566
disc_loss: 0.047236566
disc_acc: 0.9850247524752476

Validation results:
gen_loss: -0.002728586
disc_loss: 0.002728586
disc_acc: 0.9990079365079365


	Epoch 115
Training results:
gen_loss: -0.08278741
disc_loss: 0.08278741
disc_acc: 0.975

Validation results:
gen_loss: -0.011354353
disc_loss: 0.011354353
disc_acc: 1.0


	Epoch 116
Training results:
gen_loss: -0.07505543
disc_loss: 0.07505543
disc_acc: 0.9783415841584159

Validation results:
gen_loss: -0.0031902427
disc_loss: 0.0031902427
disc_acc: 1.0


	Epoch 117
Training results:
gen_loss: -0.0102191605
disc_loss: 0.0102191605
disc_acc: 0.99740099009901

Validation results:
gen_loss: -0.00022349371
disc_loss: 0.00022349371
disc_acc: 1.0


	Epoch 118
Training results:
gen_loss: -0.00014069135
disc_loss: 0.00014069135
disc_acc: 1.0

Validation results:
gen_loss: -0.00013262458
disc_loss: 0.00013262458
disc_acc: 1.0


	Epoch 119
Training results:
gen_loss: -6.9335176e-05
disc_loss: 6.9335176e-05
disc_acc: 1.0

Validation results:
gen_loss: -0.00011043617
disc_loss: 0.00011043617
disc_acc: 1.0


	Epoch 120
Training results:
gen_loss: -7.796329e-05
disc_loss: 7.796329e-05
disc_acc: 1.0

Validation results:
gen_loss: -0.00010033318
disc_loss: 0.00010033318
disc_acc: 1.0


	Epoch 121
Training results:
gen_loss: -7.4712036e-05
disc_loss: 7.4712036e-05
disc_acc: 1.0

Validation results:
gen_loss: -5.9202997e-05
disc_loss: 5.9202997e-05
disc_acc: 1.0


	Epoch 122
Training results:
gen_loss: -4.6795452e-05
disc_loss: 4.6795452e-05
disc_acc: 1.0

Validation results:
gen_loss: -0.00014048908
disc_loss: 0.00014048908
disc_acc: 1.0


	Epoch 123
Training results:
gen_loss: -0.42957604
disc_loss: 0.42957604
disc_acc: 0.9280940594059406

Validation results:
gen_loss: -0.0055853804
disc_loss: 0.0055853804
disc_acc: 0.9990079365079365


	Epoch 124
Training results:
gen_loss: -0.0008272764
disc_loss: 0.0008272764
disc_acc: 1.0

Validation results:
gen_loss: -0.0014439346
disc_loss: 0.0014439346
disc_acc: 0.9995039682539683


	Epoch 125
Training results:
gen_loss: -0.0015444952
disc_loss: 0.0015444952
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -0.00041097435
disc_loss: 0.00041097435
disc_acc: 1.0


	Epoch 126
Training results:
gen_loss: -0.0042912923
disc_loss: 0.0042912923
disc_acc: 0.999009900990099

Validation results:
gen_loss: -0.009965055
disc_loss: 0.009965055
disc_acc: 0.9985119047619048


	Epoch 127
Training results:
gen_loss: -0.15412341
disc_loss: 0.15412341
disc_acc: 0.9672029702970297

Validation results:
gen_loss: -0.08953033
disc_loss: 0.08953033
disc_acc: 0.9399801587301587


	Epoch 128
Training results:
gen_loss: -0.028918004
disc_loss: 0.028918004
disc_acc: 0.9897277227722773

Validation results:
gen_loss: -0.00080230256
disc_loss: 0.00080230256
disc_acc: 1.0


	Epoch 129
Training results:
gen_loss: -0.022272922
disc_loss: 0.022272922
disc_acc: 0.9928217821782178

Validation results:
gen_loss: -0.0013522333
disc_loss: 0.0013522333
disc_acc: 1.0


	Epoch 130
Training results:
gen_loss: -0.00053100876
disc_loss: 0.00053100876
disc_acc: 1.0

Validation results:
gen_loss: -0.00040436594
disc_loss: 0.00040436594
disc_acc: 1.0


	Epoch 131
Training results:
gen_loss: -0.08056001
disc_loss: 0.08056001
disc_acc: 0.9868811881188119

Validation results:
gen_loss: -0.9086868
disc_loss: 0.9086868
disc_acc: 0.7906746031746031


	Epoch 132
Training results:
gen_loss: -0.5675369
disc_loss: 0.5675369
disc_acc: 0.9352722772277228

Validation results:
gen_loss: -0.019967923
disc_loss: 0.019967923
disc_acc: 0.9970238095238095


	Epoch 133
Training results:
gen_loss: -0.018692859
disc_loss: 0.018692859
disc_acc: 0.9951732673267327

Validation results:
gen_loss: -0.054923527
disc_loss: 0.054923527
disc_acc: 0.9856150793650794


	Epoch 134
Training results:
gen_loss: -0.026341572
disc_loss: 0.026341572
disc_acc: 0.9919554455445545

Validation results:
gen_loss: -0.00029074398
disc_loss: 0.00029074398
disc_acc: 1.0


	Epoch 135
Training results:
gen_loss: -0.124617055
disc_loss: 0.124617055
disc_acc: 0.9733910891089109

Validation results:
gen_loss: -0.024941955
disc_loss: 0.024941955
disc_acc: 0.996031746031746


	Epoch 136
Training results:
gen_loss: -0.0037866104
disc_loss: 0.0037866104
disc_acc: 0.9992574257425743

Validation results:
gen_loss: -0.00057179225
disc_loss: 0.00057179225
disc_acc: 1.0


	Epoch 137
Training results:
gen_loss: -0.00026862876
disc_loss: 0.00026862876
disc_acc: 1.0

Validation results:
gen_loss: -0.00025948178
disc_loss: 0.00025948178
disc_acc: 1.0


	Epoch 138
Training results:
gen_loss: -0.00012997571
disc_loss: 0.00012997571
disc_acc: 1.0

Validation results:
gen_loss: -9.744702e-05
disc_loss: 9.744702e-05
disc_acc: 1.0


	Epoch 139
Training results:
gen_loss: -0.65249604
disc_loss: 0.65249604
disc_acc: 0.9082920792079208

Validation results:
gen_loss: -0.015863312
disc_loss: 0.015863312
disc_acc: 0.9965277777777778


	Epoch 140
Training results:
gen_loss: -0.003910054
disc_loss: 0.003910054
disc_acc: 0.9993811881188119

Validation results:
gen_loss: -0.0006623151
disc_loss: 0.0006623151
disc_acc: 1.0


	Epoch 141
Training results:
gen_loss: -0.05238999
disc_loss: 0.05238999
disc_acc: 0.9866336633663366

Validation results:
gen_loss: -0.0033430215
disc_loss: 0.0033430215
disc_acc: 0.9995039682539683


	Epoch 142
Training results:
gen_loss: -0.0012840253
disc_loss: 0.0012840253
disc_acc: 0.9998762376237624

Validation results:
gen_loss: -0.00057294866
disc_loss: 0.00057294866
disc_acc: 1.0


	Epoch 143
Training results:
gen_loss: -0.059980497
disc_loss: 0.059980497
disc_acc: 0.9858910891089109

Validation results:
gen_loss: -0.0009984944
disc_loss: 0.0009984944
disc_acc: 1.0


	Epoch 144
Training results:
gen_loss: -0.004072536
disc_loss: 0.004072536
disc_acc: 0.9995049504950495

Validation results:
gen_loss: -0.09366921
disc_loss: 0.09366921
disc_acc: 0.9538690476190477


	Epoch 145
Training results:
gen_loss: -0.016484572
disc_loss: 0.016484572
disc_acc: 0.9949257425742575

Validation results:
gen_loss: -0.00060380355
disc_loss: 0.00060380355
disc_acc: 1.0


	Epoch 146
Training results:
gen_loss: -0.0002170882
disc_loss: 0.0002170882
disc_acc: 1.0

Validation results:
gen_loss: -0.00023132774
disc_loss: 0.00023132774
disc_acc: 1.0


	Epoch 147
Training results:
gen_loss: -0.00012049452
disc_loss: 0.00012049452
disc_acc: 1.0

Validation results:
gen_loss: -9.767005e-05
disc_loss: 9.767005e-05
disc_acc: 1.0


	Epoch 148
Training results:
gen_loss: -9.635952e-05
disc_loss: 9.635952e-05
disc_acc: 1.0

Validation results:
gen_loss: -0.0021052016
disc_loss: 0.0021052016
disc_acc: 0.9990079365079365


	Epoch 149
Training results:
gen_loss: -0.0001477467
disc_loss: 0.0001477467
disc_acc: 1.0

Validation results:
gen_loss: -3.956711e-05
disc_loss: 3.956711e-05
disc_acc: 1.0


	Epoch 150
Training results:
gen_loss: -2.886745e-05
disc_loss: 2.886745e-05
disc_acc: 1.0

Validation results:
gen_loss: -4.2242784e-05
disc_loss: 4.2242784e-05
disc_acc: 1.0


	Epoch 151
Training results:
gen_loss: -3.002494e-05
disc_loss: 3.002494e-05
disc_acc: 1.0

Validation results:
gen_loss: -2.2016753e-05
disc_loss: 2.2016753e-05
disc_acc: 1.0


	Epoch 152
Training results:
gen_loss: -1.702962e-05
disc_loss: 1.702962e-05
disc_acc: 1.0

Validation results:
gen_loss: -1.39579715e-05
disc_loss: 1.39579715e-05
disc_acc: 1.0


	Epoch 153
Training results:
gen_loss: -1.33924e-05
disc_loss: 1.33924e-05
disc_acc: 1.0

Validation results:
gen_loss: -1.1007807e-05
disc_loss: 1.1007807e-05
disc_acc: 1.0


	Epoch 154
Training results:
gen_loss: -8.909915e-06
disc_loss: 8.909915e-06
disc_acc: 1.0

Validation results:
gen_loss: -1.206525e-05
disc_loss: 1.206525e-05
disc_acc: 1.0


	Epoch 155
Training results:
gen_loss: -6.7225114e-06
disc_loss: 6.7225114e-06
disc_acc: 1.0

Validation results:
gen_loss: -5.8962883e-06
disc_loss: 5.8962883e-06
disc_acc: 1.0


	Epoch 156
Training results:
gen_loss: -9.450652e-06
disc_loss: 9.450652e-06
disc_acc: 1.0

Validation results:
gen_loss: -0.002120849
disc_loss: 0.002120849
disc_acc: 0.9995039682539683


	Epoch 157
Training results:
gen_loss: -0.73883945
disc_loss: 0.73883945
disc_acc: 0.9066831683168317

Validation results:
gen_loss: -0.003037725
disc_loss: 0.003037725
disc_acc: 0.9995039682539683


	Epoch 158
Training results:
gen_loss: -0.004254411
disc_loss: 0.004254411
disc_acc: 0.9985148514851485

Validation results:
gen_loss: -0.0059131267
disc_loss: 0.0059131267
disc_acc: 0.9985119047619048


	Epoch 159
Training results:
gen_loss: -0.0579604
disc_loss: 0.0579604
disc_acc: 0.9883663366336634

Validation results:
gen_loss: -0.0016643236
disc_loss: 0.0016643236
disc_acc: 0.9995039682539683


	Epoch 160
Training results:
gen_loss: -0.0015667133
disc_loss: 0.0015667133
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -0.0005601448
disc_loss: 0.0005601448
disc_acc: 1.0


	Epoch 161
Training results:
gen_loss: -0.014024297
disc_loss: 0.014024297
disc_acc: 0.9971534653465347

Validation results:
gen_loss: -0.21148321
disc_loss: 0.21148321
disc_acc: 0.9340277777777778


	Epoch 162
Training results:
gen_loss: -0.2988266
disc_loss: 0.2988266
disc_acc: 0.9465346534653465

Validation results:
gen_loss: -0.00056131015
disc_loss: 0.00056131015
disc_acc: 1.0


	Epoch 163
Training results:
gen_loss: -0.00087062013
disc_loss: 0.00087062013
disc_acc: 1.0

Validation results:
gen_loss: -0.014773097
disc_loss: 0.014773097
disc_acc: 0.9985119047619048


	Epoch 164
Training results:
gen_loss: -0.0019053295
disc_loss: 0.0019053295
disc_acc: 0.9992574257425743

Validation results:
gen_loss: -0.00023239697
disc_loss: 0.00023239697
disc_acc: 1.0


	Epoch 165
Training results:
gen_loss: -0.00019157579
disc_loss: 0.00019157579
disc_acc: 1.0

Validation results:
gen_loss: -0.00020934675
disc_loss: 0.00020934675
disc_acc: 1.0


	Epoch 166
Training results:
gen_loss: -0.12851387
disc_loss: 0.12851387
disc_acc: 0.9719059405940594

Validation results:
gen_loss: -0.61151004
disc_loss: 0.61151004
disc_acc: 0.8253968253968254


	Epoch 167
Training results:
gen_loss: -0.015918214
disc_loss: 0.015918214
disc_acc: 0.9962871287128713

Validation results:
gen_loss: -0.00022204763
disc_loss: 0.00022204763
disc_acc: 1.0


	Epoch 168
Training results:
gen_loss: -0.08158023
disc_loss: 0.08158023
disc_acc: 0.9852722772277228

Validation results:
gen_loss: -0.010738928
disc_loss: 0.010738928
disc_acc: 0.9990079365079365


	Epoch 169
Training results:
gen_loss: -0.3500692
disc_loss: 0.3500692
disc_acc: 0.9534653465346534

Validation results:
gen_loss: -1.2293724
disc_loss: 1.2293724
disc_acc: 0.777281746031746


	Epoch 170
Training results:
gen_loss: -0.21873161
disc_loss: 0.21873161
disc_acc: 0.9702970297029703

Validation results:
gen_loss: -0.009876715
disc_loss: 0.009876715
disc_acc: 0.9965277777777778


	Epoch 171
Training results:
gen_loss: -0.0013005194
disc_loss: 0.0013005194
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -0.00010280277
disc_loss: 0.00010280277
disc_acc: 1.0


	Epoch 172
Training results:
gen_loss: -0.050816793
disc_loss: 0.050816793
disc_acc: 0.9883663366336634

Validation results:
gen_loss: -0.004067129
disc_loss: 0.004067129
disc_acc: 0.9990079365079365


	Epoch 173
Training results:
gen_loss: -0.0010433896
disc_loss: 0.0010433896
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -8.285673e-05
disc_loss: 8.285673e-05
disc_acc: 1.0


	Epoch 174
Training results:
gen_loss: -8.010246e-05
disc_loss: 8.010246e-05
disc_acc: 1.0

Validation results:
gen_loss: -6.766847e-05
disc_loss: 6.766847e-05
disc_acc: 1.0


	Epoch 175
Training results:
gen_loss: -7.268125e-05
disc_loss: 7.268125e-05
disc_acc: 1.0

Validation results:
gen_loss: -5.6256533e-05
disc_loss: 5.6256533e-05
disc_acc: 1.0


	Epoch 176
Training results:
gen_loss: -3.910323e-05
disc_loss: 3.910323e-05
disc_acc: 1.0

Validation results:
gen_loss: -3.8525377e-05
disc_loss: 3.8525377e-05
disc_acc: 1.0


	Epoch 177
Training results:
gen_loss: -0.46530938
disc_loss: 0.46530938
disc_acc: 0.9202970297029703

Validation results:
gen_loss: -1.5433325
disc_loss: 1.5433325
disc_acc: 0.9325396825396826


	Epoch 178
Training results:
gen_loss: -0.028597867
disc_loss: 0.028597867
disc_acc: 0.9939356435643565

Validation results:
gen_loss: -0.0110927895
disc_loss: 0.0110927895
disc_acc: 0.9970238095238095


	Epoch 179
Training results:
gen_loss: -0.022063024
disc_loss: 0.022063024
disc_acc: 0.9952970297029703

Validation results:
gen_loss: -0.002762462
disc_loss: 0.002762462
disc_acc: 0.9995039682539683


	Epoch 180
Training results:
gen_loss: -0.0056812246
disc_loss: 0.0056812246
disc_acc: 0.998391089108911

Validation results:
gen_loss: -0.00014197303
disc_loss: 0.00014197303
disc_acc: 1.0


	Epoch 181
Training results:
gen_loss: -0.03910911
disc_loss: 0.03910911
disc_acc: 0.9903465346534653

Validation results:
gen_loss: -0.00032958752
disc_loss: 0.00032958752
disc_acc: 1.0


	Epoch 182
Training results:
gen_loss: -0.00019468898
disc_loss: 0.00019468898
disc_acc: 1.0

Validation results:
gen_loss: -0.000119125856
disc_loss: 0.000119125856
disc_acc: 1.0


	Epoch 183
Training results:
gen_loss: -0.0009270499
disc_loss: 0.0009270499
disc_acc: 0.9996287128712872

Validation results:
gen_loss: -0.0001104176
disc_loss: 0.0001104176
disc_acc: 1.0


	Epoch 184
Training results:
gen_loss: -8.297225e-05
disc_loss: 8.297225e-05
disc_acc: 1.0

Validation results:
gen_loss: -0.00018145546
disc_loss: 0.00018145546
disc_acc: 1.0


	Epoch 185
Training results:
gen_loss: -0.4561252
disc_loss: 0.4561252
disc_acc: 0.9379950495049505

Validation results:
gen_loss: -0.20134085
disc_loss: 0.20134085
disc_acc: 0.9370039682539683


	Epoch 186
Training results:
gen_loss: -0.013618795
disc_loss: 0.013618795
disc_acc: 0.9961633663366337

Validation results:
gen_loss: -0.0005524405
disc_loss: 0.0005524405
disc_acc: 1.0


	Epoch 187
Training results:
gen_loss: -0.032038722
disc_loss: 0.032038722
disc_acc: 0.9920792079207921

Validation results:
gen_loss: -0.0056831343
disc_loss: 0.0056831343
disc_acc: 0.9975198412698413


	Epoch 188
Training results:
gen_loss: -0.0040892335
disc_loss: 0.0040892335
disc_acc: 0.999009900990099

Validation results:
gen_loss: -0.0007274572
disc_loss: 0.0007274572
disc_acc: 1.0


	Epoch 189
Training results:
gen_loss: -0.00046587444
disc_loss: 0.00046587444
disc_acc: 1.0

Validation results:
gen_loss: -0.00019400279
disc_loss: 0.00019400279
disc_acc: 1.0


	Epoch 190
Training results:
gen_loss: -0.14302179
disc_loss: 0.14302179
disc_acc: 0.9702970297029703

Validation results:
gen_loss: -0.0029966147
disc_loss: 0.0029966147
disc_acc: 1.0


	Epoch 191
Training results:
gen_loss: -0.00058400334
disc_loss: 0.00058400334
disc_acc: 1.0

Validation results:
gen_loss: -0.0019822493
disc_loss: 0.0019822493
disc_acc: 0.9995039682539683


	Epoch 192
Training results:
gen_loss: -0.00012952564
disc_loss: 0.00012952564
disc_acc: 1.0

Validation results:
gen_loss: -0.00010147521
disc_loss: 0.00010147521
disc_acc: 1.0


	Epoch 193
Training results:
gen_loss: -0.35780597
disc_loss: 0.35780597
disc_acc: 0.9542079207920792

Validation results:
gen_loss: -1.8942305
disc_loss: 1.8942305
disc_acc: 0.7182539682539683


	Epoch 194
Training results:
gen_loss: -0.11674293
disc_loss: 0.11674293
disc_acc: 0.9767326732673267

Validation results:
gen_loss: -0.0005988174
disc_loss: 0.0005988174
disc_acc: 1.0


	Epoch 195
Training results:
gen_loss: -0.00050383626
disc_loss: 0.00050383626
disc_acc: 1.0

Validation results:
gen_loss: -0.0003546501
disc_loss: 0.0003546501
disc_acc: 1.0


	Epoch 196
Training results:
gen_loss: -0.00025894848
disc_loss: 0.00025894848
disc_acc: 1.0

Validation results:
gen_loss: -0.0010226828
disc_loss: 0.0010226828
disc_acc: 1.0


	Epoch 197
Training results:
gen_loss: -0.00013682993
disc_loss: 0.00013682993
disc_acc: 1.0

Validation results:
gen_loss: -0.00011664053
disc_loss: 0.00011664053
disc_acc: 1.0


	Epoch 198
Training results:
gen_loss: -0.0001409199
disc_loss: 0.0001409199
disc_acc: 1.0

Validation results:
gen_loss: -0.000322439
disc_loss: 0.000322439
disc_acc: 1.0


	Epoch 199
Training results:
gen_loss: -0.00018941125
disc_loss: 0.00018941125
disc_acc: 1.0

Validation results:
gen_loss: -9.445811e-05
disc_loss: 9.445811e-05
disc_acc: 1.0


	Epoch 200
Training results:
gen_loss: -5.4294607e-05
disc_loss: 5.4294607e-05
disc_acc: 1.0

Validation results:
gen_loss: -4.452076e-05
disc_loss: 4.452076e-05
disc_acc: 1.0


	Epoch 201
Training results:
gen_loss: -0.00010546511
disc_loss: 0.00010546511
disc_acc: 1.0

Validation results:
gen_loss: -3.9908708e-05
disc_loss: 3.9908708e-05
disc_acc: 1.0


	Epoch 202
Training results:
gen_loss: -3.119936e-05
disc_loss: 3.119936e-05
disc_acc: 1.0

Validation results:
gen_loss: -2.6101558e-05
disc_loss: 2.6101558e-05
disc_acc: 1.0


	Epoch 203
Training results:
gen_loss: -1.817926e-05
disc_loss: 1.817926e-05
disc_acc: 1.0

Validation results:
gen_loss: -2.0615194e-05
disc_loss: 2.0615194e-05
disc_acc: 1.0


	Epoch 204
Training results:
gen_loss: -1.6088876e-05
disc_loss: 1.6088876e-05
disc_acc: 1.0

Validation results:
gen_loss: -2.0142015e-05
disc_loss: 2.0142015e-05
disc_acc: 1.0


	Epoch 205
Training results:
gen_loss: -0.58226264
disc_loss: 0.58226264
disc_acc: 0.9305693069306931

Validation results:
gen_loss: -0.020081758
disc_loss: 0.020081758
disc_acc: 0.9975198412698413


	Epoch 206
Training results:
gen_loss: -0.030999422
disc_loss: 0.030999422
disc_acc: 0.9945544554455445

Validation results:
gen_loss: -0.0068282234
disc_loss: 0.0068282234
disc_acc: 0.9975198412698413


	Epoch 207
Training results:
gen_loss: -0.0014396501
disc_loss: 0.0014396501
disc_acc: 0.9991336633663367

Validation results:
gen_loss: -5.1929776e-05
disc_loss: 5.1929776e-05
disc_acc: 1.0


	Epoch 208
Training results:
gen_loss: -0.00015739423
disc_loss: 0.00015739423
disc_acc: 1.0

Validation results:
gen_loss: -3.071731e-05
disc_loss: 3.071731e-05
disc_acc: 1.0


	Epoch 209
Training results:
gen_loss: -4.5304656e-05
disc_loss: 4.5304656e-05
disc_acc: 1.0

Validation results:
gen_loss: -2.4544197e-05
disc_loss: 2.4544197e-05
disc_acc: 1.0


	Epoch 210
Training results:
gen_loss: -2.6218015e-05
disc_loss: 2.6218015e-05
disc_acc: 1.0

Validation results:
gen_loss: -2.4145835e-05
disc_loss: 2.4145835e-05
disc_acc: 1.0


	Epoch 211
Training results:
gen_loss: -2.6608912e-05
disc_loss: 2.6608912e-05
disc_acc: 1.0

Validation results:
gen_loss: -2.1104908e-05
disc_loss: 2.1104908e-05
disc_acc: 1.0


	Epoch 212
Training results:
gen_loss: -1.591299e-05
disc_loss: 1.591299e-05
disc_acc: 1.0

Validation results:
gen_loss: -1.9966401e-05
disc_loss: 1.9966401e-05
disc_acc: 1.0


	Epoch 213
Training results:
gen_loss: -0.3619745
disc_loss: 0.3619745
disc_acc: 0.942079207920792

Validation results:
gen_loss: -0.016812243
disc_loss: 0.016812243
disc_acc: 0.9970238095238095


	Epoch 214
Training results:
gen_loss: -0.0027306317
disc_loss: 0.0027306317
disc_acc: 0.9993811881188119

Validation results:
gen_loss: -0.0165481
disc_loss: 0.0165481
disc_acc: 0.9985119047619048


	Epoch 215
Training results:
gen_loss: -0.026607351
disc_loss: 0.026607351
disc_acc: 0.9951732673267327

Validation results:
gen_loss: -0.003169595
disc_loss: 0.003169595
disc_acc: 0.9995039682539683


	Epoch 216
Training results:
gen_loss: -0.00013599342
disc_loss: 0.00013599342
disc_acc: 1.0

Validation results:
gen_loss: -7.536028e-05
disc_loss: 7.536028e-05
disc_acc: 1.0


	Epoch 217
Training results:
gen_loss: -0.00025178594
disc_loss: 0.00025178594
disc_acc: 1.0

Validation results:
gen_loss: -0.0011277946
disc_loss: 0.0011277946
disc_acc: 0.9995039682539683


	Epoch 218
Training results:
gen_loss: -4.2046177e-05
disc_loss: 4.2046177e-05
disc_acc: 1.0

Validation results:
gen_loss: -4.8255726e-05
disc_loss: 4.8255726e-05
disc_acc: 1.0


	Epoch 219
Training results:
gen_loss: -0.41194266
disc_loss: 0.41194266
disc_acc: 0.9587871287128713

Validation results:
gen_loss: -0.4962753
disc_loss: 0.4962753
disc_acc: 0.8566468253968254


	Epoch 220
Training results:
gen_loss: -0.015458539
disc_loss: 0.015458539
disc_acc: 0.9957920792079208

Validation results:
gen_loss: -0.0043379357
disc_loss: 0.0043379357
disc_acc: 0.998015873015873


	Epoch 221
Training results:
gen_loss: -0.0011980229
disc_loss: 0.0011980229
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -0.0049631773
disc_loss: 0.0049631773
disc_acc: 0.9990079365079365


	Epoch 222
Training results:
gen_loss: -0.111275285
disc_loss: 0.111275285
disc_acc: 0.9814356435643564

Validation results:
gen_loss: -0.00063388096
disc_loss: 0.00063388096
disc_acc: 1.0


	Epoch 223
Training results:
gen_loss: -0.0003842768
disc_loss: 0.0003842768
disc_acc: 1.0

Validation results:
gen_loss: -0.0002355037
disc_loss: 0.0002355037
disc_acc: 1.0


	Epoch 224
Training results:
gen_loss: -0.00024018767
disc_loss: 0.00024018767
disc_acc: 1.0

Validation results:
gen_loss: -0.00038374943
disc_loss: 0.00038374943
disc_acc: 1.0


	Epoch 225
Training results:
gen_loss: -0.00074008823
disc_loss: 0.00074008823
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -7.397197e-05
disc_loss: 7.397197e-05
disc_acc: 1.0


	Epoch 226
Training results:
gen_loss: -0.1359787
disc_loss: 0.1359787
disc_acc: 0.9698019801980198

Validation results:
gen_loss: -0.0021203603
disc_loss: 0.0021203603
disc_acc: 0.9990079365079365


	Epoch 227
Training results:
gen_loss: -0.0023167152
disc_loss: 0.0023167152
disc_acc: 0.9993811881188119

Validation results:
gen_loss: -0.0004291274
disc_loss: 0.0004291274
disc_acc: 1.0


	Epoch 228
Training results:
gen_loss: -0.20920421
disc_loss: 0.20920421
disc_acc: 0.9660891089108911

Validation results:
gen_loss: -0.028164918
disc_loss: 0.028164918
disc_acc: 0.9910714285714286


	Epoch 229
Training results:
gen_loss: -0.017535774
disc_loss: 0.017535774
disc_acc: 0.9966584158415842

Validation results:
gen_loss: -0.00029256594
disc_loss: 0.00029256594
disc_acc: 1.0


	Epoch 230
Training results:
gen_loss: -9.4639974e-05
disc_loss: 9.4639974e-05
disc_acc: 1.0

Validation results:
gen_loss: -5.4923046e-05
disc_loss: 5.4923046e-05
disc_acc: 1.0


	Epoch 231
Training results:
gen_loss: -0.021210954
disc_loss: 0.021210954
disc_acc: 0.9956683168316832

Validation results:
gen_loss: -0.00028450598
disc_loss: 0.00028450598
disc_acc: 1.0


	Epoch 232
Training results:
gen_loss: -6.900291e-05
disc_loss: 6.900291e-05
disc_acc: 1.0

Validation results:
gen_loss: -3.63244e-05
disc_loss: 3.63244e-05
disc_acc: 1.0


	Epoch 233
Training results:
gen_loss: -6.721057e-05
disc_loss: 6.721057e-05
disc_acc: 1.0

Validation results:
gen_loss: -3.053101e-05
disc_loss: 3.053101e-05
disc_acc: 1.0


	Epoch 234
Training results:
gen_loss: -0.00023305745
disc_loss: 0.00023305745
disc_acc: 0.9998762376237624

Validation results:
gen_loss: -0.000116555006
disc_loss: 0.000116555006
disc_acc: 1.0


	Epoch 235
Training results:
gen_loss: -3.0380499e-05
disc_loss: 3.0380499e-05
disc_acc: 1.0

Validation results:
gen_loss: -2.0013265e-05
disc_loss: 2.0013265e-05
disc_acc: 1.0


	Epoch 236
Training results:
gen_loss: -1.78347e-05
disc_loss: 1.78347e-05
disc_acc: 1.0

Validation results:
gen_loss: -1.7892798e-05
disc_loss: 1.7892798e-05
disc_acc: 1.0


	Epoch 237
Training results:
gen_loss: -1.37391835e-05
disc_loss: 1.37391835e-05
disc_acc: 1.0

Validation results:
gen_loss: -0.00012372379
disc_loss: 0.00012372379
disc_acc: 1.0


	Epoch 238
Training results:
gen_loss: -1.1300717e-05
disc_loss: 1.1300717e-05
disc_acc: 1.0

Validation results:
gen_loss: -1.2355337e-05
disc_loss: 1.2355337e-05
disc_acc: 1.0


	Epoch 239
Training results:
gen_loss: -9.025984e-06
disc_loss: 9.025984e-06
disc_acc: 1.0

Validation results:
gen_loss: -1.069789e-05
disc_loss: 1.069789e-05
disc_acc: 1.0


	Epoch 240
Training results:
gen_loss: -0.8090283
disc_loss: 0.8090283
disc_acc: 0.936509900990099

Validation results:
gen_loss: -0.0013912839
disc_loss: 0.0013912839
disc_acc: 0.9990079365079365


	Epoch 241
Training results:
gen_loss: -0.0017674073
disc_loss: 0.0017674073
disc_acc: 0.9996287128712872

Validation results:
gen_loss: -0.000300607
disc_loss: 0.000300607
disc_acc: 1.0


	Epoch 242
Training results:
gen_loss: -0.00018336638
disc_loss: 0.00018336638
disc_acc: 1.0

Validation results:
gen_loss: -0.0010289869
disc_loss: 0.0010289869
disc_acc: 0.9995039682539683


	Epoch 243
Training results:
gen_loss: -0.03977405
disc_loss: 0.03977405
disc_acc: 0.9917079207920793

Validation results:
gen_loss: -0.015330189
disc_loss: 0.015330189
disc_acc: 0.9970238095238095


	Epoch 244
Training results:
gen_loss: -0.0042385226
disc_loss: 0.0042385226
disc_acc: 0.9985148514851485

Validation results:
gen_loss: -0.00027760863
disc_loss: 0.00027760863
disc_acc: 1.0


	Epoch 245
Training results:
gen_loss: -0.0009745992
disc_loss: 0.0009745992
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -0.00012775711
disc_loss: 0.00012775711
disc_acc: 1.0


	Epoch 246
Training results:
gen_loss: -0.00016347246
disc_loss: 0.00016347246
disc_acc: 1.0

Validation results:
gen_loss: -4.6529363e-05
disc_loss: 4.6529363e-05
disc_acc: 1.0


	Epoch 247
Training results:
gen_loss: -4.3127577e-05
disc_loss: 4.3127577e-05
disc_acc: 1.0

Validation results:
gen_loss: -4.790914e-05
disc_loss: 4.790914e-05
disc_acc: 1.0


	Epoch 248
Training results:
gen_loss: -0.22357868
disc_loss: 0.22357868
disc_acc: 0.9653465346534653

Validation results:
gen_loss: -0.0026139559
disc_loss: 0.0026139559
disc_acc: 0.9995039682539683


	Epoch 249
Training results:
gen_loss: -0.0020279966
disc_loss: 0.0020279966
disc_acc: 0.9995049504950495

Validation results:
gen_loss: -0.00015635394
disc_loss: 0.00015635394
disc_acc: 1.0


	Epoch 250
Training results:
gen_loss: -0.19276057
disc_loss: 0.19276057
disc_acc: 0.9693069306930693

Validation results:
gen_loss: -0.0057524773
disc_loss: 0.0057524773
disc_acc: 0.998015873015873


	Epoch 251
Training results:
gen_loss: -0.00041911952
disc_loss: 0.00041911952
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -3.4803204e-05
disc_loss: 3.4803204e-05
disc_acc: 1.0


	Epoch 252
Training results:
gen_loss: -0.00195724
disc_loss: 0.00195724
disc_acc: 0.9995049504950495

Validation results:
gen_loss: -0.002463027
disc_loss: 0.002463027
disc_acc: 0.9995039682539683


	Epoch 253
Training results:
gen_loss: -0.021466298
disc_loss: 0.021466298
disc_acc: 0.9948019801980198

Validation results:
gen_loss: -3.914506e-05
disc_loss: 3.914506e-05
disc_acc: 1.0


	Epoch 254
Training results:
gen_loss: -3.106175e-05
disc_loss: 3.106175e-05
disc_acc: 1.0

Validation results:
gen_loss: -2.4160547e-05
disc_loss: 2.4160547e-05
disc_acc: 1.0


	Epoch 255
Training results:
gen_loss: -0.00028856812
disc_loss: 0.00028856812
disc_acc: 0.9998762376237624

Validation results:
gen_loss: -1.2732278e-05
disc_loss: 1.2732278e-05
disc_acc: 1.0


	Epoch 256
Training results:
gen_loss: -1.4277965e-05
disc_loss: 1.4277965e-05
disc_acc: 1.0

Validation results:
gen_loss: -8.8449315e-06
disc_loss: 8.8449315e-06
disc_acc: 1.0


	Epoch 257
Training results:
gen_loss: -2.3787206e-05
disc_loss: 2.3787206e-05
disc_acc: 1.0

Validation results:
gen_loss: -0.00016150885
disc_loss: 0.00016150885
disc_acc: 1.0


	Epoch 258
Training results:
gen_loss: -1.0523616e-05
disc_loss: 1.0523616e-05
disc_acc: 1.0

Validation results:
gen_loss: -7.897052e-06
disc_loss: 7.897052e-06
disc_acc: 1.0


	Epoch 259
Training results:
gen_loss: -6.4997557e-06
disc_loss: 6.4997557e-06
disc_acc: 1.0

Validation results:
gen_loss: -5.615193e-06
disc_loss: 5.615193e-06
disc_acc: 1.0


	Epoch 260
Training results:
gen_loss: -0.6965808
disc_loss: 0.6965808
disc_acc: 0.9321782178217822

Validation results:
gen_loss: -0.054105252
disc_loss: 0.054105252
disc_acc: 0.9950396825396826


	Epoch 261
Training results:
gen_loss: -0.007728201
disc_loss: 0.007728201
disc_acc: 0.999009900990099

Validation results:
gen_loss: -0.07141974
disc_loss: 0.07141974
disc_acc: 0.9950396825396826


	Epoch 262
Training results:
gen_loss: -0.05898092
disc_loss: 0.05898092
disc_acc: 0.9849009900990099

Validation results:
gen_loss: -0.0007402807
disc_loss: 0.0007402807
disc_acc: 1.0


	Epoch 263
Training results:
gen_loss: -0.0017837224
disc_loss: 0.0017837224
disc_acc: 0.9996287128712872

Validation results:
gen_loss: -0.00025268772
disc_loss: 0.00025268772
disc_acc: 1.0


	Epoch 264
Training results:
gen_loss: -0.047486894
disc_loss: 0.047486894
disc_acc: 0.9899752475247525

Validation results:
gen_loss: -0.0002881627
disc_loss: 0.0002881627
disc_acc: 1.0


	Epoch 265
Training results:
gen_loss: -0.001228287
disc_loss: 0.001228287
disc_acc: 0.9996287128712872

Validation results:
gen_loss: -0.00024843658
disc_loss: 0.00024843658
disc_acc: 1.0


	Epoch 266
Training results:
gen_loss: -7.13378e-05
disc_loss: 7.13378e-05
disc_acc: 1.0

Validation results:
gen_loss: -0.0007046847
disc_loss: 0.0007046847
disc_acc: 0.9995039682539683


	Epoch 267
Training results:
gen_loss: -4.824422e-05
disc_loss: 4.824422e-05
disc_acc: 1.0

Validation results:
gen_loss: -6.5462926e-05
disc_loss: 6.5462926e-05
disc_acc: 1.0


	Epoch 268
Training results:
gen_loss: -0.5725965
disc_loss: 0.5725965
disc_acc: 0.948019801980198

Validation results:
gen_loss: -0.14608876
disc_loss: 0.14608876
disc_acc: 0.9469246031746031


	Epoch 269
Training results:
gen_loss: -0.06502484
disc_loss: 0.06502484
disc_acc: 0.9893564356435643

Validation results:
gen_loss: -9.61927e-05
disc_loss: 9.61927e-05
disc_acc: 1.0


	Epoch 270
Training results:
gen_loss: -0.00017153272
disc_loss: 0.00017153272
disc_acc: 0.9998762376237624

Validation results:
gen_loss: -0.0013343687
disc_loss: 0.0013343687
disc_acc: 1.0


	Epoch 271
Training results:
gen_loss: -0.00019974343
disc_loss: 0.00019974343
disc_acc: 0.9998762376237624

Validation results:
gen_loss: -2.4990795e-05
disc_loss: 2.4990795e-05
disc_acc: 1.0


	Epoch 272
Training results:
gen_loss: -0.000120536715
disc_loss: 0.000120536715
disc_acc: 1.0

Validation results:
gen_loss: -0.0011042731
disc_loss: 0.0011042731
disc_acc: 0.9995039682539683


	Epoch 273
Training results:
gen_loss: -5.44105e-05
disc_loss: 5.44105e-05
disc_acc: 1.0

Validation results:
gen_loss: -0.007495714
disc_loss: 0.007495714
disc_acc: 0.9985119047619048


	Epoch 274
Training results:
gen_loss: -0.20771001
disc_loss: 0.20771001
disc_acc: 0.9705445544554455

Validation results:
gen_loss: -0.00018043358
disc_loss: 0.00018043358
disc_acc: 1.0


	Epoch 275
Training results:
gen_loss: -0.00022661503
disc_loss: 0.00022661503
disc_acc: 1.0

Validation results:
gen_loss: -0.00017516737
disc_loss: 0.00017516737
disc_acc: 1.0


	Epoch 276
Training results:
gen_loss: -0.0002825499
disc_loss: 0.0002825499
disc_acc: 1.0

Validation results:
gen_loss: -0.00046222893
disc_loss: 0.00046222893
disc_acc: 0.9995039682539683


	Epoch 277
Training results:
gen_loss: -0.15184888
disc_loss: 0.15184888
disc_acc: 0.9732673267326732

Validation results:
gen_loss: -0.0055793985
disc_loss: 0.0055793985
disc_acc: 0.9990079365079365


	Epoch 278
Training results:
gen_loss: -0.0040974957
disc_loss: 0.0040974957
disc_acc: 0.9988861386138614

Validation results:
gen_loss: -0.00047642947
disc_loss: 0.00047642947
disc_acc: 1.0


	Epoch 279
Training results:
gen_loss: -0.016134214
disc_loss: 0.016134214
disc_acc: 0.9959158415841585

Validation results:
gen_loss: -0.00019029345
disc_loss: 0.00019029345
disc_acc: 1.0


	Epoch 280
Training results:
gen_loss: -0.00010555472
disc_loss: 0.00010555472
disc_acc: 1.0

Validation results:
gen_loss: -3.666213e-05
disc_loss: 3.666213e-05
disc_acc: 1.0


	Epoch 281
Training results:
gen_loss: -3.3287764e-05
disc_loss: 3.3287764e-05
disc_acc: 1.0

Validation results:
gen_loss: -3.3610064e-05
disc_loss: 3.3610064e-05
disc_acc: 1.0


	Epoch 282
Training results:
gen_loss: -4.118283e-05
disc_loss: 4.118283e-05
disc_acc: 1.0

Validation results:
gen_loss: -1.986889e-05
disc_loss: 1.986889e-05
disc_acc: 1.0


	Epoch 283
Training results:
gen_loss: -2.190559e-05
disc_loss: 2.190559e-05
disc_acc: 1.0

Validation results:
gen_loss: -6.3933985e-05
disc_loss: 6.3933985e-05
disc_acc: 1.0


	Epoch 284
Training results:
gen_loss: -0.000216082
disc_loss: 0.000216082
disc_acc: 1.0

Validation results:
gen_loss: -1.847443e-05
disc_loss: 1.847443e-05
disc_acc: 1.0


	Epoch 285
Training results:
gen_loss: -0.7238677
disc_loss: 0.7238677
disc_acc: 0.9539603960396039

Validation results:
gen_loss: -0.51237375
disc_loss: 0.51237375
disc_acc: 0.9360119047619048


	Epoch 286
Training results:
gen_loss: -0.3709989
disc_loss: 0.3709989
disc_acc: 0.9597772277227723

Validation results:
gen_loss: -0.008908973
disc_loss: 0.008908973
disc_acc: 0.998015873015873


	Epoch 287
Training results:
gen_loss: -0.0021691143
disc_loss: 0.0021691143
disc_acc: 0.9992574257425743

Validation results:
gen_loss: -0.011226033
disc_loss: 0.011226033
disc_acc: 0.9985119047619048


	Epoch 288
Training results:
gen_loss: -0.019168524
disc_loss: 0.019168524
disc_acc: 0.9956683168316832

Validation results:
gen_loss: -0.00020665396
disc_loss: 0.00020665396
disc_acc: 1.0


	Epoch 289
Training results:
gen_loss: -0.0011781001
disc_loss: 0.0011781001
disc_acc: 0.9996287128712872

Validation results:
gen_loss: -0.014738741
disc_loss: 0.014738741
disc_acc: 0.9985119047619048


	Epoch 290
Training results:
gen_loss: -0.012024861
disc_loss: 0.012024861
disc_acc: 0.9969059405940595

Validation results:
gen_loss: -0.034094315
disc_loss: 0.034094315
disc_acc: 0.9970238095238095


	Epoch 291
Training results:
gen_loss: -0.018478202
disc_loss: 0.018478202
disc_acc: 0.9969059405940595

Validation results:
gen_loss: -0.034572437
disc_loss: 0.034572437
disc_acc: 0.9940476190476191


	Epoch 292
Training results:
gen_loss: -0.18072784
disc_loss: 0.18072784
disc_acc: 0.972029702970297

Validation results:
gen_loss: -2.2823668e-05
disc_loss: 2.2823668e-05
disc_acc: 1.0


	Epoch 293
Training results:
gen_loss: -0.00016593066
disc_loss: 0.00016593066
disc_acc: 1.0

Validation results:
gen_loss: -3.308767e-05
disc_loss: 3.308767e-05
disc_acc: 1.0


	Epoch 294
Training results:
gen_loss: -0.0006108398
disc_loss: 0.0006108398
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -4.0709398e-05
disc_loss: 4.0709398e-05
disc_acc: 1.0


	Epoch 295
Training results:
gen_loss: -3.2648117e-05
disc_loss: 3.2648117e-05
disc_acc: 1.0

Validation results:
gen_loss: -1.5142801e-05
disc_loss: 1.5142801e-05
disc_acc: 1.0


	Epoch 296
Training results:
gen_loss: -1.279581e-05
disc_loss: 1.279581e-05
disc_acc: 1.0

Validation results:
gen_loss: -9.594172e-06
disc_loss: 9.594172e-06
disc_acc: 1.0


	Epoch 297
Training results:
gen_loss: -8.5815955e-06
disc_loss: 8.5815955e-06
disc_acc: 1.0

Validation results:
gen_loss: -7.4275886e-06
disc_loss: 7.4275886e-06
disc_acc: 1.0


	Epoch 298
Training results:
gen_loss: -6.9661187e-06
disc_loss: 6.9661187e-06
disc_acc: 1.0

Validation results:
gen_loss: -5.133254e-06
disc_loss: 5.133254e-06
disc_acc: 1.0


	Epoch 299
Training results:
gen_loss: -0.6056215
disc_loss: 0.6056215
disc_acc: 0.9426980198019802

Validation results:
gen_loss: -0.003685827
disc_loss: 0.003685827
disc_acc: 0.9985119047619048


	Epoch 300
Training results:
gen_loss: -0.011575529
disc_loss: 0.011575529
disc_acc: 0.996410891089109

Validation results:
gen_loss: -0.022376588
disc_loss: 0.022376588
disc_acc: 0.9975198412698413


	Epoch 301
Training results:
gen_loss: -0.008543358
disc_loss: 0.008543358
disc_acc: 0.9985148514851485

Validation results:
gen_loss: -0.00013316795
disc_loss: 0.00013316795
disc_acc: 1.0


	Epoch 302
Training results:
gen_loss: -0.009256612
disc_loss: 0.009256612
disc_acc: 0.998391089108911

Validation results:
gen_loss: -9.261268e-05
disc_loss: 9.261268e-05
disc_acc: 1.0


	Epoch 303
Training results:
gen_loss: -0.00680591
disc_loss: 0.00680591
disc_acc: 0.9985148514851485

Validation results:
gen_loss: -0.001113937
disc_loss: 0.001113937
disc_acc: 1.0


	Epoch 304
Training results:
gen_loss: -0.0005336017
disc_loss: 0.0005336017
disc_acc: 1.0

Validation results:
gen_loss: -3.3739478e-05
disc_loss: 3.3739478e-05
disc_acc: 1.0


	Epoch 305
Training results:
gen_loss: -4.894236e-05
disc_loss: 4.894236e-05
disc_acc: 1.0

Validation results:
gen_loss: -0.00043848628
disc_loss: 0.00043848628
disc_acc: 0.9995039682539683


	Epoch 306
Training results:
gen_loss: -2.10701e-05
disc_loss: 2.10701e-05
disc_acc: 1.0

Validation results:
gen_loss: -5.4673947e-05
disc_loss: 5.4673947e-05
disc_acc: 1.0


	Epoch 307
Training results:
gen_loss: -0.2213049
disc_loss: 0.2213049
disc_acc: 0.9611386138613861

Validation results:
gen_loss: -0.5161377
disc_loss: 0.5161377
disc_acc: 0.908234126984127


	Epoch 308
Training results:
gen_loss: -0.012223565
disc_loss: 0.012223565
disc_acc: 0.9971534653465347

Validation results:
gen_loss: -0.00018642111
disc_loss: 0.00018642111
disc_acc: 1.0


	Epoch 309
Training results:
gen_loss: -0.51028454
disc_loss: 0.51028454
disc_acc: 0.9548267326732673

Validation results:
gen_loss: -0.27301252
disc_loss: 0.27301252
disc_acc: 0.9206349206349206


	Epoch 310
Training results:
gen_loss: -0.06996252
disc_loss: 0.06996252
disc_acc: 0.9896039603960396

Validation results:
gen_loss: -7.6037526e-05
disc_loss: 7.6037526e-05
disc_acc: 1.0


	Epoch 311
Training results:
gen_loss: -5.5768658e-05
disc_loss: 5.5768658e-05
disc_acc: 1.0

Validation results:
gen_loss: -1.928296e-06
disc_loss: 1.928296e-06
disc_acc: 1.0


	Epoch 312
Training results:
gen_loss: -7.116411e-06
disc_loss: 7.116411e-06
disc_acc: 1.0

Validation results:
gen_loss: -1.9750862e-06
disc_loss: 1.9750862e-06
disc_acc: 1.0


	Epoch 313
Training results:
gen_loss: -3.458016e-06
disc_loss: 3.458016e-06
disc_acc: 1.0

Validation results:
gen_loss: -1.0476608e-06
disc_loss: 1.0476608e-06
disc_acc: 1.0


	Epoch 314
Training results:
gen_loss: -3.911278e-06
disc_loss: 3.911278e-06
disc_acc: 1.0

Validation results:
gen_loss: -8.149911e-07
disc_loss: 8.149911e-07
disc_acc: 1.0


	Epoch 315
Training results:
gen_loss: -0.3664905
disc_loss: 0.3664905
disc_acc: 0.9657178217821782

Validation results:
gen_loss: -3.45554e-05
disc_loss: 3.45554e-05
disc_acc: 1.0


	Epoch 316
Training results:
gen_loss: -3.8586055e-05
disc_loss: 3.8586055e-05
disc_acc: 1.0

Validation results:
gen_loss: -9.273801e-06
disc_loss: 9.273801e-06
disc_acc: 1.0


	Epoch 317
Training results:
gen_loss: -0.0015509397
disc_loss: 0.0015509397
disc_acc: 0.9996287128712872

Validation results:
gen_loss: -1.9514338e-05
disc_loss: 1.9514338e-05
disc_acc: 1.0


	Epoch 318
Training results:
gen_loss: -0.06164481
disc_loss: 0.06164481
disc_acc: 0.988490099009901

Validation results:
gen_loss: -0.054086756
disc_loss: 0.054086756
disc_acc: 0.9747023809523809


	Epoch 319
Training results:
gen_loss: -0.06892993
disc_loss: 0.06892993
disc_acc: 0.9879950495049505

Validation results:
gen_loss: -0.00087459804
disc_loss: 0.00087459804
disc_acc: 0.9995039682539683


	Epoch 320
Training results:
gen_loss: -0.0003177658
disc_loss: 0.0003177658
disc_acc: 0.9998762376237624

Validation results:
gen_loss: -1.700131e-05
disc_loss: 1.700131e-05
disc_acc: 1.0


	Epoch 321
Training results:
gen_loss: -1.9572366e-05
disc_loss: 1.9572366e-05
disc_acc: 1.0

Validation results:
gen_loss: -9.949518e-06
disc_loss: 9.949518e-06
disc_acc: 1.0


	Epoch 322
Training results:
gen_loss: -0.03678424
disc_loss: 0.03678424
disc_acc: 0.9956683168316832

Validation results:
gen_loss: -0.00036440277
disc_loss: 0.00036440277
disc_acc: 1.0


	Epoch 323
Training results:
gen_loss: -0.053127438
disc_loss: 0.053127438
disc_acc: 0.9909653465346535

Validation results:
gen_loss: -0.042014442
disc_loss: 0.042014442
disc_acc: 0.9811507936507936


	Epoch 324
Training results:
gen_loss: -0.3602635
disc_loss: 0.3602635
disc_acc: 0.9705445544554455

Validation results:
gen_loss: -0.0004612777
disc_loss: 0.0004612777
disc_acc: 1.0


	Epoch 325
Training results:
gen_loss: -0.0033946529
disc_loss: 0.0033946529
disc_acc: 0.9992574257425743

Validation results:
gen_loss: -0.00027415156
disc_loss: 0.00027415156
disc_acc: 1.0


	Epoch 326
Training results:
gen_loss: -0.02310906
disc_loss: 0.02310906
disc_acc: 0.9961633663366337

Validation results:
gen_loss: -1.9324754e-05
disc_loss: 1.9324754e-05
disc_acc: 1.0


	Epoch 327
Training results:
gen_loss: -0.08293463
disc_loss: 0.08293463
disc_acc: 0.986509900990099

Validation results:
gen_loss: -0.048268154
disc_loss: 0.048268154
disc_acc: 0.9920634920634921


	Epoch 328
Training results:
gen_loss: -0.011324903
disc_loss: 0.011324903
disc_acc: 0.9982673267326733

Validation results:
gen_loss: -0.00012123597
disc_loss: 0.00012123597
disc_acc: 1.0


	Epoch 329
Training results:
gen_loss: -8.799405e-05
disc_loss: 8.799405e-05
disc_acc: 1.0

Validation results:
gen_loss: -6.3354615e-05
disc_loss: 6.3354615e-05
disc_acc: 1.0


	Epoch 330
Training results:
gen_loss: -0.00027334923
disc_loss: 0.00027334923
disc_acc: 1.0

Validation results:
gen_loss: -6.277999e-05
disc_loss: 6.277999e-05
disc_acc: 1.0


	Epoch 331
Training results:
gen_loss: -3.2030028e-05
disc_loss: 3.2030028e-05
disc_acc: 1.0

Validation results:
gen_loss: -8.430452e-05
disc_loss: 8.430452e-05
disc_acc: 1.0


	Epoch 332
Training results:
gen_loss: -3.854949e-05
disc_loss: 3.854949e-05
disc_acc: 1.0

Validation results:
gen_loss: -4.793357e-05
disc_loss: 4.793357e-05
disc_acc: 1.0


	Epoch 333
Training results:
gen_loss: -1.8918776e-05
disc_loss: 1.8918776e-05
disc_acc: 1.0

Validation results:
gen_loss: -1.8144214e-05
disc_loss: 1.8144214e-05
disc_acc: 1.0


	Epoch 334
Training results:
gen_loss: -1.4220844e-05
disc_loss: 1.4220844e-05
disc_acc: 1.0

Validation results:
gen_loss: -1.0371089e-05
disc_loss: 1.0371089e-05
disc_acc: 1.0


	Epoch 335
Training results:
gen_loss: -2.8818116e-05
disc_loss: 2.8818116e-05
disc_acc: 1.0

Validation results:
gen_loss: -1.0407104e-05
disc_loss: 1.0407104e-05
disc_acc: 1.0


	Epoch 336
Training results:
gen_loss: -8.623577e-06
disc_loss: 8.623577e-06
disc_acc: 1.0

Validation results:
gen_loss: -6.353283e-06
disc_loss: 6.353283e-06
disc_acc: 1.0


	Epoch 337
Training results:
gen_loss: -1.26006225e-05
disc_loss: 1.26006225e-05
disc_acc: 1.0

Validation results:
gen_loss: -6.250736e-06
disc_loss: 6.250736e-06
disc_acc: 1.0


	Epoch 338
Training results:
gen_loss: -5.9697086e-06
disc_loss: 5.9697086e-06
disc_acc: 1.0

Validation results:
gen_loss: -1.0549455e-05
disc_loss: 1.0549455e-05
disc_acc: 1.0


	Epoch 339
Training results:
gen_loss: -4.2871425e-06
disc_loss: 4.2871425e-06
disc_acc: 1.0

Validation results:
gen_loss: -4.0221275e-06
disc_loss: 4.0221275e-06
disc_acc: 1.0


	Epoch 340
Training results:
gen_loss: -4.0266373e-06
disc_loss: 4.0266373e-06
disc_acc: 1.0

Validation results:
gen_loss: -3.6057083e-06
disc_loss: 3.6057083e-06
disc_acc: 1.0


	Epoch 341
Training results:
gen_loss: -3.1413674e-06
disc_loss: 3.1413674e-06
disc_acc: 1.0

Validation results:
gen_loss: -3.032646e-06
disc_loss: 3.032646e-06
disc_acc: 1.0


	Epoch 342
Training results:
gen_loss: -2.421643e-06
disc_loss: 2.421643e-06
disc_acc: 1.0

Validation results:
gen_loss: -3.772383e-06
disc_loss: 3.772383e-06
disc_acc: 1.0


	Epoch 343
Training results:
gen_loss: -0.66949224
disc_loss: 0.66949224
disc_acc: 0.9507425742574257

Validation results:
gen_loss: -0.00083015295
disc_loss: 0.00083015295
disc_acc: 0.9995039682539683


	Epoch 344
Training results:
gen_loss: -0.0006580275
disc_loss: 0.0006580275
disc_acc: 0.9998762376237624

Validation results:
gen_loss: -0.02881266
disc_loss: 0.02881266
disc_acc: 0.9915674603174603


	Epoch 345
Training results:
gen_loss: -0.0010170087
disc_loss: 0.0010170087
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -2.7649417e-05
disc_loss: 2.7649417e-05
disc_acc: 1.0


	Epoch 346
Training results:
gen_loss: -0.13163985
disc_loss: 0.13163985
disc_acc: 0.9821782178217822

Validation results:
gen_loss: -0.018025635
disc_loss: 0.018025635
disc_acc: 0.9975198412698413


	Epoch 347
Training results:
gen_loss: -0.008109202
disc_loss: 0.008109202
disc_acc: 0.998391089108911

Validation results:
gen_loss: -5.9262777e-05
disc_loss: 5.9262777e-05
disc_acc: 1.0


	Epoch 348
Training results:
gen_loss: -5.3999654e-05
disc_loss: 5.3999654e-05
disc_acc: 1.0

Validation results:
gen_loss: -4.7537298e-05
disc_loss: 4.7537298e-05
disc_acc: 1.0


	Epoch 349
Training results:
gen_loss: -3.1460488e-05
disc_loss: 3.1460488e-05
disc_acc: 1.0

Validation results:
gen_loss: -4.0634346e-05
disc_loss: 4.0634346e-05
disc_acc: 1.0


	Epoch 350
Training results:
gen_loss: -0.0009055975
disc_loss: 0.0009055975
disc_acc: 0.9996287128712872

Validation results:
gen_loss: -6.703705e-05
disc_loss: 6.703705e-05
disc_acc: 1.0


	Epoch 351
Training results:
gen_loss: -0.0001226937
disc_loss: 0.0001226937
disc_acc: 1.0

Validation results:
gen_loss: -1.9826097e-05
disc_loss: 1.9826097e-05
disc_acc: 1.0


	Epoch 352
Training results:
gen_loss: -0.0023544964
disc_loss: 0.0023544964
disc_acc: 0.9993811881188119

Validation results:
gen_loss: -0.006912881
disc_loss: 0.006912881
disc_acc: 0.9995039682539683


	Epoch 353
Training results:
gen_loss: -0.617096
disc_loss: 0.617096
disc_acc: 0.9485148514851485

Validation results:
gen_loss: -0.042405546
disc_loss: 0.042405546
disc_acc: 0.9861111111111112


	Epoch 354
Training results:
gen_loss: -0.017466163
disc_loss: 0.017466163
disc_acc: 0.9962871287128713

Validation results:
gen_loss: -5.5304678e-05
disc_loss: 5.5304678e-05
disc_acc: 1.0


	Epoch 355
Training results:
gen_loss: -1.4378648e-05
disc_loss: 1.4378648e-05
disc_acc: 1.0

Validation results:
gen_loss: -1.2835783e-06
disc_loss: 1.2835783e-06
disc_acc: 1.0


	Epoch 356
Training results:
gen_loss: -0.030691506
disc_loss: 0.030691506
disc_acc: 0.9976485148514852

Validation results:
gen_loss: -9.3509625e-06
disc_loss: 9.3509625e-06
disc_acc: 1.0


	Epoch 357
Training results:
gen_loss: -0.13767613
disc_loss: 0.13767613
disc_acc: 0.989480198019802

Validation results:
gen_loss: -0.0015078286
disc_loss: 0.0015078286
disc_acc: 0.9995039682539683


	Epoch 358
Training results:
gen_loss: -0.014874432
disc_loss: 0.014874432
disc_acc: 0.9972772277227723

Validation results:
gen_loss: -8.254465e-05
disc_loss: 8.254465e-05
disc_acc: 1.0


	Epoch 359
Training results:
gen_loss: -4.4380304e-05
disc_loss: 4.4380304e-05
disc_acc: 1.0

Validation results:
gen_loss: -0.00016185183
disc_loss: 0.00016185183
disc_acc: 1.0


	Epoch 360
Training results:
gen_loss: -1.6749651e-05
disc_loss: 1.6749651e-05
disc_acc: 1.0

Validation results:
gen_loss: -0.0036415
disc_loss: 0.0036415
disc_acc: 0.9995039682539683


	Epoch 361
Training results:
gen_loss: -1.7834667e-05
disc_loss: 1.7834667e-05
disc_acc: 1.0

Validation results:
gen_loss: -5.8001417e-05
disc_loss: 5.8001417e-05
disc_acc: 1.0


	Epoch 362
Training results:
gen_loss: -0.53355527
disc_loss: 0.53355527
disc_acc: 0.9601485148514851

Validation results:
gen_loss: -1.4285682
disc_loss: 1.4285682
disc_acc: 0.9146825396825397


	Epoch 363
Training results:
gen_loss: -0.099935636
disc_loss: 0.099935636
disc_acc: 0.9853960396039604

Validation results:
gen_loss: -1.2850467e-05
disc_loss: 1.2850467e-05
disc_acc: 1.0


	Epoch 364
Training results:
gen_loss: -2.720647e-05
disc_loss: 2.720647e-05
disc_acc: 1.0

Validation results:
gen_loss: -7.0954807e-06
disc_loss: 7.0954807e-06
disc_acc: 1.0


	Epoch 365
Training results:
gen_loss: -0.0032741458
disc_loss: 0.0032741458
disc_acc: 0.9992574257425743

Validation results:
gen_loss: -0.0016177278
disc_loss: 0.0016177278
disc_acc: 0.9995039682539683


	Epoch 366
Training results:
gen_loss: -1.0601751e-05
disc_loss: 1.0601751e-05
disc_acc: 1.0

Validation results:
gen_loss: -0.00059532915
disc_loss: 0.00059532915
disc_acc: 0.9995039682539683


	Epoch 367
Training results:
gen_loss: -0.117679715
disc_loss: 0.117679715
disc_acc: 0.9881188118811881

Validation results:
gen_loss: -0.12726732
disc_loss: 0.12726732
disc_acc: 0.9553571428571429


	Epoch 368
Training results:
gen_loss: -0.017345654
disc_loss: 0.017345654
disc_acc: 0.9967821782178218

Validation results:
gen_loss: -8.030491e-05
disc_loss: 8.030491e-05
disc_acc: 1.0


	Epoch 369
Training results:
gen_loss: -0.00010350762
disc_loss: 0.00010350762
disc_acc: 1.0

Validation results:
gen_loss: -5.296655e-05
disc_loss: 5.296655e-05
disc_acc: 1.0


	Epoch 370
Training results:
gen_loss: -0.00017551222
disc_loss: 0.00017551222
disc_acc: 1.0

Validation results:
gen_loss: -2.0933465e-05
disc_loss: 2.0933465e-05
disc_acc: 1.0


	Epoch 371
Training results:
gen_loss: -1.2778928e-05
disc_loss: 1.2778928e-05
disc_acc: 1.0

Validation results:
gen_loss: -3.6247435e-05
disc_loss: 3.6247435e-05
disc_acc: 1.0


	Epoch 372
Training results:
gen_loss: -2.830849e-05
disc_loss: 2.830849e-05
disc_acc: 1.0

Validation results:
gen_loss: -7.903415e-05
disc_loss: 7.903415e-05
disc_acc: 1.0


	Epoch 373
Training results:
gen_loss: -1.2829313e-05
disc_loss: 1.2829313e-05
disc_acc: 1.0

Validation results:
gen_loss: -7.4624295e-06
disc_loss: 7.4624295e-06
disc_acc: 1.0


	Epoch 374
Training results:
gen_loss: -8.621836e-06
disc_loss: 8.621836e-06
disc_acc: 1.0

Validation results:
gen_loss: -4.3525374e-06
disc_loss: 4.3525374e-06
disc_acc: 1.0


	Epoch 375
Training results:
gen_loss: -5.58346e-06
disc_loss: 5.58346e-06
disc_acc: 1.0

Validation results:
gen_loss: -2.9309316e-05
disc_loss: 2.9309316e-05
disc_acc: 1.0


	Epoch 376
Training results:
gen_loss: -7.754357e-06
disc_loss: 7.754357e-06
disc_acc: 1.0

Validation results:
gen_loss: -2.7550068e-06
disc_loss: 2.7550068e-06
disc_acc: 1.0


	Epoch 377
Training results:
gen_loss: -4.124706e-06
disc_loss: 4.124706e-06
disc_acc: 1.0

Validation results:
gen_loss: -4.5126735e-06
disc_loss: 4.5126735e-06
disc_acc: 1.0


	Epoch 378
Training results:
gen_loss: -6.289971e-06
disc_loss: 6.289971e-06
disc_acc: 1.0

Validation results:
gen_loss: -2.1918304e-06
disc_loss: 2.1918304e-06
disc_acc: 1.0


	Epoch 379
Training results:
gen_loss: -6.3469106e-06
disc_loss: 6.3469106e-06
disc_acc: 1.0

Validation results:
gen_loss: -2.436639e-06
disc_loss: 2.436639e-06
disc_acc: 1.0


	Epoch 380
Training results:
gen_loss: -3.745756e-06
disc_loss: 3.745756e-06
disc_acc: 1.0

Validation results:
gen_loss: -2.7394335e-06
disc_loss: 2.7394335e-06
disc_acc: 1.0


	Epoch 381
Training results:
gen_loss: -0.019445732
disc_loss: 0.019445732
disc_acc: 0.9981435643564357

Validation results:
gen_loss: -3.302268
disc_loss: 3.302268
disc_acc: 0.8333333333333334


	Epoch 382
Training results:
gen_loss: -0.7971234
disc_loss: 0.7971234
disc_acc: 0.9476485148514852

Validation results:
gen_loss: -2.3123219e-05
disc_loss: 2.3123219e-05
disc_acc: 1.0


	Epoch 383
Training results:
gen_loss: -0.00071948284
disc_loss: 0.00071948284
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -0.0038876315
disc_loss: 0.0038876315
disc_acc: 0.9990079365079365


	Epoch 384
Training results:
gen_loss: -9.1098795e-05
disc_loss: 9.1098795e-05
disc_acc: 1.0

Validation results:
gen_loss: -0.000107054424
disc_loss: 0.000107054424
disc_acc: 1.0


	Epoch 385
Training results:
gen_loss: -0.08852722
disc_loss: 0.08852722
disc_acc: 0.990470297029703

Validation results:
gen_loss: -0.017491253
disc_loss: 0.017491253
disc_acc: 0.9965277777777778


	Epoch 386
Training results:
gen_loss: -2.0269697e-05
disc_loss: 2.0269697e-05
disc_acc: 1.0

Validation results:
gen_loss: -1.0925155e-05
disc_loss: 1.0925155e-05
disc_acc: 1.0


	Epoch 387
Training results:
gen_loss: -0.026078684
disc_loss: 0.026078684
disc_acc: 0.9976485148514852

Validation results:
gen_loss: -1.3246732e-05
disc_loss: 1.3246732e-05
disc_acc: 1.0


	Epoch 388
Training results:
gen_loss: -0.068606056
disc_loss: 0.068606056
disc_acc: 0.9939356435643565

Validation results:
gen_loss: -3.6209826
disc_loss: 3.6209826
disc_acc: 0.8318452380952381


	Epoch 389
Training results:
gen_loss: -0.16868693
disc_loss: 0.16868693
disc_acc: 0.9860148514851486

Validation results:
gen_loss: -0.00833263
disc_loss: 0.00833263
disc_acc: 0.9990079365079365


	Epoch 390
Training results:
gen_loss: -0.00020088725
disc_loss: 0.00020088725
disc_acc: 0.9998762376237624

Validation results:
gen_loss: -5.169781e-06
disc_loss: 5.169781e-06
disc_acc: 1.0


	Epoch 391
Training results:
gen_loss: -7.0970746e-06
disc_loss: 7.0970746e-06
disc_acc: 1.0

Validation results:
gen_loss: -6.2186296e-06
disc_loss: 6.2186296e-06
disc_acc: 1.0


	Epoch 392
Training results:
gen_loss: -1.7159157e-06
disc_loss: 1.7159157e-06
disc_acc: 1.0

Validation results:
gen_loss: -2.4846809e-06
disc_loss: 2.4846809e-06
disc_acc: 1.0


	Epoch 393
Training results:
gen_loss: -2.6047983e-05
disc_loss: 2.6047983e-05
disc_acc: 1.0

Validation results:
gen_loss: -1.7502443e-06
disc_loss: 1.7502443e-06
disc_acc: 1.0


	Epoch 394
Training results:
gen_loss: -2.9270263e-06
disc_loss: 2.9270263e-06
disc_acc: 1.0

Validation results:
gen_loss: -2.262581e-06
disc_loss: 2.262581e-06
disc_acc: 1.0


	Epoch 395
Training results:
gen_loss: -0.94248784
disc_loss: 0.94248784
disc_acc: 0.9415841584158415

Validation results:
gen_loss: -0.06916619
disc_loss: 0.06916619
disc_acc: 0.9905753968253969


	Epoch 396
Training results:
gen_loss: -0.032877885
disc_loss: 0.032877885
disc_acc: 0.9962871287128713

Validation results:
gen_loss: -0.00935943
disc_loss: 0.00935943
disc_acc: 0.9985119047619048


	Epoch 397
Training results:
gen_loss: -3.6909067e-05
disc_loss: 3.6909067e-05
disc_acc: 1.0

Validation results:
gen_loss: -6.330417e-05
disc_loss: 6.330417e-05
disc_acc: 1.0


	Epoch 398
Training results:
gen_loss: -0.0016649676
disc_loss: 0.0016649676
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -0.00021081825
disc_loss: 0.00021081825
disc_acc: 1.0


	Epoch 399
Training results:
gen_loss: -0.00025611685
disc_loss: 0.00025611685
disc_acc: 1.0

Validation results:
gen_loss: -2.1007127e-06
disc_loss: 2.1007127e-06
disc_acc: 1.0


	Epoch 400
Training results:
gen_loss: -0.021204378
disc_loss: 0.021204378
disc_acc: 0.9982673267326733

Validation results:
gen_loss: -0.009099054
disc_loss: 0.009099054
disc_acc: 0.9990079365079365


	Epoch 401
Training results:
gen_loss: -4.0557625e-05
disc_loss: 4.0557625e-05
disc_acc: 1.0

Validation results:
gen_loss: -5.6417025e-07
disc_loss: 5.6417025e-07
disc_acc: 1.0


	Epoch 402
Training results:
gen_loss: -4.502899e-05
disc_loss: 4.502899e-05
disc_acc: 1.0

Validation results:
gen_loss: -3.5907951e-06
disc_loss: 3.5907951e-06
disc_acc: 1.0


	Epoch 403
Training results:
gen_loss: -2.6330276e-06
disc_loss: 2.6330276e-06
disc_acc: 1.0

Validation results:
gen_loss: -4.956687e-07
disc_loss: 4.956687e-07
disc_acc: 1.0


	Epoch 404
Training results:
gen_loss: -1.2183407e-06
disc_loss: 1.2183407e-06
disc_acc: 1.0

Validation results:
gen_loss: -2.3066518e-06
disc_loss: 2.3066518e-06
disc_acc: 1.0


	Epoch 405
Training results:
gen_loss: -1.2625162e-06
disc_loss: 1.2625162e-06
disc_acc: 1.0

Validation results:
gen_loss: -5.3538943e-06
disc_loss: 5.3538943e-06
disc_acc: 1.0


	Epoch 406
Training results:
gen_loss: -5.530849e-07
disc_loss: 5.530849e-07
disc_acc: 1.0

Validation results:
gen_loss: -3.689664e-07
disc_loss: 3.689664e-07
disc_acc: 1.0


	Epoch 407
Training results:
gen_loss: -4.738808e-07
disc_loss: 4.738808e-07
disc_acc: 1.0

Validation results:
gen_loss: -1.3430115e-06
disc_loss: 1.3430115e-06
disc_acc: 1.0


	Epoch 408
Training results:
gen_loss: -0.6144498
disc_loss: 0.6144498
disc_acc: 0.9663366336633663

Validation results:
gen_loss: -0.0036684244
disc_loss: 0.0036684244
disc_acc: 0.9995039682539683


	Epoch 409
Training results:
gen_loss: -0.012745491
disc_loss: 0.012745491
disc_acc: 0.9992574257425743

Validation results:
gen_loss: -0.0038347023
disc_loss: 0.0038347023
disc_acc: 0.9985119047619048


	Epoch 410
Training results:
gen_loss: -1.9981228e-05
disc_loss: 1.9981228e-05
disc_acc: 1.0

Validation results:
gen_loss: -6.0301925e-05
disc_loss: 6.0301925e-05
disc_acc: 1.0


	Epoch 411
Training results:
gen_loss: -0.2423487
disc_loss: 0.2423487
disc_acc: 0.9780940594059406

Validation results:
gen_loss: -6.2317026e-06
disc_loss: 6.2317026e-06
disc_acc: 1.0


	Epoch 412
Training results:
gen_loss: -6.804563e-05
disc_loss: 6.804563e-05
disc_acc: 1.0

Validation results:
gen_loss: -1.3801771e-05
disc_loss: 1.3801771e-05
disc_acc: 1.0


	Epoch 413
Training results:
gen_loss: -6.93231e-06
disc_loss: 6.93231e-06
disc_acc: 1.0

Validation results:
gen_loss: -2.7310327e-06
disc_loss: 2.7310327e-06
disc_acc: 1.0


	Epoch 414
Training results:
gen_loss: -3.4477123e-06
disc_loss: 3.4477123e-06
disc_acc: 1.0

Validation results:
gen_loss: -3.921034e-05
disc_loss: 3.921034e-05
disc_acc: 1.0


	Epoch 415
Training results:
gen_loss: -0.00019264867
disc_loss: 0.00019264867
disc_acc: 0.9998762376237624

Validation results:
gen_loss: -4.84272e-06
disc_loss: 4.84272e-06
disc_acc: 1.0


	Epoch 416
Training results:
gen_loss: -0.0003791934
disc_loss: 0.0003791934
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -0.00019404189
disc_loss: 0.00019404189
disc_acc: 1.0


	Epoch 417
Training results:
gen_loss: -0.37137488
disc_loss: 0.37137488
disc_acc: 0.971039603960396

Validation results:
gen_loss: -0.0012410843
disc_loss: 0.0012410843
disc_acc: 0.9995039682539683


	Epoch 418
Training results:
gen_loss: -0.0017153462
disc_loss: 0.0017153462
disc_acc: 0.9996287128712872

Validation results:
gen_loss: -1.9139484e-06
disc_loss: 1.9139484e-06
disc_acc: 1.0


	Epoch 419
Training results:
gen_loss: -0.046489142
disc_loss: 0.046489142
disc_acc: 0.9959158415841585

Validation results:
gen_loss: -0.003221201
disc_loss: 0.003221201
disc_acc: 0.9995039682539683


	Epoch 420
Training results:
gen_loss: -4.8653296e-06
disc_loss: 4.8653296e-06
disc_acc: 1.0

Validation results:
gen_loss: -7.9958394e-05
disc_loss: 7.9958394e-05
disc_acc: 1.0


	Epoch 421
Training results:
gen_loss: -1.1804543e-06
disc_loss: 1.1804543e-06
disc_acc: 1.0

Validation results:
gen_loss: -9.693009e-06
disc_loss: 9.693009e-06
disc_acc: 1.0


	Epoch 422
Training results:
gen_loss: -6.799585e-06
disc_loss: 6.799585e-06
disc_acc: 1.0

Validation results:
gen_loss: -3.2583208e-05
disc_loss: 3.2583208e-05
disc_acc: 1.0


	Epoch 423
Training results:
gen_loss: -0.6401832
disc_loss: 0.6401832
disc_acc: 0.9642326732673268

Validation results:
gen_loss: -0.0003939914
disc_loss: 0.0003939914
disc_acc: 1.0


	Epoch 424
Training results:
gen_loss: -0.0026423836
disc_loss: 0.0026423836
disc_acc: 0.9991336633663367

Validation results:
gen_loss: -0.001959819
disc_loss: 0.001959819
disc_acc: 0.9985119047619048


	Epoch 425
Training results:
gen_loss: -7.9714606e-05
disc_loss: 7.9714606e-05
disc_acc: 1.0

Validation results:
gen_loss: -9.3271265e-05
disc_loss: 9.3271265e-05
disc_acc: 1.0


	Epoch 426
Training results:
gen_loss: -0.06668709
disc_loss: 0.06668709
disc_acc: 0.9879950495049505

Validation results:
gen_loss: -1.0245599
disc_loss: 1.0245599
disc_acc: 0.964781746031746


	Epoch 427
Training results:
gen_loss: -0.06616335
disc_loss: 0.06616335
disc_acc: 0.9917079207920793

Validation results:
gen_loss: -0.0003233718
disc_loss: 0.0003233718
disc_acc: 1.0


	Epoch 428
Training results:
gen_loss: -0.004992647
disc_loss: 0.004992647
disc_acc: 0.999009900990099

Validation results:
gen_loss: -3.8999973e-05
disc_loss: 3.8999973e-05
disc_acc: 1.0


	Epoch 429
Training results:
gen_loss: -0.0002247808
disc_loss: 0.0002247808
disc_acc: 1.0

Validation results:
gen_loss: -0.023542061
disc_loss: 0.023542061
disc_acc: 0.9915674603174603


	Epoch 430
Training results:
gen_loss: -0.044515975
disc_loss: 0.044515975
disc_acc: 0.995420792079208

Validation results:
gen_loss: -2.3201168e-05
disc_loss: 2.3201168e-05
disc_acc: 1.0


	Epoch 431
Training results:
gen_loss: -0.0011595044
disc_loss: 0.0011595044
disc_acc: 0.9996287128712872

Validation results:
gen_loss: -1.4025727e-05
disc_loss: 1.4025727e-05
disc_acc: 1.0


	Epoch 432
Training results:
gen_loss: -1.0542187e-05
disc_loss: 1.0542187e-05
disc_acc: 1.0

Validation results:
gen_loss: -0.0001375934
disc_loss: 0.0001375934
disc_acc: 1.0


	Epoch 433
Training results:
gen_loss: -5.6891995e-06
disc_loss: 5.6891995e-06
disc_acc: 1.0

Validation results:
gen_loss: -7.168141e-06
disc_loss: 7.168141e-06
disc_acc: 1.0


	Epoch 434
Training results:
gen_loss: -3.3471279e-06
disc_loss: 3.3471279e-06
disc_acc: 1.0

Validation results:
gen_loss: -5.8827904e-06
disc_loss: 5.8827904e-06
disc_acc: 1.0


	Epoch 435
Training results:
gen_loss: -1.9130082e-06
disc_loss: 1.9130082e-06
disc_acc: 1.0

Validation results:
gen_loss: -1.5389865e-06
disc_loss: 1.5389865e-06
disc_acc: 1.0


	Epoch 436
Training results:
gen_loss: -2.1528685e-06
disc_loss: 2.1528685e-06
disc_acc: 1.0

Validation results:
gen_loss: -2.1443168e-06
disc_loss: 2.1443168e-06
disc_acc: 1.0


	Epoch 437
Training results:
gen_loss: -1.2069005e-06
disc_loss: 1.2069005e-06
disc_acc: 1.0

Validation results:
gen_loss: -2.3838272e-06
disc_loss: 2.3838272e-06
disc_acc: 1.0


	Epoch 438
Training results:
gen_loss: -1.1914942e-06
disc_loss: 1.1914942e-06
disc_acc: 1.0

Validation results:
gen_loss: -9.420749e-07
disc_loss: 9.420749e-07
disc_acc: 1.0


	Epoch 439
Training results:
gen_loss: -1.1671129e-06
disc_loss: 1.1671129e-06
disc_acc: 1.0

Validation results:
gen_loss: -1.1350454e-06
disc_loss: 1.1350454e-06
disc_acc: 1.0


	Epoch 440
Training results:
gen_loss: -7.1087693e-06
disc_loss: 7.1087693e-06
disc_acc: 1.0

Validation results:
gen_loss: -1.0192455e-06
disc_loss: 1.0192455e-06
disc_acc: 1.0


	Epoch 441
Training results:
gen_loss: -1.2853321e-06
disc_loss: 1.2853321e-06
disc_acc: 1.0

Validation results:
gen_loss: -3.5271705e-07
disc_loss: 3.5271705e-07
disc_acc: 1.0


	Epoch 442
Training results:
gen_loss: -5.7064625e-07
disc_loss: 5.7064625e-07
disc_acc: 1.0

Validation results:
gen_loss: -6.8395417e-07
disc_loss: 6.8395417e-07
disc_acc: 1.0


	Epoch 443
Training results:
gen_loss: -7.030049e-07
disc_loss: 7.030049e-07
disc_acc: 1.0

Validation results:
gen_loss: -0.028394867
disc_loss: 0.028394867
disc_acc: 0.9985119047619048


	Epoch 444
Training results:
gen_loss: -0.56374043
disc_loss: 0.56374043
disc_acc: 0.9636138613861386

Validation results:
gen_loss: -0.012913471
disc_loss: 0.012913471
disc_acc: 0.9990079365079365


	Epoch 445
Training results:
gen_loss: -0.046954863
disc_loss: 0.046954863
disc_acc: 0.994430693069307

Validation results:
gen_loss: -0.078922264
disc_loss: 0.078922264
disc_acc: 0.9846230158730159


	Epoch 446
Training results:
gen_loss: -0.0013780666
disc_loss: 0.0013780666
disc_acc: 0.9992574257425743

Validation results:
gen_loss: -0.009037091
disc_loss: 0.009037091
disc_acc: 0.9990079365079365


	Epoch 447
Training results:
gen_loss: -0.038157776
disc_loss: 0.038157776
disc_acc: 0.997029702970297

Validation results:
gen_loss: -4.5142468e-05
disc_loss: 4.5142468e-05
disc_acc: 1.0


	Epoch 448
Training results:
gen_loss: -1.0254741e-05
disc_loss: 1.0254741e-05
disc_acc: 1.0

Validation results:
gen_loss: -6.5616414e-06
disc_loss: 6.5616414e-06
disc_acc: 1.0


	Epoch 449
Training results:
gen_loss: -0.00012522013
disc_loss: 0.00012522013
disc_acc: 1.0

Validation results:
gen_loss: -0.00011160779
disc_loss: 0.00011160779
disc_acc: 1.0


	Epoch 450
Training results:
gen_loss: -1.26296e-05
disc_loss: 1.26296e-05
disc_acc: 1.0

Validation results:
gen_loss: -5.6746176e-06
disc_loss: 5.6746176e-06
disc_acc: 1.0


	Epoch 451
Training results:
gen_loss: -4.3981286e-06
disc_loss: 4.3981286e-06
disc_acc: 1.0

Validation results:
gen_loss: -2.6547958e-05
disc_loss: 2.6547958e-05
disc_acc: 1.0


	Epoch 452
Training results:
gen_loss: -1.5902712e-06
disc_loss: 1.5902712e-06
disc_acc: 1.0

Validation results:
gen_loss: -7.5183493e-07
disc_loss: 7.5183493e-07
disc_acc: 1.0


	Epoch 453
Training results:
gen_loss: -3.916173e-06
disc_loss: 3.916173e-06
disc_acc: 1.0

Validation results:
gen_loss: -9.912089e-07
disc_loss: 9.912089e-07
disc_acc: 1.0


	Epoch 454
Training results:
gen_loss: -1.1447435e-06
disc_loss: 1.1447435e-06
disc_acc: 1.0

Validation results:
gen_loss: -8.411669e-07
disc_loss: 8.411669e-07
disc_acc: 1.0


	Epoch 455
Training results:
gen_loss: -3.1782145e-06
disc_loss: 3.1782145e-06
disc_acc: 1.0

Validation results:
gen_loss: -1.5530408e-06
disc_loss: 1.5530408e-06
disc_acc: 1.0


	Epoch 456
Training results:
gen_loss: -2.692341e-06
disc_loss: 2.692341e-06
disc_acc: 1.0

Validation results:
gen_loss: -1.4655571e-06
disc_loss: 1.4655571e-06
disc_acc: 1.0


	Epoch 457
Training results:
gen_loss: -1.1950992e-06
disc_loss: 1.1950992e-06
disc_acc: 1.0

Validation results:
gen_loss: -0.00016218935
disc_loss: 0.00016218935
disc_acc: 1.0


	Epoch 458
Training results:
gen_loss: -0.7739161
disc_loss: 0.7739161
disc_acc: 0.9669554455445545

Validation results:
gen_loss: -0.3533933
disc_loss: 0.3533933
disc_acc: 0.964781746031746


	Epoch 459
Training results:
gen_loss: -0.02771365
disc_loss: 0.02771365
disc_acc: 0.9972772277227723

Validation results:
gen_loss: -1.4705753e-07
disc_loss: 1.4705753e-07
disc_acc: 1.0


	Epoch 460
Training results:
gen_loss: -1.5484815e-05
disc_loss: 1.5484815e-05
disc_acc: 1.0

Validation results:
gen_loss: -3.2312954e-07
disc_loss: 3.2312954e-07
disc_acc: 1.0


	Epoch 461
Training results:
gen_loss: -1.3278722e-05
disc_loss: 1.3278722e-05
disc_acc: 1.0

Validation results:
gen_loss: -2.0032589e-05
disc_loss: 2.0032589e-05
disc_acc: 1.0


	Epoch 462
Training results:
gen_loss: -0.100755095
disc_loss: 0.100755095
disc_acc: 0.9919554455445545

Validation results:
gen_loss: -0.9495611
disc_loss: 0.9495611
disc_acc: 0.9494047619047619


	Epoch 463
Training results:
gen_loss: -0.01820369
disc_loss: 0.01820369
disc_acc: 0.9978960396039604

Validation results:
gen_loss: -0.017207103
disc_loss: 0.017207103
disc_acc: 0.9940476190476191


	Epoch 464
Training results:
gen_loss: -0.038845636
disc_loss: 0.038845636
disc_acc: 0.9966584158415842

Validation results:
gen_loss: -5.87152e-06
disc_loss: 5.87152e-06
disc_acc: 1.0


	Epoch 465
Training results:
gen_loss: -1.3992876e-05
disc_loss: 1.3992876e-05
disc_acc: 1.0

Validation results:
gen_loss: -2.399122e-06
disc_loss: 2.399122e-06
disc_acc: 1.0


	Epoch 466
Training results:
gen_loss: -0.38293663
disc_loss: 0.38293663
disc_acc: 0.9701732673267327

Validation results:
gen_loss: -0.022494791
disc_loss: 0.022494791
disc_acc: 0.9900793650793651


	Epoch 467
Training results:
gen_loss: -0.0045498773
disc_loss: 0.0045498773
disc_acc: 0.999009900990099

Validation results:
gen_loss: -4.0666422e-05
disc_loss: 4.0666422e-05
disc_acc: 1.0


	Epoch 468
Training results:
gen_loss: -0.0013423592
disc_loss: 0.0013423592
disc_acc: 0.9993811881188119

Validation results:
gen_loss: -0.0018169209
disc_loss: 0.0018169209
disc_acc: 0.9995039682539683


	Epoch 469
Training results:
gen_loss: -1.586791e-06
disc_loss: 1.586791e-06
disc_acc: 1.0

Validation results:
gen_loss: -0.0012956826
disc_loss: 0.0012956826
disc_acc: 0.9990079365079365


	Epoch 470
Training results:
gen_loss: -0.0013950795
disc_loss: 0.0013950795
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -7.7886784e-07
disc_loss: 7.7886784e-07
disc_acc: 1.0


	Epoch 471
Training results:
gen_loss: -2.9055425e-07
disc_loss: 2.9055425e-07
disc_acc: 1.0

Validation results:
gen_loss: -5.1180984e-07
disc_loss: 5.1180984e-07
disc_acc: 1.0


	Epoch 472
Training results:
gen_loss: -2.7509996e-06
disc_loss: 2.7509996e-06
disc_acc: 1.0

Validation results:
gen_loss: -9.999107e-08
disc_loss: 9.999107e-08
disc_acc: 1.0


	Epoch 473
Training results:
gen_loss: -6.3121206e-07
disc_loss: 6.3121206e-07
disc_acc: 1.0

Validation results:
gen_loss: -3.2389042e-07
disc_loss: 3.2389042e-07
disc_acc: 1.0


	Epoch 474
Training results:
gen_loss: -2.0359978e-07
disc_loss: 2.0359978e-07
disc_acc: 1.0

Validation results:
gen_loss: -4.8014762e-08
disc_loss: 4.8014762e-08
disc_acc: 1.0


	Epoch 475
Training results:
gen_loss: -1.4351559e-07
disc_loss: 1.4351559e-07
disc_acc: 1.0

Validation results:
gen_loss: -1.0933309e-07
disc_loss: 1.0933309e-07
disc_acc: 1.0


	Epoch 476
Training results:
gen_loss: -5.29534e-07
disc_loss: 5.29534e-07
disc_acc: 1.0

Validation results:
gen_loss: -1.8773785e-07
disc_loss: 1.8773785e-07
disc_acc: 1.0


	Epoch 477
Training results:
gen_loss: -1.9387149e-07
disc_loss: 1.9387149e-07
disc_acc: 1.0

Validation results:
gen_loss: -2.7714427e-07
disc_loss: 2.7714427e-07
disc_acc: 1.0


	Epoch 478
Training results:
gen_loss: -0.82402366
disc_loss: 0.82402366
disc_acc: 0.9586633663366336

Validation results:
gen_loss: -0.023638234
disc_loss: 0.023638234
disc_acc: 0.9985119047619048


	Epoch 479
Training results:
gen_loss: -0.0010738465
disc_loss: 0.0010738465
disc_acc: 0.9998762376237624

Validation results:
gen_loss: -4.272711e-07
disc_loss: 4.272711e-07
disc_acc: 1.0


	Epoch 480
Training results:
gen_loss: -0.065764666
disc_loss: 0.065764666
disc_acc: 0.9935643564356436

Validation results:
gen_loss: -0.025936065
disc_loss: 0.025936065
disc_acc: 0.998015873015873


	Epoch 481
Training results:
gen_loss: -0.04366568
disc_loss: 0.04366568
disc_acc: 0.9952970297029703

Validation results:
gen_loss: -4.256673e-05
disc_loss: 4.256673e-05
disc_acc: 1.0


	Epoch 482
Training results:
gen_loss: -0.10596679
disc_loss: 0.10596679
disc_acc: 0.9908415841584158

Validation results:
gen_loss: -0.0013633202
disc_loss: 0.0013633202
disc_acc: 0.9995039682539683


	Epoch 483
Training results:
gen_loss: -0.0047234343
disc_loss: 0.0047234343
disc_acc: 0.9998762376237624

Validation results:
gen_loss: -2.3624207e-05
disc_loss: 2.3624207e-05
disc_acc: 1.0


	Epoch 484
Training results:
gen_loss: -8.426271e-06
disc_loss: 8.426271e-06
disc_acc: 1.0

Validation results:
gen_loss: -2.881882e-06
disc_loss: 2.881882e-06
disc_acc: 1.0


	Epoch 485
Training results:
gen_loss: -0.0012371516
disc_loss: 0.0012371516
disc_acc: 0.9997524752475248

Validation results:
gen_loss: -5.4714046e-06
disc_loss: 5.4714046e-06
disc_acc: 1.0


	Epoch 486
Training results:
gen_loss: -5.815979e-06
disc_loss: 5.815979e-06
disc_acc: 1.0

Validation results:
gen_loss: -0.0018152329
disc_loss: 0.0018152329
disc_acc: 0.9995039682539683


	Epoch 487
Training results:
gen_loss: -0.061612524
disc_loss: 0.061612524
disc_acc: 0.9902227722772278

Validation results:
gen_loss: -4.5213837e-06
disc_loss: 4.5213837e-06
disc_acc: 1.0


	Epoch 488
Training results:
gen_loss: -3.4401137e-06
disc_loss: 3.4401137e-06
disc_acc: 1.0

Validation results:
gen_loss: -1.8878031e-06
disc_loss: 1.8878031e-06
disc_acc: 1.0


	Epoch 489
Training results:
gen_loss: -6.2854547e-06
disc_loss: 6.2854547e-06
disc_acc: 1.0

Validation results:
gen_loss: -1.5738306e-06
disc_loss: 1.5738306e-06
disc_acc: 1.0


	Epoch 490
Training results:
gen_loss: -1.1673758e-06
disc_loss: 1.1673758e-06
disc_acc: 1.0

Validation results:
gen_loss: -1.6732021e-06
disc_loss: 1.6732021e-06
disc_acc: 1.0


	Epoch 491
Training results:
gen_loss: -9.134603e-07
disc_loss: 9.134603e-07
disc_acc: 1.0

Validation results:
gen_loss: -1.5083879e-06
disc_loss: 1.5083879e-06
disc_acc: 1.0


	Epoch 492
Training results:
gen_loss: -9.603477e-07
disc_loss: 9.603477e-07
disc_acc: 1.0

Validation results:
gen_loss: -1.0626983e-06
disc_loss: 1.0626983e-06
disc_acc: 1.0


	Epoch 493
Training results:
gen_loss: -9.13861e-07
disc_loss: 9.13861e-07
disc_acc: 1.0

Validation results:
gen_loss: -1.3481957e-06
disc_loss: 1.3481957e-06
disc_acc: 1.0


	Epoch 494
Training results:
gen_loss: -0.3268649
disc_loss: 0.3268649
disc_acc: 0.977970297029703

Validation results:
gen_loss: -0.11289797
disc_loss: 0.11289797
disc_acc: 0.9608134920634921


	Epoch 495
Training results:
gen_loss: -0.07193962
disc_loss: 0.07193962
disc_acc: 0.990470297029703

Validation results:
gen_loss: -0.0003375392
disc_loss: 0.0003375392
disc_acc: 1.0


	Epoch 496
Training results:
gen_loss: -1.1280327e-05
disc_loss: 1.1280327e-05
disc_acc: 1.0

Validation results:
gen_loss: -2.0374623e-06
disc_loss: 2.0374623e-06
disc_acc: 1.0


	Epoch 497
Training results:
gen_loss: -0.056708965
disc_loss: 0.056708965
disc_acc: 0.9959158415841585

Validation results:
gen_loss: -1.8211892e-06
disc_loss: 1.8211892e-06
disc_acc: 1.0


	Epoch 498
Training results:
gen_loss: -0.010312185
disc_loss: 0.010312185
disc_acc: 0.9982673267326733

Validation results:
gen_loss: -0.00028615154
disc_loss: 0.00028615154
disc_acc: 1.0


	Epoch 499
Training results:
gen_loss: -0.16358739
disc_loss: 0.16358739
disc_acc: 0.9834158415841584

Validation results:
gen_loss: -4.625392e-05
disc_loss: 4.625392e-05
disc_acc: 1.0


	Epoch 500
Training results:
gen_loss: -2.2801545e-05
disc_loss: 2.2801545e-05
disc_acc: 1.0

Validation results:
gen_loss: -9.124822e-06
disc_loss: 9.124822e-06
disc_acc: 1.0



gen_train_loss: -5.53727, -2.7251005, -2.5890434, -2.1565492, -2.071932, -2.156711, -2.1561751, -2.230742, -2.160218, -2.1657603, -2.2203355, -2.2472143, -2.0960872, -2.083834, -2.1319017, -2.1234715, -2.1336594, -2.1364896, -2.1283855, -2.1581597, -2.6646993, -2.3120537, -2.0566354, -1.9850467, -2.0523767, -2.0360959, -2.0786393, -2.1559744, -2.0298772, -1.8962908, -2.0012991, -2.0815158, -2.1481006, -2.1244788, -2.142833, -3.148554, -1.9598194, -2.0606441, -2.1025264, -2.133006, -2.134203, -2.1360495, -2.1425843, -2.1430767, -2.1487696, -2.1442585, -2.1383774, -2.0870845, -1.999492, -2.0067945, -1.8663415, -2.0839362, -2.1214576, -2.1300466, -2.1416185, -2.1057756, -1.8360944, -1.9061491, -1.9152063, -2.1465883, -2.121797, -2.1774356, -2.198678, -2.1229348, -2.1174703, -2.1281176, -2.1353478, -2.1815696, -2.0233443, -1.9646906, -1.9692959, -1.8175793, -2.0776758, -2.0101378, -2.0687153, -2.0121608, -2.2475188, -2.2540097, -2.25918, -2.253107, -2.2709575, -2.2657619, -2.252832, -2.2665842, -2.2511463, -2.246231, -2.2639494, -2.2559423, -2.2824316, -2.2757053, -2.2597106, -2.2646456, -2.2561722, -2.2618322, -2.2635663, -2.2379148, -2.3093827, -2.2698922, -2.2665865, -2.2985451, -2.255351, -2.2469547, -2.2578776, -2.292301, -2.2413058, -2.2650952, -2.0329013, -1.9764037, -1.925542, -2.0715673, -2.0934052, -2.127186, -2.134402, -2.142781, -2.1221273, -2.1389213, -2.132754, -2.1327157, -2.168422, -2.1317785, -2.1331065, -2.1477954, -2.1578946, -2.1467419, -2.1355119, -2.1358933, -2.1417418, -2.1204216, -2.139558, -2.1336489, -2.1259336, -2.1495237, -2.129426, -2.124746, -2.1303046, -2.1377976, -2.1438756, -2.1374142, -2.1397233, -1.790997, -2.9521525, -1.8757553, -1.881932, -1.784115, -1.6291845, -1.6303774, -1.7396917, -1.7525951, -1.830805, -1.7789757, -1.9449475, -1.7548574, -1.7654396, -1.7123555, -1.5400335, -1.4847863, -1.7866939, -1.817796, -1.8545167, -1.8067751, -1.7955003, -1.7953918, -1.7830588, -1.8234836, -1.8100477, -1.7874577, -1.8448445, -1.8187449, -1.8676597, -1.8161227, -1.8168678, -1.8464894, -1.7817036, -1.8034042, -1.8317443, -1.8390162, -1.7886544, -1.8026457, -1.9136523, -1.917561, -1.8418795, -1.844174, -2.2676094, -1.8951426, -1.8659058, -2.0838044, -1.9957159, -2.207981, -2.2850597, -1.9936328, -1.9130511, -2.031769, -2.1348815, -2.0617537, -2.0657744, -1.9333346, -2.0361402, -2.08565, -2.098012, -2.1246207, -2.1274858, -2.1339483, -2.141649, -2.1531816, -2.1299374, -2.1462066, -2.147144, -2.144747, -2.1228535, -2.144629, -2.1028197, -2.022173, -1.9981766, -1.9940763, -2.0334163, -2.0533025, -2.024048, -2.184671, -2.277644, -2.2076705, -2.3254626, -2.2356055, -2.3045511, -2.235909, -2.0504332, -2.0755103, -2.0690053, -1.9936646, -2.0330844, -2.063377, -2.1383882, -2.121785, -2.1357048, -2.1387625, -2.1297257, -2.1431267, -2.1392744, -2.1283534, -2.136435, -2.1361454, -2.1413476, -2.168248, -2.1388469, -2.0902617, -2.0978804, -2.1193025, -2.1132967, -2.0350025, -1.826167, -1.8607761, -1.747367, -1.6151175, -1.7261841, -1.8070363, -2.0428894, -1.9918641, -1.876973, -1.845575, -1.8523232, -1.8243179, -1.7347635, -1.709367, -1.645668, -1.6052873, -1.5424422, -1.5661187, -1.4631835, -1.5578063, -1.520009, -1.5108614, -1.4934467, -1.4716555, -1.50013, -1.5555589, -1.478038, -1.4718558, -1.4996606, -1.4614435, -1.4416982, -1.5014682, -1.6427261, -1.5844891, -1.6188003, -1.589244, -1.6382748, -1.6035398, -1.6298866, -1.6300573, -1.5888798, -1.6306854, -1.6227046, -1.7657151, -1.5459136, -1.6669047, -1.6553802, -1.6342024, -1.6307212, -1.669597, -1.6277112, -1.595324, -1.7054818, -1.6490873, -1.5943589, -1.5953046, -1.5518999, -1.5908607, -1.7524967, -1.6579317, -1.6650484, -1.6461334, -1.6601845, -1.8463337, -1.8041608, -1.8026685, -1.8452034, -1.815262, -1.7994359, -1.7865237, -1.813377, -1.8164285, -1.8216612, -1.7813556, -1.801971, -1.8546305, -1.81627, -1.7909936, -1.797611, -1.8297822, -1.8082201, -1.8020532, -1.8171433, -1.7756011, -1.8067836, -1.7995683, -1.8104384, -1.810846, -1.8389581, -1.9274925, -1.7931381, -1.7824801, -1.7879295, -1.7944344, -1.7972575, -1.7999908, -1.785269, -1.8157755, -1.797538, -1.8100772, -1.8677701, -1.7492293, -1.6989546, -1.6900673, -1.8220972, -1.7943226, -1.8031683, -1.7715023, -1.7410953, -1.7657065, -1.7402775, -1.7092648, -1.7321095, -1.6572022, -1.6646966, -1.5364004, -1.6335998, -1.6098641, -1.6307158, -1.6982819, -1.6287587, -1.6183625, -1.6318609, -1.613425, -1.6586587, -1.7016292, -1.6400999, -1.6939502, -1.7038432, -1.694001, -1.670246, -1.6669371, -1.879112, -1.8486375, -1.8389121, -1.7461678, -1.8487542, -1.9169866, -1.8101614, -1.8513027, -1.8862363, -1.9407365, -1.8128415, -1.876354, -1.8647734, -1.8585852, -1.755554, -1.8052232, -1.8408942, -1.9599519, -1.9471911, -1.9146554, -1.8178861, -1.7137154, -1.7258193, -1.7408673, -1.7470893, -1.7638612, -1.7694906, -1.7947787, -1.7907968, -1.7489899, -1.7819505, -1.7560167, -1.6648815, -1.6192138, -1.7766141, -1.7589314, -1.7434505, -1.644981, -1.6841172, -1.7234133, -1.6870579, -1.617149, -1.604015, -1.7153053, -1.5777708, -1.6996778, -1.5830842, -1.6373895, -1.6386807, -1.6198231, -1.5568463, -1.5686018, -1.5223916, -1.4492385, -1.4179425, -1.4109223, -1.4018179, -1.4479511, -1.4095597, -1.4837799, -1.4768001, -1.4264426, -1.5210241, -1.7408135, -1.7650422, -1.7474518, -1.7603103, -1.6818702, -1.6762122, -1.6575034, -1.5916096, -1.5214908, -1.5411053, -1.5638734, -1.5951952, -1.519327, -1.5175873, -1.6052985, -1.5067438, -1.6262276, -1.5635326, -1.5090733, -1.5859349, -1.4867114, -1.4102936, -1.3916284, -1.3834052, -1.3734908, -1.3797898, -1.4213884, -1.478116, -1.4449531, -1.4270717, -1.4063514, -1.3670614, -1.4042406, -1.3474599, -1.3948504, -1.3572742, -1.4551163, -1.43845, -1.428499, -1.4522954, -1.4010471, -1.3845979, -1.4000559, -1.3633549, -1.4398539, -1.3752627, -1.43069, -1.3802607, -1.3988798, -1.3804562, -1.3892171, -1.4131991, -1.4373577, -1.409653, -1.349, -1.3661172, -1.3309664, -1.3943357, -5.7154927, -2.1569734, -1.7437778, -1.7154473, -1.5785937, -1.4985594, -1.4519703, -1.3216434, -1.1239977, -1.0678568, -1.0320927, -0.7831516, -0.6868841, -0.7232311, -0.63086796, -0.5825474, -0.536956, -0.54428387, -0.3619415, -0.28039932, -0.4567445, -0.487098, -0.34372953, -0.45134962, -0.34072575, -0.25641146, -0.43941116, -0.28849554, -0.36180753, -0.35297796, -0.35820478, -0.16344777, -0.43198544, -0.2519095, -0.335027, -0.239541, -0.45451766, -0.26878214, -0.20053801, -0.19866055, -0.4496548, -0.18146667, -0.17924397, -0.48798573, -0.1754378, -0.20171699, -0.18665798, -0.17493887, -0.23802872, -0.29423276, -0.31689766, -0.16538328, -0.31442717, -0.22671336, -0.13025972, -0.22079854, -0.11239371, -0.16463926, -0.22712497, -0.53926384, -0.21379572, -0.12953454, -0.15539059, -0.20631409, -0.199712, -0.31470302, -0.1396297, -0.052758984, -0.3297161, -0.14323771, -0.01171961, -0.20509824, -0.10373695, -0.1087377, -0.22163777, -0.017409123, -0.25362656, -0.13398537, -0.07670936, -0.0056417114, -0.05786776, -0.5264505, -0.08431212, -0.06544067, -0.001966619, -0.086972594, -0.15570208, -0.0667239, -0.22581789, -0.029057903, -0.01157707, -0.2395026, -0.016327702, -0.00037294254, -0.6753586, -0.0260856, -0.0015403205, -0.00046481585, -0.00014650101, -0.15357368, -0.074837014, -0.050283417, -0.031787805, -0.24361934, -0.0039059394, -0.00039916753, -0.00017960949, -9.83847e-05, -4.4373064e-05, -0.9357059, -0.02165622, -0.089066446, -0.109716915, -0.0014182886, -0.047236566, -0.08278741, -0.07505543, -0.0102191605, -0.00014069135, -6.9335176e-05, -7.796329e-05, -7.4712036e-05, -4.6795452e-05, -0.42957604, -0.0008272764, -0.0015444952, -0.0042912923, -0.15412341, -0.028918004, -0.022272922, -0.00053100876, -0.08056001, -0.5675369, -0.018692859, -0.026341572, -0.124617055, -0.0037866104, -0.00026862876, -0.00012997571, -0.65249604, -0.003910054, -0.05238999, -0.0012840253, -0.059980497, -0.004072536, -0.016484572, -0.0002170882, -0.00012049452, -9.635952e-05, -0.0001477467, -2.886745e-05, -3.002494e-05, -1.702962e-05, -1.33924e-05, -8.909915e-06, -6.7225114e-06, -9.450652e-06, -0.73883945, -0.004254411, -0.0579604, -0.0015667133, -0.014024297, -0.2988266, -0.00087062013, -0.0019053295, -0.00019157579, -0.12851387, -0.015918214, -0.08158023, -0.3500692, -0.21873161, -0.0013005194, -0.050816793, -0.0010433896, -8.010246e-05, -7.268125e-05, -3.910323e-05, -0.46530938, -0.028597867, -0.022063024, -0.0056812246, -0.03910911, -0.00019468898, -0.0009270499, -8.297225e-05, -0.4561252, -0.013618795, -0.032038722, -0.0040892335, -0.00046587444, -0.14302179, -0.00058400334, -0.00012952564, -0.35780597, -0.11674293, -0.00050383626, -0.00025894848, -0.00013682993, -0.0001409199, -0.00018941125, -5.4294607e-05, -0.00010546511, -3.119936e-05, -1.817926e-05, -1.6088876e-05, -0.58226264, -0.030999422, -0.0014396501, -0.00015739423, -4.5304656e-05, -2.6218015e-05, -2.6608912e-05, -1.591299e-05, -0.3619745, -0.0027306317, -0.026607351, -0.00013599342, -0.00025178594, -4.2046177e-05, -0.41194266, -0.015458539, -0.0011980229, -0.111275285, -0.0003842768, -0.00024018767, -0.00074008823, -0.1359787, -0.0023167152, -0.20920421, -0.017535774, -9.4639974e-05, -0.021210954, -6.900291e-05, -6.721057e-05, -0.00023305745, -3.0380499e-05, -1.78347e-05, -1.37391835e-05, -1.1300717e-05, -9.025984e-06, -0.8090283, -0.0017674073, -0.00018336638, -0.03977405, -0.0042385226, -0.0009745992, -0.00016347246, -4.3127577e-05, -0.22357868, -0.0020279966, -0.19276057, -0.00041911952, -0.00195724, -0.021466298, -3.106175e-05, -0.00028856812, -1.4277965e-05, -2.3787206e-05, -1.0523616e-05, -6.4997557e-06, -0.6965808, -0.007728201, -0.05898092, -0.0017837224, -0.047486894, -0.001228287, -7.13378e-05, -4.824422e-05, -0.5725965, -0.06502484, -0.00017153272, -0.00019974343, -0.000120536715, -5.44105e-05, -0.20771001, -0.00022661503, -0.0002825499, -0.15184888, -0.0040974957, -0.016134214, -0.00010555472, -3.3287764e-05, -4.118283e-05, -2.190559e-05, -0.000216082, -0.7238677, -0.3709989, -0.0021691143, -0.019168524, -0.0011781001, -0.012024861, -0.018478202, -0.18072784, -0.00016593066, -0.0006108398, -3.2648117e-05, -1.279581e-05, -8.5815955e-06, -6.9661187e-06, -0.6056215, -0.011575529, -0.008543358, -0.009256612, -0.00680591, -0.0005336017, -4.894236e-05, -2.10701e-05, -0.2213049, -0.012223565, -0.51028454, -0.06996252, -5.5768658e-05, -7.116411e-06, -3.458016e-06, -3.911278e-06, -0.3664905, -3.8586055e-05, -0.0015509397, -0.06164481, -0.06892993, -0.0003177658, -1.9572366e-05, -0.03678424, -0.053127438, -0.3602635, -0.0033946529, -0.02310906, -0.08293463, -0.011324903, -8.799405e-05, -0.00027334923, -3.2030028e-05, -3.854949e-05, -1.8918776e-05, -1.4220844e-05, -2.8818116e-05, -8.623577e-06, -1.26006225e-05, -5.9697086e-06, -4.2871425e-06, -4.0266373e-06, -3.1413674e-06, -2.421643e-06, -0.66949224, -0.0006580275, -0.0010170087, -0.13163985, -0.008109202, -5.3999654e-05, -3.1460488e-05, -0.0009055975, -0.0001226937, -0.0023544964, -0.617096, -0.017466163, -1.4378648e-05, -0.030691506, -0.13767613, -0.014874432, -4.4380304e-05, -1.6749651e-05, -1.7834667e-05, -0.53355527, -0.099935636, -2.720647e-05, -0.0032741458, -1.0601751e-05, -0.117679715, -0.017345654, -0.00010350762, -0.00017551222, -1.2778928e-05, -2.830849e-05, -1.2829313e-05, -8.621836e-06, -5.58346e-06, -7.754357e-06, -4.124706e-06, -6.289971e-06, -6.3469106e-06, -3.745756e-06, -0.019445732, -0.7971234, -0.00071948284, -9.1098795e-05, -0.08852722, -2.0269697e-05, -0.026078684, -0.068606056, -0.16868693, -0.00020088725, -7.0970746e-06, -1.7159157e-06, -2.6047983e-05, -2.9270263e-06, -0.94248784, -0.032877885, -3.6909067e-05, -0.0016649676, -0.00025611685, -0.021204378, -4.0557625e-05, -4.502899e-05, -2.6330276e-06, -1.2183407e-06, -1.2625162e-06, -5.530849e-07, -4.738808e-07, -0.6144498, -0.012745491, -1.9981228e-05, -0.2423487, -6.804563e-05, -6.93231e-06, -3.4477123e-06, -0.00019264867, -0.0003791934, -0.37137488, -0.0017153462, -0.046489142, -4.8653296e-06, -1.1804543e-06, -6.799585e-06, -0.6401832, -0.0026423836, -7.9714606e-05, -0.06668709, -0.06616335, -0.004992647, -0.0002247808, -0.044515975, -0.0011595044, -1.0542187e-05, -5.6891995e-06, -3.3471279e-06, -1.9130082e-06, -2.1528685e-06, -1.2069005e-06, -1.1914942e-06, -1.1671129e-06, -7.1087693e-06, -1.2853321e-06, -5.7064625e-07, -7.030049e-07, -0.56374043, -0.046954863, -0.0013780666, -0.038157776, -1.0254741e-05, -0.00012522013, -1.26296e-05, -4.3981286e-06, -1.5902712e-06, -3.916173e-06, -1.1447435e-06, -3.1782145e-06, -2.692341e-06, -1.1950992e-06, -0.7739161, -0.02771365, -1.5484815e-05, -1.3278722e-05, -0.100755095, -0.01820369, -0.038845636, -1.3992876e-05, -0.38293663, -0.0045498773, -0.0013423592, -1.586791e-06, -0.0013950795, -2.9055425e-07, -2.7509996e-06, -6.3121206e-07, -2.0359978e-07, -1.4351559e-07, -5.29534e-07, -1.9387149e-07, -0.82402366, -0.0010738465, -0.065764666, -0.04366568, -0.10596679, -0.0047234343, -8.426271e-06, -0.0012371516, -5.815979e-06, -0.061612524, -3.4401137e-06, -6.2854547e-06, -1.1673758e-06, -9.134603e-07, -9.603477e-07, -9.13861e-07, -0.3268649, -0.07193962, -1.1280327e-05, -0.056708965, -0.010312185, -0.16358739, -2.2801545e-05
disc_train_loss: 5.53727, 2.7251005, 2.5890434, 2.1565492, 2.071932, 2.156711, 2.1561751, 2.230742, 2.160218, 2.1657603, 2.2203355, 2.2472143, 2.0960872, 2.083834, 2.1319017, 2.1234715, 2.1336594, 2.1364896, 2.1283855, 2.1581597, 2.6646993, 2.3120537, 2.0566354, 1.9850467, 2.0523767, 2.0360959, 2.0786393, 2.1559744, 2.0298772, 1.8962908, 2.0012991, 2.0815158, 2.1481006, 2.1244788, 2.142833, 3.148554, 1.9598194, 2.0606441, 2.1025264, 2.133006, 2.134203, 2.1360495, 2.1425843, 2.1430767, 2.1487696, 2.1442585, 2.1383774, 2.0870845, 1.999492, 2.0067945, 1.8663415, 2.0839362, 2.1214576, 2.1300466, 2.1416185, 2.1057756, 1.8360944, 1.9061491, 1.9152063, 2.1465883, 2.121797, 2.1774356, 2.198678, 2.1229348, 2.1174703, 2.1281176, 2.1353478, 2.1815696, 2.0233443, 1.9646906, 1.9692959, 1.8175793, 2.0776758, 2.0101378, 2.0687153, 2.0121608, 2.2475188, 2.2540097, 2.25918, 2.253107, 2.2709575, 2.2657619, 2.252832, 2.2665842, 2.2511463, 2.246231, 2.2639494, 2.2559423, 2.2824316, 2.2757053, 2.2597106, 2.2646456, 2.2561722, 2.2618322, 2.2635663, 2.2379148, 2.3093827, 2.2698922, 2.2665865, 2.2985451, 2.255351, 2.2469547, 2.2578776, 2.292301, 2.2413058, 2.2650952, 2.0329013, 1.9764037, 1.925542, 2.0715673, 2.0934052, 2.127186, 2.134402, 2.142781, 2.1221273, 2.1389213, 2.132754, 2.1327157, 2.168422, 2.1317785, 2.1331065, 2.1477954, 2.1578946, 2.1467419, 2.1355119, 2.1358933, 2.1417418, 2.1204216, 2.139558, 2.1336489, 2.1259336, 2.1495237, 2.129426, 2.124746, 2.1303046, 2.1377976, 2.1438756, 2.1374142, 2.1397233, 1.790997, 2.9521525, 1.8757553, 1.881932, 1.784115, 1.6291845, 1.6303774, 1.7396917, 1.7525951, 1.830805, 1.7789757, 1.9449475, 1.7548574, 1.7654396, 1.7123555, 1.5400335, 1.4847863, 1.7866939, 1.817796, 1.8545167, 1.8067751, 1.7955003, 1.7953918, 1.7830588, 1.8234836, 1.8100477, 1.7874577, 1.8448445, 1.8187449, 1.8676597, 1.8161227, 1.8168678, 1.8464894, 1.7817036, 1.8034042, 1.8317443, 1.8390162, 1.7886544, 1.8026457, 1.9136523, 1.917561, 1.8418795, 1.844174, 2.2676094, 1.8951426, 1.8659058, 2.0838044, 1.9957159, 2.207981, 2.2850597, 1.9936328, 1.9130511, 2.031769, 2.1348815, 2.0617537, 2.0657744, 1.9333346, 2.0361402, 2.08565, 2.098012, 2.1246207, 2.1274858, 2.1339483, 2.141649, 2.1531816, 2.1299374, 2.1462066, 2.147144, 2.144747, 2.1228535, 2.144629, 2.1028197, 2.022173, 1.9981766, 1.9940763, 2.0334163, 2.0533025, 2.024048, 2.184671, 2.277644, 2.2076705, 2.3254626, 2.2356055, 2.3045511, 2.235909, 2.0504332, 2.0755103, 2.0690053, 1.9936646, 2.0330844, 2.063377, 2.1383882, 2.121785, 2.1357048, 2.1387625, 2.1297257, 2.1431267, 2.1392744, 2.1283534, 2.136435, 2.1361454, 2.1413476, 2.168248, 2.1388469, 2.0902617, 2.0978804, 2.1193025, 2.1132967, 2.0350025, 1.826167, 1.8607761, 1.747367, 1.6151175, 1.7261841, 1.8070363, 2.0428894, 1.9918641, 1.876973, 1.845575, 1.8523232, 1.8243179, 1.7347635, 1.709367, 1.645668, 1.6052873, 1.5424422, 1.5661187, 1.4631835, 1.5578063, 1.520009, 1.5108614, 1.4934467, 1.4716555, 1.50013, 1.5555589, 1.478038, 1.4718558, 1.4996606, 1.4614435, 1.4416982, 1.5014682, 1.6427261, 1.5844891, 1.6188003, 1.589244, 1.6382748, 1.6035398, 1.6298866, 1.6300573, 1.5888798, 1.6306854, 1.6227046, 1.7657151, 1.5459136, 1.6669047, 1.6553802, 1.6342024, 1.6307212, 1.669597, 1.6277112, 1.595324, 1.7054818, 1.6490873, 1.5943589, 1.5953046, 1.5518999, 1.5908607, 1.7524967, 1.6579317, 1.6650484, 1.6461334, 1.6601845, 1.8463337, 1.8041608, 1.8026685, 1.8452034, 1.815262, 1.7994359, 1.7865237, 1.813377, 1.8164285, 1.8216612, 1.7813556, 1.801971, 1.8546305, 1.81627, 1.7909936, 1.797611, 1.8297822, 1.8082201, 1.8020532, 1.8171433, 1.7756011, 1.8067836, 1.7995683, 1.8104384, 1.810846, 1.8389581, 1.9274925, 1.7931381, 1.7824801, 1.7879295, 1.7944344, 1.7972575, 1.7999908, 1.785269, 1.8157755, 1.797538, 1.8100772, 1.8677701, 1.7492293, 1.6989546, 1.6900673, 1.8220972, 1.7943226, 1.8031683, 1.7715023, 1.7410953, 1.7657065, 1.7402775, 1.7092648, 1.7321095, 1.6572022, 1.6646966, 1.5364004, 1.6335998, 1.6098641, 1.6307158, 1.6982819, 1.6287587, 1.6183625, 1.6318609, 1.613425, 1.6586587, 1.7016292, 1.6400999, 1.6939502, 1.7038432, 1.694001, 1.670246, 1.6669371, 1.879112, 1.8486375, 1.8389121, 1.7461678, 1.8487542, 1.9169866, 1.8101614, 1.8513027, 1.8862363, 1.9407365, 1.8128415, 1.876354, 1.8647734, 1.8585852, 1.755554, 1.8052232, 1.8408942, 1.9599519, 1.9471911, 1.9146554, 1.8178861, 1.7137154, 1.7258193, 1.7408673, 1.7470893, 1.7638612, 1.7694906, 1.7947787, 1.7907968, 1.7489899, 1.7819505, 1.7560167, 1.6648815, 1.6192138, 1.7766141, 1.7589314, 1.7434505, 1.644981, 1.6841172, 1.7234133, 1.6870579, 1.617149, 1.604015, 1.7153053, 1.5777708, 1.6996778, 1.5830842, 1.6373895, 1.6386807, 1.6198231, 1.5568463, 1.5686018, 1.5223916, 1.4492385, 1.4179425, 1.4109223, 1.4018179, 1.4479511, 1.4095597, 1.4837799, 1.4768001, 1.4264426, 1.5210241, 1.7408135, 1.7650422, 1.7474518, 1.7603103, 1.6818702, 1.6762122, 1.6575034, 1.5916096, 1.5214908, 1.5411053, 1.5638734, 1.5951952, 1.519327, 1.5175873, 1.6052985, 1.5067438, 1.6262276, 1.5635326, 1.5090733, 1.5859349, 1.4867114, 1.4102936, 1.3916284, 1.3834052, 1.3734908, 1.3797898, 1.4213884, 1.478116, 1.4449531, 1.4270717, 1.4063514, 1.3670614, 1.4042406, 1.3474599, 1.3948504, 1.3572742, 1.4551163, 1.43845, 1.428499, 1.4522954, 1.4010471, 1.3845979, 1.4000559, 1.3633549, 1.4398539, 1.3752627, 1.43069, 1.3802607, 1.3988798, 1.3804562, 1.3892171, 1.4131991, 1.4373577, 1.409653, 1.349, 1.3661172, 1.3309664, 1.3943357, 5.7154927, 2.1569734, 1.7437778, 1.7154473, 1.5785937, 1.4985594, 1.4519703, 1.3216434, 1.1239977, 1.0678568, 1.0320927, 0.7831516, 0.6868841, 0.7232311, 0.63086796, 0.5825474, 0.536956, 0.54428387, 0.3619415, 0.28039932, 0.4567445, 0.487098, 0.34372953, 0.45134962, 0.34072575, 0.25641146, 0.43941116, 0.28849554, 0.36180753, 0.35297796, 0.35820478, 0.16344777, 0.43198544, 0.2519095, 0.335027, 0.239541, 0.45451766, 0.26878214, 0.20053801, 0.19866055, 0.4496548, 0.18146667, 0.17924397, 0.48798573, 0.1754378, 0.20171699, 0.18665798, 0.17493887, 0.23802872, 0.29423276, 0.31689766, 0.16538328, 0.31442717, 0.22671336, 0.13025972, 0.22079854, 0.11239371, 0.16463926, 0.22712497, 0.53926384, 0.21379572, 0.12953454, 0.15539059, 0.20631409, 0.199712, 0.31470302, 0.1396297, 0.052758984, 0.3297161, 0.14323771, 0.01171961, 0.20509824, 0.10373695, 0.1087377, 0.22163777, 0.017409123, 0.25362656, 0.13398537, 0.07670936, 0.0056417114, 0.05786776, 0.5264505, 0.08431212, 0.06544067, 0.001966619, 0.086972594, 0.15570208, 0.0667239, 0.22581789, 0.029057903, 0.01157707, 0.2395026, 0.016327702, 0.00037294254, 0.6753586, 0.0260856, 0.0015403205, 0.00046481585, 0.00014650101, 0.15357368, 0.074837014, 0.050283417, 0.031787805, 0.24361934, 0.0039059394, 0.00039916753, 0.00017960949, 9.83847e-05, 4.4373064e-05, 0.9357059, 0.02165622, 0.089066446, 0.109716915, 0.0014182886, 0.047236566, 0.08278741, 0.07505543, 0.0102191605, 0.00014069135, 6.9335176e-05, 7.796329e-05, 7.4712036e-05, 4.6795452e-05, 0.42957604, 0.0008272764, 0.0015444952, 0.0042912923, 0.15412341, 0.028918004, 0.022272922, 0.00053100876, 0.08056001, 0.5675369, 0.018692859, 0.026341572, 0.124617055, 0.0037866104, 0.00026862876, 0.00012997571, 0.65249604, 0.003910054, 0.05238999, 0.0012840253, 0.059980497, 0.004072536, 0.016484572, 0.0002170882, 0.00012049452, 9.635952e-05, 0.0001477467, 2.886745e-05, 3.002494e-05, 1.702962e-05, 1.33924e-05, 8.909915e-06, 6.7225114e-06, 9.450652e-06, 0.73883945, 0.004254411, 0.0579604, 0.0015667133, 0.014024297, 0.2988266, 0.00087062013, 0.0019053295, 0.00019157579, 0.12851387, 0.015918214, 0.08158023, 0.3500692, 0.21873161, 0.0013005194, 0.050816793, 0.0010433896, 8.010246e-05, 7.268125e-05, 3.910323e-05, 0.46530938, 0.028597867, 0.022063024, 0.0056812246, 0.03910911, 0.00019468898, 0.0009270499, 8.297225e-05, 0.4561252, 0.013618795, 0.032038722, 0.0040892335, 0.00046587444, 0.14302179, 0.00058400334, 0.00012952564, 0.35780597, 0.11674293, 0.00050383626, 0.00025894848, 0.00013682993, 0.0001409199, 0.00018941125, 5.4294607e-05, 0.00010546511, 3.119936e-05, 1.817926e-05, 1.6088876e-05, 0.58226264, 0.030999422, 0.0014396501, 0.00015739423, 4.5304656e-05, 2.6218015e-05, 2.6608912e-05, 1.591299e-05, 0.3619745, 0.0027306317, 0.026607351, 0.00013599342, 0.00025178594, 4.2046177e-05, 0.41194266, 0.015458539, 0.0011980229, 0.111275285, 0.0003842768, 0.00024018767, 0.00074008823, 0.1359787, 0.0023167152, 0.20920421, 0.017535774, 9.4639974e-05, 0.021210954, 6.900291e-05, 6.721057e-05, 0.00023305745, 3.0380499e-05, 1.78347e-05, 1.37391835e-05, 1.1300717e-05, 9.025984e-06, 0.8090283, 0.0017674073, 0.00018336638, 0.03977405, 0.0042385226, 0.0009745992, 0.00016347246, 4.3127577e-05, 0.22357868, 0.0020279966, 0.19276057, 0.00041911952, 0.00195724, 0.021466298, 3.106175e-05, 0.00028856812, 1.4277965e-05, 2.3787206e-05, 1.0523616e-05, 6.4997557e-06, 0.6965808, 0.007728201, 0.05898092, 0.0017837224, 0.047486894, 0.001228287, 7.13378e-05, 4.824422e-05, 0.5725965, 0.06502484, 0.00017153272, 0.00019974343, 0.000120536715, 5.44105e-05, 0.20771001, 0.00022661503, 0.0002825499, 0.15184888, 0.0040974957, 0.016134214, 0.00010555472, 3.3287764e-05, 4.118283e-05, 2.190559e-05, 0.000216082, 0.7238677, 0.3709989, 0.0021691143, 0.019168524, 0.0011781001, 0.012024861, 0.018478202, 0.18072784, 0.00016593066, 0.0006108398, 3.2648117e-05, 1.279581e-05, 8.5815955e-06, 6.9661187e-06, 0.6056215, 0.011575529, 0.008543358, 0.009256612, 0.00680591, 0.0005336017, 4.894236e-05, 2.10701e-05, 0.2213049, 0.012223565, 0.51028454, 0.06996252, 5.5768658e-05, 7.116411e-06, 3.458016e-06, 3.911278e-06, 0.3664905, 3.8586055e-05, 0.0015509397, 0.06164481, 0.06892993, 0.0003177658, 1.9572366e-05, 0.03678424, 0.053127438, 0.3602635, 0.0033946529, 0.02310906, 0.08293463, 0.011324903, 8.799405e-05, 0.00027334923, 3.2030028e-05, 3.854949e-05, 1.8918776e-05, 1.4220844e-05, 2.8818116e-05, 8.623577e-06, 1.26006225e-05, 5.9697086e-06, 4.2871425e-06, 4.0266373e-06, 3.1413674e-06, 2.421643e-06, 0.66949224, 0.0006580275, 0.0010170087, 0.13163985, 0.008109202, 5.3999654e-05, 3.1460488e-05, 0.0009055975, 0.0001226937, 0.0023544964, 0.617096, 0.017466163, 1.4378648e-05, 0.030691506, 0.13767613, 0.014874432, 4.4380304e-05, 1.6749651e-05, 1.7834667e-05, 0.53355527, 0.099935636, 2.720647e-05, 0.0032741458, 1.0601751e-05, 0.117679715, 0.017345654, 0.00010350762, 0.00017551222, 1.2778928e-05, 2.830849e-05, 1.2829313e-05, 8.621836e-06, 5.58346e-06, 7.754357e-06, 4.124706e-06, 6.289971e-06, 6.3469106e-06, 3.745756e-06, 0.019445732, 0.7971234, 0.00071948284, 9.1098795e-05, 0.08852722, 2.0269697e-05, 0.026078684, 0.068606056, 0.16868693, 0.00020088725, 7.0970746e-06, 1.7159157e-06, 2.6047983e-05, 2.9270263e-06, 0.94248784, 0.032877885, 3.6909067e-05, 0.0016649676, 0.00025611685, 0.021204378, 4.0557625e-05, 4.502899e-05, 2.6330276e-06, 1.2183407e-06, 1.2625162e-06, 5.530849e-07, 4.738808e-07, 0.6144498, 0.012745491, 1.9981228e-05, 0.2423487, 6.804563e-05, 6.93231e-06, 3.4477123e-06, 0.00019264867, 0.0003791934, 0.37137488, 0.0017153462, 0.046489142, 4.8653296e-06, 1.1804543e-06, 6.799585e-06, 0.6401832, 0.0026423836, 7.9714606e-05, 0.06668709, 0.06616335, 0.004992647, 0.0002247808, 0.044515975, 0.0011595044, 1.0542187e-05, 5.6891995e-06, 3.3471279e-06, 1.9130082e-06, 2.1528685e-06, 1.2069005e-06, 1.1914942e-06, 1.1671129e-06, 7.1087693e-06, 1.2853321e-06, 5.7064625e-07, 7.030049e-07, 0.56374043, 0.046954863, 0.0013780666, 0.038157776, 1.0254741e-05, 0.00012522013, 1.26296e-05, 4.3981286e-06, 1.5902712e-06, 3.916173e-06, 1.1447435e-06, 3.1782145e-06, 2.692341e-06, 1.1950992e-06, 0.7739161, 0.02771365, 1.5484815e-05, 1.3278722e-05, 0.100755095, 0.01820369, 0.038845636, 1.3992876e-05, 0.38293663, 0.0045498773, 0.0013423592, 1.586791e-06, 0.0013950795, 2.9055425e-07, 2.7509996e-06, 6.3121206e-07, 2.0359978e-07, 1.4351559e-07, 5.29534e-07, 1.9387149e-07, 0.82402366, 0.0010738465, 0.065764666, 0.04366568, 0.10596679, 0.0047234343, 8.426271e-06, 0.0012371516, 5.815979e-06, 0.061612524, 3.4401137e-06, 6.2854547e-06, 1.1673758e-06, 9.134603e-07, 9.603477e-07, 9.13861e-07, 0.3268649, 0.07193962, 1.1280327e-05, 0.056708965, 0.010312185, 0.16358739, 2.2801545e-05
disc_train_acc: 0.002103960396039604, 0.2829207920792079, 0.22685643564356436, 0.24653465346534653, 0.23849009900990098, 0.16175742574257426, 0.14913366336633663, 0.15804455445544555, 0.12314356435643564, 0.15247524752475247, 0.20544554455445543, 0.1943069306930693, 0.2125, 0.19554455445544555, 0.1422029702970297, 0.13551980198019803, 0.13836633663366338, 0.1275990099009901, 0.1311881188118812, 0.1504950495049505, 0.14294554455445543, 0.17487623762376237, 0.22871287128712872, 0.22314356435643565, 0.24245049504950494, 0.235519801980198, 0.21794554455445544, 0.21435643564356435, 0.2295792079207921, 0.2396039603960396, 0.250990099009901, 0.201980198019802, 0.14826732673267326, 0.1400990099009901, 0.13626237623762377, 0.14492574257425742, 0.19381188118811882, 0.1948019801980198, 0.19146039603960396, 0.14579207920792078, 0.12141089108910891, 0.12413366336633663, 0.12524752475247525, 0.1245049504950495, 0.21027227722772276, 0.19071782178217822, 0.12883663366336634, 0.19653465346534654, 0.24455445544554455, 0.23155940594059407, 0.27772277227722775, 0.20445544554455444, 0.15284653465346534, 0.125, 0.13650990099009902, 0.2349009900990099, 0.26683168316831685, 0.2474009900990099, 0.25853960396039605, 0.1568069306930693, 0.13353960396039605, 0.14888613861386138, 0.15222772277227722, 0.12834158415841584, 0.12685643564356436, 0.1297029702970297, 0.12017326732673267, 0.15334158415841584, 0.2412128712871287, 0.25594059405940595, 0.24938118811881188, 0.2957920792079208, 0.22314356435643565, 0.24108910891089108, 0.21262376237623762, 0.24826732673267327, 0.15655940594059406, 0.12821782178217822, 0.1275990099009901, 0.13873762376237625, 0.14492574257425742, 0.13316831683168318, 0.13032178217821783, 0.1342821782178218, 0.12277227722772277, 0.12425742574257426, 0.1264851485148515, 0.125, 0.12945544554455446, 0.12685643564356436, 0.12871287128712872, 0.13131188118811882, 0.12623762376237624, 0.1342821782178218, 0.12797029702970297, 0.1297029702970297, 0.12153465346534653, 0.13465346534653466, 0.13366336633663367, 0.12846534653465347, 0.1292079207920792, 0.12141089108910891, 0.1271039603960396, 0.12883663366336634, 0.1290841584158416, 0.15655940594059406, 0.2316831683168317, 0.23193069306930694, 0.24084158415841583, 0.1650990099009901, 0.15346534653465346, 0.13836633663366338, 0.14665841584158415, 0.13452970297029704, 0.12314356435643564, 0.11794554455445544, 0.12586633663366337, 0.1349009900990099, 0.13551980198019803, 0.1219059405940594, 0.1275990099009901, 0.12252475247524752, 0.12165841584158416, 0.12351485148514851, 0.1280940594059406, 0.12363861386138614, 0.12747524752475248, 0.125990099009901, 0.1297029702970297, 0.12091584158415841, 0.12933168316831684, 0.13551980198019803, 0.12314356435643564, 0.12326732673267327, 0.12896039603960396, 0.11893564356435643, 0.12116336633663366, 0.12821782178217822, 0.14975247524752475, 0.27561881188118814, 0.23626237623762375, 0.23886138613861385, 0.22896039603960397, 0.27512376237623765, 0.3097772277227723, 0.31472772277227723, 0.2912128712871287, 0.299009900990099, 0.25655940594059407, 0.2727722772277228, 0.2131188118811881, 0.2918316831683168, 0.29257425742574256, 0.30185643564356435, 0.27363861386138616, 0.25742574257425743, 0.21633663366336633, 0.1889851485148515, 0.2030940594059406, 0.2321782178217822, 0.22995049504950496, 0.2459158415841584, 0.23688118811881187, 0.19071782178217822, 0.18688118811881188, 0.18725247524752475, 0.18935643564356436, 0.18935643564356436, 0.20804455445544554, 0.18712871287128713, 0.1806930693069307, 0.1860148514851485, 0.17809405940594059, 0.19975247524752476, 0.23688118811881187, 0.19517326732673268, 0.1870049504950495, 0.18056930693069306, 0.22883663366336635, 0.2620049504950495, 0.2662128712871287, 0.2801980198019802, 0.26212871287128714, 0.25742574257425743, 0.27202970297029705, 0.25544554455445545, 0.2332920792079208, 0.21806930693069307, 0.21472772277227722, 0.23230198019801981, 0.2680693069306931, 0.252970297029703, 0.2228960396039604, 0.2311881188118812, 0.22636138613861387, 0.2592821782178218, 0.20408415841584157, 0.16225247524752476, 0.15173267326732673, 0.1290841584158416, 0.13415841584158417, 0.12586633663366337, 0.12128712871287128, 0.1297029702970297, 0.1219059405940594, 0.12982673267326733, 0.13267326732673268, 0.12797029702970297, 0.12871287128712872, 0.12363861386138614, 0.23353960396039605, 0.2426980198019802, 0.2459158415841584, 0.24133663366336633, 0.23613861386138613, 0.24702970297029703, 0.22252475247524753, 0.20965346534653465, 0.1962871287128713, 0.19084158415841584, 0.19504950495049506, 0.2014851485148515, 0.19554455445544555, 0.18626237623762376, 0.2214108910891089, 0.23316831683168318, 0.2280940594059406, 0.23638613861386137, 0.2125, 0.2047029702970297, 0.15185643564356435, 0.13391089108910892, 0.12487623762376238, 0.12326732673267327, 0.12153465346534653, 0.1301980198019802, 0.12425742574257426, 0.12314356435643564, 0.12425742574257426, 0.12227722772277227, 0.13044554455445545, 0.15222772277227722, 0.18118811881188118, 0.1827970297029703, 0.1792079207920792, 0.14245049504950494, 0.139480198019802, 0.21448019801980198, 0.27933168316831686, 0.27821782178217824, 0.27413366336633666, 0.261509900990099, 0.27091584158415843, 0.2214108910891089, 0.1735148514851485, 0.18576732673267327, 0.22586633663366337, 0.2448019801980198, 0.23452970297029702, 0.2561881188118812, 0.26831683168316833, 0.27673267326732676, 0.2995049504950495, 0.32165841584158417, 0.31163366336633663, 0.3100247524752475, 0.3165841584158416, 0.3224009900990099, 0.29777227722772276, 0.33304455445544556, 0.30915841584158416, 0.275, 0.25185643564356436, 0.313490099009901, 0.28898514851485146, 0.27710396039603963, 0.263490099009901, 0.2556930693069307, 0.24715346534653465, 0.3481435643564356, 0.3157178217821782, 0.3378712871287129, 0.3409653465346535, 0.30086633663366336, 0.2962871287128713, 0.3110148514851485, 0.3209158415841584, 0.2957920792079208, 0.2952970297029703, 0.3012376237623762, 0.2887376237623762, 0.30866336633663366, 0.3507425742574257, 0.28465346534653463, 0.2535891089108911, 0.24752475247524752, 0.2608910891089109, 0.2573019801980198, 0.3069306930693069, 0.328960396039604, 0.3261138613861386, 0.3073019801980198, 0.2954207920792079, 0.3150990099009901, 0.3527227722772277, 0.3436881188118812, 0.25965346534653466, 0.2681930693069307, 0.2988861386138614, 0.3238861386138614, 0.31027227722772277, 0.18576732673267327, 0.1896039603960396, 0.20123762376237625, 0.19641089108910892, 0.2084158415841584, 0.1875, 0.18688118811881188, 0.19096534653465347, 0.18935643564356436, 0.18415841584158416, 0.1941831683168317, 0.19603960396039605, 0.19653465346534654, 0.18638613861386139, 0.1860148514851485, 0.19034653465346535, 0.1879950495049505, 0.18452970297029703, 0.18787128712871287, 0.19752475247524753, 0.18663366336633663, 0.18923267326732673, 0.18923267326732673, 0.18712871287128713, 0.18886138613861386, 0.18366336633663366, 0.18948019801980198, 0.18465346534653465, 0.18663366336633663, 0.19393564356435644, 0.1860148514851485, 0.2162128712871287, 0.18712871287128713, 0.19022277227722773, 0.1922029702970297, 0.2004950495049505, 0.19146039603960396, 0.22227722772277228, 0.2830445544554455, 0.28836633663366334, 0.31027227722772277, 0.2146039603960396, 0.2422029702970297, 0.22524752475247525, 0.24554455445544554, 0.2660891089108911, 0.2478960396039604, 0.25866336633663367, 0.25705445544554456, 0.26262376237623763, 0.2830445544554455, 0.282549504950495, 0.3491336633663366, 0.32215346534653466, 0.33824257425742577, 0.33502475247524754, 0.2975247524752475, 0.30383663366336633, 0.32116336633663367, 0.33044554455445546, 0.33564356435643566, 0.3235148514851485, 0.32784653465346536, 0.2954207920792079, 0.29455445544554454, 0.26534653465346536, 0.3341584158415842, 0.3160891089108911, 0.33242574257425744, 0.2584158415841584, 0.2733910891089109, 0.2775990099009901, 0.31893564356435644, 0.27722772277227725, 0.25804455445544555, 0.28935643564356434, 0.28329207920792077, 0.24133663366336633, 0.2641089108910891, 0.2962871287128713, 0.23094059405940595, 0.2129950495049505, 0.2592821782178218, 0.2928217821782178, 0.2745049504950495, 0.23081683168316833, 0.1948019801980198, 0.1875, 0.26212871287128714, 0.23948019801980197, 0.3149752475247525, 0.296039603960396, 0.2745049504950495, 0.2680693069306931, 0.24047029702970296, 0.25383663366336634, 0.22623762376237624, 0.23316831683168318, 0.25173267326732673, 0.23737623762376237, 0.2375, 0.29294554455445543, 0.31274752475247525, 0.21584158415841584, 0.263490099009901, 0.22995049504950496, 0.29554455445544553, 0.29777227722772276, 0.2469059405940594, 0.26014851485148516, 0.30396039603960395, 0.32363861386138615, 0.2670792079207921, 0.32301980198019803, 0.2801980198019802, 0.3074257425742574, 0.30705445544554455, 0.2908415841584158, 0.3089108910891089, 0.31163366336633663, 0.33353960396039606, 0.3264851485148515, 0.3025990099009901, 0.2849009900990099, 0.31844059405940595, 0.30643564356435643, 0.3022277227722772, 0.3301980198019802, 0.29146039603960394, 0.2886138613861386, 0.3014851485148515, 0.296039603960396, 0.24678217821782178, 0.2448019801980198, 0.2407178217821782, 0.22004950495049505, 0.27660891089108913, 0.2784653465346535, 0.27363861386138616, 0.30816831683168316, 0.3175742574257426, 0.3264851485148515, 0.30247524752475247, 0.3061881188118812, 0.3198019801980198, 0.32821782178217823, 0.3032178217821782, 0.32215346534653466, 0.29158415841584157, 0.30334158415841583, 0.3131188118811881, 0.28539603960396037, 0.31943069306930694, 0.31014851485148515, 0.3136138613861386, 0.3172029702970297, 0.3175742574257426, 0.3186881188118812, 0.3073019801980198, 0.30024752475247524, 0.3108910891089109, 0.31076732673267327, 0.33564356435643566, 0.3284653465346535, 0.3318069306930693, 0.341460396039604, 0.3214108910891089, 0.3551980198019802, 0.33353960396039606, 0.3349009900990099, 0.3110148514851485, 0.3047029702970297, 0.33452970297029705, 0.3295792079207921, 0.3149752475247525, 0.3315594059405941, 0.3181930693069307, 0.35148514851485146, 0.3120049504950495, 0.35457920792079206, 0.35247524752475246, 0.34888613861386136, 0.3327970297029703, 0.3120049504950495, 0.3113861386138614, 0.33663366336633666, 0.33762376237623765, 0.3459158415841584, 0.34628712871287126, 0.341460396039604, 0.0023514851485148514, 0.2243811881188119, 0.24975247524752475, 0.26064356435643565, 0.2952970297029703, 0.3349009900990099, 0.36076732673267325, 0.4064356435643564, 0.49764851485148515, 0.5214108910891089, 0.5488861386138614, 0.6452970297029703, 0.6981435643564357, 0.6922029702970297, 0.7363861386138614, 0.7566831683168317, 0.7663366336633664, 0.781559405940594, 0.8481435643564357, 0.8772277227722772, 0.813490099009901, 0.8021039603960396, 0.8587871287128713, 0.8356435643564356, 0.8521039603960396, 0.8914603960396039, 0.825, 0.8834158415841584, 0.8525990099009901, 0.8543316831683169, 0.861509900990099, 0.9235148514851486, 0.8400990099009901, 0.8966584158415841, 0.8659653465346535, 0.8949257425742574, 0.8352722772277228, 0.8923267326732673, 0.9122524752475247, 0.9103960396039604, 0.847029702970297, 0.9236386138613861, 0.9185643564356436, 0.8295792079207921, 0.9207920792079208, 0.9224009900990099, 0.9288366336633663, 0.9272277227722773, 0.9071782178217822, 0.8952970297029703, 0.8910891089108911, 0.9297029702970298, 0.8997524752475248, 0.9206683168316832, 0.9516089108910891, 0.9247524752475248, 0.9533415841584159, 0.9474009900990099, 0.9186881188118812, 0.8511138613861386, 0.925990099009901, 0.9443069306930693, 0.9465346534653465, 0.9251237623762376, 0.9285891089108911, 0.9148514851485149, 0.9532178217821782, 0.9834158415841584, 0.9178217821782179, 0.9580445544554456, 0.9969059405940595, 0.932920792079208, 0.9701732673267327, 0.965470297029703, 0.9405940594059405, 0.9957920792079208, 0.9292079207920793, 0.9612623762376238, 0.9764851485148515, 0.999009900990099, 0.986509900990099, 0.9099009900990099, 0.9842821782178218, 0.9805693069306931, 0.9998762376237624, 0.9775990099009901, 0.9597772277227723, 0.9790841584158416, 0.9429455445544555, 0.9908415841584158, 0.9975247524752475, 0.9441831683168317, 0.9943069306930693, 1.0, 0.8831683168316832, 0.9913366336633663, 0.9997524752475248, 1.0, 1.0, 0.9584158415841584, 0.976980198019802, 0.9832920792079208, 0.9903465346534653, 0.9412128712871287, 0.9992574257425743, 1.0, 1.0, 1.0, 1.0, 0.884529702970297, 0.994430693069307, 0.9753712871287129, 0.9719059405940594, 1.0, 0.9850247524752476, 0.975, 0.9783415841584159, 0.99740099009901, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9280940594059406, 1.0, 0.9997524752475248, 0.999009900990099, 0.9672029702970297, 0.9897277227722773, 0.9928217821782178, 1.0, 0.9868811881188119, 0.9352722772277228, 0.9951732673267327, 0.9919554455445545, 0.9733910891089109, 0.9992574257425743, 1.0, 1.0, 0.9082920792079208, 0.9993811881188119, 0.9866336633663366, 0.9998762376237624, 0.9858910891089109, 0.9995049504950495, 0.9949257425742575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9066831683168317, 0.9985148514851485, 0.9883663366336634, 0.9997524752475248, 0.9971534653465347, 0.9465346534653465, 1.0, 0.9992574257425743, 1.0, 0.9719059405940594, 0.9962871287128713, 0.9852722772277228, 0.9534653465346534, 0.9702970297029703, 0.9997524752475248, 0.9883663366336634, 0.9997524752475248, 1.0, 1.0, 1.0, 0.9202970297029703, 0.9939356435643565, 0.9952970297029703, 0.998391089108911, 0.9903465346534653, 1.0, 0.9996287128712872, 1.0, 0.9379950495049505, 0.9961633663366337, 0.9920792079207921, 0.999009900990099, 1.0, 0.9702970297029703, 1.0, 1.0, 0.9542079207920792, 0.9767326732673267, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9305693069306931, 0.9945544554455445, 0.9991336633663367, 1.0, 1.0, 1.0, 1.0, 1.0, 0.942079207920792, 0.9993811881188119, 0.9951732673267327, 1.0, 1.0, 1.0, 0.9587871287128713, 0.9957920792079208, 0.9997524752475248, 0.9814356435643564, 1.0, 1.0, 0.9997524752475248, 0.9698019801980198, 0.9993811881188119, 0.9660891089108911, 0.9966584158415842, 1.0, 0.9956683168316832, 1.0, 1.0, 0.9998762376237624, 1.0, 1.0, 1.0, 1.0, 1.0, 0.936509900990099, 0.9996287128712872, 1.0, 0.9917079207920793, 0.9985148514851485, 0.9997524752475248, 1.0, 1.0, 0.9653465346534653, 0.9995049504950495, 0.9693069306930693, 0.9997524752475248, 0.9995049504950495, 0.9948019801980198, 1.0, 0.9998762376237624, 1.0, 1.0, 1.0, 1.0, 0.9321782178217822, 0.999009900990099, 0.9849009900990099, 0.9996287128712872, 0.9899752475247525, 0.9996287128712872, 1.0, 1.0, 0.948019801980198, 0.9893564356435643, 0.9998762376237624, 0.9998762376237624, 1.0, 1.0, 0.9705445544554455, 1.0, 1.0, 0.9732673267326732, 0.9988861386138614, 0.9959158415841585, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9539603960396039, 0.9597772277227723, 0.9992574257425743, 0.9956683168316832, 0.9996287128712872, 0.9969059405940595, 0.9969059405940595, 0.972029702970297, 1.0, 0.9997524752475248, 1.0, 1.0, 1.0, 1.0, 0.9426980198019802, 0.996410891089109, 0.9985148514851485, 0.998391089108911, 0.9985148514851485, 1.0, 1.0, 1.0, 0.9611386138613861, 0.9971534653465347, 0.9548267326732673, 0.9896039603960396, 1.0, 1.0, 1.0, 1.0, 0.9657178217821782, 1.0, 0.9996287128712872, 0.988490099009901, 0.9879950495049505, 0.9998762376237624, 1.0, 0.9956683168316832, 0.9909653465346535, 0.9705445544554455, 0.9992574257425743, 0.9961633663366337, 0.986509900990099, 0.9982673267326733, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9507425742574257, 0.9998762376237624, 0.9997524752475248, 0.9821782178217822, 0.998391089108911, 1.0, 1.0, 0.9996287128712872, 1.0, 0.9993811881188119, 0.9485148514851485, 0.9962871287128713, 1.0, 0.9976485148514852, 0.989480198019802, 0.9972772277227723, 1.0, 1.0, 1.0, 0.9601485148514851, 0.9853960396039604, 1.0, 0.9992574257425743, 1.0, 0.9881188118811881, 0.9967821782178218, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9981435643564357, 0.9476485148514852, 0.9997524752475248, 1.0, 0.990470297029703, 1.0, 0.9976485148514852, 0.9939356435643565, 0.9860148514851486, 0.9998762376237624, 1.0, 1.0, 1.0, 1.0, 0.9415841584158415, 0.9962871287128713, 1.0, 0.9997524752475248, 1.0, 0.9982673267326733, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9663366336633663, 0.9992574257425743, 1.0, 0.9780940594059406, 1.0, 1.0, 1.0, 0.9998762376237624, 0.9997524752475248, 0.971039603960396, 0.9996287128712872, 0.9959158415841585, 1.0, 1.0, 1.0, 0.9642326732673268, 0.9991336633663367, 1.0, 0.9879950495049505, 0.9917079207920793, 0.999009900990099, 1.0, 0.995420792079208, 0.9996287128712872, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9636138613861386, 0.994430693069307, 0.9992574257425743, 0.997029702970297, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9669554455445545, 0.9972772277227723, 1.0, 1.0, 0.9919554455445545, 0.9978960396039604, 0.9966584158415842, 1.0, 0.9701732673267327, 0.999009900990099, 0.9993811881188119, 1.0, 0.9997524752475248, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9586633663366336, 0.9998762376237624, 0.9935643564356436, 0.9952970297029703, 0.9908415841584158, 0.9998762376237624, 1.0, 0.9997524752475248, 1.0, 0.9902227722772278, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.977970297029703, 0.990470297029703, 1.0, 0.9959158415841585, 0.9982673267326733, 0.9834158415841584, 1.0
gen_val_loss: -5.5387955, -1.8456204, -2.2531445, -1.9039419, -2.2546418, -2.1324432, -2.1419933, -2.1022446, -2.1365902, -2.4493008, -1.9383608, -2.2011626, -2.317465, -2.1447294, -2.124371, -2.1105452, -2.2123837, -2.1280057, -2.1010349, -2.5000684, -1.9985459, -2.0665965, -1.85668, -2.033308, -2.2767012, -2.131386, -2.1155474, -2.1419997, -1.9412495, -1.8594198, -1.7953107, -1.9452198, -2.1220741, -2.118636, -2.1991365, -2.6186962, -1.8281316, -2.207206, -2.1840668, -2.1096165, -2.1425474, -2.122908, -2.1282413, -2.1434166, -2.1285632, -2.111273, -2.1092658, -1.9337374, -1.8378156, -1.996102, -1.7916478, -2.0894113, -2.1173995, -2.1208549, -2.4382377, -1.6979438, -1.9877533, -2.0000384, -2.245339, -2.211377, -2.1924863, -2.1585376, -2.1373634, -2.1031454, -2.0902123, -2.1557422, -2.184194, -2.0658839, -1.9272935, -1.8387926, -2.0529823, -1.7873132, -1.7943645, -2.2036996, -2.0995154, -2.129629, -2.2205086, -2.2870219, -2.3020864, -2.2617126, -2.3141112, -2.2254517, -2.1844575, -2.2660809, -2.237853, -2.2368073, -2.2849963, -2.271974, -2.3635476, -2.2535505, -2.2950304, -2.2676787, -2.2180696, -2.252806, -2.2638528, -2.2519412, -2.2709422, -2.2609618, -2.2859979, -2.2296774, -2.2631233, -2.2495835, -2.2190256, -2.2573614, -2.2957544, -2.0131488, -1.9533912, -1.8333818, -2.1223276, -1.8192651, -2.1327229, -2.256093, -2.2019548, -2.1039774, -2.100022, -2.1421678, -2.1073902, -2.0552983, -2.1528559, -2.1283996, -2.1332595, -2.1489205, -2.0987024, -2.1140654, -2.1076806, -2.0949535, -2.1690097, -2.0906255, -2.102058, -2.1475542, -2.1406562, -2.240926, -2.1559935, -2.0976365, -2.114877, -2.15567, -2.1686625, -2.1094947, -1.9515847, -1.6301502, -1.6820496, -1.8137329, -1.8755562, -1.5853956, -1.6703023, -1.4774214, -1.6000248, -1.7694088, -1.9760422, -1.4919628, -1.6884587, -1.7531519, -1.5217212, -1.3883313, -1.4500105, -1.5865953, -1.9340388, -1.8535311, -1.8316596, -1.8139157, -1.7855022, -1.8983731, -1.7973698, -1.8380128, -1.8021375, -1.785052, -1.833322, -1.7920169, -1.7733921, -1.8279445, -1.7800528, -1.7975553, -1.8206965, -1.7807901, -2.023608, -1.766512, -1.877569, -1.7946762, -1.8913925, -1.9648174, -1.7946131, -1.7633244, -1.7281188, -2.0587308, -2.1995726, -2.096671, -2.0138526, -2.28165, -1.871936, -1.8536814, -2.060189, -2.178283, -2.0365481, -1.9856907, -2.1306987, -2.076415, -2.0427842, -2.0840156, -2.1238618, -2.1250696, -2.1005795, -2.133733, -2.128595, -2.126978, -2.1236389, -2.1775217, -2.2583776, -2.1284506, -2.1308215, -2.143695, -1.8849286, -1.8764426, -1.9163841, -2.065509, -2.0637946, -2.0776896, -3.4099247, -1.9652139, -2.025233, -2.3438218, -2.3998039, -2.1527693, -2.5406442, -2.0223625, -2.3176851, -1.9964082, -2.1419625, -1.8581315, -2.233475, -2.1459584, -2.1514237, -2.1553354, -2.125396, -2.1269958, -2.1102512, -2.1282527, -2.1104074, -2.1186075, -2.1167047, -2.175357, -2.1699963, -2.166929, -2.0965931, -2.3395352, -2.1700535, -2.241927, -1.9266816, -1.70943, -1.6862444, -1.5710672, -1.5758712, -1.6887977, -1.4859324, -2.0322936, -1.9197538, -1.896421, -1.9061828, -1.9265567, -1.9104061, -1.6825126, -1.5933774, -1.8448362, -1.8391188, -1.722304, -1.4807662, -1.5807453, -1.3781668, -1.9490826, -1.4095782, -1.7068851, -1.4202745, -1.5335965, -1.4546381, -1.6022217, -1.5707039, -1.5426493, -1.3813447, -1.4213191, -1.4337889, -1.8233947, -1.6284349, -1.49121, -1.6117817, -1.5869839, -1.8483435, -1.9282702, -1.624495, -1.6054065, -1.5576446, -1.646585, -1.5882409, -1.7808518, -1.4577211, -1.7502524, -1.6407405, -1.5257311, -1.6015278, -1.5720168, -1.6872534, -1.6756644, -1.6119806, -1.5601517, -1.547819, -1.581002, -1.5497441, -2.0175524, -1.7248677, -1.5675405, -1.5691725, -1.9467824, -1.845994, -1.76581, -1.769411, -1.816697, -1.830165, -1.8565224, -1.7850956, -1.7815894, -1.8844332, -1.845371, -1.8099828, -1.7554667, -1.8379554, -1.8190523, -1.7452756, -1.7594533, -1.816929, -1.8742013, -1.9837003, -1.7490876, -1.8473687, -1.8507895, -1.9477854, -1.8283014, -1.8587447, -1.7834455, -1.865225, -1.8212078, -1.7857609, -1.8034204, -1.803171, -1.7794788, -1.8027656, -1.8641187, -1.7979746, -1.8519396, -1.7649264, -1.8126086, -1.8373939, -1.6691266, -1.5985495, -1.7931461, -1.7217572, -1.7731323, -1.7115408, -1.7484034, -1.755933, -1.7028488, -1.8498838, -1.6160191, -1.5348759, -1.7289352, -1.5051526, -1.5717114, -1.542636, -1.5328672, -2.0003998, -1.713064, -1.6320301, -1.6470928, -1.508557, -1.6714324, -1.7830625, -1.8416624, -1.7254989, -1.6776278, -1.8061274, -1.7092267, -1.6939033, -2.1702325, -1.6541001, -1.8207316, -1.6878619, -1.6746336, -2.0461705, -1.7476215, -1.821947, -1.582801, -1.7346413, -1.677903, -1.9211535, -1.8250456, -1.855937, -1.8587565, -1.7649134, -1.9340273, -1.9470724, -1.9980795, -1.8267497, -2.0304198, -2.1271298, -1.7130185, -1.631518, -1.9751865, -1.7343614, -1.7551059, -1.7916126, -1.8008953, -1.794658, -1.9025865, -2.0404456, -1.7067276, -1.5019176, -1.9253782, -1.6677314, -1.7464529, -1.4814823, -1.9846553, -1.9417074, -1.7400719, -1.4406585, -1.3777405, -1.425053, -1.6501675, -1.5921308, -1.8269202, -1.3740356, -1.5425041, -1.6505347, -1.7842146, -1.5516757, -1.2865908, -1.3604425, -1.2854816, -1.151045, -1.5032837, -1.2927078, -1.4339513, -1.5862098, -1.3537121, -1.4339085, -1.3169299, -1.6905047, -1.7273179, -1.7694694, -1.9481248, -1.9887155, -2.1723757, -1.6027304, -1.9887608, -1.5836912, -1.2792583, -1.4313624, -1.46116, -1.6125568, -1.6053226, -1.4627213, -1.3643295, -1.6721137, -1.6756501, -1.6445295, -1.9384128, -1.5398897, -1.2896514, -1.4318805, -1.3574326, -1.3111805, -1.543542, -1.4493494, -1.480579, -1.3217386, -1.378052, -1.3499763, -1.346961, -1.5217947, -1.2970505, -1.2363123, -1.2562495, -1.2804116, -1.2583641, -1.3867713, -1.4288183, -1.267465, -1.303739, -1.2798673, -1.526867, -1.2107121, -1.3528858, -1.4697922, -1.2289392, -1.5696632, -1.3777668, -1.2181654, -1.4198205, -1.3141847, -1.445682, -1.4271299, -1.4353839, -1.097942, -1.2605577, -1.7660481, -5.701759, -1.7179042, -1.6084311, -1.5431874, -1.4304436, -1.5423734, -1.4557594, -1.3074996, -1.0741827, -1.0217333, -0.75660163, -0.7347325, -0.671023, -0.54441583, -0.63902503, -0.5046317, -0.9287793, -0.27608505, -0.26879337, -0.26873246, -0.3471503, -0.39858857, -0.2670414, -0.8163431, -0.2829779, -0.5206138, -0.25647113, -0.4201277, -0.3613172, -0.20703767, -0.19506545, -0.11368534, -0.20995358, -0.16218324, -0.30539984, -0.15425694, -0.15606803, -0.1449, -0.20450486, -0.121026225, -0.3342289, -0.14165896, -0.1351345, -0.23850659, -0.15630002, -0.24870183, -0.2126224, -0.4028581, -0.15662447, -0.27803424, -0.1284227, -0.11190555, -1.1728419, -0.06898111, -0.31999022, -0.12304763, -0.24438377, -0.07163566, -0.36310628, -0.21154298, -0.25815174, -0.08855412, -0.11352852, -0.18067837, -0.11777721, -0.2532354, -0.13553973, -0.004112084, -0.14792995, -0.16200107, -0.001388964, -0.03374321, -0.1601914, -0.12348393, -0.06671694, -0.0023373037, -0.48907405, -0.028425027, -0.0012785045, -0.0003552587, -0.03070236, -0.006645516, -0.61438334, -0.00082295213, -0.00093148695, -0.0011759432, -0.087300815, -0.0068451497, -0.07877863, -0.0005080385, -0.00034865376, -0.15698756, -0.0068738344, -0.00019798856, -0.03134578, -0.012030008, -0.001160253, -0.00020644152, -0.00013066133, -0.19219655, -0.013912729, -0.0013653695, -0.079524964, -0.0019195979, -0.0031998283, -0.00015836101, -0.00010051481, -5.374305e-05, -4.0541378e-05, -0.0074947802, -0.15963364, -0.32223117, -0.0039024751, -0.0012376178, -0.002728586, -0.011354353, -0.0031902427, -0.00022349371, -0.00013262458, -0.00011043617, -0.00010033318, -5.9202997e-05, -0.00014048908, -0.0055853804, -0.0014439346, -0.00041097435, -0.009965055, -0.08953033, -0.00080230256, -0.0013522333, -0.00040436594, -0.9086868, -0.019967923, -0.054923527, -0.00029074398, -0.024941955, -0.00057179225, -0.00025948178, -9.744702e-05, -0.015863312, -0.0006623151, -0.0033430215, -0.00057294866, -0.0009984944, -0.09366921, -0.00060380355, -0.00023132774, -9.767005e-05, -0.0021052016, -3.956711e-05, -4.2242784e-05, -2.2016753e-05, -1.39579715e-05, -1.1007807e-05, -1.206525e-05, -5.8962883e-06, -0.002120849, -0.003037725, -0.0059131267, -0.0016643236, -0.0005601448, -0.21148321, -0.00056131015, -0.014773097, -0.00023239697, -0.00020934675, -0.61151004, -0.00022204763, -0.010738928, -1.2293724, -0.009876715, -0.00010280277, -0.004067129, -8.285673e-05, -6.766847e-05, -5.6256533e-05, -3.8525377e-05, -1.5433325, -0.0110927895, -0.002762462, -0.00014197303, -0.00032958752, -0.000119125856, -0.0001104176, -0.00018145546, -0.20134085, -0.0005524405, -0.0056831343, -0.0007274572, -0.00019400279, -0.0029966147, -0.0019822493, -0.00010147521, -1.8942305, -0.0005988174, -0.0003546501, -0.0010226828, -0.00011664053, -0.000322439, -9.445811e-05, -4.452076e-05, -3.9908708e-05, -2.6101558e-05, -2.0615194e-05, -2.0142015e-05, -0.020081758, -0.0068282234, -5.1929776e-05, -3.071731e-05, -2.4544197e-05, -2.4145835e-05, -2.1104908e-05, -1.9966401e-05, -0.016812243, -0.0165481, -0.003169595, -7.536028e-05, -0.0011277946, -4.8255726e-05, -0.4962753, -0.0043379357, -0.0049631773, -0.00063388096, -0.0002355037, -0.00038374943, -7.397197e-05, -0.0021203603, -0.0004291274, -0.028164918, -0.00029256594, -5.4923046e-05, -0.00028450598, -3.63244e-05, -3.053101e-05, -0.000116555006, -2.0013265e-05, -1.7892798e-05, -0.00012372379, -1.2355337e-05, -1.069789e-05, -0.0013912839, -0.000300607, -0.0010289869, -0.015330189, -0.00027760863, -0.00012775711, -4.6529363e-05, -4.790914e-05, -0.0026139559, -0.00015635394, -0.0057524773, -3.4803204e-05, -0.002463027, -3.914506e-05, -2.4160547e-05, -1.2732278e-05, -8.8449315e-06, -0.00016150885, -7.897052e-06, -5.615193e-06, -0.054105252, -0.07141974, -0.0007402807, -0.00025268772, -0.0002881627, -0.00024843658, -0.0007046847, -6.5462926e-05, -0.14608876, -9.61927e-05, -0.0013343687, -2.4990795e-05, -0.0011042731, -0.007495714, -0.00018043358, -0.00017516737, -0.00046222893, -0.0055793985, -0.00047642947, -0.00019029345, -3.666213e-05, -3.3610064e-05, -1.986889e-05, -6.3933985e-05, -1.847443e-05, -0.51237375, -0.008908973, -0.011226033, -0.00020665396, -0.014738741, -0.034094315, -0.034572437, -2.2823668e-05, -3.308767e-05, -4.0709398e-05, -1.5142801e-05, -9.594172e-06, -7.4275886e-06, -5.133254e-06, -0.003685827, -0.022376588, -0.00013316795, -9.261268e-05, -0.001113937, -3.3739478e-05, -0.00043848628, -5.4673947e-05, -0.5161377, -0.00018642111, -0.27301252, -7.6037526e-05, -1.928296e-06, -1.9750862e-06, -1.0476608e-06, -8.149911e-07, -3.45554e-05, -9.273801e-06, -1.9514338e-05, -0.054086756, -0.00087459804, -1.700131e-05, -9.949518e-06, -0.00036440277, -0.042014442, -0.0004612777, -0.00027415156, -1.9324754e-05, -0.048268154, -0.00012123597, -6.3354615e-05, -6.277999e-05, -8.430452e-05, -4.793357e-05, -1.8144214e-05, -1.0371089e-05, -1.0407104e-05, -6.353283e-06, -6.250736e-06, -1.0549455e-05, -4.0221275e-06, -3.6057083e-06, -3.032646e-06, -3.772383e-06, -0.00083015295, -0.02881266, -2.7649417e-05, -0.018025635, -5.9262777e-05, -4.7537298e-05, -4.0634346e-05, -6.703705e-05, -1.9826097e-05, -0.006912881, -0.042405546, -5.5304678e-05, -1.2835783e-06, -9.3509625e-06, -0.0015078286, -8.254465e-05, -0.00016185183, -0.0036415, -5.8001417e-05, -1.4285682, -1.2850467e-05, -7.0954807e-06, -0.0016177278, -0.00059532915, -0.12726732, -8.030491e-05, -5.296655e-05, -2.0933465e-05, -3.6247435e-05, -7.903415e-05, -7.4624295e-06, -4.3525374e-06, -2.9309316e-05, -2.7550068e-06, -4.5126735e-06, -2.1918304e-06, -2.436639e-06, -2.7394335e-06, -3.302268, -2.3123219e-05, -0.0038876315, -0.000107054424, -0.017491253, -1.0925155e-05, -1.3246732e-05, -3.6209826, -0.00833263, -5.169781e-06, -6.2186296e-06, -2.4846809e-06, -1.7502443e-06, -2.262581e-06, -0.06916619, -0.00935943, -6.330417e-05, -0.00021081825, -2.1007127e-06, -0.009099054, -5.6417025e-07, -3.5907951e-06, -4.956687e-07, -2.3066518e-06, -5.3538943e-06, -3.689664e-07, -1.3430115e-06, -0.0036684244, -0.0038347023, -6.0301925e-05, -6.2317026e-06, -1.3801771e-05, -2.7310327e-06, -3.921034e-05, -4.84272e-06, -0.00019404189, -0.0012410843, -1.9139484e-06, -0.003221201, -7.9958394e-05, -9.693009e-06, -3.2583208e-05, -0.0003939914, -0.001959819, -9.3271265e-05, -1.0245599, -0.0003233718, -3.8999973e-05, -0.023542061, -2.3201168e-05, -1.4025727e-05, -0.0001375934, -7.168141e-06, -5.8827904e-06, -1.5389865e-06, -2.1443168e-06, -2.3838272e-06, -9.420749e-07, -1.1350454e-06, -1.0192455e-06, -3.5271705e-07, -6.8395417e-07, -0.028394867, -0.012913471, -0.078922264, -0.009037091, -4.5142468e-05, -6.5616414e-06, -0.00011160779, -5.6746176e-06, -2.6547958e-05, -7.5183493e-07, -9.912089e-07, -8.411669e-07, -1.5530408e-06, -1.4655571e-06, -0.00016218935, -0.3533933, -1.4705753e-07, -3.2312954e-07, -2.0032589e-05, -0.9495611, -0.017207103, -5.87152e-06, -2.399122e-06, -0.022494791, -4.0666422e-05, -0.0018169209, -0.0012956826, -7.7886784e-07, -5.1180984e-07, -9.999107e-08, -3.2389042e-07, -4.8014762e-08, -1.0933309e-07, -1.8773785e-07, -2.7714427e-07, -0.023638234, -4.272711e-07, -0.025936065, -4.256673e-05, -0.0013633202, -2.3624207e-05, -2.881882e-06, -5.4714046e-06, -0.0018152329, -4.5213837e-06, -1.8878031e-06, -1.5738306e-06, -1.6732021e-06, -1.5083879e-06, -1.0626983e-06, -1.3481957e-06, -0.11289797, -0.0003375392, -2.0374623e-06, -1.8211892e-06, -0.00028615154, -4.625392e-05, -9.124822e-06
disc_val_loss: 5.5387955, 1.8456204, 2.2531445, 1.9039419, 2.2546418, 2.1324432, 2.1419933, 2.1022446, 2.1365902, 2.4493008, 1.9383608, 2.2011626, 2.317465, 2.1447294, 2.124371, 2.1105452, 2.2123837, 2.1280057, 2.1010349, 2.5000684, 1.9985459, 2.0665965, 1.85668, 2.033308, 2.2767012, 2.131386, 2.1155474, 2.1419997, 1.9412495, 1.8594198, 1.7953107, 1.9452198, 2.1220741, 2.118636, 2.1991365, 2.6186962, 1.8281316, 2.207206, 2.1840668, 2.1096165, 2.1425474, 2.122908, 2.1282413, 2.1434166, 2.1285632, 2.111273, 2.1092658, 1.9337374, 1.8378156, 1.996102, 1.7916478, 2.0894113, 2.1173995, 2.1208549, 2.4382377, 1.6979438, 1.9877533, 2.0000384, 2.245339, 2.211377, 2.1924863, 2.1585376, 2.1373634, 2.1031454, 2.0902123, 2.1557422, 2.184194, 2.0658839, 1.9272935, 1.8387926, 2.0529823, 1.7873132, 1.7943645, 2.2036996, 2.0995154, 2.129629, 2.2205086, 2.2870219, 2.3020864, 2.2617126, 2.3141112, 2.2254517, 2.1844575, 2.2660809, 2.237853, 2.2368073, 2.2849963, 2.271974, 2.3635476, 2.2535505, 2.2950304, 2.2676787, 2.2180696, 2.252806, 2.2638528, 2.2519412, 2.2709422, 2.2609618, 2.2859979, 2.2296774, 2.2631233, 2.2495835, 2.2190256, 2.2573614, 2.2957544, 2.0131488, 1.9533912, 1.8333818, 2.1223276, 1.8192651, 2.1327229, 2.256093, 2.2019548, 2.1039774, 2.100022, 2.1421678, 2.1073902, 2.0552983, 2.1528559, 2.1283996, 2.1332595, 2.1489205, 2.0987024, 2.1140654, 2.1076806, 2.0949535, 2.1690097, 2.0906255, 2.102058, 2.1475542, 2.1406562, 2.240926, 2.1559935, 2.0976365, 2.114877, 2.15567, 2.1686625, 2.1094947, 1.9515847, 1.6301502, 1.6820496, 1.8137329, 1.8755562, 1.5853956, 1.6703023, 1.4774214, 1.6000248, 1.7694088, 1.9760422, 1.4919628, 1.6884587, 1.7531519, 1.5217212, 1.3883313, 1.4500105, 1.5865953, 1.9340388, 1.8535311, 1.8316596, 1.8139157, 1.7855022, 1.8983731, 1.7973698, 1.8380128, 1.8021375, 1.785052, 1.833322, 1.7920169, 1.7733921, 1.8279445, 1.7800528, 1.7975553, 1.8206965, 1.7807901, 2.023608, 1.766512, 1.877569, 1.7946762, 1.8913925, 1.9648174, 1.7946131, 1.7633244, 1.7281188, 2.0587308, 2.1995726, 2.096671, 2.0138526, 2.28165, 1.871936, 1.8536814, 2.060189, 2.178283, 2.0365481, 1.9856907, 2.1306987, 2.076415, 2.0427842, 2.0840156, 2.1238618, 2.1250696, 2.1005795, 2.133733, 2.128595, 2.126978, 2.1236389, 2.1775217, 2.2583776, 2.1284506, 2.1308215, 2.143695, 1.8849286, 1.8764426, 1.9163841, 2.065509, 2.0637946, 2.0776896, 3.4099247, 1.9652139, 2.025233, 2.3438218, 2.3998039, 2.1527693, 2.5406442, 2.0223625, 2.3176851, 1.9964082, 2.1419625, 1.8581315, 2.233475, 2.1459584, 2.1514237, 2.1553354, 2.125396, 2.1269958, 2.1102512, 2.1282527, 2.1104074, 2.1186075, 2.1167047, 2.175357, 2.1699963, 2.166929, 2.0965931, 2.3395352, 2.1700535, 2.241927, 1.9266816, 1.70943, 1.6862444, 1.5710672, 1.5758712, 1.6887977, 1.4859324, 2.0322936, 1.9197538, 1.896421, 1.9061828, 1.9265567, 1.9104061, 1.6825126, 1.5933774, 1.8448362, 1.8391188, 1.722304, 1.4807662, 1.5807453, 1.3781668, 1.9490826, 1.4095782, 1.7068851, 1.4202745, 1.5335965, 1.4546381, 1.6022217, 1.5707039, 1.5426493, 1.3813447, 1.4213191, 1.4337889, 1.8233947, 1.6284349, 1.49121, 1.6117817, 1.5869839, 1.8483435, 1.9282702, 1.624495, 1.6054065, 1.5576446, 1.646585, 1.5882409, 1.7808518, 1.4577211, 1.7502524, 1.6407405, 1.5257311, 1.6015278, 1.5720168, 1.6872534, 1.6756644, 1.6119806, 1.5601517, 1.547819, 1.581002, 1.5497441, 2.0175524, 1.7248677, 1.5675405, 1.5691725, 1.9467824, 1.845994, 1.76581, 1.769411, 1.816697, 1.830165, 1.8565224, 1.7850956, 1.7815894, 1.8844332, 1.845371, 1.8099828, 1.7554667, 1.8379554, 1.8190523, 1.7452756, 1.7594533, 1.816929, 1.8742013, 1.9837003, 1.7490876, 1.8473687, 1.8507895, 1.9477854, 1.8283014, 1.8587447, 1.7834455, 1.865225, 1.8212078, 1.7857609, 1.8034204, 1.803171, 1.7794788, 1.8027656, 1.8641187, 1.7979746, 1.8519396, 1.7649264, 1.8126086, 1.8373939, 1.6691266, 1.5985495, 1.7931461, 1.7217572, 1.7731323, 1.7115408, 1.7484034, 1.755933, 1.7028488, 1.8498838, 1.6160191, 1.5348759, 1.7289352, 1.5051526, 1.5717114, 1.542636, 1.5328672, 2.0003998, 1.713064, 1.6320301, 1.6470928, 1.508557, 1.6714324, 1.7830625, 1.8416624, 1.7254989, 1.6776278, 1.8061274, 1.7092267, 1.6939033, 2.1702325, 1.6541001, 1.8207316, 1.6878619, 1.6746336, 2.0461705, 1.7476215, 1.821947, 1.582801, 1.7346413, 1.677903, 1.9211535, 1.8250456, 1.855937, 1.8587565, 1.7649134, 1.9340273, 1.9470724, 1.9980795, 1.8267497, 2.0304198, 2.1271298, 1.7130185, 1.631518, 1.9751865, 1.7343614, 1.7551059, 1.7916126, 1.8008953, 1.794658, 1.9025865, 2.0404456, 1.7067276, 1.5019176, 1.9253782, 1.6677314, 1.7464529, 1.4814823, 1.9846553, 1.9417074, 1.7400719, 1.4406585, 1.3777405, 1.425053, 1.6501675, 1.5921308, 1.8269202, 1.3740356, 1.5425041, 1.6505347, 1.7842146, 1.5516757, 1.2865908, 1.3604425, 1.2854816, 1.151045, 1.5032837, 1.2927078, 1.4339513, 1.5862098, 1.3537121, 1.4339085, 1.3169299, 1.6905047, 1.7273179, 1.7694694, 1.9481248, 1.9887155, 2.1723757, 1.6027304, 1.9887608, 1.5836912, 1.2792583, 1.4313624, 1.46116, 1.6125568, 1.6053226, 1.4627213, 1.3643295, 1.6721137, 1.6756501, 1.6445295, 1.9384128, 1.5398897, 1.2896514, 1.4318805, 1.3574326, 1.3111805, 1.543542, 1.4493494, 1.480579, 1.3217386, 1.378052, 1.3499763, 1.346961, 1.5217947, 1.2970505, 1.2363123, 1.2562495, 1.2804116, 1.2583641, 1.3867713, 1.4288183, 1.267465, 1.303739, 1.2798673, 1.526867, 1.2107121, 1.3528858, 1.4697922, 1.2289392, 1.5696632, 1.3777668, 1.2181654, 1.4198205, 1.3141847, 1.445682, 1.4271299, 1.4353839, 1.097942, 1.2605577, 1.7660481, 5.701759, 1.7179042, 1.6084311, 1.5431874, 1.4304436, 1.5423734, 1.4557594, 1.3074996, 1.0741827, 1.0217333, 0.75660163, 0.7347325, 0.671023, 0.54441583, 0.63902503, 0.5046317, 0.9287793, 0.27608505, 0.26879337, 0.26873246, 0.3471503, 0.39858857, 0.2670414, 0.8163431, 0.2829779, 0.5206138, 0.25647113, 0.4201277, 0.3613172, 0.20703767, 0.19506545, 0.11368534, 0.20995358, 0.16218324, 0.30539984, 0.15425694, 0.15606803, 0.1449, 0.20450486, 0.121026225, 0.3342289, 0.14165896, 0.1351345, 0.23850659, 0.15630002, 0.24870183, 0.2126224, 0.4028581, 0.15662447, 0.27803424, 0.1284227, 0.11190555, 1.1728419, 0.06898111, 0.31999022, 0.12304763, 0.24438377, 0.07163566, 0.36310628, 0.21154298, 0.25815174, 0.08855412, 0.11352852, 0.18067837, 0.11777721, 0.2532354, 0.13553973, 0.004112084, 0.14792995, 0.16200107, 0.001388964, 0.03374321, 0.1601914, 0.12348393, 0.06671694, 0.0023373037, 0.48907405, 0.028425027, 0.0012785045, 0.0003552587, 0.03070236, 0.006645516, 0.61438334, 0.00082295213, 0.00093148695, 0.0011759432, 0.087300815, 0.0068451497, 0.07877863, 0.0005080385, 0.00034865376, 0.15698756, 0.0068738344, 0.00019798856, 0.03134578, 0.012030008, 0.001160253, 0.00020644152, 0.00013066133, 0.19219655, 0.013912729, 0.0013653695, 0.079524964, 0.0019195979, 0.0031998283, 0.00015836101, 0.00010051481, 5.374305e-05, 4.0541378e-05, 0.0074947802, 0.15963364, 0.32223117, 0.0039024751, 0.0012376178, 0.002728586, 0.011354353, 0.0031902427, 0.00022349371, 0.00013262458, 0.00011043617, 0.00010033318, 5.9202997e-05, 0.00014048908, 0.0055853804, 0.0014439346, 0.00041097435, 0.009965055, 0.08953033, 0.00080230256, 0.0013522333, 0.00040436594, 0.9086868, 0.019967923, 0.054923527, 0.00029074398, 0.024941955, 0.00057179225, 0.00025948178, 9.744702e-05, 0.015863312, 0.0006623151, 0.0033430215, 0.00057294866, 0.0009984944, 0.09366921, 0.00060380355, 0.00023132774, 9.767005e-05, 0.0021052016, 3.956711e-05, 4.2242784e-05, 2.2016753e-05, 1.39579715e-05, 1.1007807e-05, 1.206525e-05, 5.8962883e-06, 0.002120849, 0.003037725, 0.0059131267, 0.0016643236, 0.0005601448, 0.21148321, 0.00056131015, 0.014773097, 0.00023239697, 0.00020934675, 0.61151004, 0.00022204763, 0.010738928, 1.2293724, 0.009876715, 0.00010280277, 0.004067129, 8.285673e-05, 6.766847e-05, 5.6256533e-05, 3.8525377e-05, 1.5433325, 0.0110927895, 0.002762462, 0.00014197303, 0.00032958752, 0.000119125856, 0.0001104176, 0.00018145546, 0.20134085, 0.0005524405, 0.0056831343, 0.0007274572, 0.00019400279, 0.0029966147, 0.0019822493, 0.00010147521, 1.8942305, 0.0005988174, 0.0003546501, 0.0010226828, 0.00011664053, 0.000322439, 9.445811e-05, 4.452076e-05, 3.9908708e-05, 2.6101558e-05, 2.0615194e-05, 2.0142015e-05, 0.020081758, 0.0068282234, 5.1929776e-05, 3.071731e-05, 2.4544197e-05, 2.4145835e-05, 2.1104908e-05, 1.9966401e-05, 0.016812243, 0.0165481, 0.003169595, 7.536028e-05, 0.0011277946, 4.8255726e-05, 0.4962753, 0.0043379357, 0.0049631773, 0.00063388096, 0.0002355037, 0.00038374943, 7.397197e-05, 0.0021203603, 0.0004291274, 0.028164918, 0.00029256594, 5.4923046e-05, 0.00028450598, 3.63244e-05, 3.053101e-05, 0.000116555006, 2.0013265e-05, 1.7892798e-05, 0.00012372379, 1.2355337e-05, 1.069789e-05, 0.0013912839, 0.000300607, 0.0010289869, 0.015330189, 0.00027760863, 0.00012775711, 4.6529363e-05, 4.790914e-05, 0.0026139559, 0.00015635394, 0.0057524773, 3.4803204e-05, 0.002463027, 3.914506e-05, 2.4160547e-05, 1.2732278e-05, 8.8449315e-06, 0.00016150885, 7.897052e-06, 5.615193e-06, 0.054105252, 0.07141974, 0.0007402807, 0.00025268772, 0.0002881627, 0.00024843658, 0.0007046847, 6.5462926e-05, 0.14608876, 9.61927e-05, 0.0013343687, 2.4990795e-05, 0.0011042731, 0.007495714, 0.00018043358, 0.00017516737, 0.00046222893, 0.0055793985, 0.00047642947, 0.00019029345, 3.666213e-05, 3.3610064e-05, 1.986889e-05, 6.3933985e-05, 1.847443e-05, 0.51237375, 0.008908973, 0.011226033, 0.00020665396, 0.014738741, 0.034094315, 0.034572437, 2.2823668e-05, 3.308767e-05, 4.0709398e-05, 1.5142801e-05, 9.594172e-06, 7.4275886e-06, 5.133254e-06, 0.003685827, 0.022376588, 0.00013316795, 9.261268e-05, 0.001113937, 3.3739478e-05, 0.00043848628, 5.4673947e-05, 0.5161377, 0.00018642111, 0.27301252, 7.6037526e-05, 1.928296e-06, 1.9750862e-06, 1.0476608e-06, 8.149911e-07, 3.45554e-05, 9.273801e-06, 1.9514338e-05, 0.054086756, 0.00087459804, 1.700131e-05, 9.949518e-06, 0.00036440277, 0.042014442, 0.0004612777, 0.00027415156, 1.9324754e-05, 0.048268154, 0.00012123597, 6.3354615e-05, 6.277999e-05, 8.430452e-05, 4.793357e-05, 1.8144214e-05, 1.0371089e-05, 1.0407104e-05, 6.353283e-06, 6.250736e-06, 1.0549455e-05, 4.0221275e-06, 3.6057083e-06, 3.032646e-06, 3.772383e-06, 0.00083015295, 0.02881266, 2.7649417e-05, 0.018025635, 5.9262777e-05, 4.7537298e-05, 4.0634346e-05, 6.703705e-05, 1.9826097e-05, 0.006912881, 0.042405546, 5.5304678e-05, 1.2835783e-06, 9.3509625e-06, 0.0015078286, 8.254465e-05, 0.00016185183, 0.0036415, 5.8001417e-05, 1.4285682, 1.2850467e-05, 7.0954807e-06, 0.0016177278, 0.00059532915, 0.12726732, 8.030491e-05, 5.296655e-05, 2.0933465e-05, 3.6247435e-05, 7.903415e-05, 7.4624295e-06, 4.3525374e-06, 2.9309316e-05, 2.7550068e-06, 4.5126735e-06, 2.1918304e-06, 2.436639e-06, 2.7394335e-06, 3.302268, 2.3123219e-05, 0.0038876315, 0.000107054424, 0.017491253, 1.0925155e-05, 1.3246732e-05, 3.6209826, 0.00833263, 5.169781e-06, 6.2186296e-06, 2.4846809e-06, 1.7502443e-06, 2.262581e-06, 0.06916619, 0.00935943, 6.330417e-05, 0.00021081825, 2.1007127e-06, 0.009099054, 5.6417025e-07, 3.5907951e-06, 4.956687e-07, 2.3066518e-06, 5.3538943e-06, 3.689664e-07, 1.3430115e-06, 0.0036684244, 0.0038347023, 6.0301925e-05, 6.2317026e-06, 1.3801771e-05, 2.7310327e-06, 3.921034e-05, 4.84272e-06, 0.00019404189, 0.0012410843, 1.9139484e-06, 0.003221201, 7.9958394e-05, 9.693009e-06, 3.2583208e-05, 0.0003939914, 0.001959819, 9.3271265e-05, 1.0245599, 0.0003233718, 3.8999973e-05, 0.023542061, 2.3201168e-05, 1.4025727e-05, 0.0001375934, 7.168141e-06, 5.8827904e-06, 1.5389865e-06, 2.1443168e-06, 2.3838272e-06, 9.420749e-07, 1.1350454e-06, 1.0192455e-06, 3.5271705e-07, 6.8395417e-07, 0.028394867, 0.012913471, 0.078922264, 0.009037091, 4.5142468e-05, 6.5616414e-06, 0.00011160779, 5.6746176e-06, 2.6547958e-05, 7.5183493e-07, 9.912089e-07, 8.411669e-07, 1.5530408e-06, 1.4655571e-06, 0.00016218935, 0.3533933, 1.4705753e-07, 3.2312954e-07, 2.0032589e-05, 0.9495611, 0.017207103, 5.87152e-06, 2.399122e-06, 0.022494791, 4.0666422e-05, 0.0018169209, 0.0012956826, 7.7886784e-07, 5.1180984e-07, 9.999107e-08, 3.2389042e-07, 4.8014762e-08, 1.0933309e-07, 1.8773785e-07, 2.7714427e-07, 0.023638234, 4.272711e-07, 0.025936065, 4.256673e-05, 0.0013633202, 2.3624207e-05, 2.881882e-06, 5.4714046e-06, 0.0018152329, 4.5213837e-06, 1.8878031e-06, 1.5738306e-06, 1.6732021e-06, 1.5083879e-06, 1.0626983e-06, 1.3481957e-06, 0.11289797, 0.0003375392, 2.0374623e-06, 1.8211892e-06, 0.00028615154, 4.625392e-05, 9.124822e-06
disc_val_acc: 0.004464285714285714, 0.3645833333333333, 0.26785714285714285, 0.3030753968253968, 0.16567460317460317, 0.12152777777777778, 0.13442460317460317, 0.16865079365079366, 0.10962301587301587, 0.2113095238095238, 0.2822420634920635, 0.17410714285714285, 0.19146825396825398, 0.11557539682539683, 0.16567460317460317, 0.12202380952380952, 0.12946428571428573, 0.1195436507936508, 0.12549603174603174, 0.1259920634920635, 0.2544642857142857, 0.19642857142857142, 0.27132936507936506, 0.2088293650793651, 0.17410714285714285, 0.18700396825396826, 0.23759920634920634, 0.18898809523809523, 0.19444444444444445, 0.2524801587301587, 0.25396825396825395, 0.22123015873015872, 0.10119047619047619, 0.1488095238095238, 0.12053571428571429, 0.18551587301587302, 0.19246031746031747, 0.1597222222222222, 0.12103174603174603, 0.125, 0.11160714285714286, 0.11706349206349206, 0.13392857142857142, 0.11160714285714286, 0.13392857142857142, 0.17410714285714285, 0.15873015873015872, 0.27331349206349204, 0.27827380952380953, 0.2465277777777778, 0.28521825396825395, 0.14087301587301587, 0.12698412698412698, 0.12797619047619047, 0.13343253968253968, 0.26884920634920634, 0.2584325396825397, 0.20238095238095238, 0.13541666666666666, 0.11607142857142858, 0.16220238095238096, 0.12053571428571429, 0.12748015873015872, 0.11259920634920635, 0.11507936507936507, 0.11607142857142858, 0.12400793650793651, 0.22321428571428573, 0.20634920634920634, 0.2648809523809524, 0.21478174603174602, 0.3005952380952381, 0.2802579365079365, 0.18204365079365079, 0.28125, 0.2058531746031746, 0.16319444444444445, 0.1284722222222222, 0.12450396825396826, 0.17162698412698413, 0.15823412698412698, 0.14434523809523808, 0.18601190476190477, 0.12996031746031747, 0.13640873015873015, 0.1259920634920635, 0.12053571428571429, 0.13740079365079366, 0.11755952380952381, 0.10962301587301587, 0.12946428571428573, 0.11507936507936507, 0.14682539682539683, 0.12251984126984126, 0.12152777777777778, 0.12003968253968254, 0.1527777777777778, 0.11805555555555555, 0.13442460317460317, 0.1259920634920635, 0.1185515873015873, 0.11557539682539683, 0.1453373015873016, 0.12549603174603174, 0.12053571428571429, 0.22916666666666666, 0.21279761904761904, 0.25744047619047616, 0.20684523809523808, 0.24107142857142858, 0.12698412698412698, 0.10367063492063493, 0.11160714285714286, 0.13640873015873015, 0.12748015873015872, 0.13690476190476192, 0.1314484126984127, 0.19295634920634921, 0.11607142857142858, 0.12946428571428573, 0.1185515873015873, 0.12103174603174603, 0.11706349206349206, 0.14434523809523808, 0.13392857142857142, 0.12400793650793651, 0.11557539682539683, 0.12400793650793651, 0.1349206349206349, 0.12103174603174603, 0.1453373015873016, 0.11259920634920635, 0.1185515873015873, 0.13392857142857142, 0.12748015873015872, 0.1314484126984127, 0.12053571428571429, 0.13343253968253968, 0.3030753968253968, 0.3343253968253968, 0.2748015873015873, 0.2544642857142857, 0.20982142857142858, 0.3958333333333333, 0.310515873015873, 0.37797619047619047, 0.31299603174603174, 0.27132936507936506, 0.2867063492063492, 0.34375, 0.3100198412698413, 0.28273809523809523, 0.3318452380952381, 0.3655753968253968, 0.2683531746031746, 0.2435515873015873, 0.18700396825396826, 0.21825396825396826, 0.1884920634920635, 0.22817460317460317, 0.27827380952380953, 0.18154761904761904, 0.23015873015873015, 0.1974206349206349, 0.18799603174603174, 0.1884920634920635, 0.19593253968253968, 0.18898809523809523, 0.20238095238095238, 0.19642857142857142, 0.20188492063492064, 0.17261904761904762, 0.20734126984126985, 0.19940476190476192, 0.1765873015873016, 0.20238095238095238, 0.17807539682539683, 0.17807539682539683, 0.30257936507936506, 0.18601190476190477, 0.28720238095238093, 0.3040674603174603, 0.22023809523809523, 0.14037698412698413, 0.27728174603174605, 0.2594246031746032, 0.22172619047619047, 0.23412698412698413, 0.26686507936507936, 0.3318452380952381, 0.19196428571428573, 0.1865079365079365, 0.2435515873015873, 0.2261904761904762, 0.19692460317460317, 0.20982142857142858, 0.17063492063492064, 0.12748015873015872, 0.17162698412698413, 0.1324404761904762, 0.13988095238095238, 0.12351190476190477, 0.13343253968253968, 0.11706349206349206, 0.11557539682539683, 0.12251984126984126, 0.15079365079365079, 0.14434523809523808, 0.12946428571428573, 0.11805555555555555, 0.2673611111111111, 0.33283730158730157, 0.24751984126984128, 0.24454365079365079, 0.2251984126984127, 0.21478174603174602, 0.06448412698412699, 0.23065476190476192, 0.18055555555555555, 0.19890873015873015, 0.14434523809523808, 0.22123015873015872, 0.19047619047619047, 0.25297619047619047, 0.20238095238095238, 0.22668650793650794, 0.2251984126984127, 0.2316468253968254, 0.1875, 0.17113095238095238, 0.13690476190476192, 0.11507936507936507, 0.13293650793650794, 0.12202380952380952, 0.12152777777777778, 0.11755952380952381, 0.1259920634920635, 0.11507936507936507, 0.1378968253968254, 0.13640873015873015, 0.12251984126984126, 0.21279761904761904, 0.22023809523809523, 0.13194444444444445, 0.1195436507936508, 0.1284722222222222, 0.20436507936507936, 0.28521825396825395, 0.28869047619047616, 0.3209325396825397, 0.24801587301587302, 0.27232142857142855, 0.29811507936507936, 0.18551587301587302, 0.20833333333333334, 0.1884920634920635, 0.21378968253968253, 0.2534722222222222, 0.24057539682539683, 0.3125, 0.35367063492063494, 0.2286706349206349, 0.3169642857142857, 0.25892857142857145, 0.35119047619047616, 0.29910714285714285, 0.34424603174603174, 0.2614087301587302, 0.35912698412698413, 0.24057539682539683, 0.3070436507936508, 0.23412698412698413, 0.24553571428571427, 0.24156746031746032, 0.2837301587301587, 0.27529761904761907, 0.3551587301587302, 0.27976190476190477, 0.2544642857142857, 0.27529761904761907, 0.29563492063492064, 0.39037698412698413, 0.33134920634920634, 0.3030753968253968, 0.2867063492063492, 0.24751984126984128, 0.29464285714285715, 0.30505952380952384, 0.30505952380952384, 0.2926587301587302, 0.29712301587301587, 0.2986111111111111, 0.40327380952380953, 0.24950396825396826, 0.2197420634920635, 0.28273809523809523, 0.2594246031746032, 0.2876984126984127, 0.3219246031746032, 0.30853174603174605, 0.32936507936507936, 0.3090277777777778, 0.3030753968253968, 0.3566468253968254, 0.3189484126984127, 0.27232142857142855, 0.28125, 0.25396825396825395, 0.34226190476190477, 0.2698412698412698, 0.18948412698412698, 0.19642857142857142, 0.2113095238095238, 0.1661706349206349, 0.24603174603174602, 0.1765873015873016, 0.17559523809523808, 0.19642857142857142, 0.17956349206349206, 0.19196428571428573, 0.1909722222222222, 0.18353174603174602, 0.1865079365079365, 0.1939484126984127, 0.20287698412698413, 0.19047619047619047, 0.1875, 0.1775793650793651, 0.17609126984126985, 0.21031746031746032, 0.17708333333333334, 0.17261904761904762, 0.1800595238095238, 0.2088293650793651, 0.18501984126984128, 0.18700396825396826, 0.17906746031746032, 0.1909722222222222, 0.19345238095238096, 0.1840277777777778, 0.17956349206349206, 0.23115079365079366, 0.1765873015873016, 0.1909722222222222, 0.1949404761904762, 0.1746031746031746, 0.20734126984126985, 0.1775793650793651, 0.26537698412698413, 0.2638888888888889, 0.35267857142857145, 0.2663690476190476, 0.29017857142857145, 0.25793650793650796, 0.23214285714285715, 0.22916666666666666, 0.2286706349206349, 0.24950396825396826, 0.23214285714285715, 0.28422619047619047, 0.3447420634920635, 0.25892857142857145, 0.3715277777777778, 0.31994047619047616, 0.38244047619047616, 0.36259920634920634, 0.26091269841269843, 0.2663690476190476, 0.26884920634920634, 0.3353174603174603, 0.3541666666666667, 0.28422619047619047, 0.30456349206349204, 0.27827380952380953, 0.30357142857142855, 0.24603174603174602, 0.32242063492063494, 0.34077380952380953, 0.30009920634920634, 0.25049603174603174, 0.31994047619047616, 0.26438492063492064, 0.2996031746031746, 0.3194444444444444, 0.22668650793650794, 0.3100198412698413, 0.31746031746031744, 0.3323412698412698, 0.30357142857142855, 0.2822420634920635, 0.2673611111111111, 0.24503968253968253, 0.18055555555555555, 0.28720238095238093, 0.3010912698412698, 0.20634920634920634, 0.20932539682539683, 0.18898809523809523, 0.2509920634920635, 0.19246031746031747, 0.23809523809523808, 0.32043650793650796, 0.3318452380952381, 0.29464285714285715, 0.24603174603174602, 0.22916666666666666, 0.1909722222222222, 0.2113095238095238, 0.20684523809523808, 0.28621031746031744, 0.16765873015873015, 0.28869047619047616, 0.34871031746031744, 0.21031746031746032, 0.31845238095238093, 0.18303571428571427, 0.31994047619047616, 0.19940476190476192, 0.2490079365079365, 0.1984126984126984, 0.3194444444444444, 0.37648809523809523, 0.41617063492063494, 0.3864087301587302, 0.3080357142857143, 0.3611111111111111, 0.33035714285714285, 0.2996031746031746, 0.27529761904761907, 0.22172619047619047, 0.35119047619047616, 0.4126984126984127, 0.3586309523809524, 0.3373015873015873, 0.44146825396825395, 0.2916666666666667, 0.3854166666666667, 0.2961309523809524, 0.26438492063492064, 0.37103174603174605, 0.27331349206349204, 0.34226190476190477, 0.23115079365079366, 0.2251984126984127, 0.1671626984126984, 0.1865079365079365, 0.17559523809523808, 0.18501984126984128, 0.30357142857142855, 0.2088293650793651, 0.32787698412698413, 0.39732142857142855, 0.3492063492063492, 0.36755952380952384, 0.2837301587301587, 0.2628968253968254, 0.2926587301587302, 0.34871031746031744, 0.2614087301587302, 0.31994047619047616, 0.33581349206349204, 0.2177579365079365, 0.28918650793650796, 0.38244047619047616, 0.2708333333333333, 0.3273809523809524, 0.3333333333333333, 0.3040674603174603, 0.36408730158730157, 0.34077380952380953, 0.3373015873015873, 0.37996031746031744, 0.3149801587301587, 0.33035714285714285, 0.31845238095238093, 0.38392857142857145, 0.4146825396825397, 0.3333333333333333, 0.3601190476190476, 0.3368055555555556, 0.3055555555555556, 0.29216269841269843, 0.29910714285714285, 0.3630952380952381, 0.36061507936507936, 0.2614087301587302, 0.4568452380952381, 0.3288690476190476, 0.3506944444444444, 0.3998015873015873, 0.2896825396825397, 0.3695436507936508, 0.4642857142857143, 0.30853174603174605, 0.3531746031746032, 0.2619047619047619, 0.30654761904761907, 0.33978174603174605, 0.4618055555555556, 0.3630952380952381, 0.34672619047619047, 0.001488095238095238, 0.24702380952380953, 0.26785714285714285, 0.29662698412698413, 0.30257936507936506, 0.3229166666666667, 0.3263888888888889, 0.3531746031746032, 0.45436507936507936, 0.5411706349206349, 0.6870039682539683, 0.7028769841269841, 0.7336309523809523, 0.7455357142857143, 0.6537698412698413, 0.7708333333333334, 0.6349206349206349, 0.8700396825396826, 0.8779761904761905, 0.8804563492063492, 0.8735119047619048, 0.8209325396825397, 0.8998015873015873, 0.7708333333333334, 0.8754960317460317, 0.7797619047619048, 0.9255952380952381, 0.8556547619047619, 0.8938492063492064, 0.9419642857142857, 0.9454365079365079, 0.9786706349206349, 0.8740079365079365, 0.9315476190476191, 0.8804563492063492, 0.8784722222222222, 0.9623015873015873, 0.9002976190476191, 0.9290674603174603, 0.9503968253968254, 0.8849206349206349, 0.8948412698412699, 0.9623015873015873, 0.8556547619047619, 0.9424603174603174, 0.9017857142857143, 0.9161706349206349, 0.8561507936507936, 0.9196428571428571, 0.8541666666666666, 0.9598214285714286, 0.9494047619047619, 0.7242063492063492, 0.9826388888888888, 0.9122023809523809, 0.9588293650793651, 0.9409722222222222, 0.9677579365079365, 0.8764880952380952, 0.8690476190476191, 0.8759920634920635, 0.9806547619047619, 0.9409722222222222, 0.9246031746031746, 0.9523809523809523, 0.9310515873015873, 0.9632936507936508, 1.0, 0.9270833333333334, 0.9305555555555556, 1.0, 0.998015873015873, 0.9494047619047619, 0.9176587301587301, 0.9697420634920635, 0.9995039682539683, 0.8472222222222222, 0.9945436507936508, 1.0, 1.0, 0.9885912698412699, 0.9995039682539683, 0.8779761904761905, 1.0, 1.0, 0.9995039682539683, 0.9821428571428571, 0.9990079365079365, 0.972718253968254, 1.0, 1.0, 0.9315476190476191, 0.9990079365079365, 1.0, 0.9965277777777778, 0.9970238095238095, 1.0, 1.0, 1.0, 0.9389880952380952, 1.0, 1.0, 0.9756944444444444, 0.9995039682539683, 0.9995039682539683, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9454365079365079, 0.9255952380952381, 0.9995039682539683, 1.0, 0.9990079365079365, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9990079365079365, 0.9995039682539683, 1.0, 0.9985119047619048, 0.9399801587301587, 1.0, 1.0, 1.0, 0.7906746031746031, 0.9970238095238095, 0.9856150793650794, 1.0, 0.996031746031746, 1.0, 1.0, 1.0, 0.9965277777777778, 1.0, 0.9995039682539683, 1.0, 1.0, 0.9538690476190477, 1.0, 1.0, 1.0, 0.9990079365079365, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9995039682539683, 0.9995039682539683, 0.9985119047619048, 0.9995039682539683, 1.0, 0.9340277777777778, 1.0, 0.9985119047619048, 1.0, 1.0, 0.8253968253968254, 1.0, 0.9990079365079365, 0.777281746031746, 0.9965277777777778, 1.0, 0.9990079365079365, 1.0, 1.0, 1.0, 1.0, 0.9325396825396826, 0.9970238095238095, 0.9995039682539683, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9370039682539683, 1.0, 0.9975198412698413, 1.0, 1.0, 1.0, 0.9995039682539683, 1.0, 0.7182539682539683, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9975198412698413, 0.9975198412698413, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9970238095238095, 0.9985119047619048, 0.9995039682539683, 1.0, 0.9995039682539683, 1.0, 0.8566468253968254, 0.998015873015873, 0.9990079365079365, 1.0, 1.0, 1.0, 1.0, 0.9990079365079365, 1.0, 0.9910714285714286, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9990079365079365, 1.0, 0.9995039682539683, 0.9970238095238095, 1.0, 1.0, 1.0, 1.0, 0.9995039682539683, 1.0, 0.998015873015873, 1.0, 0.9995039682539683, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9950396825396826, 0.9950396825396826, 1.0, 1.0, 1.0, 1.0, 0.9995039682539683, 1.0, 0.9469246031746031, 1.0, 1.0, 1.0, 0.9995039682539683, 0.9985119047619048, 1.0, 1.0, 0.9995039682539683, 0.9990079365079365, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9360119047619048, 0.998015873015873, 0.9985119047619048, 1.0, 0.9985119047619048, 0.9970238095238095, 0.9940476190476191, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9985119047619048, 0.9975198412698413, 1.0, 1.0, 1.0, 1.0, 0.9995039682539683, 1.0, 0.908234126984127, 1.0, 0.9206349206349206, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9747023809523809, 0.9995039682539683, 1.0, 1.0, 1.0, 0.9811507936507936, 1.0, 1.0, 1.0, 0.9920634920634921, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9995039682539683, 0.9915674603174603, 1.0, 0.9975198412698413, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9995039682539683, 0.9861111111111112, 1.0, 1.0, 1.0, 0.9995039682539683, 1.0, 1.0, 0.9995039682539683, 1.0, 0.9146825396825397, 1.0, 1.0, 0.9995039682539683, 0.9995039682539683, 0.9553571428571429, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.9990079365079365, 1.0, 0.9965277777777778, 1.0, 1.0, 0.8318452380952381, 0.9990079365079365, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9905753968253969, 0.9985119047619048, 1.0, 1.0, 1.0, 0.9990079365079365, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9995039682539683, 0.9985119047619048, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9995039682539683, 1.0, 0.9995039682539683, 1.0, 1.0, 1.0, 1.0, 0.9985119047619048, 1.0, 0.964781746031746, 1.0, 1.0, 0.9915674603174603, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9985119047619048, 0.9990079365079365, 0.9846230158730159, 0.9990079365079365, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.964781746031746, 1.0, 1.0, 1.0, 0.9494047619047619, 0.9940476190476191, 1.0, 1.0, 0.9900793650793651, 1.0, 0.9995039682539683, 0.9990079365079365, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9985119047619048, 1.0, 0.998015873015873, 1.0, 0.9995039682539683, 1.0, 1.0, 1.0, 0.9995039682539683, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9608134920634921, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0

