Beginning trial described in ./config/multigen_trial.json.
Experiment type: multiple generators each corresponding to 1 key.
Experiment settings:
	byte: 0
	keys: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
	key_dataset_kwargs:
		keep_data_in_memory: True
		data_path: ./data
		download: True
		extract: True
		preprocess: True
		delete_download_after_extraction: False
		delete_extracted_after_preprocess: False
	dataloader_kwargs:
		batch_size: 16
		shuffle: True
	dataset_prop_for_validation: 0.2
	trace_map_constructor: None
	trace_map_kwargs:
		layers: [256]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	plaintext_map_constructor: None
	plaintext_map_kwargs:
		layers: [64]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	key_map_constructor: <function get_mlp_map at 0x7efdfd54e5e0>
	key_map_kwargs:
		layers: [64, 256]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	cumulative_map_constructor: None
	cumulative_map_kwargs:
		layers: [256]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	discriminator_constructor: <function get_google_style_resnet_discriminator at 0x7efdfd54e790>
	discriminator_kwargs:
	discriminator_loss_constructor: <class 'torch.nn.modules.loss.CrossEntropyLoss'>
	discriminator_loss_kwargs:
	discriminator_optimizer_constructor: <class 'torch.optim.adam.Adam'>
	discriminator_optimizer_kwargs:
	generator_loss_constructor: <class 'loss_functions.NormLoss'>
	generator_loss_kwargs:
		p: inf
	generator_optimizer_constructor: <class 'torch.optim.adam.Adam'>
	generator_optimizer_kwargs:
	device: cuda
	discriminator_pretraining_epochs: 0
	generator_pretraining_epochs: 0
	gan_training_epochs: 500
	discriminator_posttraining_epochs: 500
	seed: 0
Loading datasets.
AesKeyGroupDataset:
	Available keys: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
	Key transform: Compose(
    IntToBinary()
    ToTensor1D()
)
	Byte: 0
	Number of samples available: 10112
	Trace size: torch.Size([1, 3000])
	Key size: torch.Size([1, 8])
	Plaintext size: torch.Size([1, 8])
	Key index size: ()
Constructing generator.
KeyOnlyGenerator(
  (key_trace_map): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=8, out_features=64, bias=True)
    (2): ReLU()
    (3): Linear(in_features=64, out_features=256, bias=True)
    (4): ReLU()
    (5): Linear(in_features=256, out_features=3000, bias=True)
    (6): Unflatten(dim=-1, unflattened_size=torch.Size([1, 3000]))
  )
)

Constructing discriminator.
Discriminator(
  (model): Sequential(
    (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)
    (1): Stack(
      (F): Sequential(
        (0): Block(
          (F): Sequential(
            (0): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(1, 16, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(16, 64, kernel_size=(1,), stride=(1,))
          )
          (Id): Conv1d(1, 64, kernel_size=(1,), stride=(1,))
        )
        (1): Block(
          (F): Sequential(
            (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(64, 16, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(16, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(16, 64, kernel_size=(1,), stride=(1,))
          )
          (Id): Identity()
        )
        (2): Block(
          (F): Sequential(
            (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(64, 16, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(16, 16, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
            (6): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(16, 64, kernel_size=(1,), stride=(1,))
          )
          (Id): MaxPool1d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)
        )
      )
    )
    (2): Stack(
      (F): Sequential(
        (0): Block(
          (F): Sequential(
            (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(64, 32, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
          )
          (Id): Conv1d(64, 128, kernel_size=(1,), stride=(1,))
        )
        (1): Block(
          (F): Sequential(
            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
          )
          (Id): Identity()
        )
        (2): Block(
          (F): Sequential(
            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
          )
          (Id): Identity()
        )
        (3): Block(
          (F): Sequential(
            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(32, 32, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
            (6): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(32, 128, kernel_size=(1,), stride=(1,))
          )
          (Id): MaxPool1d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)
        )
      )
    )
    (3): Stack(
      (F): Sequential(
        (0): Block(
          (F): Sequential(
            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
          )
          (Id): Conv1d(128, 256, kernel_size=(1,), stride=(1,))
        )
        (1): Block(
          (F): Sequential(
            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
          )
          (Id): Identity()
        )
        (2): Block(
          (F): Sequential(
            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
          )
          (Id): Identity()
        )
        (3): Block(
          (F): Sequential(
            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(64, 64, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
            (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(64, 256, kernel_size=(1,), stride=(1,))
          )
          (Id): MaxPool1d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)
        )
      )
    )
    (4): Stack(
      (F): Sequential(
        (0): Block(
          (F): Sequential(
            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
          )
          (Id): Conv1d(256, 512, kernel_size=(1,), stride=(1,))
        )
        (1): Block(
          (F): Sequential(
            (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
            (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
          )
          (Id): Identity()
        )
        (2): Block(
          (F): Sequential(
            (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (1): ReLU()
            (2): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)
            (3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (4): ReLU()
            (5): Conv1d(128, 128, kernel_size=(3,), stride=(2,), padding=(1,), bias=False)
            (6): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (7): ReLU()
            (8): Conv1d(128, 512, kernel_size=(1,), stride=(1,))
          )
          (Id): MaxPool1d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)
        )
      )
    )
    (5): Flatten(start_dim=1, end_dim=-1)
    (6): LazyLinear(in_features=0, out_features=256, bias=True)
  )
)

Calculating initial results.
Training results:
gen_loss: 0.017001482
disc_loss: 5.53727
disc_acc: 0.002103960396039604

Validation results:
gen_loss: 0.017031386
disc_loss: 5.5387955
disc_acc: 0.004464285714285714


Training discriminator and generator simultaneously.
	Epoch 1
Training results:
gen_loss: 0.52525175
disc_loss: 2.10006
disc_acc: 0.39084158415841586

Validation results:
gen_loss: 0.3181874
disc_loss: 2.1823237
disc_acc: 0.26438492063492064


	Epoch 2
Training results:
gen_loss: 0.30071938
disc_loss: 2.1379085
disc_acc: 0.21745049504950495

Validation results:
gen_loss: 0.33390373
disc_loss: 2.1358464
disc_acc: 0.1636904761904762


	Epoch 3
Training results:
gen_loss: 0.30489984
disc_loss: 2.2672818
disc_acc: 0.19913366336633664

Validation results:
gen_loss: 0.2899613
disc_loss: 2.2461953
disc_acc: 0.27628968253968256


	Epoch 4
Training results:
gen_loss: 0.2837664
disc_loss: 2.3494503
disc_acc: 0.2089108910891089

Validation results:
gen_loss: 0.23575172
disc_loss: 2.3343983
disc_acc: 0.2013888888888889


	Epoch 5
Training results:
gen_loss: 0.24197432
disc_loss: 2.4485397
disc_acc: 0.17314356435643563

Validation results:
gen_loss: 0.17846759
disc_loss: 2.707921
disc_acc: 0.13045634920634921


	Epoch 6
Training results:
gen_loss: 0.15275744
disc_loss: 2.7587557
disc_acc: 0.0948019801980198

Validation results:
gen_loss: 0.089058176
disc_loss: 2.7564485
disc_acc: 0.1195436507936508


	Epoch 7
Training results:
gen_loss: 0.11087323
disc_loss: 2.7958782
disc_acc: 0.08267326732673268

Validation results:
gen_loss: 0.088090256
disc_loss: 2.7684011
disc_acc: 0.06001984126984127


	Epoch 8
Training results:
gen_loss: 0.14764236
disc_loss: 3.08615
disc_acc: 0.07462871287128713

Validation results:
gen_loss: 0.08413117
disc_loss: 2.788105
disc_acc: 0.05555555555555555


	Epoch 9
Training results:
gen_loss: 0.11840607
disc_loss: 2.8112717
disc_acc: 0.07388613861386138

Validation results:
gen_loss: 0.090587005
disc_loss: 2.802881
disc_acc: 0.09821428571428571


	Epoch 10
Training results:
gen_loss: 0.09807018
disc_loss: 2.794377
disc_acc: 0.07475247524752475

Validation results:
gen_loss: 0.09450354
disc_loss: 2.784839
disc_acc: 0.05853174603174603


	Epoch 11
Training results:
gen_loss: 0.09891535
disc_loss: 2.7870336
disc_acc: 0.07475247524752475

Validation results:
gen_loss: 0.09903469
disc_loss: 2.7691586
disc_acc: 0.06349206349206349


	Epoch 12
Training results:
gen_loss: 0.09977156
disc_loss: 2.7944045
disc_acc: 0.0681930693069307

Validation results:
gen_loss: 0.19684617
disc_loss: 2.9969509
disc_acc: 0.05257936507936508


	Epoch 13
Training results:
gen_loss: 0.1039396
disc_loss: 2.8033595
disc_acc: 0.0686881188118812

Validation results:
gen_loss: 0.09550054
disc_loss: 2.772588
disc_acc: 0.06349206349206349


	Epoch 14
Training results:
gen_loss: 0.10510834
disc_loss: 2.8025198
disc_acc: 0.07042079207920791

Validation results:
gen_loss: 0.100343905
disc_loss: 2.7984946
disc_acc: 0.0625


	Epoch 15
Training results:
gen_loss: 0.10528498
disc_loss: 2.8081598
disc_acc: 0.06930693069306931

Validation results:
gen_loss: 0.10502072
disc_loss: 2.815228
disc_acc: 0.062003968253968256


	Epoch 16
Training results:
gen_loss: 0.112279035
disc_loss: 2.831529
disc_acc: 0.061014851485148514

Validation results:
gen_loss: 0.101169206
disc_loss: 2.8130257
disc_acc: 0.057539682539682536


	Epoch 17
Training results:
gen_loss: 0.11011439
disc_loss: 2.8229995
disc_acc: 0.06745049504950495

Validation results:
gen_loss: 0.082885794
disc_loss: 2.786345
disc_acc: 0.07341269841269842


	Epoch 18
Training results:
gen_loss: 0.09930267
disc_loss: 2.8084888
disc_acc: 0.06386138613861386

Validation results:
gen_loss: 0.20489745
disc_loss: 3.057695
disc_acc: 0.062003968253968256


	Epoch 19
Training results:
gen_loss: 0.20953463
disc_loss: 3.3810384
disc_acc: 0.07957920792079208

Validation results:
gen_loss: 0.14327154
disc_loss: 3.0082476
disc_acc: 0.06845238095238096


	Epoch 20
Training results:
gen_loss: 0.13064475
disc_loss: 2.8663619
disc_acc: 0.06732673267326733

Validation results:
gen_loss: 0.10979677
disc_loss: 2.8364403
disc_acc: 0.07093253968253968


	Epoch 21
Training results:
gen_loss: 0.104772046
disc_loss: 2.8181279
disc_acc: 0.0625

Validation results:
gen_loss: 0.094197504
disc_loss: 2.785176
disc_acc: 0.0625


	Epoch 22
Training results:
gen_loss: 0.09716896
disc_loss: 2.7994592
disc_acc: 0.06398514851485149

Validation results:
gen_loss: 0.11853106
disc_loss: 2.841372
disc_acc: 0.05803571428571429


	Epoch 23
Training results:
gen_loss: 0.10073997
disc_loss: 2.815749
disc_acc: 0.059158415841584155

Validation results:
gen_loss: 0.10539363
disc_loss: 2.816093
disc_acc: 0.060515873015873016


	Epoch 24
Training results:
gen_loss: 0.10428841
disc_loss: 2.8145726
disc_acc: 0.06423267326732673

Validation results:
gen_loss: 0.10242872
disc_loss: 2.8515441
disc_acc: 0.062003968253968256


	Epoch 25
Training results:
gen_loss: 0.1048351
disc_loss: 2.8290825
disc_acc: 0.055693069306930694

Validation results:
gen_loss: 0.15482065
disc_loss: 2.9266996
disc_acc: 0.062003968253968256


	Epoch 26
Training results:
gen_loss: 0.11289402
disc_loss: 2.8283591
disc_acc: 0.06720297029702971

Validation results:
gen_loss: 0.08480393
disc_loss: 2.8265214
disc_acc: 0.06498015873015874


	Epoch 27
Training results:
gen_loss: 0.13018173
disc_loss: 2.905354
disc_acc: 0.06225247524752475

Validation results:
gen_loss: 0.37720877
disc_loss: 3.407525
disc_acc: 0.05853174603174603


	Epoch 28
Training results:
gen_loss: 0.13726057
disc_loss: 2.9407554
disc_acc: 0.059777227722772275

Validation results:
gen_loss: 0.085383385
disc_loss: 2.7939222
disc_acc: 0.057539682539682536


	Epoch 29
Training results:
gen_loss: 0.11862559
disc_loss: 2.845843
disc_acc: 0.06287128712871287

Validation results:
gen_loss: 0.09880198
disc_loss: 2.8162975
disc_acc: 0.06299603174603174


	Epoch 30
Training results:
gen_loss: 0.10402212
disc_loss: 2.8136487
disc_acc: 0.06683168316831684

Validation results:
gen_loss: 0.11405261
disc_loss: 2.8040788
disc_acc: 0.062003968253968256


	Epoch 31
Training results:
gen_loss: 0.10754109
disc_loss: 2.832669
disc_acc: 0.059777227722772275

Validation results:
gen_loss: 0.14290042
disc_loss: 2.927999
disc_acc: 0.05406746031746032


	Epoch 32
Training results:
gen_loss: 0.12792751
disc_loss: 2.8684914
disc_acc: 0.06435643564356436

Validation results:
gen_loss: 0.093050405
disc_loss: 2.7936585
disc_acc: 0.05505952380952381


	Epoch 33
Training results:
gen_loss: 0.12934178
disc_loss: 2.8598979
disc_acc: 0.06646039603960396

Validation results:
gen_loss: 0.1366156
disc_loss: 2.9093127
disc_acc: 0.06299603174603174


	Epoch 34
Training results:
gen_loss: 0.102203764
disc_loss: 2.8114998
disc_acc: 0.06386138613861386

Validation results:
gen_loss: 0.20112294
disc_loss: 2.9144013
disc_acc: 0.053075396825396824


	Epoch 35
Training results:
gen_loss: 0.1133616
disc_loss: 2.8200417
disc_acc: 0.06707920792079208

Validation results:
gen_loss: 0.10567213
disc_loss: 2.6609743
disc_acc: 0.09970238095238096


	Epoch 36
Training results:
gen_loss: 0.115474954
disc_loss: 2.834013
disc_acc: 0.06707920792079208

Validation results:
gen_loss: 0.093437955
disc_loss: 2.7960355
disc_acc: 0.062003968253968256


	Epoch 37
Training results:
gen_loss: 0.12294091
disc_loss: 2.8466723
disc_acc: 0.07116336633663366

Validation results:
gen_loss: 0.100011416
disc_loss: 2.8117843
disc_acc: 0.062003968253968256


	Epoch 38
Training results:
gen_loss: 0.11158682
disc_loss: 2.8341541
disc_acc: 0.06361386138613861

Validation results:
gen_loss: 0.12613206
disc_loss: 2.8487585
disc_acc: 0.05853174603174603


	Epoch 39
Training results:
gen_loss: 0.11714846
disc_loss: 2.8432174
disc_acc: 0.06324257425742574

Validation results:
gen_loss: 0.18649818
disc_loss: 2.9340534
disc_acc: 0.05853174603174603


	Epoch 40
Training results:
gen_loss: 0.23270938
disc_loss: 8.005877
disc_acc: 0.057673267326732676

Validation results:
gen_loss: 0.28462112
disc_loss: 3.6403599
disc_acc: 0.0679563492063492


	Epoch 41
Training results:
gen_loss: 0.18178561
disc_loss: 3.0789967
disc_acc: 0.06435643564356436

Validation results:
gen_loss: 0.10537281
disc_loss: 2.8954675
disc_acc: 0.061507936507936505


	Epoch 42
Training results:
gen_loss: 0.13575277
disc_loss: 2.9028995
disc_acc: 0.06806930693069307

Validation results:
gen_loss: 0.089381516
disc_loss: 2.8462744
disc_acc: 0.05853174603174603


	Epoch 43
Training results:
gen_loss: 0.1167375
disc_loss: 2.8543906
disc_acc: 0.06423267326732673

Validation results:
gen_loss: 0.100880675
disc_loss: 2.80478
disc_acc: 0.05853174603174603


	Epoch 44
Training results:
gen_loss: 0.14405656
disc_loss: 3.7878516
disc_acc: 0.06324257425742574

Validation results:
gen_loss: 0.41685647
disc_loss: 6.2358317
disc_acc: 0.05505952380952381


	Epoch 45
Training results:
gen_loss: 0.16626674
disc_loss: 3.079936
disc_acc: 0.0676980198019802

Validation results:
gen_loss: 0.11224392
disc_loss: 2.8382626
disc_acc: 0.06349206349206349


	Epoch 46
Training results:
gen_loss: 0.105250865
disc_loss: 2.8234804
disc_acc: 0.06683168316831684

Validation results:
gen_loss: 0.08728003
disc_loss: 2.792612
disc_acc: 0.06398809523809523


	Epoch 47
Training results:
gen_loss: 0.10253604
disc_loss: 2.8328187
disc_acc: 0.06522277227722773

Validation results:
gen_loss: 0.23035362
disc_loss: 3.6694856
disc_acc: 0.07093253968253968


	Epoch 48
Training results:
gen_loss: 0.0990201
disc_loss: 2.8249178
disc_acc: 0.06324257425742574

Validation results:
gen_loss: 0.07996825
disc_loss: 2.7816255
disc_acc: 0.057539682539682536


	Epoch 49
Training results:
gen_loss: 0.08653171
disc_loss: 2.791402
disc_acc: 0.062376237623762376

Validation results:
gen_loss: 0.089849174
disc_loss: 2.806636
disc_acc: 0.054563492063492064


	Epoch 50
Training results:
gen_loss: 0.099723086
disc_loss: 2.8171062
disc_acc: 0.05866336633663366

Validation results:
gen_loss: 0.083460815
disc_loss: 2.787572
disc_acc: 0.062003968253968256


	Epoch 51
Training results:
gen_loss: 0.090402946
disc_loss: 2.7972908
disc_acc: 0.060767326732673266

Validation results:
gen_loss: 0.0799394
disc_loss: 2.7841775
disc_acc: 0.057539682539682536


	Epoch 52
Training results:
gen_loss: 0.10342824
disc_loss: 2.826917
disc_acc: 0.06361386138613861

Validation results:
gen_loss: 0.077984534
disc_loss: 2.7896054
disc_acc: 0.10317460317460317


	Epoch 53
Training results:
gen_loss: 0.16775103
disc_loss: 3.180618
disc_acc: 0.0646039603960396

Validation results:
gen_loss: 0.09586286
disc_loss: 2.8559637
disc_acc: 0.054563492063492064


	Epoch 54
Training results:
gen_loss: 0.2251809
disc_loss: 4.0847707
disc_acc: 0.06695544554455446

Validation results:
gen_loss: 0.1616104
disc_loss: 3.203857
disc_acc: 0.05853174603174603


	Epoch 55
Training results:
gen_loss: 0.13479793
disc_loss: 2.9247482
disc_acc: 0.06163366336633663

Validation results:
gen_loss: 0.0921697
disc_loss: 2.7909064
disc_acc: 0.05853174603174603


	Epoch 56
Training results:
gen_loss: 0.114367895
disc_loss: 2.913552
disc_acc: 0.06398514851485149

Validation results:
gen_loss: 0.15285675
disc_loss: 2.9549887
disc_acc: 0.05257936507936508


	Epoch 57
Training results:
gen_loss: 0.117979534
disc_loss: 2.8564506
disc_acc: 0.06646039603960396

Validation results:
gen_loss: 0.09387574
disc_loss: 2.7914345
disc_acc: 0.06349206349206349


	Epoch 58
Training results:
gen_loss: 0.2946286
disc_loss: 6.514241
disc_acc: 0.06175742574257426

Validation results:
gen_loss: 0.14136642
disc_loss: 2.9412212
disc_acc: 0.05853174603174603


	Epoch 59
Training results:
gen_loss: 0.12605391
disc_loss: 2.8746326
disc_acc: 0.05952970297029703

Validation results:
gen_loss: 0.16789791
disc_loss: 2.9100335
disc_acc: 0.062003968253968256


	Epoch 60
Training results:
gen_loss: 0.11576103
disc_loss: 2.8226664
disc_acc: 0.07017326732673268

Validation results:
gen_loss: 0.17522426
disc_loss: 2.7817602
disc_acc: 0.06001984126984127


	Epoch 61
Training results:
gen_loss: 0.10547016
disc_loss: 2.8116462
disc_acc: 0.0655940594059406

Validation results:
gen_loss: 0.09459019
disc_loss: 2.8051894
disc_acc: 0.062003968253968256


	Epoch 62
Training results:
gen_loss: 0.09921822
disc_loss: 2.8031409
disc_acc: 0.0681930693069307

Validation results:
gen_loss: 0.113884374
disc_loss: 2.8493242
disc_acc: 0.062003968253968256


	Epoch 63
Training results:
gen_loss: 0.22984415
disc_loss: 4.3947954
disc_acc: 0.06064356435643564

Validation results:
gen_loss: 0.122648634
disc_loss: 2.8649898
disc_acc: 0.06398809523809523


	Epoch 64
Training results:
gen_loss: 0.105786614
disc_loss: 2.8322027
disc_acc: 0.060767326732673266

Validation results:
gen_loss: 0.094149895
disc_loss: 2.8014476
disc_acc: 0.053075396825396824


	Epoch 65
Training results:
gen_loss: 0.09271254
disc_loss: 2.800769
disc_acc: 0.06089108910891089

Validation results:
gen_loss: 0.07735532
disc_loss: 2.791553
disc_acc: 0.054563492063492064


	Epoch 66
Training results:
gen_loss: 0.10321609
disc_loss: 2.8164937
disc_acc: 0.0629950495049505

Validation results:
gen_loss: 0.10485202
disc_loss: 2.8967447
disc_acc: 0.062003968253968256


	Epoch 67
Training results:
gen_loss: 0.09629644
disc_loss: 2.8105884
disc_acc: 0.06163366336633663

Validation results:
gen_loss: 0.08645017
disc_loss: 2.787878
disc_acc: 0.06845238095238096


	Epoch 68
Training results:
gen_loss: 0.10424127
disc_loss: 2.829189
disc_acc: 0.06534653465346535

Validation results:
gen_loss: 0.31369594
disc_loss: 3.1785226
disc_acc: 0.07093253968253968


	Epoch 69
Training results:
gen_loss: 0.11526961
disc_loss: 2.8306913
disc_acc: 0.06212871287128713

Validation results:
gen_loss: 0.13045536
disc_loss: 2.840002
disc_acc: 0.062003968253968256


	Epoch 70
Training results:
gen_loss: 0.11209127
disc_loss: 2.8323777
disc_acc: 0.06361386138613861

Validation results:
gen_loss: 0.14792714
disc_loss: 2.8644118
disc_acc: 0.05704365079365079


	Epoch 71
Training results:
gen_loss: 0.09987366
disc_loss: 2.8158908
disc_acc: 0.061014851485148514

Validation results:
gen_loss: 0.13515086
disc_loss: 2.900092
disc_acc: 0.05704365079365079


	Epoch 72
Training results:
gen_loss: 0.11915159
disc_loss: 2.8592417
disc_acc: 0.0655940594059406

Validation results:
gen_loss: 0.07259586
disc_loss: 2.7773173
disc_acc: 0.0689484126984127


	Epoch 73
Training results:
gen_loss: 0.10251906
disc_loss: 2.8190768
disc_acc: 0.06287128712871287

Validation results:
gen_loss: 0.14257151
disc_loss: 2.8735785
disc_acc: 0.06349206349206349


	Epoch 74
Training results:
gen_loss: 0.106930114
disc_loss: 2.8233585
disc_acc: 0.06584158415841584

Validation results:
gen_loss: 0.083322324
disc_loss: 2.8152995
disc_acc: 0.05853174603174603


	Epoch 75
Training results:
gen_loss: 0.12048562
disc_loss: 2.8775647
disc_acc: 0.06386138613861386

Validation results:
gen_loss: 0.10242673
disc_loss: 2.81219
disc_acc: 0.053075396825396824


	Epoch 76
Training results:
gen_loss: 0.1059772
disc_loss: 2.8222914
disc_acc: 0.06150990099009901

Validation results:
gen_loss: 0.11025551
disc_loss: 2.841538
disc_acc: 0.05803571428571429


	Epoch 77
Training results:
gen_loss: 0.099874735
disc_loss: 2.8123033
disc_acc: 0.060767326732673266

Validation results:
gen_loss: 0.116036385
disc_loss: 2.8277981
disc_acc: 0.05853174603174603


	Epoch 78
Training results:
gen_loss: 0.10512071
disc_loss: 2.8199701
disc_acc: 0.06324257425742574

Validation results:
gen_loss: 0.20747946
disc_loss: 2.8365495
disc_acc: 0.07093253968253968


	Epoch 79
Training results:
gen_loss: 0.3099122
disc_loss: 4.465689
disc_acc: 0.09752475247524753

Validation results:
gen_loss: 0.17884542
disc_loss: 2.9153767
disc_acc: 0.06349206349206349


	Epoch 80
Training results:
gen_loss: 0.12208349
disc_loss: 2.8672051
disc_acc: 0.062376237623762376

Validation results:
gen_loss: 0.12649563
disc_loss: 2.8703303
disc_acc: 0.09623015873015874


	Epoch 81
Training results:
gen_loss: 0.10806931
disc_loss: 2.8291614
disc_acc: 0.061386138613861385

Validation results:
gen_loss: 0.10330222
disc_loss: 2.80851
disc_acc: 0.053075396825396824


	Epoch 82
Training results:
gen_loss: 0.098306954
disc_loss: 2.8139355
disc_acc: 0.057673267326732676

Validation results:
gen_loss: 0.09742818
disc_loss: 2.8094358
disc_acc: 0.05505952380952381


	Epoch 83
Training results:
gen_loss: 0.096480615
disc_loss: 2.8041668
disc_acc: 0.06398514851485149

Validation results:
gen_loss: 0.08411563
disc_loss: 2.784161
disc_acc: 0.062003968253968256


	Epoch 84
Training results:
gen_loss: 0.10777538
disc_loss: 2.8232157
disc_acc: 0.0625

Validation results:
gen_loss: 0.109386325
disc_loss: 2.8388069
disc_acc: 0.057539682539682536


	Epoch 85
Training results:
gen_loss: 0.10691936
disc_loss: 2.8187437
disc_acc: 0.06064356435643564

Validation results:
gen_loss: 0.07832588
disc_loss: 2.7813616
disc_acc: 0.06696428571428571


	Epoch 86
Training results:
gen_loss: 0.12318866
disc_loss: 2.8389218
disc_acc: 0.06905940594059407

Validation results:
gen_loss: 0.092140965
disc_loss: 2.8095407
disc_acc: 0.06349206349206349


	Epoch 87
Training results:
gen_loss: 0.109095536
disc_loss: 2.8292572
disc_acc: 0.06349009900990099

Validation results:
gen_loss: 0.14544277
disc_loss: 2.9022636
disc_acc: 0.06299603174603174


	Epoch 88
Training results:
gen_loss: 0.1080128
disc_loss: 2.828922
disc_acc: 0.06324257425742574

Validation results:
gen_loss: 0.08133338
disc_loss: 2.7988179
disc_acc: 0.057539682539682536


	Epoch 89
Training results:
gen_loss: 0.10028758
disc_loss: 2.816235
disc_acc: 0.06410891089108911

Validation results:
gen_loss: 0.091039196
disc_loss: 2.790646
disc_acc: 0.053075396825396824


	Epoch 90
Training results:
gen_loss: 0.104967386
disc_loss: 2.8186982
disc_acc: 0.06262376237623762

Validation results:
gen_loss: 0.12190744
disc_loss: 2.8093178
disc_acc: 0.05704365079365079


	Epoch 91
Training results:
gen_loss: 0.10241072
disc_loss: 2.8205905
disc_acc: 0.06225247524752475

Validation results:
gen_loss: 0.11101323
disc_loss: 2.8071883
disc_acc: 0.06398809523809523


	Epoch 92
Training results:
gen_loss: 0.23820648
disc_loss: 4.393727
disc_acc: 0.05952970297029703

Validation results:
gen_loss: 0.16748099
disc_loss: 2.9435723
disc_acc: 0.07390873015873016


	Epoch 93
Training results:
gen_loss: 0.118588954
disc_loss: 2.8570452
disc_acc: 0.06844059405940595

Validation results:
gen_loss: 0.13577384
disc_loss: 2.865853
disc_acc: 0.062003968253968256


	Epoch 94
Training results:
gen_loss: 0.106710225
disc_loss: 2.8290908
disc_acc: 0.0702970297029703

Validation results:
gen_loss: 0.18281299
disc_loss: 2.9951348
disc_acc: 0.060515873015873016


	Epoch 95
Training results:
gen_loss: 0.10207955
disc_loss: 2.8223593
disc_acc: 0.06175742574257426

Validation results:
gen_loss: 0.08609135
disc_loss: 2.802829
disc_acc: 0.07837301587301587


	Epoch 96
Training results:
gen_loss: 0.09914889
disc_loss: 2.8162854
disc_acc: 0.06150990099009901

Validation results:
gen_loss: 0.08443322
disc_loss: 2.7885776
disc_acc: 0.05853174603174603


	Epoch 97
Training results:
gen_loss: 0.14180702
disc_loss: 3.1396687
disc_acc: 0.0681930693069307

Validation results:
gen_loss: 0.24604918
disc_loss: 3.1528609
disc_acc: 0.06299603174603174


	Epoch 98
Training results:
gen_loss: 0.11761575
disc_loss: 2.8552005
disc_acc: 0.06522277227722773

Validation results:
gen_loss: 0.13458304
disc_loss: 2.869675
disc_acc: 0.05505952380952381


	Epoch 99
Training results:
gen_loss: 0.09553843
disc_loss: 2.808198
disc_acc: 0.06386138613861386

Validation results:
gen_loss: 0.07642735
disc_loss: 2.786132
disc_acc: 0.06349206349206349


	Epoch 100
Training results:
gen_loss: 0.09266819
disc_loss: 2.8006845
disc_acc: 0.05965346534653465

Validation results:
gen_loss: 0.08366725
disc_loss: 2.7912161
disc_acc: 0.0689484126984127


	Epoch 101
Training results:
gen_loss: 0.09366136
disc_loss: 2.7973914
disc_acc: 0.06287128712871287

Validation results:
gen_loss: 0.090336196
disc_loss: 2.805815
disc_acc: 0.05704365079365079


	Epoch 102
Training results:
gen_loss: 0.09440275
disc_loss: 2.8021474
disc_acc: 0.06163366336633663

Validation results:
gen_loss: 0.13223407
disc_loss: 2.8412025
disc_acc: 0.05803571428571429


	Epoch 103
Training results:
gen_loss: 0.09968926
disc_loss: 2.814644
disc_acc: 0.06571782178217822

Validation results:
gen_loss: 0.08516953
disc_loss: 2.7815325
disc_acc: 0.05505952380952381


	Epoch 104
Training results:
gen_loss: 0.09375926
disc_loss: 2.8039758
disc_acc: 0.062376237623762376

Validation results:
gen_loss: 0.09667089
disc_loss: 2.8153262
disc_acc: 0.062003968253968256


	Epoch 105
Training results:
gen_loss: 0.109078765
disc_loss: 2.8219838
disc_acc: 0.06262376237623762

Validation results:
gen_loss: 0.09258818
disc_loss: 2.786753
disc_acc: 0.06349206349206349


	Epoch 106
Training results:
gen_loss: 0.09757626
disc_loss: 2.8084729
disc_acc: 0.060767326732673266

Validation results:
gen_loss: 0.10319224
disc_loss: 2.793984
disc_acc: 0.07291666666666667


	Epoch 107
Training results:
gen_loss: 0.100652896
disc_loss: 2.8128684
disc_acc: 0.062376237623762376

Validation results:
gen_loss: 0.10133666
disc_loss: 2.805562
disc_acc: 0.0625


	Epoch 108
Training results:
gen_loss: 0.14407235
disc_loss: 2.9069428
disc_acc: 0.061386138613861385

Validation results:
gen_loss: 0.09948618
disc_loss: 2.7985625
disc_acc: 0.053075396825396824


	Epoch 109
Training results:
gen_loss: 0.114157304
disc_loss: 2.8183222
disc_acc: 0.07116336633663366

Validation results:
gen_loss: 0.102489434
disc_loss: 2.800803
disc_acc: 0.061507936507936505


	Epoch 110
Training results:
gen_loss: 0.11217813
disc_loss: 2.821684
disc_acc: 0.06967821782178218

Validation results:
gen_loss: 0.10664911
disc_loss: 2.8159132
disc_acc: 0.05853174603174603


	Epoch 111
Training results:
gen_loss: 0.10852163
disc_loss: 2.828739
disc_acc: 0.06732673267326733

Validation results:
gen_loss: 0.08157351
disc_loss: 2.7927823
disc_acc: 0.06349206349206349


	Epoch 112
Training results:
gen_loss: 0.10342
disc_loss: 2.808486
disc_acc: 0.06893564356435644

Validation results:
gen_loss: 0.1045479
disc_loss: 2.8081121
disc_acc: 0.057539682539682536


	Epoch 113
Training results:
gen_loss: 0.10046908
disc_loss: 2.816259
disc_acc: 0.06150990099009901

Validation results:
gen_loss: 0.110388026
disc_loss: 2.7995415
disc_acc: 0.06349206349206349


	Epoch 114
Training results:
gen_loss: 0.09919427
disc_loss: 2.8138213
disc_acc: 0.05903465346534653

Validation results:
gen_loss: 0.0872729
disc_loss: 2.7921276
disc_acc: 0.05257936507936508


	Epoch 115
Training results:
gen_loss: 0.262097
disc_loss: 4.396301
disc_acc: 0.07017326732673268

Validation results:
gen_loss: 0.15405129
disc_loss: 2.940701
disc_acc: 0.07341269841269842


	Epoch 116
Training results:
gen_loss: 0.11542081
disc_loss: 2.8480213
disc_acc: 0.060767326732673266

Validation results:
gen_loss: 0.113136455
disc_loss: 2.831209
disc_acc: 0.07341269841269842


	Epoch 117
Training results:
gen_loss: 0.09884004
disc_loss: 2.808716
disc_acc: 0.06262376237623762

Validation results:
gen_loss: 0.097726606
disc_loss: 2.8184402
disc_acc: 0.05505952380952381


	Epoch 118
Training results:
gen_loss: 0.09325732
disc_loss: 2.7987473
disc_acc: 0.06336633663366337

Validation results:
gen_loss: 0.103024535
disc_loss: 2.8052998
disc_acc: 0.05257936507936508


	Epoch 119
Training results:
gen_loss: 0.0896007
disc_loss: 2.7988706
disc_acc: 0.059158415841584155

Validation results:
gen_loss: 0.07912711
disc_loss: 2.7864273
disc_acc: 0.0689484126984127


	Epoch 120
Training results:
gen_loss: 0.09049569
disc_loss: 2.7983732
disc_acc: 0.05742574257425743

Validation results:
gen_loss: 0.12908275
disc_loss: 2.830998
disc_acc: 0.06349206349206349


	Epoch 121
Training results:
gen_loss: 0.097769886
disc_loss: 2.8087296
disc_acc: 0.06349009900990099

Validation results:
gen_loss: 0.08623513
disc_loss: 2.80583
disc_acc: 0.06349206349206349


	Epoch 122
Training results:
gen_loss: 0.095527
disc_loss: 2.8105009
disc_acc: 0.05631188118811881

Validation results:
gen_loss: 0.08729032
disc_loss: 2.7919114
disc_acc: 0.05853174603174603


	Epoch 123
Training results:
gen_loss: 0.100976855
disc_loss: 2.8102312
disc_acc: 0.06423267326732673

Validation results:
gen_loss: 0.09291174
disc_loss: 2.8277953
disc_acc: 0.054563492063492064


	Epoch 124
Training results:
gen_loss: 0.098402575
disc_loss: 2.809754
disc_acc: 0.059777227722772275

Validation results:
gen_loss: 0.09797966
disc_loss: 2.8024094
disc_acc: 0.06299603174603174


	Epoch 125
Training results:
gen_loss: 0.10465314
disc_loss: 2.8207488
disc_acc: 0.06497524752475248

Validation results:
gen_loss: 0.0917277
disc_loss: 2.806688
disc_acc: 0.053075396825396824


	Epoch 126
Training results:
gen_loss: 0.100074224
disc_loss: 2.8123496
disc_acc: 0.0599009900990099

Validation results:
gen_loss: 0.09467273
disc_loss: 2.838599
disc_acc: 0.062003968253968256


	Epoch 127
Training results:
gen_loss: 0.094407655
disc_loss: 2.8025217
disc_acc: 0.06608910891089109

Validation results:
gen_loss: 0.078891166
disc_loss: 2.780778
disc_acc: 0.060515873015873016


	Epoch 128
Training results:
gen_loss: 0.120460734
disc_loss: 2.8528252
disc_acc: 0.0655940594059406

Validation results:
gen_loss: 0.14921838
disc_loss: 2.9189792
disc_acc: 0.07390873015873016


	Epoch 129
Training results:
gen_loss: 0.106708355
disc_loss: 2.8222008
disc_acc: 0.06361386138613861

Validation results:
gen_loss: 0.097381085
disc_loss: 2.8186214
disc_acc: 0.05853174603174603


	Epoch 130
Training results:
gen_loss: 0.09698039
disc_loss: 2.803507
disc_acc: 0.0646039603960396

Validation results:
gen_loss: 0.09161546
disc_loss: 2.8083792
disc_acc: 0.05803571428571429


	Epoch 131
Training results:
gen_loss: 0.118386
disc_loss: 2.8278027
disc_acc: 0.06782178217821783

Validation results:
gen_loss: 0.26619363
disc_loss: 3.0332823
disc_acc: 0.12251984126984126


	Epoch 132
Training results:
gen_loss: 0.11911351
disc_loss: 2.8508785
disc_acc: 0.06336633663366337

Validation results:
gen_loss: 0.08481706
disc_loss: 2.7901368
disc_acc: 0.06349206349206349


	Epoch 133
Training results:
gen_loss: 0.09391185
disc_loss: 2.7991936
disc_acc: 0.06448019801980198

Validation results:
gen_loss: 0.07800195
disc_loss: 2.7857323
disc_acc: 0.07341269841269842


	Epoch 134
Training results:
gen_loss: 0.08699534
disc_loss: 2.7915275
disc_acc: 0.06089108910891089

Validation results:
gen_loss: 0.085709535
disc_loss: 2.798675
disc_acc: 0.06001984126984127


	Epoch 135
Training results:
gen_loss: 0.093857795
disc_loss: 2.805231
disc_acc: 0.06027227722772277

Validation results:
gen_loss: 0.081781104
disc_loss: 2.7800553
disc_acc: 0.07093253968253968


	Epoch 136
Training results:
gen_loss: 0.1264183
disc_loss: 2.8873696
disc_acc: 0.06212871287128713

Validation results:
gen_loss: 0.16411604
disc_loss: 2.8659601
disc_acc: 0.062003968253968256


	Epoch 137
Training results:
gen_loss: 0.111342266
disc_loss: 2.8304427
disc_acc: 0.06943069306930694

Validation results:
gen_loss: 0.100228995
disc_loss: 2.7989812
disc_acc: 0.07093253968253968


	Epoch 138
Training results:
gen_loss: 0.10121383
disc_loss: 2.8122985
disc_acc: 0.0629950495049505

Validation results:
gen_loss: 0.14734508
disc_loss: 3.1564412
disc_acc: 0.06299603174603174


	Epoch 139
Training results:
gen_loss: 0.11917971
disc_loss: 2.864825
disc_acc: 0.057920792079207924

Validation results:
gen_loss: 0.09955085
disc_loss: 2.818351
disc_acc: 0.062003968253968256


	Epoch 140
Training results:
gen_loss: 0.10096079
disc_loss: 2.812672
disc_acc: 0.0646039603960396

Validation results:
gen_loss: 0.13793318
disc_loss: 2.8669646
disc_acc: 0.05853174603174603


	Epoch 141
Training results:
gen_loss: 0.106778964
disc_loss: 2.8230343
disc_acc: 0.06274752475247525

Validation results:
gen_loss: 0.09585009
disc_loss: 2.8169515
disc_acc: 0.060515873015873016


	Epoch 142
Training results:
gen_loss: 0.11182565
disc_loss: 2.8321435
disc_acc: 0.06918316831683169

Validation results:
gen_loss: 0.097952165
disc_loss: 2.8355167
disc_acc: 0.062003968253968256


	Epoch 143
Training results:
gen_loss: 0.100640826
disc_loss: 2.8102143
disc_acc: 0.06262376237623762

Validation results:
gen_loss: 0.07983432
disc_loss: 2.7745562
disc_acc: 0.06845238095238096


	Epoch 144
Training results:
gen_loss: 0.09957626
disc_loss: 2.8081229
disc_acc: 0.0655940594059406

Validation results:
gen_loss: 0.10296306
disc_loss: 2.8215156
disc_acc: 0.05505952380952381


	Epoch 145
Training results:
gen_loss: 0.099638276
disc_loss: 2.8131092
disc_acc: 0.06188118811881188

Validation results:
gen_loss: 0.2210891
disc_loss: 3.1189625
disc_acc: 0.0625


	Epoch 146
Training results:
gen_loss: 0.11659226
disc_loss: 2.8592553
disc_acc: 0.060148514851485146

Validation results:
gen_loss: 0.119743556
disc_loss: 2.8448164
disc_acc: 0.05505952380952381


	Epoch 147
Training results:
gen_loss: 0.11331485
disc_loss: 2.8258572
disc_acc: 0.07004950495049506

Validation results:
gen_loss: 0.10982352
disc_loss: 2.8255613
disc_acc: 0.07093253968253968


	Epoch 148
Training results:
gen_loss: 0.09850852
disc_loss: 2.8104136
disc_acc: 0.06361386138613861

Validation results:
gen_loss: 0.09435213
disc_loss: 2.8062716
disc_acc: 0.061507936507936505


	Epoch 149
Training results:
gen_loss: 0.09654512
disc_loss: 2.8090727
disc_acc: 0.06163366336633663

Validation results:
gen_loss: 0.07238233
disc_loss: 2.7767117
disc_acc: 0.07390873015873016


	Epoch 150
Training results:
gen_loss: 0.10123611
disc_loss: 2.8097525
disc_acc: 0.06386138613861386

Validation results:
gen_loss: 0.0988357
disc_loss: 2.8265631
disc_acc: 0.06349206349206349


	Epoch 151
Training results:
gen_loss: 0.10182277
disc_loss: 2.8163023
disc_acc: 0.05841584158415842

Validation results:
gen_loss: 0.10789008
disc_loss: 2.8121748
disc_acc: 0.05803571428571429


	Epoch 152
Training results:
gen_loss: 0.10278491
disc_loss: 2.8123884
disc_acc: 0.0629950495049505

Validation results:
gen_loss: 0.08457247
disc_loss: 2.7939363
disc_acc: 0.057539682539682536


	Epoch 153
Training results:
gen_loss: 0.09500386
disc_loss: 2.8031678
disc_acc: 0.06423267326732673

Validation results:
gen_loss: 0.0777863
disc_loss: 2.7813668
disc_acc: 0.0689484126984127


	Epoch 154
Training results:
gen_loss: 0.09677702
disc_loss: 2.807429
disc_acc: 0.06646039603960396

Validation results:
gen_loss: 0.1136804
disc_loss: 2.804075
disc_acc: 0.06398809523809523


	Epoch 155
Training results:
gen_loss: 0.10672806
disc_loss: 2.8169196
disc_acc: 0.06794554455445545

Validation results:
gen_loss: 0.08926102
disc_loss: 2.8157904
disc_acc: 0.06845238095238096


	Epoch 156
Training results:
gen_loss: 0.10475488
disc_loss: 2.8168845
disc_acc: 0.06782178217821783

Validation results:
gen_loss: 0.09941321
disc_loss: 2.8106177
disc_acc: 0.061507936507936505


	Epoch 157
Training results:
gen_loss: 0.11284433
disc_loss: 2.8473282
disc_acc: 0.06175742574257426

Validation results:
gen_loss: 0.101054735
disc_loss: 2.7975342
disc_acc: 0.057539682539682536


	Epoch 158
Training results:
gen_loss: 0.09523455
disc_loss: 2.7991908
disc_acc: 0.06311881188118812

Validation results:
gen_loss: 0.0864851
disc_loss: 2.7922835
disc_acc: 0.06845238095238096


	Epoch 159
Training results:
gen_loss: 0.10098887
disc_loss: 2.8130047
disc_acc: 0.06113861386138614

Validation results:
gen_loss: 0.09790936
disc_loss: 2.8085084
disc_acc: 0.062003968253968256


	Epoch 160
Training results:
gen_loss: 0.10123542
disc_loss: 2.806696
disc_acc: 0.07103960396039603

Validation results:
gen_loss: 0.15637165
disc_loss: 2.9179354
disc_acc: 0.06845238095238096


	Epoch 161
Training results:
gen_loss: 0.10454526
disc_loss: 2.8170683
disc_acc: 0.06497524752475248

Validation results:
gen_loss: 0.10101279
disc_loss: 2.7985954
disc_acc: 0.07341269841269842


	Epoch 162
Training results:
gen_loss: 0.098000884
disc_loss: 2.8095834
disc_acc: 0.06027227722772277

Validation results:
gen_loss: 0.0814308
disc_loss: 2.7844224
disc_acc: 0.07093253968253968


	Epoch 163
Training results:
gen_loss: 0.09416544
disc_loss: 2.8044438
disc_acc: 0.06212871287128713

Validation results:
gen_loss: 0.11717489
disc_loss: 2.8136868
disc_acc: 0.061507936507936505


	Epoch 164
Training results:
gen_loss: 0.10516918
disc_loss: 2.8201125
disc_acc: 0.06051980198019802

Validation results:
gen_loss: 0.14022997
disc_loss: 2.861975
disc_acc: 0.06398809523809523


	Epoch 165
Training results:
gen_loss: 0.114567354
disc_loss: 2.8612251
disc_acc: 0.062004950495049505

Validation results:
gen_loss: 0.09385653
disc_loss: 2.8007238
disc_acc: 0.05853174603174603


	Epoch 166
Training results:
gen_loss: 0.09195876
disc_loss: 2.799006
disc_acc: 0.06188118811881188

Validation results:
gen_loss: 0.083327904
disc_loss: 2.792566
disc_acc: 0.062003968253968256


	Epoch 167
Training results:
gen_loss: 0.092376545
disc_loss: 2.8017018
disc_acc: 0.062004950495049505

Validation results:
gen_loss: 0.08575284
disc_loss: 2.7994459
disc_acc: 0.06845238095238096


	Epoch 168
Training results:
gen_loss: 0.09501709
disc_loss: 2.8122458
disc_acc: 0.06051980198019802

Validation results:
gen_loss: 0.08806723
disc_loss: 2.8066301
disc_acc: 0.060515873015873016


	Epoch 169
Training results:
gen_loss: 0.09737865
disc_loss: 2.8118978
disc_acc: 0.06089108910891089

Validation results:
gen_loss: 0.08775935
disc_loss: 2.8050673
disc_acc: 0.057539682539682536


	Epoch 170
Training results:
gen_loss: 0.097332716
disc_loss: 2.8061223
disc_acc: 0.06311881188118812

Validation results:
gen_loss: 0.088985994
disc_loss: 2.7926157
disc_acc: 0.0744047619047619


	Epoch 171
Training results:
gen_loss: 0.10956284
disc_loss: 2.8310542
disc_acc: 0.0594059405940594

Validation results:
gen_loss: 0.093716204
disc_loss: 2.7917
disc_acc: 0.062003968253968256


	Epoch 172
Training results:
gen_loss: 0.09768055
disc_loss: 2.8057215
disc_acc: 0.06646039603960396

Validation results:
gen_loss: 0.089391656
disc_loss: 2.7932498
disc_acc: 0.07341269841269842


	Epoch 173
Training results:
gen_loss: 0.09550523
disc_loss: 2.8092268
disc_acc: 0.060148514851485146

Validation results:
gen_loss: 0.07953076
disc_loss: 2.7828257
disc_acc: 0.054563492063492064


	Epoch 174
Training results:
gen_loss: 0.10483548
disc_loss: 2.819306
disc_acc: 0.060767326732673266

Validation results:
gen_loss: 0.103139736
disc_loss: 2.8210764
disc_acc: 0.05704365079365079


	Epoch 175
Training results:
gen_loss: 0.10516183
disc_loss: 2.821313
disc_acc: 0.0655940594059406

Validation results:
gen_loss: 0.07983588
disc_loss: 2.7834692
disc_acc: 0.06349206349206349


	Epoch 176
Training results:
gen_loss: 0.09931234
disc_loss: 2.8101692
disc_acc: 0.06398514851485149

Validation results:
gen_loss: 0.10404249
disc_loss: 2.8280075
disc_acc: 0.05505952380952381


	Epoch 177
Training results:
gen_loss: 0.111025676
disc_loss: 2.8297775
disc_acc: 0.06881188118811882

Validation results:
gen_loss: 0.14773192
disc_loss: 2.9732633
disc_acc: 0.062003968253968256


	Epoch 178
Training results:
gen_loss: 0.097709686
disc_loss: 2.8073335
disc_acc: 0.06126237623762376

Validation results:
gen_loss: 0.083669625
disc_loss: 2.7881513
disc_acc: 0.060515873015873016


	Epoch 179
Training results:
gen_loss: 0.091606244
disc_loss: 2.8042731
disc_acc: 0.06150990099009901

Validation results:
gen_loss: 0.0928159
disc_loss: 2.810494
disc_acc: 0.0679563492063492


	Epoch 180
Training results:
gen_loss: 0.094853096
disc_loss: 2.8031893
disc_acc: 0.06522277227722773

Validation results:
gen_loss: 0.07970552
disc_loss: 2.7928462
disc_acc: 0.062003968253968256


	Epoch 181
Training results:
gen_loss: 0.10846662
disc_loss: 2.8215842
disc_acc: 0.06732673267326733

Validation results:
gen_loss: 0.076774985
disc_loss: 2.7940142
disc_acc: 0.062003968253968256


	Epoch 182
Training results:
gen_loss: 0.100117095
disc_loss: 2.808454
disc_acc: 0.06150990099009901

Validation results:
gen_loss: 0.07955641
disc_loss: 2.7948112
disc_acc: 0.0625


	Epoch 183
Training results:
gen_loss: 0.09369287
disc_loss: 2.8010056
disc_acc: 0.06361386138613861

Validation results:
gen_loss: 0.083045386
disc_loss: 2.7866604
disc_acc: 0.05257936507936508


	Epoch 184
Training results:
gen_loss: 0.09789073
disc_loss: 2.8171666
disc_acc: 0.062376237623762376

Validation results:
gen_loss: 0.10516898
disc_loss: 2.799278
disc_acc: 0.060515873015873016


	Epoch 185
Training results:
gen_loss: 0.10553175
disc_loss: 2.8162956
disc_acc: 0.06188118811881188

Validation results:
gen_loss: 0.0886647
disc_loss: 2.8008046
disc_acc: 0.05803571428571429


	Epoch 186
Training results:
gen_loss: 0.095554195
disc_loss: 2.8057477
disc_acc: 0.058292079207920795

Validation results:
gen_loss: 0.087798424
disc_loss: 2.7859764
disc_acc: 0.05257936507936508


	Epoch 187
Training results:
gen_loss: 0.08934421
disc_loss: 2.7966864
disc_acc: 0.0646039603960396

Validation results:
gen_loss: 0.12444908
disc_loss: 2.8197875
disc_acc: 0.05853174603174603


	Epoch 188
Training results:
gen_loss: 0.123282224
disc_loss: 2.8808935
disc_acc: 0.062376237623762376

Validation results:
gen_loss: 0.24917857
disc_loss: 3.0640593
disc_acc: 0.0689484126984127


	Epoch 189
Training results:
gen_loss: 0.096243076
disc_loss: 2.8093052
disc_acc: 0.06113861386138614

Validation results:
gen_loss: 0.086401306
disc_loss: 2.7948048
disc_acc: 0.05704365079365079


	Epoch 190
Training results:
gen_loss: 0.091502614
disc_loss: 2.7964046
disc_acc: 0.06571782178217822

Validation results:
gen_loss: 0.092839055
disc_loss: 2.7937033
disc_acc: 0.05853174603174603


	Epoch 191
Training results:
gen_loss: 0.10050031
disc_loss: 2.816466
disc_acc: 0.06361386138613861

Validation results:
gen_loss: 0.1455792
disc_loss: 2.8610668
disc_acc: 0.060515873015873016


	Epoch 192
Training results:
gen_loss: 0.10259975
disc_loss: 2.8091183
disc_acc: 0.06262376237623762

Validation results:
gen_loss: 0.1012958
disc_loss: 2.8008378
disc_acc: 0.05803571428571429


	Epoch 193
Training results:
gen_loss: 0.29342136
disc_loss: 6.4849877
disc_acc: 0.07957920792079208

Validation results:
gen_loss: 0.21993436
disc_loss: 3.4820926
disc_acc: 0.06845238095238096


	Epoch 194
Training results:
gen_loss: 0.1601282
disc_loss: 2.9935005
disc_acc: 0.05804455445544555

Validation results:
gen_loss: 0.1715066
disc_loss: 3.0625744
disc_acc: 0.060515873015873016


	Epoch 195
Training results:
gen_loss: 0.1238103
disc_loss: 2.8765795
disc_acc: 0.062004950495049505

Validation results:
gen_loss: 0.11602413
disc_loss: 2.8141494
disc_acc: 0.06845238095238096


	Epoch 196
Training results:
gen_loss: 0.11215765
disc_loss: 2.8400307
disc_acc: 0.06485148514851485

Validation results:
gen_loss: 0.094124235
disc_loss: 2.8270614
disc_acc: 0.0625


	Epoch 197
Training results:
gen_loss: 0.106513046
disc_loss: 2.8285751
disc_acc: 0.062004950495049505

Validation results:
gen_loss: 0.09965584
disc_loss: 2.8140788
disc_acc: 0.053075396825396824


	Epoch 198
Training results:
gen_loss: 0.10227933
disc_loss: 2.8182104
disc_acc: 0.06324257425742574

Validation results:
gen_loss: 0.09324849
disc_loss: 2.797476
disc_acc: 0.053075396825396824


	Epoch 199
Training results:
gen_loss: 0.09697922
disc_loss: 2.8064938
disc_acc: 0.06089108910891089

Validation results:
gen_loss: 0.124023184
disc_loss: 2.8240151
disc_acc: 0.06845238095238096


	Epoch 200
Training results:
gen_loss: 0.103014566
disc_loss: 2.8396645
disc_acc: 0.06064356435643564

Validation results:
gen_loss: 0.43241987
disc_loss: 3.6656363
disc_acc: 0.054563492063492064


	Epoch 201
Training results:
gen_loss: 0.13671567
disc_loss: 2.973687
disc_acc: 0.06361386138613861

Validation results:
gen_loss: 0.102525875
disc_loss: 2.8011355
disc_acc: 0.06349206349206349


	Epoch 202
Training results:
gen_loss: 0.09035348
disc_loss: 2.7992687
disc_acc: 0.05693069306930693

Validation results:
gen_loss: 0.11082102
disc_loss: 2.8312902
disc_acc: 0.05853174603174603


	Epoch 203
Training results:
gen_loss: 0.09569129
disc_loss: 2.8028362
disc_acc: 0.06150990099009901

Validation results:
gen_loss: 0.10276273
disc_loss: 2.8261545
disc_acc: 0.05853174603174603


	Epoch 204
Training results:
gen_loss: 0.090977505
disc_loss: 2.7995274
disc_acc: 0.059158415841584155

Validation results:
gen_loss: 0.10284615
disc_loss: 2.8211336
disc_acc: 0.05803571428571429


	Epoch 205
Training results:
gen_loss: 0.09488322
disc_loss: 2.800807
disc_acc: 0.06423267326732673

Validation results:
gen_loss: 0.09235094
disc_loss: 2.7980669
disc_acc: 0.057539682539682536


	Epoch 206
Training results:
gen_loss: 0.09685627
disc_loss: 2.809735
disc_acc: 0.06188118811881188

Validation results:
gen_loss: 0.10063264
disc_loss: 2.799379
disc_acc: 0.060515873015873016


	Epoch 207
Training results:
gen_loss: 0.10190747
disc_loss: 2.8164074
disc_acc: 0.062376237623762376

Validation results:
gen_loss: 0.104344204
disc_loss: 2.8001463
disc_acc: 0.05704365079365079


	Epoch 208
Training results:
gen_loss: 0.10249275
disc_loss: 2.813015
disc_acc: 0.06695544554455446

Validation results:
gen_loss: 0.18095179
disc_loss: 3.0915966
disc_acc: 0.06299603174603174


	Epoch 209
Training results:
gen_loss: 0.23308069
disc_loss: 3.9462812
disc_acc: 0.07128712871287128

Validation results:
gen_loss: 0.09260381
disc_loss: 2.810065
disc_acc: 0.06101190476190476


	Epoch 210
Training results:
gen_loss: 0.10112468
disc_loss: 2.8123367
disc_acc: 0.061386138613861385

Validation results:
gen_loss: 0.082765505
disc_loss: 2.7884014
disc_acc: 0.06349206349206349


	Epoch 211
Training results:
gen_loss: 0.091591574
disc_loss: 2.796674
disc_acc: 0.06324257425742574

Validation results:
gen_loss: 0.09265937
disc_loss: 2.8033848
disc_acc: 0.06845238095238096


	Epoch 212
Training results:
gen_loss: 0.09072406
disc_loss: 2.7964072
disc_acc: 0.06150990099009901

Validation results:
gen_loss: 0.09097905
disc_loss: 2.8019192
disc_acc: 0.07093253968253968


	Epoch 213
Training results:
gen_loss: 0.08809097
disc_loss: 2.7956398
disc_acc: 0.06064356435643564

Validation results:
gen_loss: 0.08321269
disc_loss: 2.784047
disc_acc: 0.06001984126984127


	Epoch 214
Training results:
gen_loss: 0.090037994
disc_loss: 2.7985048
disc_acc: 0.06002475247524752

Validation results:
gen_loss: 0.08247948
disc_loss: 2.7934945
disc_acc: 0.0679563492063492


	Epoch 215
Training results:
gen_loss: 0.09309964
disc_loss: 2.8043704
disc_acc: 0.06188118811881188

Validation results:
gen_loss: 0.101086654
disc_loss: 2.8218665
disc_acc: 0.05853174603174603


	Epoch 216
Training results:
gen_loss: 0.094376385
disc_loss: 2.801764
disc_acc: 0.060148514851485146

Validation results:
gen_loss: 0.0850223
disc_loss: 2.8123345
disc_acc: 0.05803571428571429


	Epoch 217
Training results:
gen_loss: 0.09675359
disc_loss: 2.812366
disc_acc: 0.057301980198019804

Validation results:
gen_loss: 0.12816508
disc_loss: 2.843579
disc_acc: 0.0625


	Epoch 218
Training results:
gen_loss: 0.0943022
disc_loss: 2.802595
disc_acc: 0.06274752475247525

Validation results:
gen_loss: 0.10081758
disc_loss: 2.806377
disc_acc: 0.07093253968253968


	Epoch 219
Training results:
gen_loss: 0.105064966
disc_loss: 2.822166
disc_acc: 0.058787128712871284

Validation results:
gen_loss: 0.10141732
disc_loss: 2.841268
disc_acc: 0.05505952380952381


	Epoch 220
Training results:
gen_loss: 0.10887696
disc_loss: 2.8210642
disc_acc: 0.06410891089108911

Validation results:
gen_loss: 0.10023551
disc_loss: 2.8136837
disc_acc: 0.062003968253968256


	Epoch 221
Training results:
gen_loss: 0.09857368
disc_loss: 2.8104663
disc_acc: 0.0594059405940594

Validation results:
gen_loss: 0.08589665
disc_loss: 2.786084
disc_acc: 0.0689484126984127


	Epoch 222
Training results:
gen_loss: 0.09302791
disc_loss: 2.8044531
disc_acc: 0.06089108910891089

Validation results:
gen_loss: 0.16175194
disc_loss: 2.8481507
disc_acc: 0.061507936507936505


	Epoch 223
Training results:
gen_loss: 0.10078595
disc_loss: 2.8125577
disc_acc: 0.06089108910891089

Validation results:
gen_loss: 0.11619833
disc_loss: 2.8257215
disc_acc: 0.06349206349206349


	Epoch 224
Training results:
gen_loss: 0.095292374
disc_loss: 2.8284705
disc_acc: 0.06150990099009901

Validation results:
gen_loss: 0.13895865
disc_loss: 2.886958
disc_acc: 0.06349206349206349


	Epoch 225
Training results:
gen_loss: 0.12055375
disc_loss: 2.8589272
disc_acc: 0.06398514851485149

Validation results:
gen_loss: 0.09855504
disc_loss: 2.8195899
disc_acc: 0.05853174603174603


	Epoch 226
Training results:
gen_loss: 0.093801506
disc_loss: 2.801847
disc_acc: 0.06113861386138614

Validation results:
gen_loss: 0.075442545
disc_loss: 2.7765703
disc_acc: 0.05505952380952381


	Epoch 227
Training results:
gen_loss: 0.09154355
disc_loss: 2.8001027
disc_acc: 0.06051980198019802

Validation results:
gen_loss: 0.09475519
disc_loss: 2.7927008
disc_acc: 0.05505952380952381


	Epoch 228
Training results:
gen_loss: 0.10187741
disc_loss: 2.815333
disc_acc: 0.06398514851485149

Validation results:
gen_loss: 0.1457322
disc_loss: 2.85016
disc_acc: 0.0679563492063492


	Epoch 229
Training results:
gen_loss: 0.10340224
disc_loss: 2.8155215
disc_acc: 0.060148514851485146

Validation results:
gen_loss: 0.09544774
disc_loss: 2.8127367
disc_acc: 0.05704365079365079


	Epoch 230
Training results:
gen_loss: 0.09726849
disc_loss: 2.8105779
disc_acc: 0.05655940594059406

Validation results:
gen_loss: 0.11705941
disc_loss: 2.814473
disc_acc: 0.057539682539682536


	Epoch 231
Training results:
gen_loss: 0.090529665
disc_loss: 2.7998424
disc_acc: 0.06002475247524752

Validation results:
gen_loss: 0.08796418
disc_loss: 2.7979896
disc_acc: 0.05853174603174603


	Epoch 232
Training results:
gen_loss: 0.100187875
disc_loss: 2.8177364
disc_acc: 0.06225247524752475

Validation results:
gen_loss: 0.10011865
disc_loss: 2.8231914
disc_acc: 0.06398809523809523


	Epoch 233
Training results:
gen_loss: 0.10188785
disc_loss: 2.8169603
disc_acc: 0.06410891089108911

Validation results:
gen_loss: 0.08238767
disc_loss: 2.7859435
disc_acc: 0.06349206349206349


	Epoch 234
Training results:
gen_loss: 0.0933269
disc_loss: 2.8014045
disc_acc: 0.055074257425742575

Validation results:
gen_loss: 0.079450525
disc_loss: 2.7880707
disc_acc: 0.053075396825396824


	Epoch 235
Training results:
gen_loss: 0.10497664
disc_loss: 2.818621
disc_acc: 0.06881188118811882

Validation results:
gen_loss: 0.09353579
disc_loss: 2.8151045
disc_acc: 0.060515873015873016


	Epoch 236
Training results:
gen_loss: 0.09804418
disc_loss: 2.8122752
disc_acc: 0.06410891089108911

Validation results:
gen_loss: 0.08482159
disc_loss: 2.8131077
disc_acc: 0.06845238095238096


	Epoch 237
Training results:
gen_loss: 0.09306919
disc_loss: 2.8001528
disc_acc: 0.06126237623762376

Validation results:
gen_loss: 0.10832404
disc_loss: 2.8256395
disc_acc: 0.06299603174603174


	Epoch 238
Training results:
gen_loss: 0.099956885
disc_loss: 2.8128397
disc_acc: 0.06324257425742574

Validation results:
gen_loss: 0.11307429
disc_loss: 2.8335557
disc_acc: 0.06349206349206349


	Epoch 239
Training results:
gen_loss: 0.09840824
disc_loss: 2.8101072
disc_acc: 0.060767326732673266

Validation results:
gen_loss: 0.09953852
disc_loss: 2.8618689
disc_acc: 0.06349206349206349


	Epoch 240
Training results:
gen_loss: 0.09955412
disc_loss: 2.8186119
disc_acc: 0.0599009900990099

Validation results:
gen_loss: 0.11240767
disc_loss: 2.8149438
disc_acc: 0.06001984126984127


	Epoch 241
Training results:
gen_loss: 0.09776785
disc_loss: 2.8057835
disc_acc: 0.06410891089108911

Validation results:
gen_loss: 0.1267817
disc_loss: 2.8334463
disc_acc: 0.057539682539682536


	Epoch 242
Training results:
gen_loss: 0.09654637
disc_loss: 2.8069017
disc_acc: 0.0625

Validation results:
gen_loss: 0.08211226
disc_loss: 2.785598
disc_acc: 0.05406746031746032


	Epoch 243
Training results:
gen_loss: 0.09292541
disc_loss: 2.8025439
disc_acc: 0.060396039603960394

Validation results:
gen_loss: 0.10087365
disc_loss: 2.794295
disc_acc: 0.06845238095238096


	Epoch 244
Training results:
gen_loss: 0.15622829
disc_loss: 2.886462
disc_acc: 0.07574257425742574

Validation results:
gen_loss: 0.116823345
disc_loss: 2.8994415
disc_acc: 0.057539682539682536


	Epoch 245
Training results:
gen_loss: 0.09507885
disc_loss: 2.8130472
disc_acc: 0.05891089108910891

Validation results:
gen_loss: 0.07593661
disc_loss: 2.7835028
disc_acc: 0.08134920634920635


	Epoch 246
Training results:
gen_loss: 0.09358208
disc_loss: 2.8027067
disc_acc: 0.06695544554455446

Validation results:
gen_loss: 0.08905529
disc_loss: 2.7896624
disc_acc: 0.05853174603174603


	Epoch 247
Training results:
gen_loss: 0.09524745
disc_loss: 2.804512
disc_acc: 0.060767326732673266

Validation results:
gen_loss: 0.08377917
disc_loss: 2.7949522
disc_acc: 0.06101190476190476


	Epoch 248
Training results:
gen_loss: 0.09160501
disc_loss: 2.7957027
disc_acc: 0.06373762376237624

Validation results:
gen_loss: 0.076683454
disc_loss: 2.7858984
disc_acc: 0.05505952380952381


	Epoch 249
Training results:
gen_loss: 0.10615187
disc_loss: 2.8179607
disc_acc: 0.06621287128712872

Validation results:
gen_loss: 0.091119014
disc_loss: 2.7861888
disc_acc: 0.06349206349206349


	Epoch 250
Training results:
gen_loss: 0.09194378
disc_loss: 2.8018904
disc_acc: 0.057920792079207924

Validation results:
gen_loss: 0.09235254
disc_loss: 2.793246
disc_acc: 0.06349206349206349


	Epoch 251
Training results:
gen_loss: 0.09837914
disc_loss: 2.8098726
disc_acc: 0.06212871287128713

Validation results:
gen_loss: 0.12232254
disc_loss: 2.8275554
disc_acc: 0.062003968253968256


	Epoch 252
Training results:
gen_loss: 0.09142571
disc_loss: 2.8002398
disc_acc: 0.061014851485148514

Validation results:
gen_loss: 0.09274908
disc_loss: 2.8115098
disc_acc: 0.05257936507936508


	Epoch 253
Training results:
gen_loss: 0.09738389
disc_loss: 2.8142793
disc_acc: 0.0577970297029703

Validation results:
gen_loss: 0.10481435
disc_loss: 2.800681
disc_acc: 0.05853174603174603


	Epoch 254
Training results:
gen_loss: 0.1085051
disc_loss: 2.8286595
disc_acc: 0.06349009900990099

Validation results:
gen_loss: 0.083916485
disc_loss: 2.7962914
disc_acc: 0.0625


	Epoch 255
Training results:
gen_loss: 0.096998245
disc_loss: 2.8115237
disc_acc: 0.060396039603960394

Validation results:
gen_loss: 0.085077025
disc_loss: 2.7938502
disc_acc: 0.0689484126984127


	Epoch 256
Training results:
gen_loss: 0.090127066
disc_loss: 2.7930713
disc_acc: 0.06448019801980198

Validation results:
gen_loss: 0.094539106
disc_loss: 2.822727
disc_acc: 0.06845238095238096


	Epoch 257
Training results:
gen_loss: 0.10542119
disc_loss: 2.8199475
disc_acc: 0.06287128712871287

Validation results:
gen_loss: 0.10093332
disc_loss: 2.8278244
disc_acc: 0.05257936507936508


	Epoch 258
Training results:
gen_loss: 0.09931208
disc_loss: 2.8119102
disc_acc: 0.06188118811881188

Validation results:
gen_loss: 0.13178128
disc_loss: 2.8580747
disc_acc: 0.07390873015873016


	Epoch 259
Training results:
gen_loss: 0.09519961
disc_loss: 2.803989
disc_acc: 0.05841584158415842

Validation results:
gen_loss: 0.11589042
disc_loss: 2.8295522
disc_acc: 0.05505952380952381


	Epoch 260
Training results:
gen_loss: 0.09387291
disc_loss: 2.8009663
disc_acc: 0.06720297029702971

Validation results:
gen_loss: 0.10546299
disc_loss: 2.8020108
disc_acc: 0.05853174603174603


	Epoch 261
Training results:
gen_loss: 0.10359017
disc_loss: 2.826622
disc_acc: 0.059158415841584155

Validation results:
gen_loss: 0.08138712
disc_loss: 2.7926364
disc_acc: 0.06349206349206349


	Epoch 262
Training results:
gen_loss: 0.100739785
disc_loss: 2.815542
disc_acc: 0.05952970297029703

Validation results:
gen_loss: 0.090359494
disc_loss: 2.8150496
disc_acc: 0.053075396825396824


	Epoch 263
Training results:
gen_loss: 0.104178615
disc_loss: 2.8177884
disc_acc: 0.06262376237623762

Validation results:
gen_loss: 0.08629018
disc_loss: 2.786198
disc_acc: 0.06001984126984127


	Epoch 264
Training results:
gen_loss: 0.0945718
disc_loss: 2.797661
disc_acc: 0.06646039603960396

Validation results:
gen_loss: 0.11262426
disc_loss: 2.8078291
disc_acc: 0.07390873015873016


	Epoch 265
Training results:
gen_loss: 0.099596776
disc_loss: 2.8115613
disc_acc: 0.0599009900990099

Validation results:
gen_loss: 0.08932959
disc_loss: 2.8071876
disc_acc: 0.05853174603174603


	Epoch 266
Training results:
gen_loss: 0.09309599
disc_loss: 2.8010354
disc_acc: 0.05952970297029703

Validation results:
gen_loss: 0.11263926
disc_loss: 2.8071382
disc_acc: 0.053075396825396824


	Epoch 267
Training results:
gen_loss: 0.093273915
disc_loss: 2.800002
disc_acc: 0.06683168316831684

Validation results:
gen_loss: 0.10693407
disc_loss: 2.8578057
disc_acc: 0.05853174603174603


	Epoch 268
Training results:
gen_loss: 0.12289893
disc_loss: 2.8600454
disc_acc: 0.06683168316831684

Validation results:
gen_loss: 0.12017885
disc_loss: 2.905739
disc_acc: 0.053075396825396824


	Epoch 269
Training results:
gen_loss: 0.09605352
disc_loss: 2.809592
disc_acc: 0.061014851485148514

Validation results:
gen_loss: 0.1065551
disc_loss: 2.814338
disc_acc: 0.060515873015873016


	Epoch 270
Training results:
gen_loss: 0.085952446
disc_loss: 2.7919445
disc_acc: 0.06311881188118812

Validation results:
gen_loss: 0.09841336
disc_loss: 2.7981172
disc_acc: 0.06349206349206349


	Epoch 271
Training results:
gen_loss: 0.09741808
disc_loss: 2.8033636
disc_acc: 0.06175742574257426

Validation results:
gen_loss: 0.09405213
disc_loss: 2.8310337
disc_acc: 0.057539682539682536


	Epoch 272
Training results:
gen_loss: 0.103249095
disc_loss: 2.8145967
disc_acc: 0.06311881188118812

Validation results:
gen_loss: 0.08651026
disc_loss: 2.798131
disc_acc: 0.062003968253968256


	Epoch 273
Training results:
gen_loss: 0.09946995
disc_loss: 2.8102868
disc_acc: 0.06051980198019802

Validation results:
gen_loss: 0.07181094
disc_loss: 2.7760873
disc_acc: 0.05803571428571429


	Epoch 274
Training results:
gen_loss: 0.099088624
disc_loss: 2.8125207
disc_acc: 0.06608910891089109

Validation results:
gen_loss: 0.14147818
disc_loss: 2.8646414
disc_acc: 0.05505952380952381


	Epoch 275
Training results:
gen_loss: 0.10756661
disc_loss: 2.8302338
disc_acc: 0.06274752475247525

Validation results:
gen_loss: 0.12971056
disc_loss: 2.817168
disc_acc: 0.062003968253968256


	Epoch 276
Training results:
gen_loss: 0.08951784
disc_loss: 2.7957742
disc_acc: 0.06225247524752475

Validation results:
gen_loss: 0.086921304
disc_loss: 2.799724
disc_acc: 0.062003968253968256


	Epoch 277
Training results:
gen_loss: 0.10244689
disc_loss: 2.8162966
disc_acc: 0.06287128712871287

Validation results:
gen_loss: 0.10022938
disc_loss: 2.856648
disc_acc: 0.06299603174603174


	Epoch 278
Training results:
gen_loss: 0.09951249
disc_loss: 2.8096483
disc_acc: 0.06658415841584159

Validation results:
gen_loss: 0.11460823
disc_loss: 2.807206
disc_acc: 0.05853174603174603


	Epoch 279
Training results:
gen_loss: 0.10274049
disc_loss: 2.8194168
disc_acc: 0.06386138613861386

Validation results:
gen_loss: 0.12544839
disc_loss: 2.8641336
disc_acc: 0.07390873015873016


	Epoch 280
Training results:
gen_loss: 0.09821167
disc_loss: 2.8075335
disc_acc: 0.06423267326732673

Validation results:
gen_loss: 0.12446782
disc_loss: 2.833965
disc_acc: 0.062003968253968256


	Epoch 281
Training results:
gen_loss: 0.09561424
disc_loss: 2.8052285
disc_acc: 0.06027227722772277

Validation results:
gen_loss: 0.09374799
disc_loss: 2.7916596
disc_acc: 0.062003968253968256


	Epoch 282
Training results:
gen_loss: 0.14100724
disc_loss: 2.89134
disc_acc: 0.06633663366336634

Validation results:
gen_loss: 0.099357635
disc_loss: 2.817239
disc_acc: 0.07093253968253968


	Epoch 283
Training results:
gen_loss: 0.09280965
disc_loss: 2.798361
disc_acc: 0.062004950495049505

Validation results:
gen_loss: 0.08588871
disc_loss: 2.796984
disc_acc: 0.05505952380952381


	Epoch 284
Training results:
gen_loss: 0.09267332
disc_loss: 2.802216
disc_acc: 0.0629950495049505

Validation results:
gen_loss: 0.08383661
disc_loss: 2.7963
disc_acc: 0.06349206349206349


	Epoch 285
Training results:
gen_loss: 0.0887103
disc_loss: 2.7913997
disc_acc: 0.0650990099009901

Validation results:
gen_loss: 0.12960668
disc_loss: 2.823003
disc_acc: 0.0689484126984127


	Epoch 286
Training results:
gen_loss: 0.098356955
disc_loss: 2.806847
disc_acc: 0.06188118811881188

Validation results:
gen_loss: 0.12425077
disc_loss: 2.8331363
disc_acc: 0.057539682539682536


	Epoch 287
Training results:
gen_loss: 0.09474472
disc_loss: 2.8054137
disc_acc: 0.057920792079207924

Validation results:
gen_loss: 0.103718415
disc_loss: 2.8250368
disc_acc: 0.060515873015873016


	Epoch 288
Training results:
gen_loss: 0.0988705
disc_loss: 2.813004
disc_acc: 0.06571782178217822

Validation results:
gen_loss: 0.095572054
disc_loss: 2.7881212
disc_acc: 0.06001984126984127


	Epoch 289
Training results:
gen_loss: 0.09932072
disc_loss: 2.8112016
disc_acc: 0.05841584158415842

Validation results:
gen_loss: 0.09632627
disc_loss: 2.807293
disc_acc: 0.06845238095238096


	Epoch 290
Training results:
gen_loss: 0.096293546
disc_loss: 2.8076766
disc_acc: 0.06212871287128713

Validation results:
gen_loss: 0.10713302
disc_loss: 2.82112
disc_acc: 0.053075396825396824


	Epoch 291
Training results:
gen_loss: 0.09316693
disc_loss: 2.8028445
disc_acc: 0.06113861386138614

Validation results:
gen_loss: 0.08480409
disc_loss: 2.7878582
disc_acc: 0.057539682539682536


	Epoch 292
Training results:
gen_loss: 0.10494738
disc_loss: 2.822433
disc_acc: 0.062004950495049505

Validation results:
gen_loss: 0.11287712
disc_loss: 2.8219104
disc_acc: 0.05505952380952381


	Epoch 293
Training results:
gen_loss: 0.09771281
disc_loss: 2.8108964
disc_acc: 0.06027227722772277

Validation results:
gen_loss: 0.13108861
disc_loss: 2.8701966
disc_acc: 0.06398809523809523


	Epoch 294
Training results:
gen_loss: 0.095631704
disc_loss: 2.8048239
disc_acc: 0.06311881188118812

Validation results:
gen_loss: 0.0924134
disc_loss: 2.782117
disc_acc: 0.07390873015873016


	Epoch 295
Training results:
gen_loss: 0.100674234
disc_loss: 2.8090897
disc_acc: 0.06163366336633663

Validation results:
gen_loss: 0.14540912
disc_loss: 2.8448913
disc_acc: 0.06299603174603174


	Epoch 296
Training results:
gen_loss: 0.100078106
disc_loss: 2.812756
disc_acc: 0.05928217821782178

Validation results:
gen_loss: 0.12756297
disc_loss: 2.8726933
disc_acc: 0.05853174603174603


	Epoch 297
Training results:
gen_loss: 0.102369204
disc_loss: 2.8131874
disc_acc: 0.0629950495049505

Validation results:
gen_loss: 0.09787169
disc_loss: 2.8086276
disc_acc: 0.061507936507936505


	Epoch 298
Training results:
gen_loss: 0.090412855
disc_loss: 2.799346
disc_acc: 0.06373762376237624

Validation results:
gen_loss: 0.085859336
disc_loss: 2.801927
disc_acc: 0.0625


	Epoch 299
Training results:
gen_loss: 0.09572999
disc_loss: 2.802907
disc_acc: 0.06534653465346535

Validation results:
gen_loss: 0.085629135
disc_loss: 2.7859416
disc_acc: 0.057539682539682536


	Epoch 300
Training results:
gen_loss: 0.109504744
disc_loss: 2.8347728
disc_acc: 0.06163366336633663

Validation results:
gen_loss: 0.12267467
disc_loss: 2.8153014
disc_acc: 0.06299603174603174


	Epoch 301
Training results:
gen_loss: 0.09081155
disc_loss: 2.7998323
disc_acc: 0.060767326732673266

Validation results:
gen_loss: 0.072454266
disc_loss: 2.7752213
disc_acc: 0.07390873015873016


	Epoch 302
Training results:
gen_loss: 0.09323912
disc_loss: 2.8004649
disc_acc: 0.0599009900990099

Validation results:
gen_loss: 0.09025572
disc_loss: 2.7874968
disc_acc: 0.062003968253968256


	Epoch 303
Training results:
gen_loss: 0.09896575
disc_loss: 2.8093755
disc_acc: 0.062376237623762376

Validation results:
gen_loss: 0.082926616
disc_loss: 2.7949317
disc_acc: 0.062003968253968256


	Epoch 304
Training results:
gen_loss: 0.10081471
disc_loss: 2.8158903
disc_acc: 0.06336633663366337

Validation results:
gen_loss: 0.09401109
disc_loss: 2.7920423
disc_acc: 0.05853174603174603


	Epoch 305
Training results:
gen_loss: 0.1047631
disc_loss: 2.821033
disc_acc: 0.0577970297029703

Validation results:
gen_loss: 0.10439407
disc_loss: 2.828
disc_acc: 0.0689484126984127


	Epoch 306
Training results:
gen_loss: 0.09773865
disc_loss: 2.8039677
disc_acc: 0.06695544554455446

Validation results:
gen_loss: 0.090189844
disc_loss: 2.803197
disc_acc: 0.07043650793650794


	Epoch 307
Training results:
gen_loss: 0.09444135
disc_loss: 2.8053079
disc_acc: 0.06361386138613861

Validation results:
gen_loss: 0.08248314
disc_loss: 2.795966
disc_acc: 0.062003968253968256


	Epoch 308
Training results:
gen_loss: 0.09854473
disc_loss: 2.8113127
disc_acc: 0.06188118811881188

Validation results:
gen_loss: 0.09830398
disc_loss: 2.813699
disc_acc: 0.06845238095238096


	Epoch 309
Training results:
gen_loss: 0.10030935
disc_loss: 2.8162792
disc_acc: 0.061014851485148514

Validation results:
gen_loss: 0.08284822
disc_loss: 2.79943
disc_acc: 0.06349206349206349


	Epoch 310
Training results:
gen_loss: 0.09522478
disc_loss: 2.804076
disc_acc: 0.05928217821782178

Validation results:
gen_loss: 0.08695815
disc_loss: 2.8230605
disc_acc: 0.05505952380952381


	Epoch 311
Training results:
gen_loss: 0.100312695
disc_loss: 2.808454
disc_acc: 0.06633663366336634

Validation results:
gen_loss: 0.10215883
disc_loss: 2.8074439
disc_acc: 0.053075396825396824


	Epoch 312
Training results:
gen_loss: 0.101718694
disc_loss: 2.8141365
disc_acc: 0.06274752475247525

Validation results:
gen_loss: 0.096473046
disc_loss: 2.8097918
disc_acc: 0.05704365079365079


	Epoch 313
Training results:
gen_loss: 0.09821214
disc_loss: 2.8094327
disc_acc: 0.06113861386138614

Validation results:
gen_loss: 0.103199124
disc_loss: 2.8276312
disc_acc: 0.06349206349206349


	Epoch 314
Training results:
gen_loss: 0.1025774
disc_loss: 2.8163493
disc_acc: 0.06089108910891089

Validation results:
gen_loss: 0.09684709
disc_loss: 2.7933955
disc_acc: 0.07390873015873016


	Epoch 315
Training results:
gen_loss: 0.09341627
disc_loss: 2.798287
disc_acc: 0.06448019801980198

Validation results:
gen_loss: 0.11229314
disc_loss: 2.8259377
disc_acc: 0.05505952380952381


	Epoch 316
Training results:
gen_loss: 0.10404072
disc_loss: 2.818726
disc_acc: 0.06212871287128713

Validation results:
gen_loss: 0.101144776
disc_loss: 2.8427694
disc_acc: 0.062003968253968256


	Epoch 317
Training results:
gen_loss: 0.09785017
disc_loss: 2.8125842
disc_acc: 0.06064356435643564

Validation results:
gen_loss: 0.10685369
disc_loss: 2.8093274
disc_acc: 0.062003968253968256


	Epoch 318
Training results:
gen_loss: 0.09653227
disc_loss: 2.8033016
disc_acc: 0.062004950495049505

Validation results:
gen_loss: 0.09262444
disc_loss: 2.8097334
disc_acc: 0.06349206349206349


	Epoch 319
Training results:
gen_loss: 0.096515715
disc_loss: 2.8078284
disc_acc: 0.061014851485148514

Validation results:
gen_loss: 0.093369514
disc_loss: 2.804952
disc_acc: 0.05853174603174603


	Epoch 320
Training results:
gen_loss: 0.09861172
disc_loss: 2.8166533
disc_acc: 0.061014851485148514

Validation results:
gen_loss: 0.09363176
disc_loss: 2.8081143
disc_acc: 0.06349206349206349


	Epoch 321
Training results:
gen_loss: 0.10317899
disc_loss: 2.8127987
disc_acc: 0.06126237623762376

Validation results:
gen_loss: 0.077655874
disc_loss: 2.7884603
disc_acc: 0.053075396825396824


	Epoch 322
Training results:
gen_loss: 0.09122839
disc_loss: 2.7993848
disc_acc: 0.06448019801980198

Validation results:
gen_loss: 0.12144364
disc_loss: 2.8043756
disc_acc: 0.06845238095238096


	Epoch 323
Training results:
gen_loss: 0.10739549
disc_loss: 2.817476
disc_acc: 0.0646039603960396

Validation results:
gen_loss: 0.11263665
disc_loss: 2.8377967
disc_acc: 0.06349206349206349


	Epoch 324
Training results:
gen_loss: 0.09912575
disc_loss: 2.8145843
disc_acc: 0.060148514851485146

Validation results:
gen_loss: 0.11368342
disc_loss: 2.8134038
disc_acc: 0.05803571428571429


	Epoch 325
Training results:
gen_loss: 0.090628356
disc_loss: 2.8023062
disc_acc: 0.06089108910891089

Validation results:
gen_loss: 0.07694922
disc_loss: 2.7895422
disc_acc: 0.05853174603174603


	Epoch 326
Training results:
gen_loss: 0.102821805
disc_loss: 2.8168342
disc_acc: 0.061386138613861385

Validation results:
gen_loss: 0.08007548
disc_loss: 2.7887516
disc_acc: 0.05803571428571429


	Epoch 327
Training results:
gen_loss: 0.10519446
disc_loss: 2.818645
disc_acc: 0.06683168316831684

Validation results:
gen_loss: 0.11707692
disc_loss: 2.8650541
disc_acc: 0.060515873015873016


	Epoch 328
Training results:
gen_loss: 0.094429195
disc_loss: 2.805066
disc_acc: 0.06188118811881188

Validation results:
gen_loss: 0.09685343
disc_loss: 2.818469
disc_acc: 0.05853174603174603


	Epoch 329
Training results:
gen_loss: 0.0967545
disc_loss: 2.8090734
disc_acc: 0.05952970297029703

Validation results:
gen_loss: 0.07771852
disc_loss: 2.7880156
disc_acc: 0.06845238095238096


	Epoch 330
Training results:
gen_loss: 0.0973933
disc_loss: 2.8061829
disc_acc: 0.0646039603960396

Validation results:
gen_loss: 0.23725672
disc_loss: 2.7705283
disc_acc: 0.05853174603174603


	Epoch 331
Training results:
gen_loss: 0.35549474
disc_loss: 8.911293
disc_acc: 0.07462871287128713

Validation results:
gen_loss: 0.19403468
disc_loss: 3.0928068
disc_acc: 0.05257936507936508


	Epoch 332
Training results:
gen_loss: 0.15096955
disc_loss: 2.9511588
disc_acc: 0.06188118811881188

Validation results:
gen_loss: 0.11578571
disc_loss: 2.8979363
disc_acc: 0.060515873015873016


	Epoch 333
Training results:
gen_loss: 0.12231814
disc_loss: 2.8747501
disc_acc: 0.05866336633663366

Validation results:
gen_loss: 0.1307423
disc_loss: 2.8473072
disc_acc: 0.0625


	Epoch 334
Training results:
gen_loss: 0.108959585
disc_loss: 2.8339894
disc_acc: 0.06646039603960396

Validation results:
gen_loss: 0.09940573
disc_loss: 2.8188324
disc_acc: 0.05257936507936508


	Epoch 335
Training results:
gen_loss: 0.101647556
disc_loss: 2.81579
disc_acc: 0.06212871287128713

Validation results:
gen_loss: 0.09783404
disc_loss: 2.7981713
disc_acc: 0.06349206349206349


	Epoch 336
Training results:
gen_loss: 0.09767376
disc_loss: 2.8071883
disc_acc: 0.06571782178217822

Validation results:
gen_loss: 0.10893058
disc_loss: 2.813769
disc_acc: 0.053075396825396824


	Epoch 337
Training results:
gen_loss: 0.09812577
disc_loss: 2.805916
disc_acc: 0.06361386138613861

Validation results:
gen_loss: 0.12727597
disc_loss: 2.8151143
disc_acc: 0.06349206349206349


	Epoch 338
Training results:
gen_loss: 0.09656592
disc_loss: 2.8063607
disc_acc: 0.06089108910891089

Validation results:
gen_loss: 0.09795394
disc_loss: 2.7977383
disc_acc: 0.057539682539682536


	Epoch 339
Training results:
gen_loss: 0.09892067
disc_loss: 2.8118618
disc_acc: 0.06534653465346535

Validation results:
gen_loss: 0.11017143
disc_loss: 2.8066843
disc_acc: 0.06845238095238096


	Epoch 340
Training results:
gen_loss: 0.09895058
disc_loss: 2.8109398
disc_acc: 0.06027227722772277

Validation results:
gen_loss: 0.10538682
disc_loss: 2.8314016
disc_acc: 0.06398809523809523


	Epoch 341
Training results:
gen_loss: 0.10123919
disc_loss: 2.8180168
disc_acc: 0.060148514851485146

Validation results:
gen_loss: 0.08168997
disc_loss: 2.7853456
disc_acc: 0.06299603174603174


	Epoch 342
Training results:
gen_loss: 0.098584816
disc_loss: 2.811431
disc_acc: 0.060767326732673266

Validation results:
gen_loss: 0.10648008
disc_loss: 2.8009946
disc_acc: 0.061507936507936505


	Epoch 343
Training results:
gen_loss: 0.102137186
disc_loss: 2.8135571
disc_acc: 0.06336633663366337

Validation results:
gen_loss: 0.08711725
disc_loss: 2.8093252
disc_acc: 0.061507936507936505


	Epoch 344
Training results:
gen_loss: 0.09851677
disc_loss: 2.8104415
disc_acc: 0.06361386138613861

Validation results:
gen_loss: 0.08409366
disc_loss: 2.7979941
disc_acc: 0.060515873015873016


	Epoch 345
Training results:
gen_loss: 0.102652825
disc_loss: 2.8109434
disc_acc: 0.058292079207920795

Validation results:
gen_loss: 0.11852958
disc_loss: 2.8799736
disc_acc: 0.06001984126984127


	Epoch 346
Training results:
gen_loss: 0.11568847
disc_loss: 2.8296332
disc_acc: 0.06745049504950495

Validation results:
gen_loss: 0.18449251
disc_loss: 2.9699404
disc_acc: 0.09871031746031746


	Epoch 347
Training results:
gen_loss: 0.13246502
disc_loss: 2.8292398
disc_acc: 0.06980198019801981

Validation results:
gen_loss: 0.07732494
disc_loss: 2.782963
disc_acc: 0.06101190476190476


	Epoch 348
Training results:
gen_loss: 0.10665463
disc_loss: 2.8144913
disc_acc: 0.06782178217821783

Validation results:
gen_loss: 0.10408691
disc_loss: 2.8168974
disc_acc: 0.060515873015873016


	Epoch 349
Training results:
gen_loss: 0.096805185
disc_loss: 2.811316
disc_acc: 0.05903465346534653

Validation results:
gen_loss: 0.07527927
disc_loss: 2.7785559
disc_acc: 0.05853174603174603


	Epoch 350
Training results:
gen_loss: 0.09396971
disc_loss: 2.806079
disc_acc: 0.05965346534653465

Validation results:
gen_loss: 0.07935124
disc_loss: 2.788417
disc_acc: 0.057539682539682536


	Epoch 351
Training results:
gen_loss: 0.10405136
disc_loss: 2.8271651
disc_acc: 0.06435643564356436

Validation results:
gen_loss: 0.099112995
disc_loss: 2.8224475
disc_acc: 0.05704365079365079


	Epoch 352
Training results:
gen_loss: 0.09407321
disc_loss: 2.8088355
disc_acc: 0.059158415841584155

Validation results:
gen_loss: 0.08741901
disc_loss: 2.799945
disc_acc: 0.07390873015873016


	Epoch 353
Training results:
gen_loss: 0.10934251
disc_loss: 2.8219519
disc_acc: 0.06584158415841584

Validation results:
gen_loss: 0.10516235
disc_loss: 2.8156435
disc_acc: 0.05853174603174603


	Epoch 354
Training results:
gen_loss: 0.098869994
disc_loss: 2.8165736
disc_acc: 0.056064356435643566

Validation results:
gen_loss: 0.16496055
disc_loss: 2.8689053
disc_acc: 0.05505952380952381


	Epoch 355
Training results:
gen_loss: 0.101082794
disc_loss: 2.819664
disc_acc: 0.06225247524752475

Validation results:
gen_loss: 0.082892604
disc_loss: 2.797385
disc_acc: 0.062003968253968256


	Epoch 356
Training results:
gen_loss: 0.1035209
disc_loss: 2.814054
disc_acc: 0.060396039603960394

Validation results:
gen_loss: 0.08240759
disc_loss: 2.7914207
disc_acc: 0.05505952380952381


	Epoch 357
Training results:
gen_loss: 0.09653181
disc_loss: 2.8070107
disc_acc: 0.061386138613861385

Validation results:
gen_loss: 0.08782961
disc_loss: 2.8197274
disc_acc: 0.057539682539682536


	Epoch 358
Training results:
gen_loss: 0.09893166
disc_loss: 2.8131092
disc_acc: 0.06150990099009901

Validation results:
gen_loss: 0.13735849
disc_loss: 2.8657184
disc_acc: 0.053075396825396824


	Epoch 359
Training results:
gen_loss: 0.09577208
disc_loss: 2.8021696
disc_acc: 0.06212871287128713

Validation results:
gen_loss: 0.13893802
disc_loss: 2.8596888
disc_acc: 0.0625


	Epoch 360
Training results:
gen_loss: 0.095708534
disc_loss: 2.809991
disc_acc: 0.057920792079207924

Validation results:
gen_loss: 0.08045101
disc_loss: 2.7826545
disc_acc: 0.05803571428571429


	Epoch 361
Training results:
gen_loss: 0.099710576
disc_loss: 2.8107522
disc_acc: 0.06633663366336634

Validation results:
gen_loss: 0.091005124
disc_loss: 2.7942832
disc_acc: 0.0689484126984127


	Epoch 362
Training results:
gen_loss: 0.10492763
disc_loss: 2.8281507
disc_acc: 0.059777227722772275

Validation results:
gen_loss: 0.10008548
disc_loss: 2.8199291
disc_acc: 0.06349206349206349


	Epoch 363
Training results:
gen_loss: 0.09525864
disc_loss: 2.801223
disc_acc: 0.06051980198019802

Validation results:
gen_loss: 0.10268968
disc_loss: 2.8172336
disc_acc: 0.06845238095238096


	Epoch 364
Training results:
gen_loss: 0.09656654
disc_loss: 2.8037162
disc_acc: 0.06423267326732673

Validation results:
gen_loss: 0.08619234
disc_loss: 2.799067
disc_acc: 0.0625


	Epoch 365
Training results:
gen_loss: 0.09919737
disc_loss: 2.8099685
disc_acc: 0.06534653465346535

Validation results:
gen_loss: 0.08681903
disc_loss: 2.8012648
disc_acc: 0.062003968253968256


	Epoch 366
Training results:
gen_loss: 0.09940168
disc_loss: 2.8100069
disc_acc: 0.0629950495049505

Validation results:
gen_loss: 0.09003403
disc_loss: 2.7949986
disc_acc: 0.0625


	Epoch 367
Training results:
gen_loss: 0.09994267
disc_loss: 2.8079677
disc_acc: 0.06831683168316832

Validation results:
gen_loss: 0.12725277
disc_loss: 2.8466678
disc_acc: 0.06349206349206349


	Epoch 368
Training results:
gen_loss: 0.09923141
disc_loss: 2.8123786
disc_acc: 0.0594059405940594

Validation results:
gen_loss: 0.108973734
disc_loss: 2.8022358
disc_acc: 0.053075396825396824


	Epoch 369
Training results:
gen_loss: 0.092955016
disc_loss: 2.8009188
disc_acc: 0.06287128712871287

Validation results:
gen_loss: 0.08308982
disc_loss: 2.7763014
disc_acc: 0.06349206349206349


	Epoch 370
Training results:
gen_loss: 0.09783233
disc_loss: 2.8108926
disc_acc: 0.0655940594059406

Validation results:
gen_loss: 0.091252856
disc_loss: 2.790798
disc_acc: 0.05853174603174603


	Epoch 371
Training results:
gen_loss: 0.10392688
disc_loss: 2.819884
disc_acc: 0.061386138613861385

Validation results:
gen_loss: 0.13133529
disc_loss: 2.8391619
disc_acc: 0.05853174603174603


	Epoch 372
Training results:
gen_loss: 0.09630172
disc_loss: 2.8078377
disc_acc: 0.06472772277227723

Validation results:
gen_loss: 0.11445666
disc_loss: 2.8450918
disc_acc: 0.062003968253968256


	Epoch 373
Training results:
gen_loss: 0.09978151
disc_loss: 2.80985
disc_acc: 0.06089108910891089

Validation results:
gen_loss: 0.076592326
disc_loss: 2.791934
disc_acc: 0.06349206349206349


	Epoch 374
Training results:
gen_loss: 0.10253662
disc_loss: 2.8229249
disc_acc: 0.05717821782178218

Validation results:
gen_loss: 0.074068114
disc_loss: 2.7864838
disc_acc: 0.061507936507936505


	Epoch 375
Training results:
gen_loss: 0.09950853
disc_loss: 2.809067
disc_acc: 0.06163366336633663

Validation results:
gen_loss: 0.12490745
disc_loss: 2.8795035
disc_acc: 0.057539682539682536


	Epoch 376
Training results:
gen_loss: 0.100507304
disc_loss: 2.8145862
disc_acc: 0.059777227722772275

Validation results:
gen_loss: 0.0994546
disc_loss: 2.8100402
disc_acc: 0.061507936507936505


	Epoch 377
Training results:
gen_loss: 0.09349432
disc_loss: 2.8028045
disc_acc: 0.058787128712871284

Validation results:
gen_loss: 0.07551199
disc_loss: 2.783651
disc_acc: 0.06845238095238096


	Epoch 378
Training results:
gen_loss: 0.111857966
disc_loss: 2.8381853
disc_acc: 0.06163366336633663

Validation results:
gen_loss: 0.14100182
disc_loss: 2.855818
disc_acc: 0.0625


	Epoch 379
Training results:
gen_loss: 0.10105905
disc_loss: 2.8093538
disc_acc: 0.06163366336633663

Validation results:
gen_loss: 0.07780123
disc_loss: 2.782399
disc_acc: 0.06349206349206349


	Epoch 380
Training results:
gen_loss: 0.0875213
disc_loss: 2.8000028
disc_acc: 0.05754950495049505

Validation results:
gen_loss: 0.0836913
disc_loss: 2.7753367
disc_acc: 0.06845238095238096


	Epoch 381
Training results:
gen_loss: 0.09404113
disc_loss: 2.8000467
disc_acc: 0.06175742574257426

Validation results:
gen_loss: 0.117605984
disc_loss: 2.7995613
disc_acc: 0.062003968253968256


	Epoch 382
Training results:
gen_loss: 0.11075548
disc_loss: 2.8309753
disc_acc: 0.06150990099009901

Validation results:
gen_loss: 0.12434332
disc_loss: 2.8439882
disc_acc: 0.06349206349206349


	Epoch 383
Training results:
gen_loss: 0.10065147
disc_loss: 2.8102303
disc_acc: 0.06423267326732673

Validation results:
gen_loss: 0.09131556
disc_loss: 2.7926161
disc_acc: 0.06398809523809523


	Epoch 384
Training results:
gen_loss: 0.0904013
disc_loss: 2.7980754
disc_acc: 0.06126237623762376

Validation results:
gen_loss: 0.100104265
disc_loss: 2.8058827
disc_acc: 0.053075396825396824


	Epoch 385
Training results:
gen_loss: 0.10094046
disc_loss: 2.8154702
disc_acc: 0.0625

Validation results:
gen_loss: 0.09484308
disc_loss: 2.8300831
disc_acc: 0.05505952380952381


	Epoch 386
Training results:
gen_loss: 0.10108463
disc_loss: 2.8134263
disc_acc: 0.06225247524752475

Validation results:
gen_loss: 0.1017368
disc_loss: 2.7829738
disc_acc: 0.07093253968253968


	Epoch 387
Training results:
gen_loss: 0.102856144
disc_loss: 2.8076022
disc_acc: 0.06435643564356436

Validation results:
gen_loss: 0.07731703
disc_loss: 2.7911172
disc_acc: 0.057539682539682536


	Epoch 388
Training results:
gen_loss: 0.101890266
disc_loss: 2.8143117
disc_acc: 0.06188118811881188

Validation results:
gen_loss: 0.09752193
disc_loss: 2.8005521
disc_acc: 0.06349206349206349


	Epoch 389
Training results:
gen_loss: 0.099005386
disc_loss: 2.8059483
disc_acc: 0.0681930693069307

Validation results:
gen_loss: 0.12580673
disc_loss: 2.8332603
disc_acc: 0.06845238095238096


	Epoch 390
Training results:
gen_loss: 0.0988962
disc_loss: 2.812715
disc_acc: 0.05717821782178218

Validation results:
gen_loss: 0.0806301
disc_loss: 2.781092
disc_acc: 0.057539682539682536


	Epoch 391
Training results:
gen_loss: 0.09560775
disc_loss: 2.8068786
disc_acc: 0.06287128712871287

Validation results:
gen_loss: 0.08496752
disc_loss: 2.78363
disc_acc: 0.0689484126984127


	Epoch 392
Training results:
gen_loss: 0.09709207
disc_loss: 2.8069522
disc_acc: 0.0655940594059406

Validation results:
gen_loss: 0.10499773
disc_loss: 2.8076
disc_acc: 0.062003968253968256


	Epoch 393
Training results:
gen_loss: 0.096382976
disc_loss: 2.805782
disc_acc: 0.06225247524752475

Validation results:
gen_loss: 0.09178115
disc_loss: 2.7951188
disc_acc: 0.07341269841269842


	Epoch 394
Training results:
gen_loss: 0.10339527
disc_loss: 2.819263
disc_acc: 0.06435643564356436

Validation results:
gen_loss: 0.100696474
disc_loss: 2.8075707
disc_acc: 0.05853174603174603


	Epoch 395
Training results:
gen_loss: 0.09265241
disc_loss: 2.801508
disc_acc: 0.0594059405940594

Validation results:
gen_loss: 0.113794364
disc_loss: 2.8395345
disc_acc: 0.05853174603174603


	Epoch 396
Training results:
gen_loss: 0.09936584
disc_loss: 2.8163943
disc_acc: 0.05891089108910891

Validation results:
gen_loss: 0.12342575
disc_loss: 2.8166454
disc_acc: 0.053075396825396824


	Epoch 397
Training results:
gen_loss: 0.098825
disc_loss: 2.808503
disc_acc: 0.06274752475247525

Validation results:
gen_loss: 0.07854863
disc_loss: 2.7811887
disc_acc: 0.062003968253968256


	Epoch 398
Training results:
gen_loss: 0.09037217
disc_loss: 2.8024988
disc_acc: 0.05816831683168317

Validation results:
gen_loss: 0.09768119
disc_loss: 2.8014503
disc_acc: 0.06845238095238096


	Epoch 399
Training results:
gen_loss: 0.098529935
disc_loss: 2.8110385
disc_acc: 0.06336633663366337

Validation results:
gen_loss: 0.099041045
disc_loss: 2.8210108
disc_acc: 0.060515873015873016


	Epoch 400
Training results:
gen_loss: 0.095511
disc_loss: 2.806158
disc_acc: 0.05841584158415842

Validation results:
gen_loss: 0.07484744
disc_loss: 2.7814524
disc_acc: 0.05853174603174603


	Epoch 401
Training results:
gen_loss: 0.10747871
disc_loss: 2.826914
disc_acc: 0.06212871287128713

Validation results:
gen_loss: 0.09411675
disc_loss: 2.8085093
disc_acc: 0.06746031746031746


	Epoch 402
Training results:
gen_loss: 0.09381919
disc_loss: 2.806105
disc_acc: 0.057920792079207924

Validation results:
gen_loss: 0.13222504
disc_loss: 2.8432524
disc_acc: 0.05704365079365079


	Epoch 403
Training results:
gen_loss: 0.108570725
disc_loss: 2.8315816
disc_acc: 0.06336633663366337

Validation results:
gen_loss: 0.089744195
disc_loss: 2.806736
disc_acc: 0.060515873015873016


	Epoch 404
Training results:
gen_loss: 0.09276578
disc_loss: 2.7982724
disc_acc: 0.06410891089108911

Validation results:
gen_loss: 0.097806245
disc_loss: 2.7997565
disc_acc: 0.062003968253968256


	Epoch 405
Training results:
gen_loss: 0.09596804
disc_loss: 2.809162
disc_acc: 0.05952970297029703

Validation results:
gen_loss: 0.100923166
disc_loss: 2.8027685
disc_acc: 0.062003968253968256


	Epoch 406
Training results:
gen_loss: 0.10291607
disc_loss: 2.822624
disc_acc: 0.060148514851485146

Validation results:
gen_loss: 0.119841784
disc_loss: 2.8451931
disc_acc: 0.05803571428571429


	Epoch 407
Training results:
gen_loss: 0.09362319
disc_loss: 2.8056707
disc_acc: 0.058787128712871284

Validation results:
gen_loss: 0.08649983
disc_loss: 2.816179
disc_acc: 0.053075396825396824


	Epoch 408
Training results:
gen_loss: 0.10139696
disc_loss: 2.8132422
disc_acc: 0.06212871287128713

Validation results:
gen_loss: 0.08720117
disc_loss: 2.8132176
disc_acc: 0.057539682539682536


	Epoch 409
Training results:
gen_loss: 0.105534256
disc_loss: 2.8146214
disc_acc: 0.06373762376237624

Validation results:
gen_loss: 0.12277655
disc_loss: 2.853108
disc_acc: 0.062003968253968256


	Epoch 410
Training results:
gen_loss: 0.09600242
disc_loss: 2.810087
disc_acc: 0.06336633663366337

Validation results:
gen_loss: 0.085816644
disc_loss: 2.7826133
disc_acc: 0.06299603174603174


	Epoch 411
Training results:
gen_loss: 0.09845278
disc_loss: 2.8129332
disc_acc: 0.0625

Validation results:
gen_loss: 0.11406085
disc_loss: 2.8208013
disc_acc: 0.062003968253968256


	Epoch 412
Training results:
gen_loss: 0.09662037
disc_loss: 2.8068855
disc_acc: 0.060396039603960394

Validation results:
gen_loss: 0.10334334
disc_loss: 2.811649
disc_acc: 0.05803571428571429


	Epoch 413
Training results:
gen_loss: 0.09975679
disc_loss: 2.8106842
disc_acc: 0.06225247524752475

Validation results:
gen_loss: 0.10524836
disc_loss: 2.813284
disc_acc: 0.062003968253968256


	Epoch 414
Training results:
gen_loss: 0.09168745
disc_loss: 2.8024385
disc_acc: 0.0599009900990099

Validation results:
gen_loss: 0.08226454
disc_loss: 2.8024023
disc_acc: 0.06349206349206349


	Epoch 415
Training results:
gen_loss: 0.09773856
disc_loss: 2.8099236
disc_acc: 0.060767326732673266

Validation results:
gen_loss: 0.0955454
disc_loss: 2.8008647
disc_acc: 0.13640873015873015


	Epoch 416
Training results:
gen_loss: 0.1082431
disc_loss: 2.81598
disc_acc: 0.06423267326732673

Validation results:
gen_loss: 0.11555668
disc_loss: 2.9117484
disc_acc: 0.062003968253968256


	Epoch 417
Training results:
gen_loss: 0.107114434
disc_loss: 2.8210015
disc_acc: 0.06225247524752475

Validation results:
gen_loss: 0.10106857
disc_loss: 2.851845
disc_acc: 0.05853174603174603


	Epoch 418
Training results:
gen_loss: 0.09488981
disc_loss: 2.8024545
disc_acc: 0.05891089108910891

Validation results:
gen_loss: 0.08662792
disc_loss: 2.7888796
disc_acc: 0.05704365079365079


	Epoch 419
Training results:
gen_loss: 0.09577984
disc_loss: 2.8091464
disc_acc: 0.06150990099009901

Validation results:
gen_loss: 0.09291218
disc_loss: 2.8089774
disc_acc: 0.06845238095238096


	Epoch 420
Training results:
gen_loss: 0.09879682
disc_loss: 2.8081963
disc_acc: 0.06522277227722773

Validation results:
gen_loss: 0.09261915
disc_loss: 2.8076952
disc_acc: 0.05803571428571429


	Epoch 421
Training results:
gen_loss: 0.10267026
disc_loss: 2.8206737
disc_acc: 0.060767326732673266

Validation results:
gen_loss: 0.08702373
disc_loss: 2.8024611
disc_acc: 0.0625


	Epoch 422
Training results:
gen_loss: 0.09447159
disc_loss: 2.8007643
disc_acc: 0.06262376237623762

Validation results:
gen_loss: 0.08515607
disc_loss: 2.7938728
disc_acc: 0.06845238095238096


	Epoch 423
Training results:
gen_loss: 0.10279122
disc_loss: 2.8170445
disc_acc: 0.0577970297029703

Validation results:
gen_loss: 0.086227
disc_loss: 2.780288
disc_acc: 0.0625


	Epoch 424
Training results:
gen_loss: 0.0953552
disc_loss: 2.8055596
disc_acc: 0.060767326732673266

Validation results:
gen_loss: 0.08155988
disc_loss: 2.81806
disc_acc: 0.0679563492063492


	Epoch 425
Training results:
gen_loss: 0.106487915
disc_loss: 2.8268201
disc_acc: 0.06373762376237624

Validation results:
gen_loss: 0.08885095
disc_loss: 2.7990882
disc_acc: 0.060515873015873016


	Epoch 426
Training results:
gen_loss: 0.099360384
disc_loss: 2.8133605
disc_acc: 0.06435643564356436

Validation results:
gen_loss: 0.09906398
disc_loss: 2.830618
disc_acc: 0.05853174603174603


	Epoch 427
Training results:
gen_loss: 0.096172564
disc_loss: 2.802965
disc_acc: 0.06410891089108911

Validation results:
gen_loss: 0.0897825
disc_loss: 2.7987573
disc_acc: 0.057539682539682536


	Epoch 428
Training results:
gen_loss: 0.101398125
disc_loss: 2.8081968
disc_acc: 0.06373762376237624

Validation results:
gen_loss: 0.197695
disc_loss: 3.0404627
disc_acc: 0.057539682539682536


	Epoch 429
Training results:
gen_loss: 0.109646626
disc_loss: 2.8216631
disc_acc: 0.06683168316831684

Validation results:
gen_loss: 0.10678095
disc_loss: 2.810561
disc_acc: 0.053075396825396824


	Epoch 430
Training results:
gen_loss: 0.09263218
disc_loss: 2.7997708
disc_acc: 0.06188118811881188

Validation results:
gen_loss: 0.078935206
disc_loss: 2.7791023
disc_acc: 0.062003968253968256


	Epoch 431
Training results:
gen_loss: 0.09408359
disc_loss: 2.8007524
disc_acc: 0.06435643564356436

Validation results:
gen_loss: 0.0984881
disc_loss: 2.8099463
disc_acc: 0.060515873015873016


	Epoch 432
Training results:
gen_loss: 0.09975276
disc_loss: 2.8154423
disc_acc: 0.06027227722772277

Validation results:
gen_loss: 0.08132303
disc_loss: 2.7774596
disc_acc: 0.07341269841269842


	Epoch 433
Training results:
gen_loss: 0.10110728
disc_loss: 2.8130677
disc_acc: 0.06150990099009901

Validation results:
gen_loss: 0.099869594
disc_loss: 2.8340807
disc_acc: 0.07093253968253968


	Epoch 434
Training results:
gen_loss: 0.09446215
disc_loss: 2.8053749
disc_acc: 0.059158415841584155

Validation results:
gen_loss: 0.105176546
disc_loss: 2.801514
disc_acc: 0.07093253968253968


	Epoch 435
Training results:
gen_loss: 0.10464742
disc_loss: 2.8167057
disc_acc: 0.06336633663366337

Validation results:
gen_loss: 0.08924873
disc_loss: 2.791949
disc_acc: 0.060515873015873016


	Epoch 436
Training results:
gen_loss: 0.09455489
disc_loss: 2.807141
disc_acc: 0.06757425742574258

Validation results:
gen_loss: 0.08629946
disc_loss: 2.8182185
disc_acc: 0.05803571428571429


	Epoch 437
Training results:
gen_loss: 0.10031544
disc_loss: 2.811345
disc_acc: 0.06782178217821783

Validation results:
gen_loss: 0.09066249
disc_loss: 2.8006947
disc_acc: 0.05803571428571429


	Epoch 438
Training results:
gen_loss: 0.097157605
disc_loss: 2.8107204
disc_acc: 0.06225247524752475

Validation results:
gen_loss: 0.08041667
disc_loss: 2.782178
disc_acc: 0.06398809523809523


	Epoch 439
Training results:
gen_loss: 0.10003321
disc_loss: 2.8088913
disc_acc: 0.0625

Validation results:
gen_loss: 0.090427466
disc_loss: 2.7846346
disc_acc: 0.06299603174603174


	Epoch 440
Training results:
gen_loss: 0.100263566
disc_loss: 2.8101652
disc_acc: 0.06163366336633663

Validation results:
gen_loss: 0.093593664
disc_loss: 2.8450165
disc_acc: 0.06398809523809523


	Epoch 441
Training results:
gen_loss: 0.09768028
disc_loss: 2.8091643
disc_acc: 0.06794554455445545

Validation results:
gen_loss: 0.07910173
disc_loss: 2.7901704
disc_acc: 0.052083333333333336


	Epoch 442
Training results:
gen_loss: 0.09141419
disc_loss: 2.8021336
disc_acc: 0.059158415841584155

Validation results:
gen_loss: 0.08808893
disc_loss: 2.8041384
disc_acc: 0.05803571428571429


	Epoch 443
Training results:
gen_loss: 0.10575918
disc_loss: 2.8224156
disc_acc: 0.0650990099009901

Validation results:
gen_loss: 0.090749525
disc_loss: 2.7929268
disc_acc: 0.06845238095238096


	Epoch 444
Training results:
gen_loss: 0.08795806
disc_loss: 2.7977848
disc_acc: 0.05816831683168317

Validation results:
gen_loss: 0.08754012
disc_loss: 2.7916903
disc_acc: 0.053075396825396824


	Epoch 445
Training results:
gen_loss: 0.09545846
disc_loss: 2.8037708
disc_acc: 0.06373762376237624

Validation results:
gen_loss: 0.09134142
disc_loss: 2.807485
disc_acc: 0.05853174603174603


	Epoch 446
Training results:
gen_loss: 0.09793535
disc_loss: 2.8180583
disc_acc: 0.0594059405940594

Validation results:
gen_loss: 0.09535312
disc_loss: 2.8261697
disc_acc: 0.05505952380952381


	Epoch 447
Training results:
gen_loss: 0.09310987
disc_loss: 2.8039377
disc_acc: 0.057920792079207924

Validation results:
gen_loss: 0.09535937
disc_loss: 2.7879357
disc_acc: 0.0679563492063492


	Epoch 448
Training results:
gen_loss: 0.1017677
disc_loss: 2.8177063
disc_acc: 0.06027227722772277

Validation results:
gen_loss: 0.077360235
disc_loss: 2.783353
disc_acc: 0.053075396825396824


	Epoch 449
Training results:
gen_loss: 0.10094177
disc_loss: 2.810602
disc_acc: 0.06794554455445545

Validation results:
gen_loss: 0.14820659
disc_loss: 2.838636
disc_acc: 0.062003968253968256


	Epoch 450
Training results:
gen_loss: 0.09997969
disc_loss: 2.8078823
disc_acc: 0.06410891089108911

Validation results:
gen_loss: 0.094464876
disc_loss: 2.8115356
disc_acc: 0.061507936507936505


	Epoch 451
Training results:
gen_loss: 0.09043614
disc_loss: 2.7986193
disc_acc: 0.06163366336633663

Validation results:
gen_loss: 0.08428026
disc_loss: 2.7885678
disc_acc: 0.06845238095238096


	Epoch 452
Training results:
gen_loss: 0.10548091
disc_loss: 2.8223183
disc_acc: 0.06163366336633663

Validation results:
gen_loss: 0.09366182
disc_loss: 2.8048031
disc_acc: 0.05704365079365079


	Epoch 453
Training results:
gen_loss: 0.09348206
disc_loss: 2.8008044
disc_acc: 0.060148514851485146

Validation results:
gen_loss: 0.07997521
disc_loss: 2.7767286
disc_acc: 0.06349206349206349


	Epoch 454
Training results:
gen_loss: 0.09076423
disc_loss: 2.7975354
disc_acc: 0.0625

Validation results:
gen_loss: 0.09819605
disc_loss: 2.812082
disc_acc: 0.0625


	Epoch 455
Training results:
gen_loss: 0.110409014
disc_loss: 2.830235
disc_acc: 0.06596534653465347

Validation results:
gen_loss: 0.095464274
disc_loss: 2.8355346
disc_acc: 0.07043650793650794


	Epoch 456
Training results:
gen_loss: 0.10230304
disc_loss: 2.8177116
disc_acc: 0.0625

Validation results:
gen_loss: 0.1055493
disc_loss: 2.8124125
disc_acc: 0.06299603174603174


	Epoch 457
Training results:
gen_loss: 0.08981435
disc_loss: 2.7932148
disc_acc: 0.06262376237623762

Validation results:
gen_loss: 0.0830044
disc_loss: 2.793258
disc_acc: 0.05853174603174603


	Epoch 458
Training results:
gen_loss: 0.09327422
disc_loss: 2.7985895
disc_acc: 0.06311881188118812

Validation results:
gen_loss: 0.08527105
disc_loss: 2.7939773
disc_acc: 0.05257936507936508


	Epoch 459
Training results:
gen_loss: 0.10891947
disc_loss: 2.8236783
disc_acc: 0.062376237623762376

Validation results:
gen_loss: 0.09368356
disc_loss: 2.7921214
disc_acc: 0.052083333333333336


	Epoch 460
Training results:
gen_loss: 0.09706285
disc_loss: 2.8068335
disc_acc: 0.06262376237623762

Validation results:
gen_loss: 0.10493012
disc_loss: 2.8173783
disc_acc: 0.06746031746031746


	Epoch 461
Training results:
gen_loss: 0.09256135
disc_loss: 2.8024113
disc_acc: 0.056064356435643566

Validation results:
gen_loss: 0.08854315
disc_loss: 2.7802937
disc_acc: 0.060515873015873016


	Epoch 462
Training results:
gen_loss: 0.09550008
disc_loss: 2.807765
disc_acc: 0.06262376237623762

Validation results:
gen_loss: 0.110373445
disc_loss: 2.8282993
disc_acc: 0.05505952380952381


	Epoch 463
Training results:
gen_loss: 0.1015525
disc_loss: 2.81913
disc_acc: 0.06485148514851485

Validation results:
gen_loss: 0.08208009
disc_loss: 2.7902303
disc_acc: 0.05654761904761905


	Epoch 464
Training results:
gen_loss: 0.09668266
disc_loss: 2.8061993
disc_acc: 0.05903465346534653

Validation results:
gen_loss: 0.11440508
disc_loss: 2.8666472
disc_acc: 0.05704365079365079


	Epoch 465
Training results:
gen_loss: 0.09935856
disc_loss: 2.80806
disc_acc: 0.06423267326732673

Validation results:
gen_loss: 0.09220015
disc_loss: 2.8109558
disc_acc: 0.0689484126984127


	Epoch 466
Training results:
gen_loss: 0.09573311
disc_loss: 2.8075979
disc_acc: 0.059777227722772275

Validation results:
gen_loss: 0.09189301
disc_loss: 2.7987175
disc_acc: 0.06845238095238096


	Epoch 467
Training results:
gen_loss: 0.09892019
disc_loss: 2.8061233
disc_acc: 0.06398514851485149

Validation results:
gen_loss: 0.107534915
disc_loss: 2.8219075
disc_acc: 0.07093253968253968


	Epoch 468
Training results:
gen_loss: 0.102952294
disc_loss: 2.816369
disc_acc: 0.06398514851485149

Validation results:
gen_loss: 0.10498235
disc_loss: 2.8050737
disc_acc: 0.0689484126984127


	Epoch 469
Training results:
gen_loss: 0.09229302
disc_loss: 2.801724
disc_acc: 0.061014851485148514

Validation results:
gen_loss: 0.114973664
disc_loss: 2.8422263
disc_acc: 0.05853174603174603


	Epoch 470
Training results:
gen_loss: 0.09887034
disc_loss: 2.8099372
disc_acc: 0.0629950495049505

Validation results:
gen_loss: 0.08555546
disc_loss: 2.7850502
disc_acc: 0.07390873015873016


	Epoch 471
Training results:
gen_loss: 0.098459706
disc_loss: 2.8166897
disc_acc: 0.05903465346534653

Validation results:
gen_loss: 0.10450334
disc_loss: 2.816314
disc_acc: 0.054563492063492064


	Epoch 472
Training results:
gen_loss: 0.09358499
disc_loss: 2.803668
disc_acc: 0.06386138613861386

Validation results:
gen_loss: 0.12392765
disc_loss: 2.8390257
disc_acc: 0.060515873015873016


	Epoch 473
Training results:
gen_loss: 0.09627265
disc_loss: 2.808799
disc_acc: 0.06497524752475248

Validation results:
gen_loss: 0.08922928
disc_loss: 2.8189662
disc_acc: 0.0625


	Epoch 474
Training results:
gen_loss: 0.093666196
disc_loss: 2.802817
disc_acc: 0.05680693069306931

Validation results:
gen_loss: 0.087926835
disc_loss: 2.7942045
disc_acc: 0.060515873015873016


	Epoch 475
Training results:
gen_loss: 0.09837589
disc_loss: 2.810004
disc_acc: 0.06212871287128713

Validation results:
gen_loss: 0.10183648
disc_loss: 2.8123357
disc_acc: 0.053075396825396824


	Epoch 476
Training results:
gen_loss: 0.09610087
disc_loss: 2.811363
disc_acc: 0.05272277227722772

Validation results:
gen_loss: 0.09342349
disc_loss: 2.8129904
disc_acc: 0.0625


	Epoch 477
Training results:
gen_loss: 0.10088401
disc_loss: 2.8106675
disc_acc: 0.06349009900990099

Validation results:
gen_loss: 0.119172394
disc_loss: 2.8376024
disc_acc: 0.05853174603174603


	Epoch 478
Training results:
gen_loss: 0.09652906
disc_loss: 2.8093295
disc_acc: 0.06225247524752475

Validation results:
gen_loss: 0.09402035
disc_loss: 2.790491
disc_acc: 0.053075396825396824


	Epoch 479
Training results:
gen_loss: 0.1057496
disc_loss: 2.8221354
disc_acc: 0.0646039603960396

Validation results:
gen_loss: 0.08933897
disc_loss: 2.8110209
disc_acc: 0.0689484126984127


	Epoch 480
Training results:
gen_loss: 0.097112685
disc_loss: 2.8004837
disc_acc: 0.06262376237623762

Validation results:
gen_loss: 0.088486485
disc_loss: 2.7823694
disc_acc: 0.057539682539682536


	Epoch 481
Training results:
gen_loss: 0.091378726
disc_loss: 2.798309
disc_acc: 0.060396039603960394

Validation results:
gen_loss: 0.10773062
disc_loss: 2.8089511
disc_acc: 0.06845238095238096


	Epoch 482
Training results:
gen_loss: 0.10154295
disc_loss: 2.8148398
disc_acc: 0.060767326732673266

Validation results:
gen_loss: 0.10185704
disc_loss: 2.8148074
disc_acc: 0.07390873015873016


	Epoch 483
Training results:
gen_loss: 0.10314365
disc_loss: 2.8199773
disc_acc: 0.061014851485148514

Validation results:
gen_loss: 0.08818204
disc_loss: 2.8015404
disc_acc: 0.05505952380952381


	Epoch 484
Training results:
gen_loss: 0.09747763
disc_loss: 2.8047838
disc_acc: 0.06324257425742574

Validation results:
gen_loss: 0.09229005
disc_loss: 2.7959745
disc_acc: 0.06349206349206349


	Epoch 485
Training results:
gen_loss: 0.09489763
disc_loss: 2.801864
disc_acc: 0.06163366336633663

Validation results:
gen_loss: 0.1470593
disc_loss: 2.892877
disc_acc: 0.06398809523809523


	Epoch 486
Training results:
gen_loss: 0.111334726
disc_loss: 2.8220177
disc_acc: 0.06695544554455446

Validation results:
gen_loss: 0.1343249
disc_loss: 2.8982973
disc_acc: 0.07093253968253968


	Epoch 487
Training results:
gen_loss: 0.09480236
disc_loss: 2.8006833
disc_acc: 0.06212871287128713

Validation results:
gen_loss: 0.09270797
disc_loss: 2.7957
disc_acc: 0.062003968253968256


	Epoch 488
Training results:
gen_loss: 0.09475072
disc_loss: 2.800759
disc_acc: 0.0655940594059406

Validation results:
gen_loss: 0.08884286
disc_loss: 2.7976909
disc_acc: 0.07341269841269842


	Epoch 489
Training results:
gen_loss: 0.099947415
disc_loss: 2.809624
disc_acc: 0.06027227722772277

Validation results:
gen_loss: 0.11596097
disc_loss: 2.8260515
disc_acc: 0.05853174603174603


	Epoch 490
Training results:
gen_loss: 0.09590782
disc_loss: 2.8041525
disc_acc: 0.06051980198019802

Validation results:
gen_loss: 0.08406011
disc_loss: 2.7976027
disc_acc: 0.06398809523809523


	Epoch 491
Training results:
gen_loss: 0.10607821
disc_loss: 2.821349
disc_acc: 0.06485148514851485

Validation results:
gen_loss: 0.08474695
disc_loss: 2.7876885
disc_acc: 0.07291666666666667


	Epoch 492
Training results:
gen_loss: 0.09333467
disc_loss: 2.800261
disc_acc: 0.06410891089108911

Validation results:
gen_loss: 0.08068653
disc_loss: 2.8020496
disc_acc: 0.07390873015873016


	Epoch 493
Training results:
gen_loss: 0.09962699
disc_loss: 2.8106847
disc_acc: 0.06373762376237624

Validation results:
gen_loss: 0.084076025
disc_loss: 2.7843196
disc_acc: 0.062003968253968256


	Epoch 494
Training results:
gen_loss: 0.099296495
disc_loss: 2.8131204
disc_acc: 0.05903465346534653

Validation results:
gen_loss: 0.08726848
disc_loss: 2.7953796
disc_acc: 0.06398809523809523


	Epoch 495
Training results:
gen_loss: 0.098543406
disc_loss: 2.8081076
disc_acc: 0.06225247524752475

Validation results:
gen_loss: 0.09974073
disc_loss: 2.828846
disc_acc: 0.06398809523809523


	Epoch 496
Training results:
gen_loss: 0.09784215
disc_loss: 2.804147
disc_acc: 0.06905940594059407

Validation results:
gen_loss: 0.11679336
disc_loss: 2.8338182
disc_acc: 0.0679563492063492


	Epoch 497
Training results:
gen_loss: 0.104997836
disc_loss: 2.8119826
disc_acc: 0.06695544554455446

Validation results:
gen_loss: 0.08433308
disc_loss: 2.7739882
disc_acc: 0.0679563492063492


	Epoch 498
Training results:
gen_loss: 0.111222416
disc_loss: 2.8085015
disc_acc: 0.07202970297029702

Validation results:
gen_loss: 0.11059459
disc_loss: 2.6914513
disc_acc: 0.0679563492063492


	Epoch 499
Training results:
gen_loss: 0.100740805
disc_loss: 2.794521
disc_acc: 0.06448019801980198

Validation results:
gen_loss: 0.11352239
disc_loss: 2.7978396
disc_acc: 0.06101190476190476


	Epoch 500
Training results:
gen_loss: 0.1037674
disc_loss: 2.8051715
disc_acc: 0.06707920792079208

Validation results:
gen_loss: 0.091171235
disc_loss: 2.782826
disc_acc: 0.06349206349206349



Training new discriminator on static trained discriminator.
	Initial performance
Training results:
gen_loss: 0.013013866
disc_loss: 5.651923
disc_acc: 0.00012376237623762376

Validation results:
gen_loss: 0.012968319
disc_loss: 5.6450133
disc_acc: 0.0


	Epoch 1
Training results:
gen_loss: 0.35904342
disc_loss: 2.202012
disc_acc: 0.2316831683168317

Validation results:
gen_loss: 0.34824762
disc_loss: 1.7541593
disc_acc: 0.29017857142857145


	Epoch 2
Training results:
gen_loss: 0.4220092
disc_loss: 1.7773899
disc_acc: 0.31027227722772277

Validation results:
gen_loss: 0.3908976
disc_loss: 1.675208
disc_acc: 0.31200396825396826


	Epoch 3
Training results:
gen_loss: 0.4652453
disc_loss: 1.650882
disc_acc: 0.3660891089108911

Validation results:
gen_loss: 0.6183429
disc_loss: 1.7299148
disc_acc: 0.30009920634920634


	Epoch 4
Training results:
gen_loss: 0.56520903
disc_loss: 1.2199625
disc_acc: 0.5014851485148515

Validation results:
gen_loss: 0.61975163
disc_loss: 0.8916099
disc_acc: 0.5987103174603174


	Epoch 5
Training results:
gen_loss: 0.6458632
disc_loss: 0.99753153
disc_acc: 0.5829207920792079

Validation results:
gen_loss: 0.8157705
disc_loss: 0.95207953
disc_acc: 0.6850198412698413


	Epoch 6
Training results:
gen_loss: 0.71056706
disc_loss: 0.8499673
disc_acc: 0.6430693069306931

Validation results:
gen_loss: 0.78007287
disc_loss: 0.70997584
disc_acc: 0.6999007936507936


	Epoch 7
Training results:
gen_loss: 0.71330845
disc_loss: 0.8378756
disc_acc: 0.6452970297029703

Validation results:
gen_loss: 0.7235755
disc_loss: 0.8531943
disc_acc: 0.6493055555555556


	Epoch 8
Training results:
gen_loss: 0.73043674
disc_loss: 0.78901875
disc_acc: 0.6613861386138614

Validation results:
gen_loss: 0.72812206
disc_loss: 0.4688307
disc_acc: 0.8000992063492064


	Epoch 9
Training results:
gen_loss: 0.76655763
disc_loss: 0.6427303
disc_acc: 0.7196782178217822

Validation results:
gen_loss: 0.7792859
disc_loss: 0.5386692
disc_acc: 0.7490079365079365


	Epoch 10
Training results:
gen_loss: 0.78171116
disc_loss: 0.58638513
disc_acc: 0.7319306930693069

Validation results:
gen_loss: 0.82750344
disc_loss: 0.46660495
disc_acc: 0.7534722222222222


	Epoch 11
Training results:
gen_loss: 0.78732246
disc_loss: 0.5891163
disc_acc: 0.7246287128712872

Validation results:
gen_loss: 0.79760003
disc_loss: 0.47591418
disc_acc: 0.7817460317460317


	Epoch 12
Training results:
gen_loss: 0.78094316
disc_loss: 0.599045
disc_acc: 0.7297029702970297

Validation results:
gen_loss: 0.8402584
disc_loss: 0.46802765
disc_acc: 0.7703373015873016


	Epoch 13
Training results:
gen_loss: 0.7894135
disc_loss: 0.63771504
disc_acc: 0.7125

Validation results:
gen_loss: 0.7788191
disc_loss: 0.50669307
disc_acc: 0.7678571428571429


	Epoch 14
Training results:
gen_loss: 0.77456075
disc_loss: 0.62100106
disc_acc: 0.7133663366336633

Validation results:
gen_loss: 0.799463
disc_loss: 0.4734895
disc_acc: 0.7624007936507936


	Epoch 15
Training results:
gen_loss: 0.8077397
disc_loss: 0.5197511
disc_acc: 0.74740099009901

Validation results:
gen_loss: 0.82940644
disc_loss: 0.47415182
disc_acc: 0.7624007936507936


	Epoch 16
Training results:
gen_loss: 0.78349817
disc_loss: 0.5847322
disc_acc: 0.7252475247524752

Validation results:
gen_loss: 0.72675806
disc_loss: 0.5681807
disc_acc: 0.6994047619047619


	Epoch 17
Training results:
gen_loss: 0.76140606
disc_loss: 0.73024553
disc_acc: 0.6846534653465347

Validation results:
gen_loss: 0.79325825
disc_loss: 0.52596277
disc_acc: 0.7534722222222222


	Epoch 18
Training results:
gen_loss: 0.77130646
disc_loss: 0.6303457
disc_acc: 0.7121287128712871

Validation results:
gen_loss: 0.7919465
disc_loss: 0.56318206
disc_acc: 0.7276785714285714


	Epoch 19
Training results:
gen_loss: 0.7976756
disc_loss: 0.5629068
disc_acc: 0.7426980198019802

Validation results:
gen_loss: 0.8201672
disc_loss: 0.44143927
disc_acc: 0.7787698412698413


	Epoch 20
Training results:
gen_loss: 0.7874189
disc_loss: 0.68338424
disc_acc: 0.7073019801980198

Validation results:
gen_loss: 0.7282655
disc_loss: 0.6261612
disc_acc: 0.6974206349206349


	Epoch 21
Training results:
gen_loss: 0.79382694
disc_loss: 0.5109131
disc_acc: 0.7524752475247525

Validation results:
gen_loss: 0.79356974
disc_loss: 0.5376935
disc_acc: 0.7470238095238095


	Epoch 22
Training results:
gen_loss: 0.77173394
disc_loss: 0.63633007
disc_acc: 0.7118811881188118

Validation results:
gen_loss: 0.76876825
disc_loss: 0.5179754
disc_acc: 0.7524801587301587


	Epoch 23
Training results:
gen_loss: 0.7693986
disc_loss: 0.73245525
disc_acc: 0.6840346534653465

Validation results:
gen_loss: 0.77132785
disc_loss: 0.5863403
disc_acc: 0.748015873015873


	Epoch 24
Training results:
gen_loss: 0.7684297
disc_loss: 0.6166502
disc_acc: 0.7097772277227723

Validation results:
gen_loss: 0.78684276
disc_loss: 0.55005336
disc_acc: 0.751984126984127


	Epoch 25
Training results:
gen_loss: 0.77582186
disc_loss: 0.6549123
disc_acc: 0.7045792079207921

Validation results:
gen_loss: 0.76512456
disc_loss: 0.50035745
disc_acc: 0.7584325396825397


	Epoch 26
Training results:
gen_loss: 0.76881635
disc_loss: 0.64446676
disc_acc: 0.6996287128712871

Validation results:
gen_loss: 0.78612065
disc_loss: 0.7513348
disc_acc: 0.6919642857142857


	Epoch 27
Training results:
gen_loss: 0.778762
disc_loss: 0.643604
disc_acc: 0.7003712871287129

Validation results:
gen_loss: 0.7517868
disc_loss: 0.5238401
disc_acc: 0.7564484126984127


	Epoch 28
Training results:
gen_loss: 0.7828465
disc_loss: 0.5126681
disc_acc: 0.745049504950495

Validation results:
gen_loss: 0.779557
disc_loss: 0.48271427
disc_acc: 0.7663690476190477


	Epoch 29
Training results:
gen_loss: 0.78137946
disc_loss: 0.8482835
disc_acc: 0.6603960396039604

Validation results:
gen_loss: 0.73745936
disc_loss: 1.0921383
disc_acc: 0.6001984126984127


	Epoch 30
Training results:
gen_loss: 0.77341926
disc_loss: 0.6256469
disc_acc: 0.7129950495049505

Validation results:
gen_loss: 0.74535465
disc_loss: 0.50070035
disc_acc: 0.753968253968254


	Epoch 31
Training results:
gen_loss: 0.773175
disc_loss: 0.54407233
disc_acc: 0.7341584158415841

Validation results:
gen_loss: 0.7673481
disc_loss: 0.46736458
disc_acc: 0.7633928571428571


	Epoch 32
Training results:
gen_loss: 0.784431
disc_loss: 0.5288498
disc_acc: 0.7574257425742574

Validation results:
gen_loss: 0.7720641
disc_loss: 0.54022264
disc_acc: 0.7127976190476191


	Epoch 33
Training results:
gen_loss: 0.7816318
disc_loss: 0.6181724
disc_acc: 0.7241336633663367

Validation results:
gen_loss: 0.7836386
disc_loss: 0.43701345
disc_acc: 0.7881944444444444


	Epoch 34
Training results:
gen_loss: 0.7865831
disc_loss: 0.6124547
disc_acc: 0.7206683168316832

Validation results:
gen_loss: 0.7891577
disc_loss: 0.5505691
disc_acc: 0.7336309523809523


	Epoch 35
Training results:
gen_loss: 0.78226125
disc_loss: 0.646215
disc_acc: 0.7034653465346534

Validation results:
gen_loss: 0.7555121
disc_loss: 0.7402059
disc_acc: 0.6785714285714286


	Epoch 36
Training results:
gen_loss: 0.7828248
disc_loss: 0.55921495
disc_acc: 0.7457920792079208

Validation results:
gen_loss: 0.77482885
disc_loss: 0.5311614
disc_acc: 0.7301587301587301


	Epoch 37
Training results:
gen_loss: 0.7719665
disc_loss: 0.6170432
disc_acc: 0.7116336633663366

Validation results:
gen_loss: 0.8013414
disc_loss: 0.538366
disc_acc: 0.71875


	Epoch 38
Training results:
gen_loss: 0.79073
disc_loss: 0.5524397
disc_acc: 0.7358910891089109

Validation results:
gen_loss: 0.8329172
disc_loss: 0.4803604
disc_acc: 0.7336309523809523


	Epoch 39
Training results:
gen_loss: 0.7958009
disc_loss: 0.6262389
disc_acc: 0.7158415841584158

Validation results:
gen_loss: 0.81689614
disc_loss: 0.5696569
disc_acc: 0.7291666666666666


	Epoch 40
Training results:
gen_loss: 0.7716005
disc_loss: 0.6146885
disc_acc: 0.7169554455445545

Validation results:
gen_loss: 0.8050917
disc_loss: 0.51759803
disc_acc: 0.7420634920634921


	Epoch 41
Training results:
gen_loss: 0.7689265
disc_loss: 0.55670005
disc_acc: 0.7297029702970297

Validation results:
gen_loss: 0.77350914
disc_loss: 0.4157599
disc_acc: 0.7936507936507936


	Epoch 42
Training results:
gen_loss: 0.79110616
disc_loss: 0.65244395
disc_acc: 0.7058168316831683

Validation results:
gen_loss: 0.8034843
disc_loss: 0.725244
disc_acc: 0.6850198412698413


	Epoch 43
Training results:
gen_loss: 0.7878845
disc_loss: 0.5777729
disc_acc: 0.7282178217821782

Validation results:
gen_loss: 0.7573871
disc_loss: 0.6550471
disc_acc: 0.6939484126984127


	Epoch 44
Training results:
gen_loss: 0.78269464
disc_loss: 0.5276522
disc_acc: 0.7415841584158416

Validation results:
gen_loss: 0.7842276
disc_loss: 0.46789992
disc_acc: 0.7648809523809523


	Epoch 45
Training results:
gen_loss: 0.7920845
disc_loss: 0.5539684
disc_acc: 0.7435643564356436

Validation results:
gen_loss: 0.79302335
disc_loss: 1.4181982
disc_acc: 0.5744047619047619


	Epoch 46
Training results:
gen_loss: 0.8023126
disc_loss: 0.5849018
disc_acc: 0.7341584158415841

Validation results:
gen_loss: 0.8243864
disc_loss: 0.5197273
disc_acc: 0.7430555555555556


	Epoch 47
Training results:
gen_loss: 0.7890558
disc_loss: 0.53052
disc_acc: 0.744059405940594

Validation results:
gen_loss: 0.7857494
disc_loss: 0.46933457
disc_acc: 0.7703373015873016


	Epoch 48
Training results:
gen_loss: 0.79303885
disc_loss: 0.5297088
disc_acc: 0.755569306930693

Validation results:
gen_loss: 0.82194924
disc_loss: 0.74682105
disc_acc: 0.6696428571428571


	Epoch 49
Training results:
gen_loss: 0.81286913
disc_loss: 0.66076607
disc_acc: 0.7300742574257426

Validation results:
gen_loss: 0.7946183
disc_loss: 0.54142827
disc_acc: 0.7301587301587301


	Epoch 50
Training results:
gen_loss: 0.79847527
disc_loss: 0.47705173
disc_acc: 0.7606435643564357

Validation results:
gen_loss: 0.8039775
disc_loss: 0.38094047
disc_acc: 0.8194444444444444


	Epoch 51
Training results:
gen_loss: 0.79042786
disc_loss: 0.53243095
disc_acc: 0.7491336633663367

Validation results:
gen_loss: 0.7358483
disc_loss: 0.69607705
disc_acc: 0.7033730158730159


	Epoch 52
Training results:
gen_loss: 0.80143136
disc_loss: 0.57994866
disc_acc: 0.7300742574257426

Validation results:
gen_loss: 0.81836635
disc_loss: 0.63126457
disc_acc: 0.6845238095238095


	Epoch 53
Training results:
gen_loss: 0.816395
disc_loss: 0.50341135
disc_acc: 0.7576732673267327

Validation results:
gen_loss: 0.7689414
disc_loss: 0.56577927
disc_acc: 0.6924603174603174


	Epoch 54
Training results:
gen_loss: 0.81042624
disc_loss: 0.57416576
disc_acc: 0.7340346534653466

Validation results:
gen_loss: 0.80756956
disc_loss: 0.4810379
disc_acc: 0.753968253968254


	Epoch 55
Training results:
gen_loss: 0.8055606
disc_loss: 0.53822345
disc_acc: 0.746410891089109

Validation results:
gen_loss: 0.86260253
disc_loss: 0.5207451
disc_acc: 0.7609126984126984


	Epoch 56
Training results:
gen_loss: 0.8051352
disc_loss: 0.50632375
disc_acc: 0.7626237623762376

Validation results:
gen_loss: 0.85590434
disc_loss: 0.54384714
disc_acc: 0.7217261904761905


	Epoch 57
Training results:
gen_loss: 0.82301885
disc_loss: 0.46890658
disc_acc: 0.7712871287128713

Validation results:
gen_loss: 0.87952375
disc_loss: 0.48699796
disc_acc: 0.7470238095238095


	Epoch 58
Training results:
gen_loss: 0.8151048
disc_loss: 0.62155
disc_acc: 0.7330445544554456

Validation results:
gen_loss: 0.80688447
disc_loss: 0.5358465
disc_acc: 0.7609126984126984


	Epoch 59
Training results:
gen_loss: 0.812943
disc_loss: 0.5021881
disc_acc: 0.763490099009901

Validation results:
gen_loss: 0.8002188
disc_loss: 0.39894852
disc_acc: 0.8219246031746031


	Epoch 60
Training results:
gen_loss: 0.82670987
disc_loss: 0.390564
disc_acc: 0.8054455445544555

Validation results:
gen_loss: 0.8369436
disc_loss: 0.38874078
disc_acc: 0.7906746031746031


	Epoch 61
Training results:
gen_loss: 0.81769294
disc_loss: 0.45516574
disc_acc: 0.7814356435643565

Validation results:
gen_loss: 0.81847614
disc_loss: 0.3912146
disc_acc: 0.8070436507936508


	Epoch 62
Training results:
gen_loss: 0.83646685
disc_loss: 0.4012995
disc_acc: 0.8055693069306931

Validation results:
gen_loss: 0.8511553
disc_loss: 0.47829637
disc_acc: 0.8149801587301587


	Epoch 63
Training results:
gen_loss: 0.83196235
disc_loss: 0.63664323
disc_acc: 0.746039603960396

Validation results:
gen_loss: 0.7786316
disc_loss: 0.45316032
disc_acc: 0.7718253968253969


	Epoch 64
Training results:
gen_loss: 0.8075434
disc_loss: 0.51659125
disc_acc: 0.7586633663366337

Validation results:
gen_loss: 0.8150475
disc_loss: 0.34804112
disc_acc: 0.8442460317460317


	Epoch 65
Training results:
gen_loss: 0.8191034
disc_loss: 0.41586462
disc_acc: 0.7971534653465346

Validation results:
gen_loss: 0.7974417
disc_loss: 0.3883138
disc_acc: 0.7827380952380952


	Epoch 66
Training results:
gen_loss: 0.81404793
disc_loss: 0.44001818
disc_acc: 0.7816831683168317

Validation results:
gen_loss: 0.83411705
disc_loss: 0.49791694
disc_acc: 0.7703373015873016


	Epoch 67
Training results:
gen_loss: 0.8351068
disc_loss: 0.41531008
disc_acc: 0.7900990099009901

Validation results:
gen_loss: 0.79706126
disc_loss: 0.38808903
disc_acc: 0.7901785714285714


	Epoch 68
Training results:
gen_loss: 0.8340482
disc_loss: 0.37990233
disc_acc: 0.8087871287128713

Validation results:
gen_loss: 0.8199448
disc_loss: 0.41597363
disc_acc: 0.7881944444444444


	Epoch 69
Training results:
gen_loss: 0.847851
disc_loss: 0.59808856
disc_acc: 0.7648514851485149

Validation results:
gen_loss: 0.8418622
disc_loss: 0.50908554
disc_acc: 0.7862103174603174


	Epoch 70
Training results:
gen_loss: 0.8381618
disc_loss: 0.42644203
disc_acc: 0.7960396039603961

Validation results:
gen_loss: 0.8385519
disc_loss: 0.30215552
disc_acc: 0.8571428571428571


	Epoch 71
Training results:
gen_loss: 0.8375277
disc_loss: 0.4717059
disc_acc: 0.790470297029703

Validation results:
gen_loss: 0.87465894
disc_loss: 0.41402817
disc_acc: 0.7876984126984127


	Epoch 72
Training results:
gen_loss: 0.84176236
disc_loss: 0.39301854
disc_acc: 0.8043316831683168

Validation results:
gen_loss: 0.80745006
disc_loss: 0.5538585
disc_acc: 0.7698412698412699


	Epoch 73
Training results:
gen_loss: 0.84299815
disc_loss: 0.41851804
disc_acc: 0.7978960396039604

Validation results:
gen_loss: 0.80990016
disc_loss: 0.37252998
disc_acc: 0.8288690476190477


	Epoch 74
Training results:
gen_loss: 0.8389715
disc_loss: 0.40334937
disc_acc: 0.8068069306930693

Validation results:
gen_loss: 0.84098005
disc_loss: 0.33438936
disc_acc: 0.814484126984127


	Epoch 75
Training results:
gen_loss: 0.8436992
disc_loss: 0.45571712
disc_acc: 0.8016089108910891

Validation results:
gen_loss: 0.8236689
disc_loss: 0.31944823
disc_acc: 0.8715277777777778


	Epoch 76
Training results:
gen_loss: 0.83861303
disc_loss: 0.96380174
disc_acc: 0.7409653465346535

Validation results:
gen_loss: 0.7432195
disc_loss: 0.97383
disc_acc: 0.6532738095238095


	Epoch 77
Training results:
gen_loss: 0.80119884
disc_loss: 0.5308698
disc_acc: 0.7636138613861386

Validation results:
gen_loss: 0.7782859
disc_loss: 0.4878872
disc_acc: 0.8060515873015873


	Epoch 78
Training results:
gen_loss: 0.8267823
disc_loss: 0.41972277
disc_acc: 0.807549504950495

Validation results:
gen_loss: 0.7976519
disc_loss: 0.40609685
disc_acc: 0.8601190476190477


	Epoch 79
Training results:
gen_loss: 0.8225794
disc_loss: 0.4401967
disc_acc: 0.800990099009901

Validation results:
gen_loss: 0.8240927
disc_loss: 0.3213107
disc_acc: 0.8308531746031746


	Epoch 80
Training results:
gen_loss: 0.84889644
disc_loss: 0.34117424
disc_acc: 0.8367574257425743

Validation results:
gen_loss: 0.83897567
disc_loss: 0.26462772
disc_acc: 0.9027777777777778


	Epoch 81
Training results:
gen_loss: 0.84253097
disc_loss: 0.39817244
disc_acc: 0.8242574257425742

Validation results:
gen_loss: 0.8580464
disc_loss: 0.27562422
disc_acc: 0.8834325396825397


	Epoch 82
Training results:
gen_loss: 0.85933715
disc_loss: 0.38960764
disc_acc: 0.8237623762376237

Validation results:
gen_loss: 0.8446822
disc_loss: 0.28911898
disc_acc: 0.8427579365079365


	Epoch 83
Training results:
gen_loss: 0.8665951
disc_loss: 0.35070848
disc_acc: 0.8517326732673267

Validation results:
gen_loss: 0.958056
disc_loss: 0.6296368
disc_acc: 0.7485119047619048


	Epoch 84
Training results:
gen_loss: 0.87756926
disc_loss: 0.37375495
disc_acc: 0.8478960396039604

Validation results:
gen_loss: 0.86528754
disc_loss: 0.3594628
disc_acc: 0.8328373015873016


	Epoch 85
Training results:
gen_loss: 0.8757554
disc_loss: 0.340901
disc_acc: 0.8478960396039604

Validation results:
gen_loss: 0.83557075
disc_loss: 0.32943526
disc_acc: 0.8516865079365079


	Epoch 86
Training results:
gen_loss: 0.8935022
disc_loss: 0.28671092
disc_acc: 0.8819306930693069

Validation results:
gen_loss: 0.8985605
disc_loss: 0.9238822
disc_acc: 0.7757936507936508


	Epoch 87
Training results:
gen_loss: 0.8909663
disc_loss: 0.6209937
disc_acc: 0.8133663366336633

Validation results:
gen_loss: 0.9162244
disc_loss: 0.35067087
disc_acc: 0.8516865079365079


	Epoch 88
Training results:
gen_loss: 0.9122139
disc_loss: 0.25681558
disc_acc: 0.8983910891089109

Validation results:
gen_loss: 0.8944649
disc_loss: 0.25470117
disc_acc: 0.9161706349206349


	Epoch 89
Training results:
gen_loss: 0.9015791
disc_loss: 0.30959412
disc_acc: 0.8806930693069307

Validation results:
gen_loss: 0.9328052
disc_loss: 0.14970118
disc_acc: 0.933531746031746


	Epoch 90
Training results:
gen_loss: 0.9350044
disc_loss: 0.16196226
disc_acc: 0.9373762376237624

Validation results:
gen_loss: 0.93178827
disc_loss: 0.3464603
disc_acc: 0.8685515873015873


	Epoch 91
Training results:
gen_loss: 0.915654
disc_loss: 0.26526314
disc_acc: 0.8975247524752475

Validation results:
gen_loss: 0.8764644
disc_loss: 0.29582042
disc_acc: 0.873015873015873


	Epoch 92
Training results:
gen_loss: 0.9281613
disc_loss: 0.4083357
disc_acc: 0.8735148514851485

Validation results:
gen_loss: 0.9395774
disc_loss: 0.18336426
disc_acc: 0.9255952380952381


	Epoch 93
Training results:
gen_loss: 0.93039525
disc_loss: 0.24017052
disc_acc: 0.9125

Validation results:
gen_loss: 0.9331035
disc_loss: 0.18501233
disc_acc: 0.9201388888888888


	Epoch 94
Training results:
gen_loss: 0.93749946
disc_loss: 0.20518988
disc_acc: 0.926980198019802

Validation results:
gen_loss: 0.9120106
disc_loss: 0.30931845
disc_acc: 0.8864087301587301


	Epoch 95
Training results:
gen_loss: 0.94721437
disc_loss: 0.16634993
disc_acc: 0.9382425742574257

Validation results:
gen_loss: 0.94545543
disc_loss: 0.24595596
disc_acc: 0.9186507936507936


	Epoch 96
Training results:
gen_loss: 0.94230837
disc_loss: 0.30982828
disc_acc: 0.9024752475247525

Validation results:
gen_loss: 0.9462482
disc_loss: 0.29258603
disc_acc: 0.8988095238095238


	Epoch 97
Training results:
gen_loss: 0.9505417
disc_loss: 0.3940643
disc_acc: 0.8986386138613861

Validation results:
gen_loss: 0.95936006
disc_loss: 0.21401326
disc_acc: 0.9270833333333334


	Epoch 98
Training results:
gen_loss: 0.96284413
disc_loss: 0.13237202
disc_acc: 0.948019801980198

Validation results:
gen_loss: 0.9729296
disc_loss: 0.053890835
disc_acc: 0.9801587301587301


	Epoch 99
Training results:
gen_loss: 0.9463748
disc_loss: 0.23080623
disc_acc: 0.927970297029703

Validation results:
gen_loss: 0.96408105
disc_loss: 0.05943965
disc_acc: 0.9836309523809523


	Epoch 100
Training results:
gen_loss: 0.9441335
disc_loss: 0.24821453
disc_acc: 0.9184405940594059

Validation results:
gen_loss: 0.93609124
disc_loss: 0.29466376
disc_acc: 0.8963293650793651


	Epoch 101
Training results:
gen_loss: 0.94444394
disc_loss: 0.20377484
disc_acc: 0.9248762376237624

Validation results:
gen_loss: 0.92120886
disc_loss: 0.21304537
disc_acc: 0.9077380952380952


	Epoch 102
Training results:
gen_loss: 0.9603211
disc_loss: 0.18070507
disc_acc: 0.9417079207920792

Validation results:
gen_loss: 0.97717464
disc_loss: 0.109186545
disc_acc: 0.9771825396825397


	Epoch 103
Training results:
gen_loss: 0.94486403
disc_loss: 0.56559235
disc_acc: 0.8686881188118812

Validation results:
gen_loss: 0.95543444
disc_loss: 0.29422247
disc_acc: 0.9265873015873016


	Epoch 104
Training results:
gen_loss: 0.9569205
disc_loss: 0.20985053
disc_acc: 0.9399752475247525

Validation results:
gen_loss: 0.96736145
disc_loss: 0.05094621
disc_acc: 0.9866071428571429


	Epoch 105
Training results:
gen_loss: 0.9628392
disc_loss: 0.14789443
disc_acc: 0.9532178217821782

Validation results:
gen_loss: 0.9682953
disc_loss: 0.065797724
disc_acc: 0.9756944444444444


	Epoch 106
Training results:
gen_loss: 0.9729929
disc_loss: 0.07355403
disc_acc: 0.9742574257425742

Validation results:
gen_loss: 0.97396076
disc_loss: 0.08411302
disc_acc: 0.964781746031746


	Epoch 107
Training results:
gen_loss: 0.97091055
disc_loss: 0.09508419
disc_acc: 0.9669554455445545

Validation results:
gen_loss: 0.9626292
disc_loss: 0.117041856
disc_acc: 0.9598214285714286


	Epoch 108
Training results:
gen_loss: 0.96433663
disc_loss: 0.12062418
disc_acc: 0.9565594059405941

Validation results:
gen_loss: 0.9747318
disc_loss: 0.06394099
disc_acc: 0.9766865079365079


	Epoch 109
Training results:
gen_loss: 0.9558689
disc_loss: 0.7290931
disc_acc: 0.8898514851485149

Validation results:
gen_loss: 0.9758618
disc_loss: 0.08634907
disc_acc: 0.9702380952380952


	Epoch 110
Training results:
gen_loss: 0.9663567
disc_loss: 0.13902986
disc_acc: 0.9573019801980198

Validation results:
gen_loss: 0.97370446
disc_loss: 0.067675754
disc_acc: 0.9722222222222222


	Epoch 111
Training results:
gen_loss: 0.97586125
disc_loss: 0.076315254
disc_acc: 0.9727722772277227

Validation results:
gen_loss: 0.9721771
disc_loss: 0.11809174
disc_acc: 0.9553571428571429


	Epoch 112
Training results:
gen_loss: 0.94685966
disc_loss: 0.32703945
disc_acc: 0.9051980198019802

Validation results:
gen_loss: 0.9469241
disc_loss: 0.14099641
disc_acc: 0.9444444444444444


	Epoch 113
Training results:
gen_loss: 0.940763
disc_loss: 0.2398244
disc_acc: 0.9196782178217822

Validation results:
gen_loss: 0.95160663
disc_loss: 0.12108002
disc_acc: 0.9573412698412699


	Epoch 114
Training results:
gen_loss: 0.9622651
disc_loss: 0.12576793
disc_acc: 0.9602722772277228

Validation results:
gen_loss: 0.97597253
disc_loss: 0.037500635
disc_acc: 0.9910714285714286


	Epoch 115
Training results:
gen_loss: 0.96552145
disc_loss: 0.10835665
disc_acc: 0.9612623762376238

Validation results:
gen_loss: 0.9401869
disc_loss: 0.38331407
disc_acc: 0.8824404761904762


	Epoch 116
Training results:
gen_loss: 0.95495296
disc_loss: 0.2294078
disc_acc: 0.9316831683168317

Validation results:
gen_loss: 0.9077872
disc_loss: 1.4370687
disc_acc: 0.6944444444444444


	Epoch 117
Training results:
gen_loss: 0.9661535
disc_loss: 0.13080995
disc_acc: 0.9544554455445544

Validation results:
gen_loss: 0.97136027
disc_loss: 0.16717899
disc_acc: 0.941468253968254


	Epoch 118
Training results:
gen_loss: 0.9738138
disc_loss: 0.108262315
disc_acc: 0.9667079207920792

Validation results:
gen_loss: 0.95688045
disc_loss: 0.21231426
disc_acc: 0.939484126984127


	Epoch 119
Training results:
gen_loss: 0.9601706
disc_loss: 0.28604916
disc_acc: 0.9206683168316832

Validation results:
gen_loss: 0.9796982
disc_loss: 0.06232319
disc_acc: 0.9796626984126984


	Epoch 120
Training results:
gen_loss: 0.91754705
disc_loss: 0.36818448
disc_acc: 0.8636138613861386

Validation results:
gen_loss: 0.8589642
disc_loss: 0.40721738
disc_acc: 0.7802579365079365


	Epoch 121
Training results:
gen_loss: 0.8572372
disc_loss: 0.3601624
disc_acc: 0.8245049504950495

Validation results:
gen_loss: 0.8861763
disc_loss: 0.43749383
disc_acc: 0.8199404761904762


	Epoch 122
Training results:
gen_loss: 0.8652192
disc_loss: 0.31465194
disc_acc: 0.8425742574257425

Validation results:
gen_loss: 0.84027606
disc_loss: 0.2586993
disc_acc: 0.8878968253968254


	Epoch 123
Training results:
gen_loss: 0.84986126
disc_loss: 0.417446
disc_acc: 0.814480198019802

Validation results:
gen_loss: 0.848936
disc_loss: 0.4344632
disc_acc: 0.7867063492063492


	Epoch 124
Training results:
gen_loss: 0.8634486
disc_loss: 0.33944443
disc_acc: 0.8419554455445545

Validation results:
gen_loss: 0.8552225
disc_loss: 0.24979807
disc_acc: 0.8606150793650794


	Epoch 125
Training results:
gen_loss: 0.8707678
disc_loss: 0.3414881
disc_acc: 0.8419554455445545

Validation results:
gen_loss: 0.89338017
disc_loss: 0.339924
disc_acc: 0.8482142857142857


	Epoch 126
Training results:
gen_loss: 0.8806276
disc_loss: 0.3916472
disc_acc: 0.8285891089108911

Validation results:
gen_loss: 0.90461826
disc_loss: 0.5112691
disc_acc: 0.7991071428571429


	Epoch 127
Training results:
gen_loss: 0.8741899
disc_loss: 0.34991735
disc_acc: 0.849009900990099

Validation results:
gen_loss: 0.86170894
disc_loss: 0.3227906
disc_acc: 0.8695436507936508


	Epoch 128
Training results:
gen_loss: 0.88734674
disc_loss: 0.39060026
disc_acc: 0.8407178217821782

Validation results:
gen_loss: 0.8757495
disc_loss: 0.19317116
disc_acc: 0.9290674603174603


	Epoch 129
Training results:
gen_loss: 0.88394904
disc_loss: 0.32351837
disc_acc: 0.8613861386138614

Validation results:
gen_loss: 0.8633042
disc_loss: 0.44902653
disc_acc: 0.8328373015873016


	Epoch 130
Training results:
gen_loss: 0.8871287
disc_loss: 0.28477532
disc_acc: 0.8681930693069307

Validation results:
gen_loss: 0.87001127
disc_loss: 0.24335422
disc_acc: 0.902281746031746


	Epoch 131
Training results:
gen_loss: 0.8930436
disc_loss: 0.353235
disc_acc: 0.8599009900990099

Validation results:
gen_loss: 0.89195544
disc_loss: 0.32004166
disc_acc: 0.8511904761904762


	Epoch 132
Training results:
gen_loss: 0.8931993
disc_loss: 0.3261546
disc_acc: 0.8575495049504951

Validation results:
gen_loss: 0.8690669
disc_loss: 0.25523245
disc_acc: 0.9221230158730159


	Epoch 133
Training results:
gen_loss: 0.89645296
disc_loss: 0.3178163
disc_acc: 0.8716584158415842

Validation results:
gen_loss: 0.87562376
disc_loss: 0.214847
disc_acc: 0.9280753968253969


	Epoch 134
Training results:
gen_loss: 0.91282225
disc_loss: 0.25296742
disc_acc: 0.8952970297029703

Validation results:
gen_loss: 0.91361344
disc_loss: 0.14199166
disc_acc: 0.9494047619047619


	Epoch 135
Training results:
gen_loss: 0.89475095
disc_loss: 0.31618357
disc_acc: 0.8646039603960396

Validation results:
gen_loss: 0.91257584
disc_loss: 0.26010704
disc_acc: 0.8685515873015873


	Epoch 136
Training results:
gen_loss: 0.90357214
disc_loss: 0.30164814
disc_acc: 0.876608910891089

Validation results:
gen_loss: 0.87697905
disc_loss: 0.28317532
disc_acc: 0.8874007936507936


	Epoch 137
Training results:
gen_loss: 0.9181717
disc_loss: 0.31444687
disc_acc: 0.8821782178217822

Validation results:
gen_loss: 0.94979763
disc_loss: 0.101376995
disc_acc: 0.9722222222222222


	Epoch 138
Training results:
gen_loss: 0.94712746
disc_loss: 0.23705111
disc_acc: 0.9170792079207921

Validation results:
gen_loss: 0.9754747
disc_loss: 0.04517851
disc_acc: 0.9880952380952381


	Epoch 139
Training results:
gen_loss: 0.9573836
disc_loss: 0.29926413
disc_acc: 0.9133663366336634

Validation results:
gen_loss: 0.96181613
disc_loss: 1.1936812
disc_acc: 0.7881944444444444


	Epoch 140
Training results:
gen_loss: 0.97177106
disc_loss: 0.12586284
disc_acc: 0.9602722772277228

Validation results:
gen_loss: 0.9370146
disc_loss: 0.21760973
disc_acc: 0.9345238095238095


	Epoch 141
Training results:
gen_loss: 0.96272093
disc_loss: 0.14918478
disc_acc: 0.9516089108910891

Validation results:
gen_loss: 0.9640994
disc_loss: 0.087201186
disc_acc: 0.9682539682539683


	Epoch 142
Training results:
gen_loss: 0.9714849
disc_loss: 0.17493896
disc_acc: 0.9464108910891089

Validation results:
gen_loss: 0.9843789
disc_loss: 0.07873089
disc_acc: 0.9732142857142857


	Epoch 143
Training results:
gen_loss: 0.97615576
disc_loss: 0.113987684
disc_acc: 0.9643564356435643

Validation results:
gen_loss: 0.9892113
disc_loss: 0.024894632
disc_acc: 0.9910714285714286


	Epoch 144
Training results:
gen_loss: 0.9819166
disc_loss: 0.058266878
disc_acc: 0.9811881188118812

Validation results:
gen_loss: 0.9765015
disc_loss: 0.12349554
disc_acc: 0.970734126984127


	Epoch 145
Training results:
gen_loss: 0.9755721
disc_loss: 0.098782256
disc_acc: 0.9686881188118812

Validation results:
gen_loss: 0.9525141
disc_loss: 0.21683273
disc_acc: 0.9246031746031746


	Epoch 146
Training results:
gen_loss: 0.97346914
disc_loss: 0.5030573
disc_acc: 0.9103960396039604

Validation results:
gen_loss: 0.97941333
disc_loss: 0.10169537
disc_acc: 0.964781746031746


	Epoch 147
Training results:
gen_loss: 0.9818112
disc_loss: 0.133045
disc_acc: 0.9663366336633663

Validation results:
gen_loss: 0.98690856
disc_loss: 0.056219805
disc_acc: 0.9861111111111112


	Epoch 148
Training results:
gen_loss: 0.9879772
disc_loss: 0.046524372
disc_acc: 0.9837871287128713

Validation results:
gen_loss: 0.9910477
disc_loss: 0.032529388
disc_acc: 0.9880952380952381


	Epoch 149
Training results:
gen_loss: 0.988982
disc_loss: 0.049144648
disc_acc: 0.9841584158415841

Validation results:
gen_loss: 0.9963505
disc_loss: 0.0091074845
disc_acc: 0.9955357142857143


	Epoch 150
Training results:
gen_loss: 0.9866708
disc_loss: 0.058237724
disc_acc: 0.9839108910891089

Validation results:
gen_loss: 0.98877025
disc_loss: 0.017822227
disc_acc: 0.9935515873015873


	Epoch 151
Training results:
gen_loss: 0.986344
disc_loss: 0.05157785
disc_acc: 0.9847772277227723

Validation results:
gen_loss: 0.9896453
disc_loss: 0.039203625
disc_acc: 0.9861111111111112


	Epoch 152
Training results:
gen_loss: 0.97183776
disc_loss: 0.37512878
disc_acc: 0.9245049504950495

Validation results:
gen_loss: 0.9768466
disc_loss: 0.73092973
disc_acc: 0.8883928571428571


	Epoch 153
Training results:
gen_loss: 0.9412505
disc_loss: 0.39498246
disc_acc: 0.8790841584158415

Validation results:
gen_loss: 0.89861006
disc_loss: 0.31431633
disc_acc: 0.8432539682539683


	Epoch 154
Training results:
gen_loss: 0.8809438
disc_loss: 0.33987546
disc_acc: 0.8547029702970297

Validation results:
gen_loss: 0.87794465
disc_loss: 0.20938304
disc_acc: 0.9146825396825397


	Epoch 155
Training results:
gen_loss: 0.8882989
disc_loss: 0.26641485
disc_acc: 0.873019801980198

Validation results:
gen_loss: 0.9210123
disc_loss: 0.40890813
disc_acc: 0.7881944444444444


	Epoch 156
Training results:
gen_loss: 0.88850254
disc_loss: 0.2919346
disc_acc: 0.8736386138613862

Validation results:
gen_loss: 0.8945686
disc_loss: 0.18987949
disc_acc: 0.9236111111111112


	Epoch 157
Training results:
gen_loss: 0.8961484
disc_loss: 0.2624463
disc_acc: 0.8834158415841584

Validation results:
gen_loss: 0.88183105
disc_loss: 0.2510408
disc_acc: 0.8943452380952381


	Epoch 158
Training results:
gen_loss: 0.90345097
disc_loss: 0.39090106
disc_acc: 0.8530940594059406

Validation results:
gen_loss: 0.91193527
disc_loss: 0.23475231
disc_acc: 0.9166666666666666


	Epoch 159
Training results:
gen_loss: 0.9384681
disc_loss: 0.22787063
disc_acc: 0.9174504950495049

Validation results:
gen_loss: 0.8992444
disc_loss: 0.19227067
disc_acc: 0.9221230158730159


	Epoch 160
Training results:
gen_loss: 0.9546152
disc_loss: 0.1252249
disc_acc: 0.9496287128712871

Validation results:
gen_loss: 0.97071326
disc_loss: 0.08143297
disc_acc: 0.9712301587301587


	Epoch 161
Training results:
gen_loss: 0.98397046
disc_loss: 0.08046306
disc_acc: 0.9774752475247525

Validation results:
gen_loss: 0.9756795
disc_loss: 0.17369089
disc_acc: 0.9384920634920635


	Epoch 162
Training results:
gen_loss: 0.9831798
disc_loss: 0.07947696
disc_acc: 0.9756188118811882

Validation results:
gen_loss: 0.97148484
disc_loss: 0.1183284
disc_acc: 0.9563492063492064


	Epoch 163
Training results:
gen_loss: 0.93572044
disc_loss: 0.62823313
disc_acc: 0.8485148514851485

Validation results:
gen_loss: 0.9130493
disc_loss: 0.44063702
disc_acc: 0.8194444444444444


	Epoch 164
Training results:
gen_loss: 0.8928345
disc_loss: 0.31525505
disc_acc: 0.8650990099009901

Validation results:
gen_loss: 0.8782891
disc_loss: 0.21137366
disc_acc: 0.9350198412698413


	Epoch 165
Training results:
gen_loss: 0.88803965
disc_loss: 0.33751765
disc_acc: 0.8673267326732673

Validation results:
gen_loss: 0.9325538
disc_loss: 0.5702034
disc_acc: 0.7757936507936508


	Epoch 166
Training results:
gen_loss: 0.89799523
disc_loss: 0.262307
disc_acc: 0.8910891089108911

Validation results:
gen_loss: 0.89252263
disc_loss: 0.14937286
disc_acc: 0.9642857142857143


	Epoch 167
Training results:
gen_loss: 0.9208599
disc_loss: 0.18573736
disc_acc: 0.9262376237623763

Validation results:
gen_loss: 0.9065308
disc_loss: 0.21010858
disc_acc: 0.8993055555555556


	Epoch 168
Training results:
gen_loss: 0.90555376
disc_loss: 0.24997836
disc_acc: 0.8930693069306931

Validation results:
gen_loss: 0.9251866
disc_loss: 0.15342546
disc_acc: 0.9236111111111112


	Epoch 169
Training results:
gen_loss: 0.910795
disc_loss: 0.28859073
disc_acc: 0.888490099009901

Validation results:
gen_loss: 0.924486
disc_loss: 0.27288887
disc_acc: 0.871031746031746


	Epoch 170
Training results:
gen_loss: 0.96618545
disc_loss: 0.09646474
disc_acc: 0.9648514851485148

Validation results:
gen_loss: 0.9732766
disc_loss: 0.11971966
disc_acc: 0.9657738095238095


	Epoch 171
Training results:
gen_loss: 0.9627562
disc_loss: 0.1593475
disc_acc: 0.9469059405940594

Validation results:
gen_loss: 0.969497
disc_loss: 0.17718253
disc_acc: 0.9330357142857143


	Epoch 172
Training results:
gen_loss: 0.9717453
disc_loss: 0.49051857
disc_acc: 0.9080445544554455

Validation results:
gen_loss: 0.98068833
disc_loss: 0.25351134
disc_acc: 0.9300595238095238


	Epoch 173
Training results:
gen_loss: 0.9859853
disc_loss: 0.09588525
disc_acc: 0.9731435643564357

Validation results:
gen_loss: 0.98872197
disc_loss: 0.06808208
disc_acc: 0.9826388888888888


	Epoch 174
Training results:
gen_loss: 0.9862909
disc_loss: 0.06519662
disc_acc: 0.9798267326732674

Validation results:
gen_loss: 0.9864338
disc_loss: 0.03858165
disc_acc: 0.9861111111111112


	Epoch 175
Training results:
gen_loss: 0.98398024
disc_loss: 0.079647094
disc_acc: 0.9733910891089109

Validation results:
gen_loss: 0.9797881
disc_loss: 0.09398537
disc_acc: 0.9657738095238095


	Epoch 176
Training results:
gen_loss: 0.9906111
disc_loss: 0.030146854
disc_acc: 0.989480198019802

Validation results:
gen_loss: 0.98315096
disc_loss: 0.13622373
disc_acc: 0.9623015873015873


	Epoch 177
Training results:
gen_loss: 0.94884884
disc_loss: 0.6617474
disc_acc: 0.8503712871287129

Validation results:
gen_loss: 0.91446066
disc_loss: 0.2406638
disc_acc: 0.8869047619047619


	Epoch 178
Training results:
gen_loss: 0.9123406
disc_loss: 0.2647928
disc_acc: 0.9013613861386138

Validation results:
gen_loss: 0.92483056
disc_loss: 0.22412477
disc_acc: 0.910218253968254


	Epoch 179
Training results:
gen_loss: 0.9166976
disc_loss: 0.22610232
disc_acc: 0.9022277227722773

Validation results:
gen_loss: 0.920248
disc_loss: 0.1544858
disc_acc: 0.9449404761904762


	Epoch 180
Training results:
gen_loss: 0.95826095
disc_loss: 0.14901362
disc_acc: 0.9511138613861386

Validation results:
gen_loss: 0.9896444
disc_loss: 0.022119887
disc_acc: 0.9950396825396826


	Epoch 181
Training results:
gen_loss: 0.98349065
disc_loss: 0.06679288
disc_acc: 0.9754950495049505

Validation results:
gen_loss: 0.9623505
disc_loss: 0.19740567
disc_acc: 0.9379960317460317


	Epoch 182
Training results:
gen_loss: 0.984065
disc_loss: 0.05283632
disc_acc: 0.9824257425742574

Validation results:
gen_loss: 0.9650213
disc_loss: 0.18749504
disc_acc: 0.9424603174603174


	Epoch 183
Training results:
gen_loss: 0.971157
disc_loss: 0.64098614
disc_acc: 0.8962871287128713

Validation results:
gen_loss: 0.9610732
disc_loss: 0.31957164
disc_acc: 0.9097222222222222


	Epoch 184
Training results:
gen_loss: 0.9896562
disc_loss: 0.070018865
disc_acc: 0.9823019801980198

Validation results:
gen_loss: 0.9895428
disc_loss: 0.056770835
disc_acc: 0.9851190476190477


	Epoch 185
Training results:
gen_loss: 0.99238235
disc_loss: 0.03716349
disc_acc: 0.9898514851485148

Validation results:
gen_loss: 0.99615335
disc_loss: 0.0140861375
disc_acc: 0.9965277777777778


	Epoch 186
Training results:
gen_loss: 0.98908424
disc_loss: 0.06938126
disc_acc: 0.9805693069306931

Validation results:
gen_loss: 0.9857766
disc_loss: 0.09201299
disc_acc: 0.9712301587301587


	Epoch 187
Training results:
gen_loss: 0.98142403
disc_loss: 0.12590683
disc_acc: 0.9655940594059406

Validation results:
gen_loss: 0.978022
disc_loss: 0.12916516
disc_acc: 0.9682539682539683


	Epoch 188
Training results:
gen_loss: 0.9911332
disc_loss: 0.050981518
disc_acc: 0.9858910891089109

Validation results:
gen_loss: 0.9928101
disc_loss: 0.026731724
disc_acc: 0.9890873015873016


	Epoch 189
Training results:
gen_loss: 0.986986
disc_loss: 0.0929717
disc_acc: 0.9753712871287129

Validation results:
gen_loss: 0.9884628
disc_loss: 0.035583083
disc_acc: 0.9861111111111112


	Epoch 190
Training results:
gen_loss: 0.98462456
disc_loss: 0.13859665
disc_acc: 0.9647277227722773

Validation results:
gen_loss: 0.9930273
disc_loss: 0.07805632
disc_acc: 0.9796626984126984


	Epoch 191
Training results:
gen_loss: 0.9920104
disc_loss: 0.045556284
disc_acc: 0.9891089108910891

Validation results:
gen_loss: 0.9942098
disc_loss: 0.01431425
disc_acc: 0.9945436507936508


	Epoch 192
Training results:
gen_loss: 0.990485
disc_loss: 0.046943724
disc_acc: 0.9858910891089109

Validation results:
gen_loss: 0.99351245
disc_loss: 0.016446248
disc_acc: 0.9940476190476191


	Epoch 193
Training results:
gen_loss: 0.98705643
disc_loss: 0.27149937
disc_acc: 0.9579207920792079

Validation results:
gen_loss: 0.9745028
disc_loss: 0.56986296
disc_acc: 0.8874007936507936


	Epoch 194
Training results:
gen_loss: 0.9798799
disc_loss: 0.5935944
disc_acc: 0.9179455445544554

Validation results:
gen_loss: 0.9897864
disc_loss: 0.0829234
disc_acc: 0.9791666666666666


	Epoch 195
Training results:
gen_loss: 0.99108404
disc_loss: 0.06294373
disc_acc: 0.9831683168316832

Validation results:
gen_loss: 0.99140036
disc_loss: 0.04695071
disc_acc: 0.9890873015873016


	Epoch 196
Training results:
gen_loss: 0.9906886
disc_loss: 0.07144575
disc_acc: 0.9797029702970297

Validation results:
gen_loss: 0.9870665
disc_loss: 0.08835082
disc_acc: 0.9766865079365079


	Epoch 197
Training results:
gen_loss: 0.9922153
disc_loss: 0.025897698
disc_acc: 0.991460396039604

Validation results:
gen_loss: 0.9962301
disc_loss: 0.021992847
disc_acc: 0.9935515873015873


	Epoch 198
Training results:
gen_loss: 0.9851721
disc_loss: 0.12404075
disc_acc: 0.9653465346534653

Validation results:
gen_loss: 0.986696
disc_loss: 0.042554893
disc_acc: 0.9831349206349206


	Epoch 199
Training results:
gen_loss: 0.98443216
disc_loss: 0.082184814
disc_acc: 0.9745049504950495

Validation results:
gen_loss: 0.98650706
disc_loss: 0.062257033
disc_acc: 0.9826388888888888


	Epoch 200
Training results:
gen_loss: 0.98833627
disc_loss: 0.083169654
disc_acc: 0.9768564356435644

Validation results:
gen_loss: 0.99429387
disc_loss: 0.03844904
disc_acc: 0.9885912698412699


	Epoch 201
Training results:
gen_loss: 0.9795157
disc_loss: 0.21078701
disc_acc: 0.9457920792079207

Validation results:
gen_loss: 0.9919146
disc_loss: 0.050687186
disc_acc: 0.9885912698412699


	Epoch 202
Training results:
gen_loss: 0.983657
disc_loss: 0.16145168
disc_acc: 0.9623762376237623

Validation results:
gen_loss: 0.9825549
disc_loss: 0.07634487
disc_acc: 0.9761904761904762


	Epoch 203
Training results:
gen_loss: 0.9733048
disc_loss: 0.44904715
disc_acc: 0.9224009900990099

Validation results:
gen_loss: 0.972798
disc_loss: 0.15271606
disc_acc: 0.9578373015873016


	Epoch 204
Training results:
gen_loss: 0.98140264
disc_loss: 0.1189285
disc_acc: 0.9681930693069307

Validation results:
gen_loss: 0.9921356
disc_loss: 0.028716434
disc_acc: 0.9885912698412699


	Epoch 205
Training results:
gen_loss: 0.9875177
disc_loss: 0.09322276
disc_acc: 0.9758663366336634

Validation results:
gen_loss: 0.9702696
disc_loss: 0.15234657
disc_acc: 0.9494047619047619


	Epoch 206
Training results:
gen_loss: 0.98784
disc_loss: 0.04699375
disc_acc: 0.9844059405940594

Validation results:
gen_loss: 0.9852483
disc_loss: 0.07142355
disc_acc: 0.9737103174603174


	Epoch 207
Training results:
gen_loss: 0.979394
disc_loss: 0.34550053
disc_acc: 0.9407178217821782

Validation results:
gen_loss: 0.97117823
disc_loss: 1.4811331
disc_acc: 0.8055555555555556


	Epoch 208
Training results:
gen_loss: 0.98550034
disc_loss: 0.21468996
disc_acc: 0.9538366336633664

Validation results:
gen_loss: 0.9920865
disc_loss: 0.07188654
disc_acc: 0.9821428571428571


	Epoch 209
Training results:
gen_loss: 0.9862295
disc_loss: 0.14338373
disc_acc: 0.9660891089108911

Validation results:
gen_loss: 0.9913762
disc_loss: 0.01688373
disc_acc: 0.9945436507936508


	Epoch 210
Training results:
gen_loss: 0.98818684
disc_loss: 0.06716897
disc_acc: 0.9787128712871287

Validation results:
gen_loss: 0.9858457
disc_loss: 0.098458715
disc_acc: 0.9672619047619048


	Epoch 211
Training results:
gen_loss: 0.9865277
disc_loss: 0.07213884
disc_acc: 0.9789603960396039

Validation results:
gen_loss: 0.98836744
disc_loss: 0.034738503
disc_acc: 0.9895833333333334


	Epoch 212
Training results:
gen_loss: 0.9831438
disc_loss: 0.11536615
disc_acc: 0.9688118811881188

Validation results:
gen_loss: 0.99184245
disc_loss: 0.0731549
disc_acc: 0.9796626984126984


	Epoch 213
Training results:
gen_loss: 0.9768174
disc_loss: 0.16521223
disc_acc: 0.9523514851485149

Validation results:
gen_loss: 0.99274313
disc_loss: 0.06529186
disc_acc: 0.9856150793650794


	Epoch 214
Training results:
gen_loss: 0.9877364
disc_loss: 0.10688561
disc_acc: 0.9732673267326732

Validation results:
gen_loss: 0.9833849
disc_loss: 0.069848396
disc_acc: 0.9751984126984127


	Epoch 215
Training results:
gen_loss: 0.9859746
disc_loss: 0.1197242
disc_acc: 0.968440594059406

Validation results:
gen_loss: 0.99575645
disc_loss: 0.035560545
disc_acc: 0.9905753968253969


	Epoch 216
Training results:
gen_loss: 0.9926978
disc_loss: 0.032310773
disc_acc: 0.9902227722772278

Validation results:
gen_loss: 0.99509925
disc_loss: 0.025420403
disc_acc: 0.9910714285714286


	Epoch 217
Training results:
gen_loss: 0.98190784
disc_loss: 0.3140547
disc_acc: 0.9443069306930693

Validation results:
gen_loss: 0.9861972
disc_loss: 0.717297
disc_acc: 0.8938492063492064


	Epoch 218
Training results:
gen_loss: 0.98789257
disc_loss: 0.22466221
disc_acc: 0.9564356435643564

Validation results:
gen_loss: 0.9733425
disc_loss: 0.41928363
disc_acc: 0.9201388888888888


	Epoch 219
Training results:
gen_loss: 0.98746747
disc_loss: 0.129206
disc_acc: 0.9711633663366337

Validation results:
gen_loss: 0.99624515
disc_loss: 0.02066572
disc_acc: 0.9945436507936508


	Epoch 220
Training results:
gen_loss: 0.9889523
disc_loss: 0.09972083
disc_acc: 0.975

Validation results:
gen_loss: 0.98647606
disc_loss: 0.09192798
disc_acc: 0.9742063492063492


	Epoch 221
Training results:
gen_loss: 0.98254544
disc_loss: 0.19596493
disc_acc: 0.9538366336633664

Validation results:
gen_loss: 0.96764684
disc_loss: 0.3189664
disc_acc: 0.9047619047619048


	Epoch 222
Training results:
gen_loss: 0.9912094
disc_loss: 0.076328255
disc_acc: 0.9803217821782179

Validation results:
gen_loss: 0.9947646
disc_loss: 0.040364835
disc_acc: 0.9895833333333334


	Epoch 223
Training results:
gen_loss: 0.9927415
disc_loss: 0.035013247
disc_acc: 0.9902227722772278

Validation results:
gen_loss: 0.9860269
disc_loss: 0.10226028
disc_acc: 0.966765873015873


	Epoch 224
Training results:
gen_loss: 0.9801825
disc_loss: 0.41269442
disc_acc: 0.9313118811881188

Validation results:
gen_loss: 0.97064525
disc_loss: 0.8581523
disc_acc: 0.8670634920634921


	Epoch 225
Training results:
gen_loss: 0.98534817
disc_loss: 0.15555276
disc_acc: 0.9660891089108911

Validation results:
gen_loss: 0.9896906
disc_loss: 0.07334538
disc_acc: 0.9771825396825397


	Epoch 226
Training results:
gen_loss: 0.9863582
disc_loss: 0.101377
disc_acc: 0.9738861386138614

Validation results:
gen_loss: 0.9941528
disc_loss: 0.027087295
disc_acc: 0.9905753968253969


	Epoch 227
Training results:
gen_loss: 0.98890597
disc_loss: 0.050127465
disc_acc: 0.9849009900990099

Validation results:
gen_loss: 0.9786703
disc_loss: 0.10323078
disc_acc: 0.966765873015873


	Epoch 228
Training results:
gen_loss: 0.9831612
disc_loss: 0.14425693
disc_acc: 0.9642326732673268

Validation results:
gen_loss: 0.9938883
disc_loss: 0.071499705
disc_acc: 0.9856150793650794


	Epoch 229
Training results:
gen_loss: 0.98921263
disc_loss: 0.13489324
disc_acc: 0.9699257425742575

Validation results:
gen_loss: 0.99407494
disc_loss: 0.032731768
disc_acc: 0.9890873015873016


	Epoch 230
Training results:
gen_loss: 0.98930025
disc_loss: 0.14365523
disc_acc: 0.9702970297029703

Validation results:
gen_loss: 0.97233605
disc_loss: 0.2903776
disc_acc: 0.9201388888888888


	Epoch 231
Training results:
gen_loss: 0.9883261
disc_loss: 0.1028357
disc_acc: 0.9751237623762377

Validation results:
gen_loss: 0.98427945
disc_loss: 0.13320772
disc_acc: 0.9603174603174603


	Epoch 232
Training results:
gen_loss: 0.99004984
disc_loss: 0.06123028
disc_acc: 0.9818069306930693

Validation results:
gen_loss: 0.99629927
disc_loss: 0.048009265
disc_acc: 0.9935515873015873


	Epoch 233
Training results:
gen_loss: 0.9900423
disc_loss: 0.048177324
disc_acc: 0.9862623762376238

Validation results:
gen_loss: 0.98327357
disc_loss: 0.1030954
disc_acc: 0.9652777777777778


	Epoch 234
Training results:
gen_loss: 0.98220503
disc_loss: 0.4316396
disc_acc: 0.9301980198019802

Validation results:
gen_loss: 0.9933599
disc_loss: 0.077648774
disc_acc: 0.9796626984126984


	Epoch 235
Training results:
gen_loss: 0.98708004
disc_loss: 0.28368548
disc_acc: 0.9534653465346534

Validation results:
gen_loss: 0.9929849
disc_loss: 0.14893444
disc_acc: 0.9801587301587301


	Epoch 236
Training results:
gen_loss: 0.99037963
disc_loss: 0.11518671
disc_acc: 0.9738861386138614

Validation results:
gen_loss: 0.98675466
disc_loss: 0.0568036
disc_acc: 0.9816468253968254


	Epoch 237
Training results:
gen_loss: 0.98920065
disc_loss: 0.14454474
disc_acc: 0.9672029702970297

Validation results:
gen_loss: 0.9890797
disc_loss: 0.03523822
disc_acc: 0.9890873015873016


	Epoch 238
Training results:
gen_loss: 0.9917292
disc_loss: 0.04990431
disc_acc: 0.9862623762376238

Validation results:
gen_loss: 0.9895228
disc_loss: 0.072823815
disc_acc: 0.9776785714285714


	Epoch 239
Training results:
gen_loss: 0.9901858
disc_loss: 0.0776411
disc_acc: 0.9800742574257426

Validation results:
gen_loss: 0.99148005
disc_loss: 0.05045987
disc_acc: 0.9871031746031746


	Epoch 240
Training results:
gen_loss: 0.95917684
disc_loss: 0.8110116
disc_acc: 0.8649752475247525

Validation results:
gen_loss: 0.91352344
disc_loss: 0.7306257
disc_acc: 0.7762896825396826


	Epoch 241
Training results:
gen_loss: 0.8897536
disc_loss: 0.3873395
disc_acc: 0.8391089108910891

Validation results:
gen_loss: 0.89096475
disc_loss: 0.30292687
disc_acc: 0.8680555555555556


	Epoch 242
Training results:
gen_loss: 0.8928161
disc_loss: 0.35083005
disc_acc: 0.8574257425742574

Validation results:
gen_loss: 0.8809298
disc_loss: 0.28247803
disc_acc: 0.8839285714285714


	Epoch 243
Training results:
gen_loss: 0.8889079
disc_loss: 0.38521484
disc_acc: 0.8448019801980198

Validation results:
gen_loss: 0.8871773
disc_loss: 0.24120024
disc_acc: 0.9117063492063492


	Epoch 244
Training results:
gen_loss: 0.90495646
disc_loss: 0.22359265
disc_acc: 0.9024752475247525

Validation results:
gen_loss: 0.90072644
disc_loss: 0.19796418
disc_acc: 0.910218253968254


	Epoch 245
Training results:
gen_loss: 0.90732783
disc_loss: 0.24521288
disc_acc: 0.8969059405940594

Validation results:
gen_loss: 0.889706
disc_loss: 0.2837821
disc_acc: 0.8621031746031746


	Epoch 246
Training results:
gen_loss: 0.90747714
disc_loss: 0.30931315
disc_acc: 0.871039603960396

Validation results:
gen_loss: 0.9017435
disc_loss: 0.16896407
disc_acc: 0.9250992063492064


	Epoch 247
Training results:
gen_loss: 0.90630925
disc_loss: 0.26388842
disc_acc: 0.9003712871287128

Validation results:
gen_loss: 0.9238507
disc_loss: 0.15719692
disc_acc: 0.9384920634920635


	Epoch 248
Training results:
gen_loss: 0.90644616
disc_loss: 0.25718373
disc_acc: 0.8902227722772277

Validation results:
gen_loss: 0.903232
disc_loss: 0.16710038
disc_acc: 0.9627976190476191


	Epoch 249
Training results:
gen_loss: 0.9212117
disc_loss: 0.2506284
disc_acc: 0.8978960396039604

Validation results:
gen_loss: 0.9362603
disc_loss: 0.39984185
disc_acc: 0.7991071428571429


	Epoch 250
Training results:
gen_loss: 0.92467934
disc_loss: 0.3305377
disc_acc: 0.8886138613861386

Validation results:
gen_loss: 0.9187927
disc_loss: 0.17423002
disc_acc: 0.9489087301587301


	Epoch 251
Training results:
gen_loss: 0.9250592
disc_loss: 0.19357347
disc_acc: 0.9217821782178218

Validation results:
gen_loss: 0.9080876
disc_loss: 0.27311125
disc_acc: 0.8764880952380952


	Epoch 252
Training results:
gen_loss: 0.92695737
disc_loss: 0.2517554
disc_acc: 0.9002475247524753

Validation results:
gen_loss: 0.89903545
disc_loss: 0.3510127
disc_acc: 0.8323412698412699


	Epoch 253
Training results:
gen_loss: 0.93329114
disc_loss: 0.20098281
disc_acc: 0.9204207920792079

Validation results:
gen_loss: 0.94795024
disc_loss: 0.0812793
disc_acc: 0.9732142857142857


	Epoch 254
Training results:
gen_loss: 0.92774326
disc_loss: 0.2156168
disc_acc: 0.9101485148514852

Validation results:
gen_loss: 0.8888445
disc_loss: 0.28108665
disc_acc: 0.8521825396825397


	Epoch 255
Training results:
gen_loss: 0.92857546
disc_loss: 0.22856414
disc_acc: 0.9106435643564357

Validation results:
gen_loss: 0.9128886
disc_loss: 0.1924096
disc_acc: 0.9107142857142857


	Epoch 256
Training results:
gen_loss: 0.9284613
disc_loss: 0.22173041
disc_acc: 0.9092821782178218

Validation results:
gen_loss: 0.94619817
disc_loss: 0.10276997
disc_acc: 0.9657738095238095


	Epoch 257
Training results:
gen_loss: 0.9283925
disc_loss: 0.21595848
disc_acc: 0.9186881188118812

Validation results:
gen_loss: 0.8531677
disc_loss: 0.3344414
disc_acc: 0.8616071428571429


	Epoch 258
Training results:
gen_loss: 0.9143499
disc_loss: 0.28408745
disc_acc: 0.8930693069306931

Validation results:
gen_loss: 0.94808257
disc_loss: 0.18563905
disc_acc: 0.9141865079365079


	Epoch 259
Training results:
gen_loss: 0.9429914
disc_loss: 0.24247146
disc_acc: 0.9193069306930693

Validation results:
gen_loss: 0.940189
disc_loss: 0.22301371
disc_acc: 0.9027777777777778


	Epoch 260
Training results:
gen_loss: 0.9438067
disc_loss: 0.33975002
disc_acc: 0.8982673267326733

Validation results:
gen_loss: 0.93625957
disc_loss: 0.37169185
disc_acc: 0.8635912698412699


	Epoch 261
Training results:
gen_loss: 0.94907796
disc_loss: 0.14232673
disc_acc: 0.9474009900990099

Validation results:
gen_loss: 0.9568907
disc_loss: 0.069710486
disc_acc: 0.9732142857142857


	Epoch 262
Training results:
gen_loss: 0.9389816
disc_loss: 0.30348846
disc_acc: 0.903960396039604

Validation results:
gen_loss: 0.9476463
disc_loss: 0.2677448
disc_acc: 0.8958333333333334


	Epoch 263
Training results:
gen_loss: 0.94076216
disc_loss: 0.2255611
disc_acc: 0.9116336633663367

Validation results:
gen_loss: 0.9298793
disc_loss: 0.1269839
disc_acc: 0.9479166666666666


	Epoch 264
Training results:
gen_loss: 0.94137126
disc_loss: 0.2208342
disc_acc: 0.9220297029702971

Validation results:
gen_loss: 0.94024885
disc_loss: 0.096698
disc_acc: 0.9632936507936508


	Epoch 265
Training results:
gen_loss: 0.9527674
disc_loss: 0.123358525
disc_acc: 0.9507425742574257

Validation results:
gen_loss: 0.94232506
disc_loss: 0.18084134
disc_acc: 0.9236111111111112


	Epoch 266
Training results:
gen_loss: 0.9563602
disc_loss: 0.10114651
disc_acc: 0.9599009900990099

Validation results:
gen_loss: 0.9542563
disc_loss: 0.12612864
disc_acc: 0.9508928571428571


	Epoch 267
Training results:
gen_loss: 0.9465986
disc_loss: 0.2594113
disc_acc: 0.9091584158415842

Validation results:
gen_loss: 0.90587604
disc_loss: 0.2708
disc_acc: 0.8903769841269841


	Epoch 268
Training results:
gen_loss: 0.95138323
disc_loss: 0.16494486
disc_acc: 0.9456683168316832

Validation results:
gen_loss: 0.9454424
disc_loss: 0.28405482
disc_acc: 0.876984126984127


	Epoch 269
Training results:
gen_loss: 0.95478326
disc_loss: 0.5989105
disc_acc: 0.886509900990099

Validation results:
gen_loss: 0.97266203
disc_loss: 0.05112652
disc_acc: 0.9875992063492064


	Epoch 270
Training results:
gen_loss: 0.96676344
disc_loss: 0.098000914
disc_acc: 0.9648514851485148

Validation results:
gen_loss: 0.96027035
disc_loss: 0.10046858
disc_acc: 0.96875


	Epoch 271
Training results:
gen_loss: 0.96992743
disc_loss: 0.0756882
disc_acc: 0.9722772277227723

Validation results:
gen_loss: 0.9765573
disc_loss: 0.03690106
disc_acc: 0.9900793650793651


	Epoch 272
Training results:
gen_loss: 0.95606905
disc_loss: 0.1704343
disc_acc: 0.9356435643564357

Validation results:
gen_loss: 0.92904496
disc_loss: 0.20721151
disc_acc: 0.8834325396825397


	Epoch 273
Training results:
gen_loss: 0.95783406
disc_loss: 0.13947679
disc_acc: 0.9542079207920792

Validation results:
gen_loss: 0.9552239
disc_loss: 0.3332661
disc_acc: 0.9012896825396826


	Epoch 274
Training results:
gen_loss: 0.9610333
disc_loss: 0.11701025
disc_acc: 0.9554455445544554

Validation results:
gen_loss: 0.9382353
disc_loss: 0.3692457
disc_acc: 0.8541666666666666


	Epoch 275
Training results:
gen_loss: 0.95690536
disc_loss: 0.12982537
disc_acc: 0.9496287128712871

Validation results:
gen_loss: 0.9695227
disc_loss: 0.050664846
disc_acc: 0.9846230158730159


	Epoch 276
Training results:
gen_loss: 0.9538344
disc_loss: 0.14903876
disc_acc: 0.943069306930693

Validation results:
gen_loss: 0.946688
disc_loss: 0.14445083
disc_acc: 0.9389880952380952


	Epoch 277
Training results:
gen_loss: 0.9562044
disc_loss: 0.4192766
disc_acc: 0.8945544554455446

Validation results:
gen_loss: 0.97386545
disc_loss: 0.059428114
disc_acc: 0.9816468253968254


	Epoch 278
Training results:
gen_loss: 0.96812814
disc_loss: 0.10012723
disc_acc: 0.9643564356435643

Validation results:
gen_loss: 0.96547437
disc_loss: 0.13471606
disc_acc: 0.9424603174603174


	Epoch 279
Training results:
gen_loss: 0.9662038
disc_loss: 0.11683554
disc_acc: 0.9568069306930693

Validation results:
gen_loss: 0.9855211
disc_loss: 0.030611452
disc_acc: 0.9910714285714286


	Epoch 280
Training results:
gen_loss: 0.961177
disc_loss: 0.1677548
disc_acc: 0.9407178217821782

Validation results:
gen_loss: 0.95885974
disc_loss: 0.05286428
disc_acc: 0.9866071428571429


	Epoch 281
Training results:
gen_loss: 0.96116096
disc_loss: 0.0965783
disc_acc: 0.9621287128712871

Validation results:
gen_loss: 0.9675068
disc_loss: 0.04946709
disc_acc: 0.9836309523809523


	Epoch 282
Training results:
gen_loss: 0.9647398
disc_loss: 0.6141002
disc_acc: 0.899009900990099

Validation results:
gen_loss: 0.964796
disc_loss: 0.08836233
disc_acc: 0.9682539682539683


	Epoch 283
Training results:
gen_loss: 0.95672446
disc_loss: 0.20445898
disc_acc: 0.931930693069307

Validation results:
gen_loss: 0.96260357
disc_loss: 0.0832902
disc_acc: 0.9613095238095238


	Epoch 284
Training results:
gen_loss: 0.96880054
disc_loss: 0.087177575
disc_acc: 0.9673267326732673

Validation results:
gen_loss: 0.978694
disc_loss: 0.08720466
disc_acc: 0.9662698412698413


	Epoch 285
Training results:
gen_loss: 0.97271436
disc_loss: 0.07567664
disc_acc: 0.9714108910891089

Validation results:
gen_loss: 0.95517796
disc_loss: 0.32932845
disc_acc: 0.8606150793650794


	Epoch 286
Training results:
gen_loss: 0.9521689
disc_loss: 0.25674096
disc_acc: 0.9158415841584159

Validation results:
gen_loss: 0.9734481
disc_loss: 0.033250827
disc_acc: 0.9955357142857143


	Epoch 287
Training results:
gen_loss: 0.9526078
disc_loss: 0.18543832
disc_acc: 0.9330445544554455

Validation results:
gen_loss: 0.95051754
disc_loss: 0.22311676
disc_acc: 0.9017857142857143


	Epoch 288
Training results:
gen_loss: 0.9596813
disc_loss: 0.1570264
disc_acc: 0.9403465346534653

Validation results:
gen_loss: 0.9641483
disc_loss: 0.05236532
disc_acc: 0.9851190476190477


	Epoch 289
Training results:
gen_loss: 0.96092725
disc_loss: 0.14467043
disc_acc: 0.9518564356435644

Validation results:
gen_loss: 0.96535224
disc_loss: 0.35207134
disc_acc: 0.904265873015873


	Epoch 290
Training results:
gen_loss: 0.97325164
disc_loss: 0.09579113
disc_acc: 0.9705445544554455

Validation results:
gen_loss: 0.97709674
disc_loss: 0.0890675
disc_acc: 0.9751984126984127


	Epoch 291
Training results:
gen_loss: 0.9610613
disc_loss: 0.38942134
disc_acc: 0.9063118811881188

Validation results:
gen_loss: 0.94513035
disc_loss: 0.11033696
disc_acc: 0.9588293650793651


	Epoch 292
Training results:
gen_loss: 0.9323132
disc_loss: 0.2779984
disc_acc: 0.902970297029703

Validation results:
gen_loss: 0.9385513
disc_loss: 0.123888925
disc_acc: 0.9479166666666666


	Epoch 293
Training results:
gen_loss: 0.9407967
disc_loss: 0.13261865
disc_acc: 0.9495049504950495

Validation results:
gen_loss: 0.94791704
disc_loss: 0.13099612
disc_acc: 0.9424603174603174


	Epoch 294
Training results:
gen_loss: 0.9563587
disc_loss: 0.1112126
disc_acc: 0.9542079207920792

Validation results:
gen_loss: 0.95922965
disc_loss: 0.06405356
disc_acc: 0.9771825396825397


	Epoch 295
Training results:
gen_loss: 0.95220715
disc_loss: 0.16180848
disc_acc: 0.942450495049505

Validation results:
gen_loss: 0.94021225
disc_loss: 0.13520283
disc_acc: 0.9632936507936508


	Epoch 296
Training results:
gen_loss: 0.9566783
disc_loss: 0.11878325
disc_acc: 0.9577970297029703

Validation results:
gen_loss: 0.9552736
disc_loss: 0.14289837
disc_acc: 0.9399801587301587


	Epoch 297
Training results:
gen_loss: 0.9613697
disc_loss: 0.23241465
disc_acc: 0.9351485148514852

Validation results:
gen_loss: 0.9482359
disc_loss: 0.16899575
disc_acc: 0.9295634920634921


	Epoch 298
Training results:
gen_loss: 0.95176625
disc_loss: 0.3565973
disc_acc: 0.8983910891089109

Validation results:
gen_loss: 0.9495585
disc_loss: 0.13230775
disc_acc: 0.9692460317460317


	Epoch 299
Training results:
gen_loss: 0.96599704
disc_loss: 0.067307815
disc_acc: 0.9764851485148515

Validation results:
gen_loss: 0.9699772
disc_loss: 0.76494676
disc_acc: 0.7703373015873016


	Epoch 300
Training results:
gen_loss: 0.9608361
disc_loss: 0.15277849
disc_acc: 0.9496287128712871

Validation results:
gen_loss: 0.9494227
disc_loss: 0.21766733
disc_acc: 0.9375


	Epoch 301
Training results:
gen_loss: 0.9601678
disc_loss: 0.21355632
disc_acc: 0.941089108910891

Validation results:
gen_loss: 0.94860023
disc_loss: 0.46916145
disc_acc: 0.8581349206349206


	Epoch 302
Training results:
gen_loss: 0.9689538
disc_loss: 0.10055164
disc_acc: 0.9678217821782178

Validation results:
gen_loss: 0.98516816
disc_loss: 0.021370467
disc_acc: 0.9940476190476191


	Epoch 303
Training results:
gen_loss: 0.9696414
disc_loss: 0.123674326
disc_acc: 0.9570544554455446

Validation results:
gen_loss: 0.97522676
disc_loss: 1.2763106
disc_acc: 0.783234126984127


	Epoch 304
Training results:
gen_loss: 0.965889
disc_loss: 0.22817026
disc_acc: 0.9351485148514852

Validation results:
gen_loss: 0.9893498
disc_loss: 0.03042738
disc_acc: 0.9935515873015873


	Epoch 305
Training results:
gen_loss: 0.97117555
disc_loss: 0.13314569
disc_acc: 0.9571782178217821

Validation results:
gen_loss: 0.9685024
disc_loss: 0.112696156
disc_acc: 0.9618055555555556


	Epoch 306
Training results:
gen_loss: 0.9710244
disc_loss: 0.126555
disc_acc: 0.9607673267326733

Validation results:
gen_loss: 0.93705845
disc_loss: 0.5238298
disc_acc: 0.8194444444444444


	Epoch 307
Training results:
gen_loss: 0.9735262
disc_loss: 0.09570597
disc_acc: 0.9649752475247525

Validation results:
gen_loss: 0.97671294
disc_loss: 0.09920283
disc_acc: 0.9598214285714286


	Epoch 308
Training results:
gen_loss: 0.9646965
disc_loss: 0.25961763
disc_acc: 0.9324257425742575

Validation results:
gen_loss: 0.96975565
disc_loss: 0.22371557
disc_acc: 0.9181547619047619


	Epoch 309
Training results:
gen_loss: 0.9709587
disc_loss: 0.2207601
disc_acc: 0.9408415841584158

Validation results:
gen_loss: 0.983515
disc_loss: 0.055790868
disc_acc: 0.9761904761904762


	Epoch 310
Training results:
gen_loss: 0.97728187
disc_loss: 0.11093848
disc_acc: 0.9667079207920792

Validation results:
gen_loss: 0.98840386
disc_loss: 0.027039628
disc_acc: 0.9885912698412699


	Epoch 311
Training results:
gen_loss: 0.97542757
disc_loss: 0.1360658
disc_acc: 0.9602722772277228

Validation results:
gen_loss: 0.96413577
disc_loss: 0.21316916
disc_acc: 0.9285714285714286


	Epoch 312
Training results:
gen_loss: 0.97586536
disc_loss: 0.14656968
disc_acc: 0.9542079207920792

Validation results:
gen_loss: 0.95996225
disc_loss: 0.28493953
disc_acc: 0.8993055555555556


	Epoch 313
Training results:
gen_loss: 0.9747092
disc_loss: 0.19928887
disc_acc: 0.9465346534653465

Validation results:
gen_loss: 0.9730201
disc_loss: 1.1128061
disc_acc: 0.816468253968254


	Epoch 314
Training results:
gen_loss: 0.97785556
disc_loss: 0.3309447
disc_acc: 0.9389851485148515

Validation results:
gen_loss: 0.9926974
disc_loss: 0.015177685
disc_acc: 0.9945436507936508


	Epoch 315
Training results:
gen_loss: 0.98529804
disc_loss: 0.08385916
disc_acc: 0.9764851485148515

Validation results:
gen_loss: 0.9857852
disc_loss: 0.08934635
disc_acc: 0.9747023809523809


	Epoch 316
Training results:
gen_loss: 0.98093283
disc_loss: 0.19077708
disc_acc: 0.9587871287128713

Validation results:
gen_loss: 0.9903639
disc_loss: 0.03555935
disc_acc: 0.9866071428571429


	Epoch 317
Training results:
gen_loss: 0.9852335
disc_loss: 0.08148617
disc_acc: 0.9783415841584159

Validation results:
gen_loss: 0.9869158
disc_loss: 0.03071542
disc_acc: 0.9890873015873016


	Epoch 318
Training results:
gen_loss: 0.9860789
disc_loss: 0.052705605
disc_acc: 0.9825495049504951

Validation results:
gen_loss: 0.98952156
disc_loss: 0.0159383
disc_acc: 0.9955357142857143


	Epoch 319
Training results:
gen_loss: 0.9878691
disc_loss: 0.040755507
disc_acc: 0.9871287128712871

Validation results:
gen_loss: 0.97738045
disc_loss: 0.095379
disc_acc: 0.9623015873015873


	Epoch 320
Training results:
gen_loss: 0.98322433
disc_loss: 0.1118345
disc_acc: 0.9688118811881188

Validation results:
gen_loss: 0.9774471
disc_loss: 0.12109168
disc_acc: 0.9583333333333334


	Epoch 321
Training results:
gen_loss: 0.98467964
disc_loss: 0.11159644
disc_acc: 0.9717821782178218

Validation results:
gen_loss: 0.98357743
disc_loss: 0.12402353
disc_acc: 0.9677579365079365


	Epoch 322
Training results:
gen_loss: 0.9873564
disc_loss: 0.24392988
disc_acc: 0.9582920792079208

Validation results:
gen_loss: 0.98929197
disc_loss: 0.11356624
disc_acc: 0.9761904761904762


	Epoch 323
Training results:
gen_loss: 0.98736465
disc_loss: 0.21465114
disc_acc: 0.9576732673267326

Validation results:
gen_loss: 0.99309695
disc_loss: 0.04010025
disc_acc: 0.9880952380952381


	Epoch 324
Training results:
gen_loss: 0.99314946
disc_loss: 0.07355221
disc_acc: 0.9837871287128713

Validation results:
gen_loss: 0.9950274
disc_loss: 0.014556286
disc_acc: 0.9940476190476191


	Epoch 325
Training results:
gen_loss: 0.99460256
disc_loss: 0.021439118
disc_acc: 0.9943069306930693

Validation results:
gen_loss: 0.9981012
disc_loss: 0.003216151
disc_acc: 0.9985119047619048


	Epoch 326
Training results:
gen_loss: 0.9776331
disc_loss: 0.2146255
disc_acc: 0.9426980198019802

Validation results:
gen_loss: 0.9106947
disc_loss: 1.1517656
disc_acc: 0.7356150793650794


	Epoch 327
Training results:
gen_loss: 0.95947367
disc_loss: 0.16855514
disc_acc: 0.9478960396039604

Validation results:
gen_loss: 0.9711077
disc_loss: 0.06926811
disc_acc: 0.9697420634920635


	Epoch 328
Training results:
gen_loss: 0.9834395
disc_loss: 0.09572301
disc_acc: 0.9722772277227723

Validation results:
gen_loss: 0.9715714
disc_loss: 0.15241338
disc_acc: 0.9464285714285714


	Epoch 329
Training results:
gen_loss: 0.9841514
disc_loss: 0.15554401
disc_acc: 0.9623762376237623

Validation results:
gen_loss: 0.99731517
disc_loss: 0.029521631
disc_acc: 0.9930555555555556


	Epoch 330
Training results:
gen_loss: 0.98886245
disc_loss: 0.069391
disc_acc: 0.9783415841584159

Validation results:
gen_loss: 0.98734456
disc_loss: 0.076841444
disc_acc: 0.9742063492063492


	Epoch 331
Training results:
gen_loss: 0.9865605
disc_loss: 0.17389575
disc_acc: 0.9646039603960396

Validation results:
gen_loss: 0.99189353
disc_loss: 0.24093881
disc_acc: 0.9652777777777778


	Epoch 332
Training results:
gen_loss: 0.9906517
disc_loss: 0.13317795
disc_acc: 0.9706683168316832

Validation results:
gen_loss: 0.99114406
disc_loss: 0.05718008
disc_acc: 0.9856150793650794


	Epoch 333
Training results:
gen_loss: 0.9905345
disc_loss: 0.082573876
disc_acc: 0.9818069306930693

Validation results:
gen_loss: 0.98584735
disc_loss: 0.24038452
disc_acc: 0.9573412698412699


	Epoch 334
Training results:
gen_loss: 0.9900649
disc_loss: 0.05085734
disc_acc: 0.9837871287128713

Validation results:
gen_loss: 0.9792502
disc_loss: 0.42120293
disc_acc: 0.90625


	Epoch 335
Training results:
gen_loss: 0.98647195
disc_loss: 0.18927535
disc_acc: 0.9646039603960396

Validation results:
gen_loss: 0.98451525
disc_loss: 0.22355182
disc_acc: 0.9533730158730159


	Epoch 336
Training results:
gen_loss: 0.9937404
disc_loss: 0.0399717
disc_acc: 0.9886138613861386

Validation results:
gen_loss: 0.9928887
disc_loss: 0.029463151
disc_acc: 0.9875992063492064


	Epoch 337
Training results:
gen_loss: 0.99395204
disc_loss: 0.036202632
disc_acc: 0.9892326732673268

Validation results:
gen_loss: 0.9870875
disc_loss: 0.06545076
disc_acc: 0.9781746031746031


	Epoch 338
Training results:
gen_loss: 0.98791516
disc_loss: 0.123652466
disc_acc: 0.969430693069307

Validation results:
gen_loss: 0.98733497
disc_loss: 0.1789003
disc_acc: 0.9627976190476191


	Epoch 339
Training results:
gen_loss: 0.9881333
disc_loss: 0.2040805
disc_acc: 0.9603960396039604

Validation results:
gen_loss: 0.99334073
disc_loss: 0.047515742
disc_acc: 0.9871031746031746


	Epoch 340
Training results:
gen_loss: 0.99269813
disc_loss: 0.083331384
disc_acc: 0.9808168316831684

Validation results:
gen_loss: 0.9965133
disc_loss: 0.016909122
disc_acc: 0.9955357142857143


	Epoch 341
Training results:
gen_loss: 0.99636304
disc_loss: 0.013996256
disc_acc: 0.995420792079208

Validation results:
gen_loss: 0.9985998
disc_loss: 0.00648474
disc_acc: 0.9985119047619048


	Epoch 342
Training results:
gen_loss: 0.9913833
disc_loss: 0.09913252
disc_acc: 0.9774752475247525

Validation results:
gen_loss: 0.9928446
disc_loss: 0.040253554
disc_acc: 0.9880952380952381


	Epoch 343
Training results:
gen_loss: 0.98748463
disc_loss: 0.1882255
disc_acc: 0.9620049504950495

Validation results:
gen_loss: 0.9897532
disc_loss: 0.3056543
disc_acc: 0.9479166666666666


	Epoch 344
Training results:
gen_loss: 0.9915439
disc_loss: 0.12896794
disc_acc: 0.9731435643564357

Validation results:
gen_loss: 0.99351084
disc_loss: 0.09138134
disc_acc: 0.9801587301587301


	Epoch 345
Training results:
gen_loss: 0.99056065
disc_loss: 0.1782958
disc_acc: 0.967450495049505

Validation results:
gen_loss: 0.9896164
disc_loss: 0.3901703
disc_acc: 0.9513888888888888


	Epoch 346
Training results:
gen_loss: 0.9902945
disc_loss: 0.30128482
disc_acc: 0.9556930693069307

Validation results:
gen_loss: 0.9981474
disc_loss: 0.018495193
disc_acc: 0.9935515873015873


	Epoch 347
Training results:
gen_loss: 0.9945588
disc_loss: 0.13188362
disc_acc: 0.9804455445544554

Validation results:
gen_loss: 0.97513014
disc_loss: 0.6096887
disc_acc: 0.8928571428571429


	Epoch 348
Training results:
gen_loss: 0.9945291
disc_loss: 0.08291642
disc_acc: 0.9852722772277228

Validation results:
gen_loss: 0.996489
disc_loss: 0.032251455
disc_acc: 0.9935515873015873


	Epoch 349
Training results:
gen_loss: 0.99631757
disc_loss: 0.020678377
disc_acc: 0.9928217821782178

Validation results:
gen_loss: 0.9963195
disc_loss: 0.033420384
disc_acc: 0.9910714285714286


	Epoch 350
Training results:
gen_loss: 0.98769677
disc_loss: 0.4844989
disc_acc: 0.9367574257425743

Validation results:
gen_loss: 0.99755406
disc_loss: 0.03470007
disc_acc: 0.9920634920634921


	Epoch 351
Training results:
gen_loss: 0.9938427
disc_loss: 0.07560765
disc_acc: 0.9830445544554456

Validation results:
gen_loss: 0.9885841
disc_loss: 0.08425441
disc_acc: 0.9742063492063492


	Epoch 352
Training results:
gen_loss: 0.9951891
disc_loss: 0.044039767
disc_acc: 0.9888613861386139

Validation results:
gen_loss: 0.9962534
disc_loss: 0.013908555
disc_acc: 0.9945436507936508


	Epoch 353
Training results:
gen_loss: 0.9937094
disc_loss: 0.08180268
disc_acc: 0.9826732673267327

Validation results:
gen_loss: 0.9955677
disc_loss: 0.05106756
disc_acc: 0.9866071428571429


	Epoch 354
Training results:
gen_loss: 0.99535024
disc_loss: 0.03872279
disc_acc: 0.9912128712871288

Validation results:
gen_loss: 0.9946985
disc_loss: 0.03268424
disc_acc: 0.9910714285714286


	Epoch 355
Training results:
gen_loss: 0.9946276
disc_loss: 0.035316344
disc_acc: 0.9909653465346535

Validation results:
gen_loss: 0.99737406
disc_loss: 0.011200543
disc_acc: 0.9965277777777778


	Epoch 356
Training results:
gen_loss: 0.99417216
disc_loss: 0.049250595
disc_acc: 0.9873762376237624

Validation results:
gen_loss: 0.9836868
disc_loss: 0.14722909
disc_acc: 0.9538690476190477


	Epoch 357
Training results:
gen_loss: 0.9913138
disc_loss: 0.24729683
disc_acc: 0.9632425742574258

Validation results:
gen_loss: 0.98497355
disc_loss: 0.62231797
disc_acc: 0.9126984126984127


	Epoch 358
Training results:
gen_loss: 0.99476326
disc_loss: 0.07402053
disc_acc: 0.9856435643564356

Validation results:
gen_loss: 0.99838966
disc_loss: 0.009538192
disc_acc: 0.9970238095238095


	Epoch 359
Training results:
gen_loss: 0.99591905
disc_loss: 0.051068515
disc_acc: 0.9897277227722773

Validation results:
gen_loss: 0.9978501
disc_loss: 0.020078067
disc_acc: 0.9955357142857143


	Epoch 360
Training results:
gen_loss: 0.9955942
disc_loss: 0.031374812
disc_acc: 0.9919554455445545

Validation results:
gen_loss: 0.9961522
disc_loss: 0.020393085
disc_acc: 0.9925595238095238


	Epoch 361
Training results:
gen_loss: 0.99636096
disc_loss: 0.081600696
disc_acc: 0.9868811881188119

Validation results:
gen_loss: 0.97301126
disc_loss: 0.34859455
disc_acc: 0.9399801587301587


	Epoch 362
Training results:
gen_loss: 0.9920988
disc_loss: 0.23893337
disc_acc: 0.9623762376237623

Validation results:
gen_loss: 0.99735117
disc_loss: 0.009901093
disc_acc: 0.9970238095238095


	Epoch 363
Training results:
gen_loss: 0.9939413
disc_loss: 0.10730446
disc_acc: 0.9805693069306931

Validation results:
gen_loss: 0.9830463
disc_loss: 0.1470399
disc_acc: 0.9608134920634921


	Epoch 364
Training results:
gen_loss: 0.99077475
disc_loss: 0.56922525
disc_acc: 0.9461633663366337

Validation results:
gen_loss: 0.98699224
disc_loss: 0.87667525
disc_acc: 0.904265873015873


	Epoch 365
Training results:
gen_loss: 0.9955128
disc_loss: 0.31075537
disc_acc: 0.9686881188118812

Validation results:
gen_loss: 0.99770695
disc_loss: 0.036077883
disc_acc: 0.9915674603174603


	Epoch 366
Training results:
gen_loss: 0.9975054
disc_loss: 0.054612294
disc_acc: 0.9900990099009901

Validation results:
gen_loss: 0.9984065
disc_loss: 0.045530323
disc_acc: 0.9945436507936508


	Epoch 367
Training results:
gen_loss: 0.9975417
disc_loss: 0.018025056
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 0.9989462
disc_loss: 0.00264631
disc_acc: 0.9990079365079365


	Epoch 368
Training results:
gen_loss: 0.9958196
disc_loss: 0.13784702
disc_acc: 0.9811881188118812

Validation results:
gen_loss: 0.99676794
disc_loss: 0.042685654
disc_acc: 0.9885912698412699


	Epoch 369
Training results:
gen_loss: 0.9955772
disc_loss: 0.13618203
disc_acc: 0.9787128712871287

Validation results:
gen_loss: 0.9944171
disc_loss: 0.30217662
disc_acc: 0.9657738095238095


	Epoch 370
Training results:
gen_loss: 0.9956266
disc_loss: 0.10825442
disc_acc: 0.9837871287128713

Validation results:
gen_loss: 0.998105
disc_loss: 0.023097238
disc_acc: 0.9945436507936508


	Epoch 371
Training results:
gen_loss: 0.9972324
disc_loss: 0.030435218
disc_acc: 0.9930693069306931

Validation results:
gen_loss: 0.9942906
disc_loss: 0.05141733
disc_acc: 0.9861111111111112


	Epoch 372
Training results:
gen_loss: 0.993976
disc_loss: 0.0930348
disc_acc: 0.9819306930693069

Validation results:
gen_loss: 0.9972144
disc_loss: 0.056187734
disc_acc: 0.9871031746031746


	Epoch 373
Training results:
gen_loss: 0.99617237
disc_loss: 0.074962206
disc_acc: 0.9872524752475248

Validation results:
gen_loss: 0.99861705
disc_loss: 0.011348717
disc_acc: 0.9955357142857143


	Epoch 374
Training results:
gen_loss: 0.9984091
disc_loss: 0.009267812
disc_acc: 0.99740099009901

Validation results:
gen_loss: 0.99721813
disc_loss: 0.041297413
disc_acc: 0.9925595238095238


	Epoch 375
Training results:
gen_loss: 0.99575096
disc_loss: 0.048194196
disc_acc: 0.9881188118811881

Validation results:
gen_loss: 0.9980011
disc_loss: 0.0090566045
disc_acc: 0.9975198412698413


	Epoch 376
Training results:
gen_loss: 0.99138814
disc_loss: 0.37270665
disc_acc: 0.9550742574257426

Validation results:
gen_loss: 0.97646713
disc_loss: 1.7019726
disc_acc: 0.7976190476190477


	Epoch 377
Training results:
gen_loss: 0.9946743
disc_loss: 0.17075993
disc_acc: 0.9732673267326732

Validation results:
gen_loss: 0.9990349
disc_loss: 0.003799654
disc_acc: 0.9995039682539683


	Epoch 378
Training results:
gen_loss: 0.99590147
disc_loss: 0.189575
disc_acc: 0.9768564356435644

Validation results:
gen_loss: 0.99886763
disc_loss: 0.047005225
disc_acc: 0.9920634920634921


	Epoch 379
Training results:
gen_loss: 0.9955911
disc_loss: 0.24524519
disc_acc: 0.9743811881188119

Validation results:
gen_loss: 0.9977419
disc_loss: 0.06751354
disc_acc: 0.9905753968253969


	Epoch 380
Training results:
gen_loss: 0.9981575
disc_loss: 0.019662881
disc_acc: 0.9948019801980198

Validation results:
gen_loss: 0.9982265
disc_loss: 0.042977408
disc_acc: 0.9945436507936508


	Epoch 381
Training results:
gen_loss: 0.995959
disc_loss: 0.1087305
disc_acc: 0.9826732673267327

Validation results:
gen_loss: 0.9966501
disc_loss: 0.03011805
disc_acc: 0.9920634920634921


	Epoch 382
Training results:
gen_loss: 0.99679303
disc_loss: 0.051275432
disc_acc: 0.9896039603960396

Validation results:
gen_loss: 0.99629015
disc_loss: 0.060427018
disc_acc: 0.9880952380952381


	Epoch 383
Training results:
gen_loss: 0.9969253
disc_loss: 0.025780344
disc_acc: 0.9929455445544555

Validation results:
gen_loss: 0.9987164
disc_loss: 0.002843222
disc_acc: 0.9990079365079365


	Epoch 384
Training results:
gen_loss: 0.992927
disc_loss: 0.16874972
disc_acc: 0.9711633663366337

Validation results:
gen_loss: 0.99699885
disc_loss: 0.09945133
disc_acc: 0.9851190476190477


	Epoch 385
Training results:
gen_loss: 0.9959488
disc_loss: 0.06716126
disc_acc: 0.9861386138613861

Validation results:
gen_loss: 0.9981559
disc_loss: 0.015736168
disc_acc: 0.9965277777777778


	Epoch 386
Training results:
gen_loss: 0.99380255
disc_loss: 0.14315942
disc_acc: 0.9742574257425742

Validation results:
gen_loss: 0.98867077
disc_loss: 0.33949953
disc_acc: 0.9439484126984127


	Epoch 387
Training results:
gen_loss: 0.9952021
disc_loss: 0.24971107
disc_acc: 0.972029702970297

Validation results:
gen_loss: 0.99907565
disc_loss: 0.0026284205
disc_acc: 0.9990079365079365


	Epoch 388
Training results:
gen_loss: 0.9957319
disc_loss: 0.1413758
disc_acc: 0.9794554455445544

Validation results:
gen_loss: 0.99361193
disc_loss: 0.09412539
disc_acc: 0.9766865079365079


	Epoch 389
Training results:
gen_loss: 0.9969632
disc_loss: 0.043881852
disc_acc: 0.9922029702970298

Validation results:
gen_loss: 0.9971756
disc_loss: 0.033209946
disc_acc: 0.9925595238095238


	Epoch 390
Training results:
gen_loss: 0.9904198
disc_loss: 0.79034007
disc_acc: 0.9334158415841585

Validation results:
gen_loss: 0.9861039
disc_loss: 3.5310447
disc_acc: 0.7886904761904762


	Epoch 391
Training results:
gen_loss: 0.996215
disc_loss: 0.40580198
disc_acc: 0.9669554455445545

Validation results:
gen_loss: 0.99797034
disc_loss: 0.041431874
disc_acc: 0.9915674603174603


	Epoch 392
Training results:
gen_loss: 0.99758285
disc_loss: 0.12891954
disc_acc: 0.9852722772277228

Validation results:
gen_loss: 0.9952157
disc_loss: 0.09259355
disc_acc: 0.9836309523809523


	Epoch 393
Training results:
gen_loss: 0.9975988
disc_loss: 0.10176627
disc_acc: 0.9870049504950495

Validation results:
gen_loss: 0.9983352
disc_loss: 0.036433484
disc_acc: 0.9940476190476191


	Epoch 394
Training results:
gen_loss: 0.9985526
disc_loss: 0.022481766
disc_acc: 0.995420792079208

Validation results:
gen_loss: 0.99805796
disc_loss: 0.020826943
disc_acc: 0.9940476190476191


	Epoch 395
Training results:
gen_loss: 0.99570245
disc_loss: 0.087130815
disc_acc: 0.9844059405940594

Validation results:
gen_loss: 0.996628
disc_loss: 0.094288774
disc_acc: 0.9821428571428571


	Epoch 396
Training results:
gen_loss: 0.99492127
disc_loss: 0.11465017
disc_acc: 0.9793316831683169

Validation results:
gen_loss: 0.9970762
disc_loss: 0.068241134
disc_acc: 0.9880952380952381


	Epoch 397
Training results:
gen_loss: 0.99545825
disc_loss: 0.088812985
disc_acc: 0.9840346534653466

Validation results:
gen_loss: 0.99731225
disc_loss: 0.020097466
disc_acc: 0.9935515873015873


	Epoch 398
Training results:
gen_loss: 0.99646205
disc_loss: 0.05189512
disc_acc: 0.9883663366336634

Validation results:
gen_loss: 0.9957223
disc_loss: 0.04600896
disc_acc: 0.9895833333333334


	Epoch 399
Training results:
gen_loss: 0.9940308
disc_loss: 0.20361082
disc_acc: 0.9709158415841584

Validation results:
gen_loss: 0.9956199
disc_loss: 0.08174988
disc_acc: 0.9841269841269841


	Epoch 400
Training results:
gen_loss: 0.99770796
disc_loss: 0.04658279
disc_acc: 0.991460396039604

Validation results:
gen_loss: 0.9962295
disc_loss: 0.07817089
disc_acc: 0.9856150793650794


	Epoch 401
Training results:
gen_loss: 0.9934499
disc_loss: 0.14587924
disc_acc: 0.975

Validation results:
gen_loss: 0.99698186
disc_loss: 0.01210988
disc_acc: 0.9940476190476191


	Epoch 402
Training results:
gen_loss: 0.997074
disc_loss: 0.049135413
disc_acc: 0.9897277227722773

Validation results:
gen_loss: 0.99697423
disc_loss: 0.015167719
disc_acc: 0.9945436507936508


	Epoch 403
Training results:
gen_loss: 0.9927803
disc_loss: 0.29330242
disc_acc: 0.9646039603960396

Validation results:
gen_loss: 0.9937739
disc_loss: 0.111723974
disc_acc: 0.9821428571428571


	Epoch 404
Training results:
gen_loss: 0.99670804
disc_loss: 0.107652195
disc_acc: 0.9836633663366336

Validation results:
gen_loss: 0.99800986
disc_loss: 0.079444036
disc_acc: 0.9900793650793651


	Epoch 405
Training results:
gen_loss: 0.996872
disc_loss: 0.14641337
disc_acc: 0.9820544554455446

Validation results:
gen_loss: 0.9970117
disc_loss: 0.13109748
disc_acc: 0.9831349206349206


	Epoch 406
Training results:
gen_loss: 0.99654216
disc_loss: 0.123196214
disc_acc: 0.9826732673267327

Validation results:
gen_loss: 0.99368083
disc_loss: 0.18035561
disc_acc: 0.970734126984127


	Epoch 407
Training results:
gen_loss: 0.99643004
disc_loss: 0.10965015
disc_acc: 0.9849009900990099

Validation results:
gen_loss: 0.9983183
disc_loss: 0.007761926
disc_acc: 0.9965277777777778


	Epoch 408
Training results:
gen_loss: 0.99464774
disc_loss: 0.15890507
disc_acc: 0.9794554455445544

Validation results:
gen_loss: 0.9943948
disc_loss: 0.11936764
disc_acc: 0.9831349206349206


	Epoch 409
Training results:
gen_loss: 0.99693066
disc_loss: 0.062291484
disc_acc: 0.9888613861386139

Validation results:
gen_loss: 0.9981471
disc_loss: 0.024876531
disc_acc: 0.9945436507936508


	Epoch 410
Training results:
gen_loss: 0.99638385
disc_loss: 0.05823036
disc_acc: 0.9883663366336634

Validation results:
gen_loss: 0.9976062
disc_loss: 0.028760875
disc_acc: 0.9930555555555556


	Epoch 411
Training results:
gen_loss: 0.99289644
disc_loss: 0.24459194
disc_acc: 0.9663366336633663

Validation results:
gen_loss: 0.99682283
disc_loss: 0.12295247
disc_acc: 0.9836309523809523


	Epoch 412
Training results:
gen_loss: 0.9977313
disc_loss: 0.098540545
disc_acc: 0.9877475247524753

Validation results:
gen_loss: 0.9993921
disc_loss: 0.017966073
disc_acc: 0.9970238095238095


	Epoch 413
Training results:
gen_loss: 0.9976462
disc_loss: 0.039970502
disc_acc: 0.9912128712871288

Validation results:
gen_loss: 0.995668
disc_loss: 0.07133021
disc_acc: 0.9866071428571429


	Epoch 414
Training results:
gen_loss: 0.9968448
disc_loss: 0.080716304
disc_acc: 0.9871287128712871

Validation results:
gen_loss: 0.99353737
disc_loss: 0.16682242
disc_acc: 0.9742063492063492


	Epoch 415
Training results:
gen_loss: 0.99543333
disc_loss: 0.4293321
disc_acc: 0.9649752475247525

Validation results:
gen_loss: 0.99391407
disc_loss: 0.31328803
disc_acc: 0.9632936507936508


	Epoch 416
Training results:
gen_loss: 0.99748814
disc_loss: 0.1718289
disc_acc: 0.9846534653465346

Validation results:
gen_loss: 0.99897474
disc_loss: 0.04538138
disc_acc: 0.9940476190476191


	Epoch 417
Training results:
gen_loss: 0.997993
disc_loss: 0.052344292
disc_acc: 0.9905940594059406

Validation results:
gen_loss: 0.9987359
disc_loss: 0.06785691
disc_acc: 0.9915674603174603


	Epoch 418
Training results:
gen_loss: 0.9958274
disc_loss: 0.1390788
disc_acc: 0.9829207920792079

Validation results:
gen_loss: 0.9972163
disc_loss: 0.02824832
disc_acc: 0.9920634920634921


	Epoch 419
Training results:
gen_loss: 0.9957813
disc_loss: 0.10214058
disc_acc: 0.9824257425742574

Validation results:
gen_loss: 0.9972213
disc_loss: 0.058350306
disc_acc: 0.9890873015873016


	Epoch 420
Training results:
gen_loss: 0.9981299
disc_loss: 0.016765913
disc_acc: 0.995420792079208

Validation results:
gen_loss: 0.9989677
disc_loss: 0.016010819
disc_acc: 0.9970238095238095


	Epoch 421
Training results:
gen_loss: 0.99400485
disc_loss: 0.39915156
disc_acc: 0.9638613861386138

Validation results:
gen_loss: 0.9973351
disc_loss: 0.09557323
disc_acc: 0.9866071428571429


	Epoch 422
Training results:
gen_loss: 0.9975292
disc_loss: 0.082779855
disc_acc: 0.9888613861386139

Validation results:
gen_loss: 0.9975452
disc_loss: 0.015040116
disc_acc: 0.9965277777777778


	Epoch 423
Training results:
gen_loss: 0.99707866
disc_loss: 0.055956747
disc_acc: 0.9896039603960396

Validation results:
gen_loss: 0.9987197
disc_loss: 0.020048136
disc_acc: 0.9945436507936508


	Epoch 424
Training results:
gen_loss: 0.99712014
disc_loss: 0.116041265
disc_acc: 0.9836633663366336

Validation results:
gen_loss: 0.9975108
disc_loss: 0.15873936
disc_acc: 0.9875992063492064


	Epoch 425
Training results:
gen_loss: 0.9953074
disc_loss: 0.0821019
disc_acc: 0.9845297029702971

Validation results:
gen_loss: 0.99463755
disc_loss: 0.086072266
disc_acc: 0.9801587301587301


	Epoch 426
Training results:
gen_loss: 0.9960819
disc_loss: 0.09511069
disc_acc: 0.9841584158415841

Validation results:
gen_loss: 0.9870346
disc_loss: 0.23478483
disc_acc: 0.9494047619047619


	Epoch 427
Training results:
gen_loss: 0.9921101
disc_loss: 0.20786308
disc_acc: 0.968440594059406

Validation results:
gen_loss: 0.9960568
disc_loss: 0.04697457
disc_acc: 0.9875992063492064


	Epoch 428
Training results:
gen_loss: 0.99622816
disc_loss: 0.037636254
disc_acc: 0.9900990099009901

Validation results:
gen_loss: 0.99799
disc_loss: 0.031806327
disc_acc: 0.9915674603174603


	Epoch 429
Training results:
gen_loss: 0.993592
disc_loss: 0.5388999
disc_acc: 0.9525990099009901

Validation results:
gen_loss: 0.99399567
disc_loss: 0.6922061
disc_acc: 0.9365079365079365


	Epoch 430
Training results:
gen_loss: 0.99628204
disc_loss: 0.22513966
disc_acc: 0.9780940594059406

Validation results:
gen_loss: 0.9983606
disc_loss: 0.02680737
disc_acc: 0.9940476190476191


	Epoch 431
Training results:
gen_loss: 0.9968804
disc_loss: 0.08667427
disc_acc: 0.9861386138613861

Validation results:
gen_loss: 0.99866253
disc_loss: 0.13026801
disc_acc: 0.9890873015873016


	Epoch 432
Training results:
gen_loss: 0.99813604
disc_loss: 0.044372015
disc_acc: 0.9939356435643565

Validation results:
gen_loss: 0.9980122
disc_loss: 0.068513505
disc_acc: 0.9920634920634921


	Epoch 433
Training results:
gen_loss: 0.9979446
disc_loss: 0.040261548
disc_acc: 0.994059405940594

Validation results:
gen_loss: 0.99815285
disc_loss: 0.028148197
disc_acc: 0.9935515873015873


	Epoch 434
Training results:
gen_loss: 0.9973107
disc_loss: 0.021208333
disc_acc: 0.9933168316831683

Validation results:
gen_loss: 0.9990792
disc_loss: 0.011040224
disc_acc: 0.9965277777777778


	Epoch 435
Training results:
gen_loss: 0.995871
disc_loss: 0.05674235
disc_acc: 0.9878712871287129

Validation results:
gen_loss: 0.9992917
disc_loss: 0.0043189796
disc_acc: 0.9985119047619048


	Epoch 436
Training results:
gen_loss: 0.99352187
disc_loss: 0.120350786
disc_acc: 0.9777227722772277

Validation results:
gen_loss: 0.9938979
disc_loss: 0.2909106
disc_acc: 0.9627976190476191


	Epoch 437
Training results:
gen_loss: 0.99511904
disc_loss: 0.42023003
disc_acc: 0.9621287128712871

Validation results:
gen_loss: 0.99902976
disc_loss: 0.0091911275
disc_acc: 0.9970238095238095


	Epoch 438
Training results:
gen_loss: 0.9975108
disc_loss: 0.079638176
disc_acc: 0.9867574257425743

Validation results:
gen_loss: 0.9976758
disc_loss: 0.05350741
disc_acc: 0.9930555555555556


	Epoch 439
Training results:
gen_loss: 0.9975537
disc_loss: 0.048090395
disc_acc: 0.9922029702970298

Validation results:
gen_loss: 0.99455214
disc_loss: 0.36998826
disc_acc: 0.964781746031746


	Epoch 440
Training results:
gen_loss: 0.99613243
disc_loss: 0.12614352
disc_acc: 0.9827970297029703

Validation results:
gen_loss: 0.9990336
disc_loss: 0.067971475
disc_acc: 0.9935515873015873


	Epoch 441
Training results:
gen_loss: 0.99556386
disc_loss: 0.23039794
disc_acc: 0.9731435643564357

Validation results:
gen_loss: 0.9988565
disc_loss: 0.04464502
disc_acc: 0.9950396825396826


	Epoch 442
Training results:
gen_loss: 0.9969561
disc_loss: 0.12279887
disc_acc: 0.9862623762376238

Validation results:
gen_loss: 0.9987699
disc_loss: 0.10808287
disc_acc: 0.9890873015873016


	Epoch 443
Training results:
gen_loss: 0.99752194
disc_loss: 0.12181084
disc_acc: 0.9866336633663366

Validation results:
gen_loss: 0.99711746
disc_loss: 0.071986265
disc_acc: 0.9851190476190477


	Epoch 444
Training results:
gen_loss: 0.99803853
disc_loss: 0.033076033
disc_acc: 0.9941831683168317

Validation results:
gen_loss: 0.9983401
disc_loss: 0.022083268
disc_acc: 0.9950396825396826


	Epoch 445
Training results:
gen_loss: 0.9959013
disc_loss: 0.14032069
disc_acc: 0.9837871287128713

Validation results:
gen_loss: 0.9973827
disc_loss: 0.017308122
disc_acc: 0.9950396825396826


	Epoch 446
Training results:
gen_loss: 0.99745965
disc_loss: 0.054381277
disc_acc: 0.9913366336633663

Validation results:
gen_loss: 0.99272716
disc_loss: 0.2387034
disc_acc: 0.9588293650793651


	Epoch 447
Training results:
gen_loss: 0.9986456
disc_loss: 0.027994355
disc_acc: 0.995049504950495

Validation results:
gen_loss: 0.9964152
disc_loss: 0.026857173
disc_acc: 0.9915674603174603


	Epoch 448
Training results:
gen_loss: 0.9956913
disc_loss: 0.11028643
disc_acc: 0.9811881188118812

Validation results:
gen_loss: 0.9968747
disc_loss: 0.048067532
disc_acc: 0.9915674603174603


	Epoch 449
Training results:
gen_loss: 0.9966387
disc_loss: 0.4180866
disc_acc: 0.9691831683168317

Validation results:
gen_loss: 0.99952424
disc_loss: 0.043940403
disc_acc: 0.9950396825396826


	Epoch 450
Training results:
gen_loss: 0.9972231
disc_loss: 0.13799295
disc_acc: 0.9839108910891089

Validation results:
gen_loss: 0.9994454
disc_loss: 0.0703184
disc_acc: 0.9945436507936508


	Epoch 451
Training results:
gen_loss: 0.99761724
disc_loss: 0.06882836
disc_acc: 0.9905940594059406

Validation results:
gen_loss: 0.99771446
disc_loss: 0.05514761
disc_acc: 0.9900793650793651


	Epoch 452
Training results:
gen_loss: 0.99865407
disc_loss: 0.010576968
disc_acc: 0.9971534653465347

Validation results:
gen_loss: 0.9940251
disc_loss: 0.1397919
disc_acc: 0.9717261904761905


	Epoch 453
Training results:
gen_loss: 0.9981084
disc_loss: 0.044947278
disc_acc: 0.992450495049505

Validation results:
gen_loss: 0.9985468
disc_loss: 0.026009273
disc_acc: 0.9945436507936508


	Epoch 454
Training results:
gen_loss: 0.99856776
disc_loss: 0.02027419
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 0.99949086
disc_loss: 0.0037422124
disc_acc: 0.9990079365079365


	Epoch 455
Training results:
gen_loss: 0.9980483
disc_loss: 0.05561759
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 0.99861497
disc_loss: 0.009433745
disc_acc: 0.9965277777777778


	Epoch 456
Training results:
gen_loss: 0.99528325
disc_loss: 0.45916063
disc_acc: 0.9649752475247525

Validation results:
gen_loss: 0.9982193
disc_loss: 0.08133389
disc_acc: 0.9905753968253969


	Epoch 457
Training results:
gen_loss: 0.9966677
disc_loss: 0.27997753
disc_acc: 0.9764851485148515

Validation results:
gen_loss: 0.99850464
disc_loss: 0.06560401
disc_acc: 0.9945436507936508


	Epoch 458
Training results:
gen_loss: 0.9975246
disc_loss: 0.062351894
disc_acc: 0.9902227722772278

Validation results:
gen_loss: 0.9980924
disc_loss: 0.059225336
disc_acc: 0.9910714285714286


	Epoch 459
Training results:
gen_loss: 0.9970234
disc_loss: 0.1216555
disc_acc: 0.9856435643564356

Validation results:
gen_loss: 0.99950224
disc_loss: 0.019374425
disc_acc: 0.9955357142857143


	Epoch 460
Training results:
gen_loss: 0.9978352
disc_loss: 0.104204655
disc_acc: 0.9867574257425743

Validation results:
gen_loss: 0.9941259
disc_loss: 0.114281036
disc_acc: 0.9781746031746031


	Epoch 461
Training results:
gen_loss: 0.9975716
disc_loss: 0.05530213
disc_acc: 0.9902227722772278

Validation results:
gen_loss: 0.9983294
disc_loss: 0.024335487
disc_acc: 0.9930555555555556


	Epoch 462
Training results:
gen_loss: 0.9975107
disc_loss: 0.14356554
disc_acc: 0.9872524752475248

Validation results:
gen_loss: 0.99686944
disc_loss: 0.28109616
disc_acc: 0.9702380952380952


	Epoch 463
Training results:
gen_loss: 0.9959309
disc_loss: 0.17417155
disc_acc: 0.9794554455445544

Validation results:
gen_loss: 0.99460393
disc_loss: 0.372421
disc_acc: 0.9464285714285714


	Epoch 464
Training results:
gen_loss: 0.9983285
disc_loss: 0.052858125
disc_acc: 0.9922029702970298

Validation results:
gen_loss: 0.9990198
disc_loss: 0.028791163
disc_acc: 0.9965277777777778


	Epoch 465
Training results:
gen_loss: 0.9970609
disc_loss: 0.07399796
disc_acc: 0.9886138613861386

Validation results:
gen_loss: 0.9932179
disc_loss: 0.12951833
disc_acc: 0.9722222222222222


	Epoch 466
Training results:
gen_loss: 0.99697423
disc_loss: 0.13577682
disc_acc: 0.9832920792079208

Validation results:
gen_loss: 0.9933751
disc_loss: 0.27419823
disc_acc: 0.9608134920634921


	Epoch 467
Training results:
gen_loss: 0.9980125
disc_loss: 0.049848028
disc_acc: 0.9912128712871288

Validation results:
gen_loss: 0.99447626
disc_loss: 0.26694125
disc_acc: 0.9618055555555556


	Epoch 468
Training results:
gen_loss: 0.997697
disc_loss: 0.029815083
disc_acc: 0.9938118811881188

Validation results:
gen_loss: 0.9974638
disc_loss: 0.028444268
disc_acc: 0.9915674603174603


	Epoch 469
Training results:
gen_loss: 0.99570155
disc_loss: 0.18463202
disc_acc: 0.9778465346534654

Validation results:
gen_loss: 0.99818146
disc_loss: 0.058383245
disc_acc: 0.9905753968253969


	Epoch 470
Training results:
gen_loss: 0.99632096
disc_loss: 0.89175606
disc_acc: 0.9556930693069307

Validation results:
gen_loss: 0.99891293
disc_loss: 0.06834765
disc_acc: 0.9925595238095238


	Epoch 471
Training results:
gen_loss: 0.9983466
disc_loss: 0.12924477
disc_acc: 0.988490099009901

Validation results:
gen_loss: 0.9986179
disc_loss: 0.16357759
disc_acc: 0.9866071428571429


	Epoch 472
Training results:
gen_loss: 0.99701285
disc_loss: 0.24346313
disc_acc: 0.9792079207920792

Validation results:
gen_loss: 0.99703586
disc_loss: 0.4969714
disc_acc: 0.9603174603174603


	Epoch 473
Training results:
gen_loss: 0.99656916
disc_loss: 0.1385255
disc_acc: 0.9845297029702971

Validation results:
gen_loss: 0.9986442
disc_loss: 0.10075279
disc_acc: 0.9905753968253969


	Epoch 474
Training results:
gen_loss: 0.9962528
disc_loss: 0.12176225
disc_acc: 0.9829207920792079

Validation results:
gen_loss: 0.9959866
disc_loss: 0.063213415
disc_acc: 0.9846230158730159


	Epoch 475
Training results:
gen_loss: 0.9957993
disc_loss: 0.11648044
disc_acc: 0.9820544554455446

Validation results:
gen_loss: 0.9969773
disc_loss: 0.027248824
disc_acc: 0.9920634920634921


	Epoch 476
Training results:
gen_loss: 0.99691707
disc_loss: 0.10620121
disc_acc: 0.9853960396039604

Validation results:
gen_loss: 0.99839216
disc_loss: 0.0113548245
disc_acc: 0.9970238095238095


	Epoch 477
Training results:
gen_loss: 0.9983777
disc_loss: 0.03596138
disc_acc: 0.9939356435643565

Validation results:
gen_loss: 0.99817055
disc_loss: 0.039946835
disc_acc: 0.9935515873015873


	Epoch 478
Training results:
gen_loss: 0.9979825
disc_loss: 0.058056813
disc_acc: 0.992450495049505

Validation results:
gen_loss: 0.99902827
disc_loss: 0.01846512
disc_acc: 0.9965277777777778


	Epoch 479
Training results:
gen_loss: 0.9974951
disc_loss: 0.16619608
disc_acc: 0.9841584158415841

Validation results:
gen_loss: 0.99333334
disc_loss: 0.95362854
disc_acc: 0.9226190476190477


	Epoch 480
Training results:
gen_loss: 0.9958476
disc_loss: 0.38226125
disc_acc: 0.9643564356435643

Validation results:
gen_loss: 0.998883
disc_loss: 0.042555306
disc_acc: 0.9950396825396826


	Epoch 481
Training results:
gen_loss: 0.9980366
disc_loss: 0.1683905
disc_acc: 0.9866336633663366

Validation results:
gen_loss: 0.99851257
disc_loss: 0.052798785
disc_acc: 0.9915674603174603


	Epoch 482
Training results:
gen_loss: 0.99841946
disc_loss: 0.10638877
disc_acc: 0.9889851485148515

Validation results:
gen_loss: 0.99930656
disc_loss: 0.020401577
disc_acc: 0.9955357142857143


	Epoch 483
Training results:
gen_loss: 0.9986043
disc_loss: 0.06636346
disc_acc: 0.9909653465346535

Validation results:
gen_loss: 0.99899274
disc_loss: 0.01981716
disc_acc: 0.9955357142857143


	Epoch 484
Training results:
gen_loss: 0.9989423
disc_loss: 0.014949123
disc_acc: 0.9977722772277228

Validation results:
gen_loss: 0.9990041
disc_loss: 0.028148975
disc_acc: 0.9955357142857143


	Epoch 485
Training results:
gen_loss: 0.9980821
disc_loss: 0.056996904
disc_acc: 0.9912128712871288

Validation results:
gen_loss: 0.9962606
disc_loss: 0.16444851
disc_acc: 0.9791666666666666


	Epoch 486
Training results:
gen_loss: 0.9983997
disc_loss: 0.03762195
disc_acc: 0.9929455445544555

Validation results:
gen_loss: 0.9981829
disc_loss: 0.054605253
disc_acc: 0.9925595238095238


	Epoch 487
Training results:
gen_loss: 0.994703
disc_loss: 0.609701
disc_acc: 0.9527227722772277

Validation results:
gen_loss: 0.9985292
disc_loss: 0.26380613
disc_acc: 0.9826388888888888


	Epoch 488
Training results:
gen_loss: 0.99871135
disc_loss: 0.11269681
disc_acc: 0.989480198019802

Validation results:
gen_loss: 0.99853724
disc_loss: 0.109774515
disc_acc: 0.9856150793650794


	Epoch 489
Training results:
gen_loss: 0.9983801
disc_loss: 0.097223714
disc_acc: 0.989480198019802

Validation results:
gen_loss: 0.9990478
disc_loss: 0.025964638
disc_acc: 0.996031746031746


	Epoch 490
Training results:
gen_loss: 0.997352
disc_loss: 0.14034356
disc_acc: 0.9847772277227723

Validation results:
gen_loss: 0.9990888
disc_loss: 0.03325732
disc_acc: 0.9955357142857143


	Epoch 491
Training results:
gen_loss: 0.9992149
disc_loss: 0.027708583
disc_acc: 0.996039603960396

Validation results:
gen_loss: 0.9990844
disc_loss: 0.009103012
disc_acc: 0.9965277777777778


	Epoch 492
Training results:
gen_loss: 0.9991273
disc_loss: 0.011921388
disc_acc: 0.99740099009901

Validation results:
gen_loss: 0.9980387
disc_loss: 0.07693323
disc_acc: 0.9905753968253969


	Epoch 493
Training results:
gen_loss: 0.99856734
disc_loss: 0.0202245
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 0.9993584
disc_loss: 0.0038527153
disc_acc: 0.9985119047619048


	Epoch 494
Training results:
gen_loss: 0.99633366
disc_loss: 0.341235
disc_acc: 0.9701732673267327

Validation results:
gen_loss: 0.9928691
disc_loss: 0.6150232
disc_acc: 0.9469246031746031


	Epoch 495
Training results:
gen_loss: 0.99790365
disc_loss: 0.23230402
disc_acc: 0.9808168316831684

Validation results:
gen_loss: 0.99814063
disc_loss: 0.26305655
disc_acc: 0.9771825396825397


	Epoch 496
Training results:
gen_loss: 0.99879426
disc_loss: 0.043285333
disc_acc: 0.9949257425742575

Validation results:
gen_loss: 0.999254
disc_loss: 0.03663372
disc_acc: 0.9945436507936508


	Epoch 497
Training results:
gen_loss: 0.99908435
disc_loss: 0.026668139
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 0.9997704
disc_loss: 0.008017996
disc_acc: 0.9985119047619048


	Epoch 498
Training results:
gen_loss: 0.99855715
disc_loss: 0.04612938
disc_acc: 0.9941831683168317

Validation results:
gen_loss: 0.99920636
disc_loss: 0.01694837
disc_acc: 0.9970238095238095


	Epoch 499
Training results:
gen_loss: 0.9991299
disc_loss: 0.040763732
disc_acc: 0.9936881188118812

Validation results:
gen_loss: 0.99873257
disc_loss: 0.015818289
disc_acc: 0.9950396825396826


	Epoch 500
Training results:
gen_loss: 0.99519867
disc_loss: 0.3376582
disc_acc: 0.9667079207920792

Validation results:
gen_loss: 0.99467695
disc_loss: 0.498991
disc_acc: 0.9568452380952381



gen_train_loss: 0.017001482, 0.52525175, 0.30071938, 0.30489984, 0.2837664, 0.24197432, 0.15275744, 0.11087323, 0.14764236, 0.11840607, 0.09807018, 0.09891535, 0.09977156, 0.1039396, 0.10510834, 0.10528498, 0.112279035, 0.11011439, 0.09930267, 0.20953463, 0.13064475, 0.104772046, 0.09716896, 0.10073997, 0.10428841, 0.1048351, 0.11289402, 0.13018173, 0.13726057, 0.11862559, 0.10402212, 0.10754109, 0.12792751, 0.12934178, 0.102203764, 0.1133616, 0.115474954, 0.12294091, 0.11158682, 0.11714846, 0.23270938, 0.18178561, 0.13575277, 0.1167375, 0.14405656, 0.16626674, 0.105250865, 0.10253604, 0.0990201, 0.08653171, 0.099723086, 0.090402946, 0.10342824, 0.16775103, 0.2251809, 0.13479793, 0.114367895, 0.117979534, 0.2946286, 0.12605391, 0.11576103, 0.10547016, 0.09921822, 0.22984415, 0.105786614, 0.09271254, 0.10321609, 0.09629644, 0.10424127, 0.11526961, 0.11209127, 0.09987366, 0.11915159, 0.10251906, 0.106930114, 0.12048562, 0.1059772, 0.099874735, 0.10512071, 0.3099122, 0.12208349, 0.10806931, 0.098306954, 0.096480615, 0.10777538, 0.10691936, 0.12318866, 0.109095536, 0.1080128, 0.10028758, 0.104967386, 0.10241072, 0.23820648, 0.118588954, 0.106710225, 0.10207955, 0.09914889, 0.14180702, 0.11761575, 0.09553843, 0.09266819, 0.09366136, 0.09440275, 0.09968926, 0.09375926, 0.109078765, 0.09757626, 0.100652896, 0.14407235, 0.114157304, 0.11217813, 0.10852163, 0.10342, 0.10046908, 0.09919427, 0.262097, 0.11542081, 0.09884004, 0.09325732, 0.0896007, 0.09049569, 0.097769886, 0.095527, 0.100976855, 0.098402575, 0.10465314, 0.100074224, 0.094407655, 0.120460734, 0.106708355, 0.09698039, 0.118386, 0.11911351, 0.09391185, 0.08699534, 0.093857795, 0.1264183, 0.111342266, 0.10121383, 0.11917971, 0.10096079, 0.106778964, 0.11182565, 0.100640826, 0.09957626, 0.099638276, 0.11659226, 0.11331485, 0.09850852, 0.09654512, 0.10123611, 0.10182277, 0.10278491, 0.09500386, 0.09677702, 0.10672806, 0.10475488, 0.11284433, 0.09523455, 0.10098887, 0.10123542, 0.10454526, 0.098000884, 0.09416544, 0.10516918, 0.114567354, 0.09195876, 0.092376545, 0.09501709, 0.09737865, 0.097332716, 0.10956284, 0.09768055, 0.09550523, 0.10483548, 0.10516183, 0.09931234, 0.111025676, 0.097709686, 0.091606244, 0.094853096, 0.10846662, 0.100117095, 0.09369287, 0.09789073, 0.10553175, 0.095554195, 0.08934421, 0.123282224, 0.096243076, 0.091502614, 0.10050031, 0.10259975, 0.29342136, 0.1601282, 0.1238103, 0.11215765, 0.106513046, 0.10227933, 0.09697922, 0.103014566, 0.13671567, 0.09035348, 0.09569129, 0.090977505, 0.09488322, 0.09685627, 0.10190747, 0.10249275, 0.23308069, 0.10112468, 0.091591574, 0.09072406, 0.08809097, 0.090037994, 0.09309964, 0.094376385, 0.09675359, 0.0943022, 0.105064966, 0.10887696, 0.09857368, 0.09302791, 0.10078595, 0.095292374, 0.12055375, 0.093801506, 0.09154355, 0.10187741, 0.10340224, 0.09726849, 0.090529665, 0.100187875, 0.10188785, 0.0933269, 0.10497664, 0.09804418, 0.09306919, 0.099956885, 0.09840824, 0.09955412, 0.09776785, 0.09654637, 0.09292541, 0.15622829, 0.09507885, 0.09358208, 0.09524745, 0.09160501, 0.10615187, 0.09194378, 0.09837914, 0.09142571, 0.09738389, 0.1085051, 0.096998245, 0.090127066, 0.10542119, 0.09931208, 0.09519961, 0.09387291, 0.10359017, 0.100739785, 0.104178615, 0.0945718, 0.099596776, 0.09309599, 0.093273915, 0.12289893, 0.09605352, 0.085952446, 0.09741808, 0.103249095, 0.09946995, 0.099088624, 0.10756661, 0.08951784, 0.10244689, 0.09951249, 0.10274049, 0.09821167, 0.09561424, 0.14100724, 0.09280965, 0.09267332, 0.0887103, 0.098356955, 0.09474472, 0.0988705, 0.09932072, 0.096293546, 0.09316693, 0.10494738, 0.09771281, 0.095631704, 0.100674234, 0.100078106, 0.102369204, 0.090412855, 0.09572999, 0.109504744, 0.09081155, 0.09323912, 0.09896575, 0.10081471, 0.1047631, 0.09773865, 0.09444135, 0.09854473, 0.10030935, 0.09522478, 0.100312695, 0.101718694, 0.09821214, 0.1025774, 0.09341627, 0.10404072, 0.09785017, 0.09653227, 0.096515715, 0.09861172, 0.10317899, 0.09122839, 0.10739549, 0.09912575, 0.090628356, 0.102821805, 0.10519446, 0.094429195, 0.0967545, 0.0973933, 0.35549474, 0.15096955, 0.12231814, 0.108959585, 0.101647556, 0.09767376, 0.09812577, 0.09656592, 0.09892067, 0.09895058, 0.10123919, 0.098584816, 0.102137186, 0.09851677, 0.102652825, 0.11568847, 0.13246502, 0.10665463, 0.096805185, 0.09396971, 0.10405136, 0.09407321, 0.10934251, 0.098869994, 0.101082794, 0.1035209, 0.09653181, 0.09893166, 0.09577208, 0.095708534, 0.099710576, 0.10492763, 0.09525864, 0.09656654, 0.09919737, 0.09940168, 0.09994267, 0.09923141, 0.092955016, 0.09783233, 0.10392688, 0.09630172, 0.09978151, 0.10253662, 0.09950853, 0.100507304, 0.09349432, 0.111857966, 0.10105905, 0.0875213, 0.09404113, 0.11075548, 0.10065147, 0.0904013, 0.10094046, 0.10108463, 0.102856144, 0.101890266, 0.099005386, 0.0988962, 0.09560775, 0.09709207, 0.096382976, 0.10339527, 0.09265241, 0.09936584, 0.098825, 0.09037217, 0.098529935, 0.095511, 0.10747871, 0.09381919, 0.108570725, 0.09276578, 0.09596804, 0.10291607, 0.09362319, 0.10139696, 0.105534256, 0.09600242, 0.09845278, 0.09662037, 0.09975679, 0.09168745, 0.09773856, 0.1082431, 0.107114434, 0.09488981, 0.09577984, 0.09879682, 0.10267026, 0.09447159, 0.10279122, 0.0953552, 0.106487915, 0.099360384, 0.096172564, 0.101398125, 0.109646626, 0.09263218, 0.09408359, 0.09975276, 0.10110728, 0.09446215, 0.10464742, 0.09455489, 0.10031544, 0.097157605, 0.10003321, 0.100263566, 0.09768028, 0.09141419, 0.10575918, 0.08795806, 0.09545846, 0.09793535, 0.09310987, 0.1017677, 0.10094177, 0.09997969, 0.09043614, 0.10548091, 0.09348206, 0.09076423, 0.110409014, 0.10230304, 0.08981435, 0.09327422, 0.10891947, 0.09706285, 0.09256135, 0.09550008, 0.1015525, 0.09668266, 0.09935856, 0.09573311, 0.09892019, 0.102952294, 0.09229302, 0.09887034, 0.098459706, 0.09358499, 0.09627265, 0.093666196, 0.09837589, 0.09610087, 0.10088401, 0.09652906, 0.1057496, 0.097112685, 0.091378726, 0.10154295, 0.10314365, 0.09747763, 0.09489763, 0.111334726, 0.09480236, 0.09475072, 0.099947415, 0.09590782, 0.10607821, 0.09333467, 0.09962699, 0.099296495, 0.098543406, 0.09784215, 0.104997836, 0.111222416, 0.100740805, 0.1037674, 0.013013866, 0.35904342, 0.4220092, 0.4652453, 0.56520903, 0.6458632, 0.71056706, 0.71330845, 0.73043674, 0.76655763, 0.78171116, 0.78732246, 0.78094316, 0.7894135, 0.77456075, 0.8077397, 0.78349817, 0.76140606, 0.77130646, 0.7976756, 0.7874189, 0.79382694, 0.77173394, 0.7693986, 0.7684297, 0.77582186, 0.76881635, 0.778762, 0.7828465, 0.78137946, 0.77341926, 0.773175, 0.784431, 0.7816318, 0.7865831, 0.78226125, 0.7828248, 0.7719665, 0.79073, 0.7958009, 0.7716005, 0.7689265, 0.79110616, 0.7878845, 0.78269464, 0.7920845, 0.8023126, 0.7890558, 0.79303885, 0.81286913, 0.79847527, 0.79042786, 0.80143136, 0.816395, 0.81042624, 0.8055606, 0.8051352, 0.82301885, 0.8151048, 0.812943, 0.82670987, 0.81769294, 0.83646685, 0.83196235, 0.8075434, 0.8191034, 0.81404793, 0.8351068, 0.8340482, 0.847851, 0.8381618, 0.8375277, 0.84176236, 0.84299815, 0.8389715, 0.8436992, 0.83861303, 0.80119884, 0.8267823, 0.8225794, 0.84889644, 0.84253097, 0.85933715, 0.8665951, 0.87756926, 0.8757554, 0.8935022, 0.8909663, 0.9122139, 0.9015791, 0.9350044, 0.915654, 0.9281613, 0.93039525, 0.93749946, 0.94721437, 0.94230837, 0.9505417, 0.96284413, 0.9463748, 0.9441335, 0.94444394, 0.9603211, 0.94486403, 0.9569205, 0.9628392, 0.9729929, 0.97091055, 0.96433663, 0.9558689, 0.9663567, 0.97586125, 0.94685966, 0.940763, 0.9622651, 0.96552145, 0.95495296, 0.9661535, 0.9738138, 0.9601706, 0.91754705, 0.8572372, 0.8652192, 0.84986126, 0.8634486, 0.8707678, 0.8806276, 0.8741899, 0.88734674, 0.88394904, 0.8871287, 0.8930436, 0.8931993, 0.89645296, 0.91282225, 0.89475095, 0.90357214, 0.9181717, 0.94712746, 0.9573836, 0.97177106, 0.96272093, 0.9714849, 0.97615576, 0.9819166, 0.9755721, 0.97346914, 0.9818112, 0.9879772, 0.988982, 0.9866708, 0.986344, 0.97183776, 0.9412505, 0.8809438, 0.8882989, 0.88850254, 0.8961484, 0.90345097, 0.9384681, 0.9546152, 0.98397046, 0.9831798, 0.93572044, 0.8928345, 0.88803965, 0.89799523, 0.9208599, 0.90555376, 0.910795, 0.96618545, 0.9627562, 0.9717453, 0.9859853, 0.9862909, 0.98398024, 0.9906111, 0.94884884, 0.9123406, 0.9166976, 0.95826095, 0.98349065, 0.984065, 0.971157, 0.9896562, 0.99238235, 0.98908424, 0.98142403, 0.9911332, 0.986986, 0.98462456, 0.9920104, 0.990485, 0.98705643, 0.9798799, 0.99108404, 0.9906886, 0.9922153, 0.9851721, 0.98443216, 0.98833627, 0.9795157, 0.983657, 0.9733048, 0.98140264, 0.9875177, 0.98784, 0.979394, 0.98550034, 0.9862295, 0.98818684, 0.9865277, 0.9831438, 0.9768174, 0.9877364, 0.9859746, 0.9926978, 0.98190784, 0.98789257, 0.98746747, 0.9889523, 0.98254544, 0.9912094, 0.9927415, 0.9801825, 0.98534817, 0.9863582, 0.98890597, 0.9831612, 0.98921263, 0.98930025, 0.9883261, 0.99004984, 0.9900423, 0.98220503, 0.98708004, 0.99037963, 0.98920065, 0.9917292, 0.9901858, 0.95917684, 0.8897536, 0.8928161, 0.8889079, 0.90495646, 0.90732783, 0.90747714, 0.90630925, 0.90644616, 0.9212117, 0.92467934, 0.9250592, 0.92695737, 0.93329114, 0.92774326, 0.92857546, 0.9284613, 0.9283925, 0.9143499, 0.9429914, 0.9438067, 0.94907796, 0.9389816, 0.94076216, 0.94137126, 0.9527674, 0.9563602, 0.9465986, 0.95138323, 0.95478326, 0.96676344, 0.96992743, 0.95606905, 0.95783406, 0.9610333, 0.95690536, 0.9538344, 0.9562044, 0.96812814, 0.9662038, 0.961177, 0.96116096, 0.9647398, 0.95672446, 0.96880054, 0.97271436, 0.9521689, 0.9526078, 0.9596813, 0.96092725, 0.97325164, 0.9610613, 0.9323132, 0.9407967, 0.9563587, 0.95220715, 0.9566783, 0.9613697, 0.95176625, 0.96599704, 0.9608361, 0.9601678, 0.9689538, 0.9696414, 0.965889, 0.97117555, 0.9710244, 0.9735262, 0.9646965, 0.9709587, 0.97728187, 0.97542757, 0.97586536, 0.9747092, 0.97785556, 0.98529804, 0.98093283, 0.9852335, 0.9860789, 0.9878691, 0.98322433, 0.98467964, 0.9873564, 0.98736465, 0.99314946, 0.99460256, 0.9776331, 0.95947367, 0.9834395, 0.9841514, 0.98886245, 0.9865605, 0.9906517, 0.9905345, 0.9900649, 0.98647195, 0.9937404, 0.99395204, 0.98791516, 0.9881333, 0.99269813, 0.99636304, 0.9913833, 0.98748463, 0.9915439, 0.99056065, 0.9902945, 0.9945588, 0.9945291, 0.99631757, 0.98769677, 0.9938427, 0.9951891, 0.9937094, 0.99535024, 0.9946276, 0.99417216, 0.9913138, 0.99476326, 0.99591905, 0.9955942, 0.99636096, 0.9920988, 0.9939413, 0.99077475, 0.9955128, 0.9975054, 0.9975417, 0.9958196, 0.9955772, 0.9956266, 0.9972324, 0.993976, 0.99617237, 0.9984091, 0.99575096, 0.99138814, 0.9946743, 0.99590147, 0.9955911, 0.9981575, 0.995959, 0.99679303, 0.9969253, 0.992927, 0.9959488, 0.99380255, 0.9952021, 0.9957319, 0.9969632, 0.9904198, 0.996215, 0.99758285, 0.9975988, 0.9985526, 0.99570245, 0.99492127, 0.99545825, 0.99646205, 0.9940308, 0.99770796, 0.9934499, 0.997074, 0.9927803, 0.99670804, 0.996872, 0.99654216, 0.99643004, 0.99464774, 0.99693066, 0.99638385, 0.99289644, 0.9977313, 0.9976462, 0.9968448, 0.99543333, 0.99748814, 0.997993, 0.9958274, 0.9957813, 0.9981299, 0.99400485, 0.9975292, 0.99707866, 0.99712014, 0.9953074, 0.9960819, 0.9921101, 0.99622816, 0.993592, 0.99628204, 0.9968804, 0.99813604, 0.9979446, 0.9973107, 0.995871, 0.99352187, 0.99511904, 0.9975108, 0.9975537, 0.99613243, 0.99556386, 0.9969561, 0.99752194, 0.99803853, 0.9959013, 0.99745965, 0.9986456, 0.9956913, 0.9966387, 0.9972231, 0.99761724, 0.99865407, 0.9981084, 0.99856776, 0.9980483, 0.99528325, 0.9966677, 0.9975246, 0.9970234, 0.9978352, 0.9975716, 0.9975107, 0.9959309, 0.9983285, 0.9970609, 0.99697423, 0.9980125, 0.997697, 0.99570155, 0.99632096, 0.9983466, 0.99701285, 0.99656916, 0.9962528, 0.9957993, 0.99691707, 0.9983777, 0.9979825, 0.9974951, 0.9958476, 0.9980366, 0.99841946, 0.9986043, 0.9989423, 0.9980821, 0.9983997, 0.994703, 0.99871135, 0.9983801, 0.997352, 0.9992149, 0.9991273, 0.99856734, 0.99633366, 0.99790365, 0.99879426, 0.99908435, 0.99855715, 0.9991299, 0.99519867
disc_train_loss: 5.53727, 2.10006, 2.1379085, 2.2672818, 2.3494503, 2.4485397, 2.7587557, 2.7958782, 3.08615, 2.8112717, 2.794377, 2.7870336, 2.7944045, 2.8033595, 2.8025198, 2.8081598, 2.831529, 2.8229995, 2.8084888, 3.3810384, 2.8663619, 2.8181279, 2.7994592, 2.815749, 2.8145726, 2.8290825, 2.8283591, 2.905354, 2.9407554, 2.845843, 2.8136487, 2.832669, 2.8684914, 2.8598979, 2.8114998, 2.8200417, 2.834013, 2.8466723, 2.8341541, 2.8432174, 8.005877, 3.0789967, 2.9028995, 2.8543906, 3.7878516, 3.079936, 2.8234804, 2.8328187, 2.8249178, 2.791402, 2.8171062, 2.7972908, 2.826917, 3.180618, 4.0847707, 2.9247482, 2.913552, 2.8564506, 6.514241, 2.8746326, 2.8226664, 2.8116462, 2.8031409, 4.3947954, 2.8322027, 2.800769, 2.8164937, 2.8105884, 2.829189, 2.8306913, 2.8323777, 2.8158908, 2.8592417, 2.8190768, 2.8233585, 2.8775647, 2.8222914, 2.8123033, 2.8199701, 4.465689, 2.8672051, 2.8291614, 2.8139355, 2.8041668, 2.8232157, 2.8187437, 2.8389218, 2.8292572, 2.828922, 2.816235, 2.8186982, 2.8205905, 4.393727, 2.8570452, 2.8290908, 2.8223593, 2.8162854, 3.1396687, 2.8552005, 2.808198, 2.8006845, 2.7973914, 2.8021474, 2.814644, 2.8039758, 2.8219838, 2.8084729, 2.8128684, 2.9069428, 2.8183222, 2.821684, 2.828739, 2.808486, 2.816259, 2.8138213, 4.396301, 2.8480213, 2.808716, 2.7987473, 2.7988706, 2.7983732, 2.8087296, 2.8105009, 2.8102312, 2.809754, 2.8207488, 2.8123496, 2.8025217, 2.8528252, 2.8222008, 2.803507, 2.8278027, 2.8508785, 2.7991936, 2.7915275, 2.805231, 2.8873696, 2.8304427, 2.8122985, 2.864825, 2.812672, 2.8230343, 2.8321435, 2.8102143, 2.8081229, 2.8131092, 2.8592553, 2.8258572, 2.8104136, 2.8090727, 2.8097525, 2.8163023, 2.8123884, 2.8031678, 2.807429, 2.8169196, 2.8168845, 2.8473282, 2.7991908, 2.8130047, 2.806696, 2.8170683, 2.8095834, 2.8044438, 2.8201125, 2.8612251, 2.799006, 2.8017018, 2.8122458, 2.8118978, 2.8061223, 2.8310542, 2.8057215, 2.8092268, 2.819306, 2.821313, 2.8101692, 2.8297775, 2.8073335, 2.8042731, 2.8031893, 2.8215842, 2.808454, 2.8010056, 2.8171666, 2.8162956, 2.8057477, 2.7966864, 2.8808935, 2.8093052, 2.7964046, 2.816466, 2.8091183, 6.4849877, 2.9935005, 2.8765795, 2.8400307, 2.8285751, 2.8182104, 2.8064938, 2.8396645, 2.973687, 2.7992687, 2.8028362, 2.7995274, 2.800807, 2.809735, 2.8164074, 2.813015, 3.9462812, 2.8123367, 2.796674, 2.7964072, 2.7956398, 2.7985048, 2.8043704, 2.801764, 2.812366, 2.802595, 2.822166, 2.8210642, 2.8104663, 2.8044531, 2.8125577, 2.8284705, 2.8589272, 2.801847, 2.8001027, 2.815333, 2.8155215, 2.8105779, 2.7998424, 2.8177364, 2.8169603, 2.8014045, 2.818621, 2.8122752, 2.8001528, 2.8128397, 2.8101072, 2.8186119, 2.8057835, 2.8069017, 2.8025439, 2.886462, 2.8130472, 2.8027067, 2.804512, 2.7957027, 2.8179607, 2.8018904, 2.8098726, 2.8002398, 2.8142793, 2.8286595, 2.8115237, 2.7930713, 2.8199475, 2.8119102, 2.803989, 2.8009663, 2.826622, 2.815542, 2.8177884, 2.797661, 2.8115613, 2.8010354, 2.800002, 2.8600454, 2.809592, 2.7919445, 2.8033636, 2.8145967, 2.8102868, 2.8125207, 2.8302338, 2.7957742, 2.8162966, 2.8096483, 2.8194168, 2.8075335, 2.8052285, 2.89134, 2.798361, 2.802216, 2.7913997, 2.806847, 2.8054137, 2.813004, 2.8112016, 2.8076766, 2.8028445, 2.822433, 2.8108964, 2.8048239, 2.8090897, 2.812756, 2.8131874, 2.799346, 2.802907, 2.8347728, 2.7998323, 2.8004649, 2.8093755, 2.8158903, 2.821033, 2.8039677, 2.8053079, 2.8113127, 2.8162792, 2.804076, 2.808454, 2.8141365, 2.8094327, 2.8163493, 2.798287, 2.818726, 2.8125842, 2.8033016, 2.8078284, 2.8166533, 2.8127987, 2.7993848, 2.817476, 2.8145843, 2.8023062, 2.8168342, 2.818645, 2.805066, 2.8090734, 2.8061829, 8.911293, 2.9511588, 2.8747501, 2.8339894, 2.81579, 2.8071883, 2.805916, 2.8063607, 2.8118618, 2.8109398, 2.8180168, 2.811431, 2.8135571, 2.8104415, 2.8109434, 2.8296332, 2.8292398, 2.8144913, 2.811316, 2.806079, 2.8271651, 2.8088355, 2.8219519, 2.8165736, 2.819664, 2.814054, 2.8070107, 2.8131092, 2.8021696, 2.809991, 2.8107522, 2.8281507, 2.801223, 2.8037162, 2.8099685, 2.8100069, 2.8079677, 2.8123786, 2.8009188, 2.8108926, 2.819884, 2.8078377, 2.80985, 2.8229249, 2.809067, 2.8145862, 2.8028045, 2.8381853, 2.8093538, 2.8000028, 2.8000467, 2.8309753, 2.8102303, 2.7980754, 2.8154702, 2.8134263, 2.8076022, 2.8143117, 2.8059483, 2.812715, 2.8068786, 2.8069522, 2.805782, 2.819263, 2.801508, 2.8163943, 2.808503, 2.8024988, 2.8110385, 2.806158, 2.826914, 2.806105, 2.8315816, 2.7982724, 2.809162, 2.822624, 2.8056707, 2.8132422, 2.8146214, 2.810087, 2.8129332, 2.8068855, 2.8106842, 2.8024385, 2.8099236, 2.81598, 2.8210015, 2.8024545, 2.8091464, 2.8081963, 2.8206737, 2.8007643, 2.8170445, 2.8055596, 2.8268201, 2.8133605, 2.802965, 2.8081968, 2.8216631, 2.7997708, 2.8007524, 2.8154423, 2.8130677, 2.8053749, 2.8167057, 2.807141, 2.811345, 2.8107204, 2.8088913, 2.8101652, 2.8091643, 2.8021336, 2.8224156, 2.7977848, 2.8037708, 2.8180583, 2.8039377, 2.8177063, 2.810602, 2.8078823, 2.7986193, 2.8223183, 2.8008044, 2.7975354, 2.830235, 2.8177116, 2.7932148, 2.7985895, 2.8236783, 2.8068335, 2.8024113, 2.807765, 2.81913, 2.8061993, 2.80806, 2.8075979, 2.8061233, 2.816369, 2.801724, 2.8099372, 2.8166897, 2.803668, 2.808799, 2.802817, 2.810004, 2.811363, 2.8106675, 2.8093295, 2.8221354, 2.8004837, 2.798309, 2.8148398, 2.8199773, 2.8047838, 2.801864, 2.8220177, 2.8006833, 2.800759, 2.809624, 2.8041525, 2.821349, 2.800261, 2.8106847, 2.8131204, 2.8081076, 2.804147, 2.8119826, 2.8085015, 2.794521, 2.8051715, 5.651923, 2.202012, 1.7773899, 1.650882, 1.2199625, 0.99753153, 0.8499673, 0.8378756, 0.78901875, 0.6427303, 0.58638513, 0.5891163, 0.599045, 0.63771504, 0.62100106, 0.5197511, 0.5847322, 0.73024553, 0.6303457, 0.5629068, 0.68338424, 0.5109131, 0.63633007, 0.73245525, 0.6166502, 0.6549123, 0.64446676, 0.643604, 0.5126681, 0.8482835, 0.6256469, 0.54407233, 0.5288498, 0.6181724, 0.6124547, 0.646215, 0.55921495, 0.6170432, 0.5524397, 0.6262389, 0.6146885, 0.55670005, 0.65244395, 0.5777729, 0.5276522, 0.5539684, 0.5849018, 0.53052, 0.5297088, 0.66076607, 0.47705173, 0.53243095, 0.57994866, 0.50341135, 0.57416576, 0.53822345, 0.50632375, 0.46890658, 0.62155, 0.5021881, 0.390564, 0.45516574, 0.4012995, 0.63664323, 0.51659125, 0.41586462, 0.44001818, 0.41531008, 0.37990233, 0.59808856, 0.42644203, 0.4717059, 0.39301854, 0.41851804, 0.40334937, 0.45571712, 0.96380174, 0.5308698, 0.41972277, 0.4401967, 0.34117424, 0.39817244, 0.38960764, 0.35070848, 0.37375495, 0.340901, 0.28671092, 0.6209937, 0.25681558, 0.30959412, 0.16196226, 0.26526314, 0.4083357, 0.24017052, 0.20518988, 0.16634993, 0.30982828, 0.3940643, 0.13237202, 0.23080623, 0.24821453, 0.20377484, 0.18070507, 0.56559235, 0.20985053, 0.14789443, 0.07355403, 0.09508419, 0.12062418, 0.7290931, 0.13902986, 0.076315254, 0.32703945, 0.2398244, 0.12576793, 0.10835665, 0.2294078, 0.13080995, 0.108262315, 0.28604916, 0.36818448, 0.3601624, 0.31465194, 0.417446, 0.33944443, 0.3414881, 0.3916472, 0.34991735, 0.39060026, 0.32351837, 0.28477532, 0.353235, 0.3261546, 0.3178163, 0.25296742, 0.31618357, 0.30164814, 0.31444687, 0.23705111, 0.29926413, 0.12586284, 0.14918478, 0.17493896, 0.113987684, 0.058266878, 0.098782256, 0.5030573, 0.133045, 0.046524372, 0.049144648, 0.058237724, 0.05157785, 0.37512878, 0.39498246, 0.33987546, 0.26641485, 0.2919346, 0.2624463, 0.39090106, 0.22787063, 0.1252249, 0.08046306, 0.07947696, 0.62823313, 0.31525505, 0.33751765, 0.262307, 0.18573736, 0.24997836, 0.28859073, 0.09646474, 0.1593475, 0.49051857, 0.09588525, 0.06519662, 0.079647094, 0.030146854, 0.6617474, 0.2647928, 0.22610232, 0.14901362, 0.06679288, 0.05283632, 0.64098614, 0.070018865, 0.03716349, 0.06938126, 0.12590683, 0.050981518, 0.0929717, 0.13859665, 0.045556284, 0.046943724, 0.27149937, 0.5935944, 0.06294373, 0.07144575, 0.025897698, 0.12404075, 0.082184814, 0.083169654, 0.21078701, 0.16145168, 0.44904715, 0.1189285, 0.09322276, 0.04699375, 0.34550053, 0.21468996, 0.14338373, 0.06716897, 0.07213884, 0.11536615, 0.16521223, 0.10688561, 0.1197242, 0.032310773, 0.3140547, 0.22466221, 0.129206, 0.09972083, 0.19596493, 0.076328255, 0.035013247, 0.41269442, 0.15555276, 0.101377, 0.050127465, 0.14425693, 0.13489324, 0.14365523, 0.1028357, 0.06123028, 0.048177324, 0.4316396, 0.28368548, 0.11518671, 0.14454474, 0.04990431, 0.0776411, 0.8110116, 0.3873395, 0.35083005, 0.38521484, 0.22359265, 0.24521288, 0.30931315, 0.26388842, 0.25718373, 0.2506284, 0.3305377, 0.19357347, 0.2517554, 0.20098281, 0.2156168, 0.22856414, 0.22173041, 0.21595848, 0.28408745, 0.24247146, 0.33975002, 0.14232673, 0.30348846, 0.2255611, 0.2208342, 0.123358525, 0.10114651, 0.2594113, 0.16494486, 0.5989105, 0.098000914, 0.0756882, 0.1704343, 0.13947679, 0.11701025, 0.12982537, 0.14903876, 0.4192766, 0.10012723, 0.11683554, 0.1677548, 0.0965783, 0.6141002, 0.20445898, 0.087177575, 0.07567664, 0.25674096, 0.18543832, 0.1570264, 0.14467043, 0.09579113, 0.38942134, 0.2779984, 0.13261865, 0.1112126, 0.16180848, 0.11878325, 0.23241465, 0.3565973, 0.067307815, 0.15277849, 0.21355632, 0.10055164, 0.123674326, 0.22817026, 0.13314569, 0.126555, 0.09570597, 0.25961763, 0.2207601, 0.11093848, 0.1360658, 0.14656968, 0.19928887, 0.3309447, 0.08385916, 0.19077708, 0.08148617, 0.052705605, 0.040755507, 0.1118345, 0.11159644, 0.24392988, 0.21465114, 0.07355221, 0.021439118, 0.2146255, 0.16855514, 0.09572301, 0.15554401, 0.069391, 0.17389575, 0.13317795, 0.082573876, 0.05085734, 0.18927535, 0.0399717, 0.036202632, 0.123652466, 0.2040805, 0.083331384, 0.013996256, 0.09913252, 0.1882255, 0.12896794, 0.1782958, 0.30128482, 0.13188362, 0.08291642, 0.020678377, 0.4844989, 0.07560765, 0.044039767, 0.08180268, 0.03872279, 0.035316344, 0.049250595, 0.24729683, 0.07402053, 0.051068515, 0.031374812, 0.081600696, 0.23893337, 0.10730446, 0.56922525, 0.31075537, 0.054612294, 0.018025056, 0.13784702, 0.13618203, 0.10825442, 0.030435218, 0.0930348, 0.074962206, 0.009267812, 0.048194196, 0.37270665, 0.17075993, 0.189575, 0.24524519, 0.019662881, 0.1087305, 0.051275432, 0.025780344, 0.16874972, 0.06716126, 0.14315942, 0.24971107, 0.1413758, 0.043881852, 0.79034007, 0.40580198, 0.12891954, 0.10176627, 0.022481766, 0.087130815, 0.11465017, 0.088812985, 0.05189512, 0.20361082, 0.04658279, 0.14587924, 0.049135413, 0.29330242, 0.107652195, 0.14641337, 0.123196214, 0.10965015, 0.15890507, 0.062291484, 0.05823036, 0.24459194, 0.098540545, 0.039970502, 0.080716304, 0.4293321, 0.1718289, 0.052344292, 0.1390788, 0.10214058, 0.016765913, 0.39915156, 0.082779855, 0.055956747, 0.116041265, 0.0821019, 0.09511069, 0.20786308, 0.037636254, 0.5388999, 0.22513966, 0.08667427, 0.044372015, 0.040261548, 0.021208333, 0.05674235, 0.120350786, 0.42023003, 0.079638176, 0.048090395, 0.12614352, 0.23039794, 0.12279887, 0.12181084, 0.033076033, 0.14032069, 0.054381277, 0.027994355, 0.11028643, 0.4180866, 0.13799295, 0.06882836, 0.010576968, 0.044947278, 0.02027419, 0.05561759, 0.45916063, 0.27997753, 0.062351894, 0.1216555, 0.104204655, 0.05530213, 0.14356554, 0.17417155, 0.052858125, 0.07399796, 0.13577682, 0.049848028, 0.029815083, 0.18463202, 0.89175606, 0.12924477, 0.24346313, 0.1385255, 0.12176225, 0.11648044, 0.10620121, 0.03596138, 0.058056813, 0.16619608, 0.38226125, 0.1683905, 0.10638877, 0.06636346, 0.014949123, 0.056996904, 0.03762195, 0.609701, 0.11269681, 0.097223714, 0.14034356, 0.027708583, 0.011921388, 0.0202245, 0.341235, 0.23230402, 0.043285333, 0.026668139, 0.04612938, 0.040763732, 0.3376582
disc_train_acc: 0.002103960396039604, 0.39084158415841586, 0.21745049504950495, 0.19913366336633664, 0.2089108910891089, 0.17314356435643563, 0.0948019801980198, 0.08267326732673268, 0.07462871287128713, 0.07388613861386138, 0.07475247524752475, 0.07475247524752475, 0.0681930693069307, 0.0686881188118812, 0.07042079207920791, 0.06930693069306931, 0.061014851485148514, 0.06745049504950495, 0.06386138613861386, 0.07957920792079208, 0.06732673267326733, 0.0625, 0.06398514851485149, 0.059158415841584155, 0.06423267326732673, 0.055693069306930694, 0.06720297029702971, 0.06225247524752475, 0.059777227722772275, 0.06287128712871287, 0.06683168316831684, 0.059777227722772275, 0.06435643564356436, 0.06646039603960396, 0.06386138613861386, 0.06707920792079208, 0.06707920792079208, 0.07116336633663366, 0.06361386138613861, 0.06324257425742574, 0.057673267326732676, 0.06435643564356436, 0.06806930693069307, 0.06423267326732673, 0.06324257425742574, 0.0676980198019802, 0.06683168316831684, 0.06522277227722773, 0.06324257425742574, 0.062376237623762376, 0.05866336633663366, 0.060767326732673266, 0.06361386138613861, 0.0646039603960396, 0.06695544554455446, 0.06163366336633663, 0.06398514851485149, 0.06646039603960396, 0.06175742574257426, 0.05952970297029703, 0.07017326732673268, 0.0655940594059406, 0.0681930693069307, 0.06064356435643564, 0.060767326732673266, 0.06089108910891089, 0.0629950495049505, 0.06163366336633663, 0.06534653465346535, 0.06212871287128713, 0.06361386138613861, 0.061014851485148514, 0.0655940594059406, 0.06287128712871287, 0.06584158415841584, 0.06386138613861386, 0.06150990099009901, 0.060767326732673266, 0.06324257425742574, 0.09752475247524753, 0.062376237623762376, 0.061386138613861385, 0.057673267326732676, 0.06398514851485149, 0.0625, 0.06064356435643564, 0.06905940594059407, 0.06349009900990099, 0.06324257425742574, 0.06410891089108911, 0.06262376237623762, 0.06225247524752475, 0.05952970297029703, 0.06844059405940595, 0.0702970297029703, 0.06175742574257426, 0.06150990099009901, 0.0681930693069307, 0.06522277227722773, 0.06386138613861386, 0.05965346534653465, 0.06287128712871287, 0.06163366336633663, 0.06571782178217822, 0.062376237623762376, 0.06262376237623762, 0.060767326732673266, 0.062376237623762376, 0.061386138613861385, 0.07116336633663366, 0.06967821782178218, 0.06732673267326733, 0.06893564356435644, 0.06150990099009901, 0.05903465346534653, 0.07017326732673268, 0.060767326732673266, 0.06262376237623762, 0.06336633663366337, 0.059158415841584155, 0.05742574257425743, 0.06349009900990099, 0.05631188118811881, 0.06423267326732673, 0.059777227722772275, 0.06497524752475248, 0.0599009900990099, 0.06608910891089109, 0.0655940594059406, 0.06361386138613861, 0.0646039603960396, 0.06782178217821783, 0.06336633663366337, 0.06448019801980198, 0.06089108910891089, 0.06027227722772277, 0.06212871287128713, 0.06943069306930694, 0.0629950495049505, 0.057920792079207924, 0.0646039603960396, 0.06274752475247525, 0.06918316831683169, 0.06262376237623762, 0.0655940594059406, 0.06188118811881188, 0.060148514851485146, 0.07004950495049506, 0.06361386138613861, 0.06163366336633663, 0.06386138613861386, 0.05841584158415842, 0.0629950495049505, 0.06423267326732673, 0.06646039603960396, 0.06794554455445545, 0.06782178217821783, 0.06175742574257426, 0.06311881188118812, 0.06113861386138614, 0.07103960396039603, 0.06497524752475248, 0.06027227722772277, 0.06212871287128713, 0.06051980198019802, 0.062004950495049505, 0.06188118811881188, 0.062004950495049505, 0.06051980198019802, 0.06089108910891089, 0.06311881188118812, 0.0594059405940594, 0.06646039603960396, 0.060148514851485146, 0.060767326732673266, 0.0655940594059406, 0.06398514851485149, 0.06881188118811882, 0.06126237623762376, 0.06150990099009901, 0.06522277227722773, 0.06732673267326733, 0.06150990099009901, 0.06361386138613861, 0.062376237623762376, 0.06188118811881188, 0.058292079207920795, 0.0646039603960396, 0.062376237623762376, 0.06113861386138614, 0.06571782178217822, 0.06361386138613861, 0.06262376237623762, 0.07957920792079208, 0.05804455445544555, 0.062004950495049505, 0.06485148514851485, 0.062004950495049505, 0.06324257425742574, 0.06089108910891089, 0.06064356435643564, 0.06361386138613861, 0.05693069306930693, 0.06150990099009901, 0.059158415841584155, 0.06423267326732673, 0.06188118811881188, 0.062376237623762376, 0.06695544554455446, 0.07128712871287128, 0.061386138613861385, 0.06324257425742574, 0.06150990099009901, 0.06064356435643564, 0.06002475247524752, 0.06188118811881188, 0.060148514851485146, 0.057301980198019804, 0.06274752475247525, 0.058787128712871284, 0.06410891089108911, 0.0594059405940594, 0.06089108910891089, 0.06089108910891089, 0.06150990099009901, 0.06398514851485149, 0.06113861386138614, 0.06051980198019802, 0.06398514851485149, 0.060148514851485146, 0.05655940594059406, 0.06002475247524752, 0.06225247524752475, 0.06410891089108911, 0.055074257425742575, 0.06881188118811882, 0.06410891089108911, 0.06126237623762376, 0.06324257425742574, 0.060767326732673266, 0.0599009900990099, 0.06410891089108911, 0.0625, 0.060396039603960394, 0.07574257425742574, 0.05891089108910891, 0.06695544554455446, 0.060767326732673266, 0.06373762376237624, 0.06621287128712872, 0.057920792079207924, 0.06212871287128713, 0.061014851485148514, 0.0577970297029703, 0.06349009900990099, 0.060396039603960394, 0.06448019801980198, 0.06287128712871287, 0.06188118811881188, 0.05841584158415842, 0.06720297029702971, 0.059158415841584155, 0.05952970297029703, 0.06262376237623762, 0.06646039603960396, 0.0599009900990099, 0.05952970297029703, 0.06683168316831684, 0.06683168316831684, 0.061014851485148514, 0.06311881188118812, 0.06175742574257426, 0.06311881188118812, 0.06051980198019802, 0.06608910891089109, 0.06274752475247525, 0.06225247524752475, 0.06287128712871287, 0.06658415841584159, 0.06386138613861386, 0.06423267326732673, 0.06027227722772277, 0.06633663366336634, 0.062004950495049505, 0.0629950495049505, 0.0650990099009901, 0.06188118811881188, 0.057920792079207924, 0.06571782178217822, 0.05841584158415842, 0.06212871287128713, 0.06113861386138614, 0.062004950495049505, 0.06027227722772277, 0.06311881188118812, 0.06163366336633663, 0.05928217821782178, 0.0629950495049505, 0.06373762376237624, 0.06534653465346535, 0.06163366336633663, 0.060767326732673266, 0.0599009900990099, 0.062376237623762376, 0.06336633663366337, 0.0577970297029703, 0.06695544554455446, 0.06361386138613861, 0.06188118811881188, 0.061014851485148514, 0.05928217821782178, 0.06633663366336634, 0.06274752475247525, 0.06113861386138614, 0.06089108910891089, 0.06448019801980198, 0.06212871287128713, 0.06064356435643564, 0.062004950495049505, 0.061014851485148514, 0.061014851485148514, 0.06126237623762376, 0.06448019801980198, 0.0646039603960396, 0.060148514851485146, 0.06089108910891089, 0.061386138613861385, 0.06683168316831684, 0.06188118811881188, 0.05952970297029703, 0.0646039603960396, 0.07462871287128713, 0.06188118811881188, 0.05866336633663366, 0.06646039603960396, 0.06212871287128713, 0.06571782178217822, 0.06361386138613861, 0.06089108910891089, 0.06534653465346535, 0.06027227722772277, 0.060148514851485146, 0.060767326732673266, 0.06336633663366337, 0.06361386138613861, 0.058292079207920795, 0.06745049504950495, 0.06980198019801981, 0.06782178217821783, 0.05903465346534653, 0.05965346534653465, 0.06435643564356436, 0.059158415841584155, 0.06584158415841584, 0.056064356435643566, 0.06225247524752475, 0.060396039603960394, 0.061386138613861385, 0.06150990099009901, 0.06212871287128713, 0.057920792079207924, 0.06633663366336634, 0.059777227722772275, 0.06051980198019802, 0.06423267326732673, 0.06534653465346535, 0.0629950495049505, 0.06831683168316832, 0.0594059405940594, 0.06287128712871287, 0.0655940594059406, 0.061386138613861385, 0.06472772277227723, 0.06089108910891089, 0.05717821782178218, 0.06163366336633663, 0.059777227722772275, 0.058787128712871284, 0.06163366336633663, 0.06163366336633663, 0.05754950495049505, 0.06175742574257426, 0.06150990099009901, 0.06423267326732673, 0.06126237623762376, 0.0625, 0.06225247524752475, 0.06435643564356436, 0.06188118811881188, 0.0681930693069307, 0.05717821782178218, 0.06287128712871287, 0.0655940594059406, 0.06225247524752475, 0.06435643564356436, 0.0594059405940594, 0.05891089108910891, 0.06274752475247525, 0.05816831683168317, 0.06336633663366337, 0.05841584158415842, 0.06212871287128713, 0.057920792079207924, 0.06336633663366337, 0.06410891089108911, 0.05952970297029703, 0.060148514851485146, 0.058787128712871284, 0.06212871287128713, 0.06373762376237624, 0.06336633663366337, 0.0625, 0.060396039603960394, 0.06225247524752475, 0.0599009900990099, 0.060767326732673266, 0.06423267326732673, 0.06225247524752475, 0.05891089108910891, 0.06150990099009901, 0.06522277227722773, 0.060767326732673266, 0.06262376237623762, 0.0577970297029703, 0.060767326732673266, 0.06373762376237624, 0.06435643564356436, 0.06410891089108911, 0.06373762376237624, 0.06683168316831684, 0.06188118811881188, 0.06435643564356436, 0.06027227722772277, 0.06150990099009901, 0.059158415841584155, 0.06336633663366337, 0.06757425742574258, 0.06782178217821783, 0.06225247524752475, 0.0625, 0.06163366336633663, 0.06794554455445545, 0.059158415841584155, 0.0650990099009901, 0.05816831683168317, 0.06373762376237624, 0.0594059405940594, 0.057920792079207924, 0.06027227722772277, 0.06794554455445545, 0.06410891089108911, 0.06163366336633663, 0.06163366336633663, 0.060148514851485146, 0.0625, 0.06596534653465347, 0.0625, 0.06262376237623762, 0.06311881188118812, 0.062376237623762376, 0.06262376237623762, 0.056064356435643566, 0.06262376237623762, 0.06485148514851485, 0.05903465346534653, 0.06423267326732673, 0.059777227722772275, 0.06398514851485149, 0.06398514851485149, 0.061014851485148514, 0.0629950495049505, 0.05903465346534653, 0.06386138613861386, 0.06497524752475248, 0.05680693069306931, 0.06212871287128713, 0.05272277227722772, 0.06349009900990099, 0.06225247524752475, 0.0646039603960396, 0.06262376237623762, 0.060396039603960394, 0.060767326732673266, 0.061014851485148514, 0.06324257425742574, 0.06163366336633663, 0.06695544554455446, 0.06212871287128713, 0.0655940594059406, 0.06027227722772277, 0.06051980198019802, 0.06485148514851485, 0.06410891089108911, 0.06373762376237624, 0.05903465346534653, 0.06225247524752475, 0.06905940594059407, 0.06695544554455446, 0.07202970297029702, 0.06448019801980198, 0.06707920792079208, 0.00012376237623762376, 0.2316831683168317, 0.31027227722772277, 0.3660891089108911, 0.5014851485148515, 0.5829207920792079, 0.6430693069306931, 0.6452970297029703, 0.6613861386138614, 0.7196782178217822, 0.7319306930693069, 0.7246287128712872, 0.7297029702970297, 0.7125, 0.7133663366336633, 0.74740099009901, 0.7252475247524752, 0.6846534653465347, 0.7121287128712871, 0.7426980198019802, 0.7073019801980198, 0.7524752475247525, 0.7118811881188118, 0.6840346534653465, 0.7097772277227723, 0.7045792079207921, 0.6996287128712871, 0.7003712871287129, 0.745049504950495, 0.6603960396039604, 0.7129950495049505, 0.7341584158415841, 0.7574257425742574, 0.7241336633663367, 0.7206683168316832, 0.7034653465346534, 0.7457920792079208, 0.7116336633663366, 0.7358910891089109, 0.7158415841584158, 0.7169554455445545, 0.7297029702970297, 0.7058168316831683, 0.7282178217821782, 0.7415841584158416, 0.7435643564356436, 0.7341584158415841, 0.744059405940594, 0.755569306930693, 0.7300742574257426, 0.7606435643564357, 0.7491336633663367, 0.7300742574257426, 0.7576732673267327, 0.7340346534653466, 0.746410891089109, 0.7626237623762376, 0.7712871287128713, 0.7330445544554456, 0.763490099009901, 0.8054455445544555, 0.7814356435643565, 0.8055693069306931, 0.746039603960396, 0.7586633663366337, 0.7971534653465346, 0.7816831683168317, 0.7900990099009901, 0.8087871287128713, 0.7648514851485149, 0.7960396039603961, 0.790470297029703, 0.8043316831683168, 0.7978960396039604, 0.8068069306930693, 0.8016089108910891, 0.7409653465346535, 0.7636138613861386, 0.807549504950495, 0.800990099009901, 0.8367574257425743, 0.8242574257425742, 0.8237623762376237, 0.8517326732673267, 0.8478960396039604, 0.8478960396039604, 0.8819306930693069, 0.8133663366336633, 0.8983910891089109, 0.8806930693069307, 0.9373762376237624, 0.8975247524752475, 0.8735148514851485, 0.9125, 0.926980198019802, 0.9382425742574257, 0.9024752475247525, 0.8986386138613861, 0.948019801980198, 0.927970297029703, 0.9184405940594059, 0.9248762376237624, 0.9417079207920792, 0.8686881188118812, 0.9399752475247525, 0.9532178217821782, 0.9742574257425742, 0.9669554455445545, 0.9565594059405941, 0.8898514851485149, 0.9573019801980198, 0.9727722772277227, 0.9051980198019802, 0.9196782178217822, 0.9602722772277228, 0.9612623762376238, 0.9316831683168317, 0.9544554455445544, 0.9667079207920792, 0.9206683168316832, 0.8636138613861386, 0.8245049504950495, 0.8425742574257425, 0.814480198019802, 0.8419554455445545, 0.8419554455445545, 0.8285891089108911, 0.849009900990099, 0.8407178217821782, 0.8613861386138614, 0.8681930693069307, 0.8599009900990099, 0.8575495049504951, 0.8716584158415842, 0.8952970297029703, 0.8646039603960396, 0.876608910891089, 0.8821782178217822, 0.9170792079207921, 0.9133663366336634, 0.9602722772277228, 0.9516089108910891, 0.9464108910891089, 0.9643564356435643, 0.9811881188118812, 0.9686881188118812, 0.9103960396039604, 0.9663366336633663, 0.9837871287128713, 0.9841584158415841, 0.9839108910891089, 0.9847772277227723, 0.9245049504950495, 0.8790841584158415, 0.8547029702970297, 0.873019801980198, 0.8736386138613862, 0.8834158415841584, 0.8530940594059406, 0.9174504950495049, 0.9496287128712871, 0.9774752475247525, 0.9756188118811882, 0.8485148514851485, 0.8650990099009901, 0.8673267326732673, 0.8910891089108911, 0.9262376237623763, 0.8930693069306931, 0.888490099009901, 0.9648514851485148, 0.9469059405940594, 0.9080445544554455, 0.9731435643564357, 0.9798267326732674, 0.9733910891089109, 0.989480198019802, 0.8503712871287129, 0.9013613861386138, 0.9022277227722773, 0.9511138613861386, 0.9754950495049505, 0.9824257425742574, 0.8962871287128713, 0.9823019801980198, 0.9898514851485148, 0.9805693069306931, 0.9655940594059406, 0.9858910891089109, 0.9753712871287129, 0.9647277227722773, 0.9891089108910891, 0.9858910891089109, 0.9579207920792079, 0.9179455445544554, 0.9831683168316832, 0.9797029702970297, 0.991460396039604, 0.9653465346534653, 0.9745049504950495, 0.9768564356435644, 0.9457920792079207, 0.9623762376237623, 0.9224009900990099, 0.9681930693069307, 0.9758663366336634, 0.9844059405940594, 0.9407178217821782, 0.9538366336633664, 0.9660891089108911, 0.9787128712871287, 0.9789603960396039, 0.9688118811881188, 0.9523514851485149, 0.9732673267326732, 0.968440594059406, 0.9902227722772278, 0.9443069306930693, 0.9564356435643564, 0.9711633663366337, 0.975, 0.9538366336633664, 0.9803217821782179, 0.9902227722772278, 0.9313118811881188, 0.9660891089108911, 0.9738861386138614, 0.9849009900990099, 0.9642326732673268, 0.9699257425742575, 0.9702970297029703, 0.9751237623762377, 0.9818069306930693, 0.9862623762376238, 0.9301980198019802, 0.9534653465346534, 0.9738861386138614, 0.9672029702970297, 0.9862623762376238, 0.9800742574257426, 0.8649752475247525, 0.8391089108910891, 0.8574257425742574, 0.8448019801980198, 0.9024752475247525, 0.8969059405940594, 0.871039603960396, 0.9003712871287128, 0.8902227722772277, 0.8978960396039604, 0.8886138613861386, 0.9217821782178218, 0.9002475247524753, 0.9204207920792079, 0.9101485148514852, 0.9106435643564357, 0.9092821782178218, 0.9186881188118812, 0.8930693069306931, 0.9193069306930693, 0.8982673267326733, 0.9474009900990099, 0.903960396039604, 0.9116336633663367, 0.9220297029702971, 0.9507425742574257, 0.9599009900990099, 0.9091584158415842, 0.9456683168316832, 0.886509900990099, 0.9648514851485148, 0.9722772277227723, 0.9356435643564357, 0.9542079207920792, 0.9554455445544554, 0.9496287128712871, 0.943069306930693, 0.8945544554455446, 0.9643564356435643, 0.9568069306930693, 0.9407178217821782, 0.9621287128712871, 0.899009900990099, 0.931930693069307, 0.9673267326732673, 0.9714108910891089, 0.9158415841584159, 0.9330445544554455, 0.9403465346534653, 0.9518564356435644, 0.9705445544554455, 0.9063118811881188, 0.902970297029703, 0.9495049504950495, 0.9542079207920792, 0.942450495049505, 0.9577970297029703, 0.9351485148514852, 0.8983910891089109, 0.9764851485148515, 0.9496287128712871, 0.941089108910891, 0.9678217821782178, 0.9570544554455446, 0.9351485148514852, 0.9571782178217821, 0.9607673267326733, 0.9649752475247525, 0.9324257425742575, 0.9408415841584158, 0.9667079207920792, 0.9602722772277228, 0.9542079207920792, 0.9465346534653465, 0.9389851485148515, 0.9764851485148515, 0.9587871287128713, 0.9783415841584159, 0.9825495049504951, 0.9871287128712871, 0.9688118811881188, 0.9717821782178218, 0.9582920792079208, 0.9576732673267326, 0.9837871287128713, 0.9943069306930693, 0.9426980198019802, 0.9478960396039604, 0.9722772277227723, 0.9623762376237623, 0.9783415841584159, 0.9646039603960396, 0.9706683168316832, 0.9818069306930693, 0.9837871287128713, 0.9646039603960396, 0.9886138613861386, 0.9892326732673268, 0.969430693069307, 0.9603960396039604, 0.9808168316831684, 0.995420792079208, 0.9774752475247525, 0.9620049504950495, 0.9731435643564357, 0.967450495049505, 0.9556930693069307, 0.9804455445544554, 0.9852722772277228, 0.9928217821782178, 0.9367574257425743, 0.9830445544554456, 0.9888613861386139, 0.9826732673267327, 0.9912128712871288, 0.9909653465346535, 0.9873762376237624, 0.9632425742574258, 0.9856435643564356, 0.9897277227722773, 0.9919554455445545, 0.9868811881188119, 0.9623762376237623, 0.9805693069306931, 0.9461633663366337, 0.9686881188118812, 0.9900990099009901, 0.9951732673267327, 0.9811881188118812, 0.9787128712871287, 0.9837871287128713, 0.9930693069306931, 0.9819306930693069, 0.9872524752475248, 0.99740099009901, 0.9881188118811881, 0.9550742574257426, 0.9732673267326732, 0.9768564356435644, 0.9743811881188119, 0.9948019801980198, 0.9826732673267327, 0.9896039603960396, 0.9929455445544555, 0.9711633663366337, 0.9861386138613861, 0.9742574257425742, 0.972029702970297, 0.9794554455445544, 0.9922029702970298, 0.9334158415841585, 0.9669554455445545, 0.9852722772277228, 0.9870049504950495, 0.995420792079208, 0.9844059405940594, 0.9793316831683169, 0.9840346534653466, 0.9883663366336634, 0.9709158415841584, 0.991460396039604, 0.975, 0.9897277227722773, 0.9646039603960396, 0.9836633663366336, 0.9820544554455446, 0.9826732673267327, 0.9849009900990099, 0.9794554455445544, 0.9888613861386139, 0.9883663366336634, 0.9663366336633663, 0.9877475247524753, 0.9912128712871288, 0.9871287128712871, 0.9649752475247525, 0.9846534653465346, 0.9905940594059406, 0.9829207920792079, 0.9824257425742574, 0.995420792079208, 0.9638613861386138, 0.9888613861386139, 0.9896039603960396, 0.9836633663366336, 0.9845297029702971, 0.9841584158415841, 0.968440594059406, 0.9900990099009901, 0.9525990099009901, 0.9780940594059406, 0.9861386138613861, 0.9939356435643565, 0.994059405940594, 0.9933168316831683, 0.9878712871287129, 0.9777227722772277, 0.9621287128712871, 0.9867574257425743, 0.9922029702970298, 0.9827970297029703, 0.9731435643564357, 0.9862623762376238, 0.9866336633663366, 0.9941831683168317, 0.9837871287128713, 0.9913366336633663, 0.995049504950495, 0.9811881188118812, 0.9691831683168317, 0.9839108910891089, 0.9905940594059406, 0.9971534653465347, 0.992450495049505, 0.9959158415841585, 0.9917079207920793, 0.9649752475247525, 0.9764851485148515, 0.9902227722772278, 0.9856435643564356, 0.9867574257425743, 0.9902227722772278, 0.9872524752475248, 0.9794554455445544, 0.9922029702970298, 0.9886138613861386, 0.9832920792079208, 0.9912128712871288, 0.9938118811881188, 0.9778465346534654, 0.9556930693069307, 0.988490099009901, 0.9792079207920792, 0.9845297029702971, 0.9829207920792079, 0.9820544554455446, 0.9853960396039604, 0.9939356435643565, 0.992450495049505, 0.9841584158415841, 0.9643564356435643, 0.9866336633663366, 0.9889851485148515, 0.9909653465346535, 0.9977722772277228, 0.9912128712871288, 0.9929455445544555, 0.9527227722772277, 0.989480198019802, 0.989480198019802, 0.9847772277227723, 0.996039603960396, 0.99740099009901, 0.9957920792079208, 0.9701732673267327, 0.9808168316831684, 0.9949257425742575, 0.9965346534653465, 0.9941831683168317, 0.9936881188118812, 0.9667079207920792
gen_val_loss: 0.017031386, 0.3181874, 0.33390373, 0.2899613, 0.23575172, 0.17846759, 0.089058176, 0.088090256, 0.08413117, 0.090587005, 0.09450354, 0.09903469, 0.19684617, 0.09550054, 0.100343905, 0.10502072, 0.101169206, 0.082885794, 0.20489745, 0.14327154, 0.10979677, 0.094197504, 0.11853106, 0.10539363, 0.10242872, 0.15482065, 0.08480393, 0.37720877, 0.085383385, 0.09880198, 0.11405261, 0.14290042, 0.093050405, 0.1366156, 0.20112294, 0.10567213, 0.093437955, 0.100011416, 0.12613206, 0.18649818, 0.28462112, 0.10537281, 0.089381516, 0.100880675, 0.41685647, 0.11224392, 0.08728003, 0.23035362, 0.07996825, 0.089849174, 0.083460815, 0.0799394, 0.077984534, 0.09586286, 0.1616104, 0.0921697, 0.15285675, 0.09387574, 0.14136642, 0.16789791, 0.17522426, 0.09459019, 0.113884374, 0.122648634, 0.094149895, 0.07735532, 0.10485202, 0.08645017, 0.31369594, 0.13045536, 0.14792714, 0.13515086, 0.07259586, 0.14257151, 0.083322324, 0.10242673, 0.11025551, 0.116036385, 0.20747946, 0.17884542, 0.12649563, 0.10330222, 0.09742818, 0.08411563, 0.109386325, 0.07832588, 0.092140965, 0.14544277, 0.08133338, 0.091039196, 0.12190744, 0.11101323, 0.16748099, 0.13577384, 0.18281299, 0.08609135, 0.08443322, 0.24604918, 0.13458304, 0.07642735, 0.08366725, 0.090336196, 0.13223407, 0.08516953, 0.09667089, 0.09258818, 0.10319224, 0.10133666, 0.09948618, 0.102489434, 0.10664911, 0.08157351, 0.1045479, 0.110388026, 0.0872729, 0.15405129, 0.113136455, 0.097726606, 0.103024535, 0.07912711, 0.12908275, 0.08623513, 0.08729032, 0.09291174, 0.09797966, 0.0917277, 0.09467273, 0.078891166, 0.14921838, 0.097381085, 0.09161546, 0.26619363, 0.08481706, 0.07800195, 0.085709535, 0.081781104, 0.16411604, 0.100228995, 0.14734508, 0.09955085, 0.13793318, 0.09585009, 0.097952165, 0.07983432, 0.10296306, 0.2210891, 0.119743556, 0.10982352, 0.09435213, 0.07238233, 0.0988357, 0.10789008, 0.08457247, 0.0777863, 0.1136804, 0.08926102, 0.09941321, 0.101054735, 0.0864851, 0.09790936, 0.15637165, 0.10101279, 0.0814308, 0.11717489, 0.14022997, 0.09385653, 0.083327904, 0.08575284, 0.08806723, 0.08775935, 0.088985994, 0.093716204, 0.089391656, 0.07953076, 0.103139736, 0.07983588, 0.10404249, 0.14773192, 0.083669625, 0.0928159, 0.07970552, 0.076774985, 0.07955641, 0.083045386, 0.10516898, 0.0886647, 0.087798424, 0.12444908, 0.24917857, 0.086401306, 0.092839055, 0.1455792, 0.1012958, 0.21993436, 0.1715066, 0.11602413, 0.094124235, 0.09965584, 0.09324849, 0.124023184, 0.43241987, 0.102525875, 0.11082102, 0.10276273, 0.10284615, 0.09235094, 0.10063264, 0.104344204, 0.18095179, 0.09260381, 0.082765505, 0.09265937, 0.09097905, 0.08321269, 0.08247948, 0.101086654, 0.0850223, 0.12816508, 0.10081758, 0.10141732, 0.10023551, 0.08589665, 0.16175194, 0.11619833, 0.13895865, 0.09855504, 0.075442545, 0.09475519, 0.1457322, 0.09544774, 0.11705941, 0.08796418, 0.10011865, 0.08238767, 0.079450525, 0.09353579, 0.08482159, 0.10832404, 0.11307429, 0.09953852, 0.11240767, 0.1267817, 0.08211226, 0.10087365, 0.116823345, 0.07593661, 0.08905529, 0.08377917, 0.076683454, 0.091119014, 0.09235254, 0.12232254, 0.09274908, 0.10481435, 0.083916485, 0.085077025, 0.094539106, 0.10093332, 0.13178128, 0.11589042, 0.10546299, 0.08138712, 0.090359494, 0.08629018, 0.11262426, 0.08932959, 0.11263926, 0.10693407, 0.12017885, 0.1065551, 0.09841336, 0.09405213, 0.08651026, 0.07181094, 0.14147818, 0.12971056, 0.086921304, 0.10022938, 0.11460823, 0.12544839, 0.12446782, 0.09374799, 0.099357635, 0.08588871, 0.08383661, 0.12960668, 0.12425077, 0.103718415, 0.095572054, 0.09632627, 0.10713302, 0.08480409, 0.11287712, 0.13108861, 0.0924134, 0.14540912, 0.12756297, 0.09787169, 0.085859336, 0.085629135, 0.12267467, 0.072454266, 0.09025572, 0.082926616, 0.09401109, 0.10439407, 0.090189844, 0.08248314, 0.09830398, 0.08284822, 0.08695815, 0.10215883, 0.096473046, 0.103199124, 0.09684709, 0.11229314, 0.101144776, 0.10685369, 0.09262444, 0.093369514, 0.09363176, 0.077655874, 0.12144364, 0.11263665, 0.11368342, 0.07694922, 0.08007548, 0.11707692, 0.09685343, 0.07771852, 0.23725672, 0.19403468, 0.11578571, 0.1307423, 0.09940573, 0.09783404, 0.10893058, 0.12727597, 0.09795394, 0.11017143, 0.10538682, 0.08168997, 0.10648008, 0.08711725, 0.08409366, 0.11852958, 0.18449251, 0.07732494, 0.10408691, 0.07527927, 0.07935124, 0.099112995, 0.08741901, 0.10516235, 0.16496055, 0.082892604, 0.08240759, 0.08782961, 0.13735849, 0.13893802, 0.08045101, 0.091005124, 0.10008548, 0.10268968, 0.08619234, 0.08681903, 0.09003403, 0.12725277, 0.108973734, 0.08308982, 0.091252856, 0.13133529, 0.11445666, 0.076592326, 0.074068114, 0.12490745, 0.0994546, 0.07551199, 0.14100182, 0.07780123, 0.0836913, 0.117605984, 0.12434332, 0.09131556, 0.100104265, 0.09484308, 0.1017368, 0.07731703, 0.09752193, 0.12580673, 0.0806301, 0.08496752, 0.10499773, 0.09178115, 0.100696474, 0.113794364, 0.12342575, 0.07854863, 0.09768119, 0.099041045, 0.07484744, 0.09411675, 0.13222504, 0.089744195, 0.097806245, 0.100923166, 0.119841784, 0.08649983, 0.08720117, 0.12277655, 0.085816644, 0.11406085, 0.10334334, 0.10524836, 0.08226454, 0.0955454, 0.11555668, 0.10106857, 0.08662792, 0.09291218, 0.09261915, 0.08702373, 0.08515607, 0.086227, 0.08155988, 0.08885095, 0.09906398, 0.0897825, 0.197695, 0.10678095, 0.078935206, 0.0984881, 0.08132303, 0.099869594, 0.105176546, 0.08924873, 0.08629946, 0.09066249, 0.08041667, 0.090427466, 0.093593664, 0.07910173, 0.08808893, 0.090749525, 0.08754012, 0.09134142, 0.09535312, 0.09535937, 0.077360235, 0.14820659, 0.094464876, 0.08428026, 0.09366182, 0.07997521, 0.09819605, 0.095464274, 0.1055493, 0.0830044, 0.08527105, 0.09368356, 0.10493012, 0.08854315, 0.110373445, 0.08208009, 0.11440508, 0.09220015, 0.09189301, 0.107534915, 0.10498235, 0.114973664, 0.08555546, 0.10450334, 0.12392765, 0.08922928, 0.087926835, 0.10183648, 0.09342349, 0.119172394, 0.09402035, 0.08933897, 0.088486485, 0.10773062, 0.10185704, 0.08818204, 0.09229005, 0.1470593, 0.1343249, 0.09270797, 0.08884286, 0.11596097, 0.08406011, 0.08474695, 0.08068653, 0.084076025, 0.08726848, 0.09974073, 0.11679336, 0.08433308, 0.11059459, 0.11352239, 0.091171235, 0.012968319, 0.34824762, 0.3908976, 0.6183429, 0.61975163, 0.8157705, 0.78007287, 0.7235755, 0.72812206, 0.7792859, 0.82750344, 0.79760003, 0.8402584, 0.7788191, 0.799463, 0.82940644, 0.72675806, 0.79325825, 0.7919465, 0.8201672, 0.7282655, 0.79356974, 0.76876825, 0.77132785, 0.78684276, 0.76512456, 0.78612065, 0.7517868, 0.779557, 0.73745936, 0.74535465, 0.7673481, 0.7720641, 0.7836386, 0.7891577, 0.7555121, 0.77482885, 0.8013414, 0.8329172, 0.81689614, 0.8050917, 0.77350914, 0.8034843, 0.7573871, 0.7842276, 0.79302335, 0.8243864, 0.7857494, 0.82194924, 0.7946183, 0.8039775, 0.7358483, 0.81836635, 0.7689414, 0.80756956, 0.86260253, 0.85590434, 0.87952375, 0.80688447, 0.8002188, 0.8369436, 0.81847614, 0.8511553, 0.7786316, 0.8150475, 0.7974417, 0.83411705, 0.79706126, 0.8199448, 0.8418622, 0.8385519, 0.87465894, 0.80745006, 0.80990016, 0.84098005, 0.8236689, 0.7432195, 0.7782859, 0.7976519, 0.8240927, 0.83897567, 0.8580464, 0.8446822, 0.958056, 0.86528754, 0.83557075, 0.8985605, 0.9162244, 0.8944649, 0.9328052, 0.93178827, 0.8764644, 0.9395774, 0.9331035, 0.9120106, 0.94545543, 0.9462482, 0.95936006, 0.9729296, 0.96408105, 0.93609124, 0.92120886, 0.97717464, 0.95543444, 0.96736145, 0.9682953, 0.97396076, 0.9626292, 0.9747318, 0.9758618, 0.97370446, 0.9721771, 0.9469241, 0.95160663, 0.97597253, 0.9401869, 0.9077872, 0.97136027, 0.95688045, 0.9796982, 0.8589642, 0.8861763, 0.84027606, 0.848936, 0.8552225, 0.89338017, 0.90461826, 0.86170894, 0.8757495, 0.8633042, 0.87001127, 0.89195544, 0.8690669, 0.87562376, 0.91361344, 0.91257584, 0.87697905, 0.94979763, 0.9754747, 0.96181613, 0.9370146, 0.9640994, 0.9843789, 0.9892113, 0.9765015, 0.9525141, 0.97941333, 0.98690856, 0.9910477, 0.9963505, 0.98877025, 0.9896453, 0.9768466, 0.89861006, 0.87794465, 0.9210123, 0.8945686, 0.88183105, 0.91193527, 0.8992444, 0.97071326, 0.9756795, 0.97148484, 0.9130493, 0.8782891, 0.9325538, 0.89252263, 0.9065308, 0.9251866, 0.924486, 0.9732766, 0.969497, 0.98068833, 0.98872197, 0.9864338, 0.9797881, 0.98315096, 0.91446066, 0.92483056, 0.920248, 0.9896444, 0.9623505, 0.9650213, 0.9610732, 0.9895428, 0.99615335, 0.9857766, 0.978022, 0.9928101, 0.9884628, 0.9930273, 0.9942098, 0.99351245, 0.9745028, 0.9897864, 0.99140036, 0.9870665, 0.9962301, 0.986696, 0.98650706, 0.99429387, 0.9919146, 0.9825549, 0.972798, 0.9921356, 0.9702696, 0.9852483, 0.97117823, 0.9920865, 0.9913762, 0.9858457, 0.98836744, 0.99184245, 0.99274313, 0.9833849, 0.99575645, 0.99509925, 0.9861972, 0.9733425, 0.99624515, 0.98647606, 0.96764684, 0.9947646, 0.9860269, 0.97064525, 0.9896906, 0.9941528, 0.9786703, 0.9938883, 0.99407494, 0.97233605, 0.98427945, 0.99629927, 0.98327357, 0.9933599, 0.9929849, 0.98675466, 0.9890797, 0.9895228, 0.99148005, 0.91352344, 0.89096475, 0.8809298, 0.8871773, 0.90072644, 0.889706, 0.9017435, 0.9238507, 0.903232, 0.9362603, 0.9187927, 0.9080876, 0.89903545, 0.94795024, 0.8888445, 0.9128886, 0.94619817, 0.8531677, 0.94808257, 0.940189, 0.93625957, 0.9568907, 0.9476463, 0.9298793, 0.94024885, 0.94232506, 0.9542563, 0.90587604, 0.9454424, 0.97266203, 0.96027035, 0.9765573, 0.92904496, 0.9552239, 0.9382353, 0.9695227, 0.946688, 0.97386545, 0.96547437, 0.9855211, 0.95885974, 0.9675068, 0.964796, 0.96260357, 0.978694, 0.95517796, 0.9734481, 0.95051754, 0.9641483, 0.96535224, 0.97709674, 0.94513035, 0.9385513, 0.94791704, 0.95922965, 0.94021225, 0.9552736, 0.9482359, 0.9495585, 0.9699772, 0.9494227, 0.94860023, 0.98516816, 0.97522676, 0.9893498, 0.9685024, 0.93705845, 0.97671294, 0.96975565, 0.983515, 0.98840386, 0.96413577, 0.95996225, 0.9730201, 0.9926974, 0.9857852, 0.9903639, 0.9869158, 0.98952156, 0.97738045, 0.9774471, 0.98357743, 0.98929197, 0.99309695, 0.9950274, 0.9981012, 0.9106947, 0.9711077, 0.9715714, 0.99731517, 0.98734456, 0.99189353, 0.99114406, 0.98584735, 0.9792502, 0.98451525, 0.9928887, 0.9870875, 0.98733497, 0.99334073, 0.9965133, 0.9985998, 0.9928446, 0.9897532, 0.99351084, 0.9896164, 0.9981474, 0.97513014, 0.996489, 0.9963195, 0.99755406, 0.9885841, 0.9962534, 0.9955677, 0.9946985, 0.99737406, 0.9836868, 0.98497355, 0.99838966, 0.9978501, 0.9961522, 0.97301126, 0.99735117, 0.9830463, 0.98699224, 0.99770695, 0.9984065, 0.9989462, 0.99676794, 0.9944171, 0.998105, 0.9942906, 0.9972144, 0.99861705, 0.99721813, 0.9980011, 0.97646713, 0.9990349, 0.99886763, 0.9977419, 0.9982265, 0.9966501, 0.99629015, 0.9987164, 0.99699885, 0.9981559, 0.98867077, 0.99907565, 0.99361193, 0.9971756, 0.9861039, 0.99797034, 0.9952157, 0.9983352, 0.99805796, 0.996628, 0.9970762, 0.99731225, 0.9957223, 0.9956199, 0.9962295, 0.99698186, 0.99697423, 0.9937739, 0.99800986, 0.9970117, 0.99368083, 0.9983183, 0.9943948, 0.9981471, 0.9976062, 0.99682283, 0.9993921, 0.995668, 0.99353737, 0.99391407, 0.99897474, 0.9987359, 0.9972163, 0.9972213, 0.9989677, 0.9973351, 0.9975452, 0.9987197, 0.9975108, 0.99463755, 0.9870346, 0.9960568, 0.99799, 0.99399567, 0.9983606, 0.99866253, 0.9980122, 0.99815285, 0.9990792, 0.9992917, 0.9938979, 0.99902976, 0.9976758, 0.99455214, 0.9990336, 0.9988565, 0.9987699, 0.99711746, 0.9983401, 0.9973827, 0.99272716, 0.9964152, 0.9968747, 0.99952424, 0.9994454, 0.99771446, 0.9940251, 0.9985468, 0.99949086, 0.99861497, 0.9982193, 0.99850464, 0.9980924, 0.99950224, 0.9941259, 0.9983294, 0.99686944, 0.99460393, 0.9990198, 0.9932179, 0.9933751, 0.99447626, 0.9974638, 0.99818146, 0.99891293, 0.9986179, 0.99703586, 0.9986442, 0.9959866, 0.9969773, 0.99839216, 0.99817055, 0.99902827, 0.99333334, 0.998883, 0.99851257, 0.99930656, 0.99899274, 0.9990041, 0.9962606, 0.9981829, 0.9985292, 0.99853724, 0.9990478, 0.9990888, 0.9990844, 0.9980387, 0.9993584, 0.9928691, 0.99814063, 0.999254, 0.9997704, 0.99920636, 0.99873257, 0.99467695
disc_val_loss: 5.5387955, 2.1823237, 2.1358464, 2.2461953, 2.3343983, 2.707921, 2.7564485, 2.7684011, 2.788105, 2.802881, 2.784839, 2.7691586, 2.9969509, 2.772588, 2.7984946, 2.815228, 2.8130257, 2.786345, 3.057695, 3.0082476, 2.8364403, 2.785176, 2.841372, 2.816093, 2.8515441, 2.9266996, 2.8265214, 3.407525, 2.7939222, 2.8162975, 2.8040788, 2.927999, 2.7936585, 2.9093127, 2.9144013, 2.6609743, 2.7960355, 2.8117843, 2.8487585, 2.9340534, 3.6403599, 2.8954675, 2.8462744, 2.80478, 6.2358317, 2.8382626, 2.792612, 3.6694856, 2.7816255, 2.806636, 2.787572, 2.7841775, 2.7896054, 2.8559637, 3.203857, 2.7909064, 2.9549887, 2.7914345, 2.9412212, 2.9100335, 2.7817602, 2.8051894, 2.8493242, 2.8649898, 2.8014476, 2.791553, 2.8967447, 2.787878, 3.1785226, 2.840002, 2.8644118, 2.900092, 2.7773173, 2.8735785, 2.8152995, 2.81219, 2.841538, 2.8277981, 2.8365495, 2.9153767, 2.8703303, 2.80851, 2.8094358, 2.784161, 2.8388069, 2.7813616, 2.8095407, 2.9022636, 2.7988179, 2.790646, 2.8093178, 2.8071883, 2.9435723, 2.865853, 2.9951348, 2.802829, 2.7885776, 3.1528609, 2.869675, 2.786132, 2.7912161, 2.805815, 2.8412025, 2.7815325, 2.8153262, 2.786753, 2.793984, 2.805562, 2.7985625, 2.800803, 2.8159132, 2.7927823, 2.8081121, 2.7995415, 2.7921276, 2.940701, 2.831209, 2.8184402, 2.8052998, 2.7864273, 2.830998, 2.80583, 2.7919114, 2.8277953, 2.8024094, 2.806688, 2.838599, 2.780778, 2.9189792, 2.8186214, 2.8083792, 3.0332823, 2.7901368, 2.7857323, 2.798675, 2.7800553, 2.8659601, 2.7989812, 3.1564412, 2.818351, 2.8669646, 2.8169515, 2.8355167, 2.7745562, 2.8215156, 3.1189625, 2.8448164, 2.8255613, 2.8062716, 2.7767117, 2.8265631, 2.8121748, 2.7939363, 2.7813668, 2.804075, 2.8157904, 2.8106177, 2.7975342, 2.7922835, 2.8085084, 2.9179354, 2.7985954, 2.7844224, 2.8136868, 2.861975, 2.8007238, 2.792566, 2.7994459, 2.8066301, 2.8050673, 2.7926157, 2.7917, 2.7932498, 2.7828257, 2.8210764, 2.7834692, 2.8280075, 2.9732633, 2.7881513, 2.810494, 2.7928462, 2.7940142, 2.7948112, 2.7866604, 2.799278, 2.8008046, 2.7859764, 2.8197875, 3.0640593, 2.7948048, 2.7937033, 2.8610668, 2.8008378, 3.4820926, 3.0625744, 2.8141494, 2.8270614, 2.8140788, 2.797476, 2.8240151, 3.6656363, 2.8011355, 2.8312902, 2.8261545, 2.8211336, 2.7980669, 2.799379, 2.8001463, 3.0915966, 2.810065, 2.7884014, 2.8033848, 2.8019192, 2.784047, 2.7934945, 2.8218665, 2.8123345, 2.843579, 2.806377, 2.841268, 2.8136837, 2.786084, 2.8481507, 2.8257215, 2.886958, 2.8195899, 2.7765703, 2.7927008, 2.85016, 2.8127367, 2.814473, 2.7979896, 2.8231914, 2.7859435, 2.7880707, 2.8151045, 2.8131077, 2.8256395, 2.8335557, 2.8618689, 2.8149438, 2.8334463, 2.785598, 2.794295, 2.8994415, 2.7835028, 2.7896624, 2.7949522, 2.7858984, 2.7861888, 2.793246, 2.8275554, 2.8115098, 2.800681, 2.7962914, 2.7938502, 2.822727, 2.8278244, 2.8580747, 2.8295522, 2.8020108, 2.7926364, 2.8150496, 2.786198, 2.8078291, 2.8071876, 2.8071382, 2.8578057, 2.905739, 2.814338, 2.7981172, 2.8310337, 2.798131, 2.7760873, 2.8646414, 2.817168, 2.799724, 2.856648, 2.807206, 2.8641336, 2.833965, 2.7916596, 2.817239, 2.796984, 2.7963, 2.823003, 2.8331363, 2.8250368, 2.7881212, 2.807293, 2.82112, 2.7878582, 2.8219104, 2.8701966, 2.782117, 2.8448913, 2.8726933, 2.8086276, 2.801927, 2.7859416, 2.8153014, 2.7752213, 2.7874968, 2.7949317, 2.7920423, 2.828, 2.803197, 2.795966, 2.813699, 2.79943, 2.8230605, 2.8074439, 2.8097918, 2.8276312, 2.7933955, 2.8259377, 2.8427694, 2.8093274, 2.8097334, 2.804952, 2.8081143, 2.7884603, 2.8043756, 2.8377967, 2.8134038, 2.7895422, 2.7887516, 2.8650541, 2.818469, 2.7880156, 2.7705283, 3.0928068, 2.8979363, 2.8473072, 2.8188324, 2.7981713, 2.813769, 2.8151143, 2.7977383, 2.8066843, 2.8314016, 2.7853456, 2.8009946, 2.8093252, 2.7979941, 2.8799736, 2.9699404, 2.782963, 2.8168974, 2.7785559, 2.788417, 2.8224475, 2.799945, 2.8156435, 2.8689053, 2.797385, 2.7914207, 2.8197274, 2.8657184, 2.8596888, 2.7826545, 2.7942832, 2.8199291, 2.8172336, 2.799067, 2.8012648, 2.7949986, 2.8466678, 2.8022358, 2.7763014, 2.790798, 2.8391619, 2.8450918, 2.791934, 2.7864838, 2.8795035, 2.8100402, 2.783651, 2.855818, 2.782399, 2.7753367, 2.7995613, 2.8439882, 2.7926161, 2.8058827, 2.8300831, 2.7829738, 2.7911172, 2.8005521, 2.8332603, 2.781092, 2.78363, 2.8076, 2.7951188, 2.8075707, 2.8395345, 2.8166454, 2.7811887, 2.8014503, 2.8210108, 2.7814524, 2.8085093, 2.8432524, 2.806736, 2.7997565, 2.8027685, 2.8451931, 2.816179, 2.8132176, 2.853108, 2.7826133, 2.8208013, 2.811649, 2.813284, 2.8024023, 2.8008647, 2.9117484, 2.851845, 2.7888796, 2.8089774, 2.8076952, 2.8024611, 2.7938728, 2.780288, 2.81806, 2.7990882, 2.830618, 2.7987573, 3.0404627, 2.810561, 2.7791023, 2.8099463, 2.7774596, 2.8340807, 2.801514, 2.791949, 2.8182185, 2.8006947, 2.782178, 2.7846346, 2.8450165, 2.7901704, 2.8041384, 2.7929268, 2.7916903, 2.807485, 2.8261697, 2.7879357, 2.783353, 2.838636, 2.8115356, 2.7885678, 2.8048031, 2.7767286, 2.812082, 2.8355346, 2.8124125, 2.793258, 2.7939773, 2.7921214, 2.8173783, 2.7802937, 2.8282993, 2.7902303, 2.8666472, 2.8109558, 2.7987175, 2.8219075, 2.8050737, 2.8422263, 2.7850502, 2.816314, 2.8390257, 2.8189662, 2.7942045, 2.8123357, 2.8129904, 2.8376024, 2.790491, 2.8110209, 2.7823694, 2.8089511, 2.8148074, 2.8015404, 2.7959745, 2.892877, 2.8982973, 2.7957, 2.7976909, 2.8260515, 2.7976027, 2.7876885, 2.8020496, 2.7843196, 2.7953796, 2.828846, 2.8338182, 2.7739882, 2.6914513, 2.7978396, 2.782826, 5.6450133, 1.7541593, 1.675208, 1.7299148, 0.8916099, 0.95207953, 0.70997584, 0.8531943, 0.4688307, 0.5386692, 0.46660495, 0.47591418, 0.46802765, 0.50669307, 0.4734895, 0.47415182, 0.5681807, 0.52596277, 0.56318206, 0.44143927, 0.6261612, 0.5376935, 0.5179754, 0.5863403, 0.55005336, 0.50035745, 0.7513348, 0.5238401, 0.48271427, 1.0921383, 0.50070035, 0.46736458, 0.54022264, 0.43701345, 0.5505691, 0.7402059, 0.5311614, 0.538366, 0.4803604, 0.5696569, 0.51759803, 0.4157599, 0.725244, 0.6550471, 0.46789992, 1.4181982, 0.5197273, 0.46933457, 0.74682105, 0.54142827, 0.38094047, 0.69607705, 0.63126457, 0.56577927, 0.4810379, 0.5207451, 0.54384714, 0.48699796, 0.5358465, 0.39894852, 0.38874078, 0.3912146, 0.47829637, 0.45316032, 0.34804112, 0.3883138, 0.49791694, 0.38808903, 0.41597363, 0.50908554, 0.30215552, 0.41402817, 0.5538585, 0.37252998, 0.33438936, 0.31944823, 0.97383, 0.4878872, 0.40609685, 0.3213107, 0.26462772, 0.27562422, 0.28911898, 0.6296368, 0.3594628, 0.32943526, 0.9238822, 0.35067087, 0.25470117, 0.14970118, 0.3464603, 0.29582042, 0.18336426, 0.18501233, 0.30931845, 0.24595596, 0.29258603, 0.21401326, 0.053890835, 0.05943965, 0.29466376, 0.21304537, 0.109186545, 0.29422247, 0.05094621, 0.065797724, 0.08411302, 0.117041856, 0.06394099, 0.08634907, 0.067675754, 0.11809174, 0.14099641, 0.12108002, 0.037500635, 0.38331407, 1.4370687, 0.16717899, 0.21231426, 0.06232319, 0.40721738, 0.43749383, 0.2586993, 0.4344632, 0.24979807, 0.339924, 0.5112691, 0.3227906, 0.19317116, 0.44902653, 0.24335422, 0.32004166, 0.25523245, 0.214847, 0.14199166, 0.26010704, 0.28317532, 0.101376995, 0.04517851, 1.1936812, 0.21760973, 0.087201186, 0.07873089, 0.024894632, 0.12349554, 0.21683273, 0.10169537, 0.056219805, 0.032529388, 0.0091074845, 0.017822227, 0.039203625, 0.73092973, 0.31431633, 0.20938304, 0.40890813, 0.18987949, 0.2510408, 0.23475231, 0.19227067, 0.08143297, 0.17369089, 0.1183284, 0.44063702, 0.21137366, 0.5702034, 0.14937286, 0.21010858, 0.15342546, 0.27288887, 0.11971966, 0.17718253, 0.25351134, 0.06808208, 0.03858165, 0.09398537, 0.13622373, 0.2406638, 0.22412477, 0.1544858, 0.022119887, 0.19740567, 0.18749504, 0.31957164, 0.056770835, 0.0140861375, 0.09201299, 0.12916516, 0.026731724, 0.035583083, 0.07805632, 0.01431425, 0.016446248, 0.56986296, 0.0829234, 0.04695071, 0.08835082, 0.021992847, 0.042554893, 0.062257033, 0.03844904, 0.050687186, 0.07634487, 0.15271606, 0.028716434, 0.15234657, 0.07142355, 1.4811331, 0.07188654, 0.01688373, 0.098458715, 0.034738503, 0.0731549, 0.06529186, 0.069848396, 0.035560545, 0.025420403, 0.717297, 0.41928363, 0.02066572, 0.09192798, 0.3189664, 0.040364835, 0.10226028, 0.8581523, 0.07334538, 0.027087295, 0.10323078, 0.071499705, 0.032731768, 0.2903776, 0.13320772, 0.048009265, 0.1030954, 0.077648774, 0.14893444, 0.0568036, 0.03523822, 0.072823815, 0.05045987, 0.7306257, 0.30292687, 0.28247803, 0.24120024, 0.19796418, 0.2837821, 0.16896407, 0.15719692, 0.16710038, 0.39984185, 0.17423002, 0.27311125, 0.3510127, 0.0812793, 0.28108665, 0.1924096, 0.10276997, 0.3344414, 0.18563905, 0.22301371, 0.37169185, 0.069710486, 0.2677448, 0.1269839, 0.096698, 0.18084134, 0.12612864, 0.2708, 0.28405482, 0.05112652, 0.10046858, 0.03690106, 0.20721151, 0.3332661, 0.3692457, 0.050664846, 0.14445083, 0.059428114, 0.13471606, 0.030611452, 0.05286428, 0.04946709, 0.08836233, 0.0832902, 0.08720466, 0.32932845, 0.033250827, 0.22311676, 0.05236532, 0.35207134, 0.0890675, 0.11033696, 0.123888925, 0.13099612, 0.06405356, 0.13520283, 0.14289837, 0.16899575, 0.13230775, 0.76494676, 0.21766733, 0.46916145, 0.021370467, 1.2763106, 0.03042738, 0.112696156, 0.5238298, 0.09920283, 0.22371557, 0.055790868, 0.027039628, 0.21316916, 0.28493953, 1.1128061, 0.015177685, 0.08934635, 0.03555935, 0.03071542, 0.0159383, 0.095379, 0.12109168, 0.12402353, 0.11356624, 0.04010025, 0.014556286, 0.003216151, 1.1517656, 0.06926811, 0.15241338, 0.029521631, 0.076841444, 0.24093881, 0.05718008, 0.24038452, 0.42120293, 0.22355182, 0.029463151, 0.06545076, 0.1789003, 0.047515742, 0.016909122, 0.00648474, 0.040253554, 0.3056543, 0.09138134, 0.3901703, 0.018495193, 0.6096887, 0.032251455, 0.033420384, 0.03470007, 0.08425441, 0.013908555, 0.05106756, 0.03268424, 0.011200543, 0.14722909, 0.62231797, 0.009538192, 0.020078067, 0.020393085, 0.34859455, 0.009901093, 0.1470399, 0.87667525, 0.036077883, 0.045530323, 0.00264631, 0.042685654, 0.30217662, 0.023097238, 0.05141733, 0.056187734, 0.011348717, 0.041297413, 0.0090566045, 1.7019726, 0.003799654, 0.047005225, 0.06751354, 0.042977408, 0.03011805, 0.060427018, 0.002843222, 0.09945133, 0.015736168, 0.33949953, 0.0026284205, 0.09412539, 0.033209946, 3.5310447, 0.041431874, 0.09259355, 0.036433484, 0.020826943, 0.094288774, 0.068241134, 0.020097466, 0.04600896, 0.08174988, 0.07817089, 0.01210988, 0.015167719, 0.111723974, 0.079444036, 0.13109748, 0.18035561, 0.007761926, 0.11936764, 0.024876531, 0.028760875, 0.12295247, 0.017966073, 0.07133021, 0.16682242, 0.31328803, 0.04538138, 0.06785691, 0.02824832, 0.058350306, 0.016010819, 0.09557323, 0.015040116, 0.020048136, 0.15873936, 0.086072266, 0.23478483, 0.04697457, 0.031806327, 0.6922061, 0.02680737, 0.13026801, 0.068513505, 0.028148197, 0.011040224, 0.0043189796, 0.2909106, 0.0091911275, 0.05350741, 0.36998826, 0.067971475, 0.04464502, 0.10808287, 0.071986265, 0.022083268, 0.017308122, 0.2387034, 0.026857173, 0.048067532, 0.043940403, 0.0703184, 0.05514761, 0.1397919, 0.026009273, 0.0037422124, 0.009433745, 0.08133389, 0.06560401, 0.059225336, 0.019374425, 0.114281036, 0.024335487, 0.28109616, 0.372421, 0.028791163, 0.12951833, 0.27419823, 0.26694125, 0.028444268, 0.058383245, 0.06834765, 0.16357759, 0.4969714, 0.10075279, 0.063213415, 0.027248824, 0.0113548245, 0.039946835, 0.01846512, 0.95362854, 0.042555306, 0.052798785, 0.020401577, 0.01981716, 0.028148975, 0.16444851, 0.054605253, 0.26380613, 0.109774515, 0.025964638, 0.03325732, 0.009103012, 0.07693323, 0.0038527153, 0.6150232, 0.26305655, 0.03663372, 0.008017996, 0.01694837, 0.015818289, 0.498991
disc_val_acc: 0.004464285714285714, 0.26438492063492064, 0.1636904761904762, 0.27628968253968256, 0.2013888888888889, 0.13045634920634921, 0.1195436507936508, 0.06001984126984127, 0.05555555555555555, 0.09821428571428571, 0.05853174603174603, 0.06349206349206349, 0.05257936507936508, 0.06349206349206349, 0.0625, 0.062003968253968256, 0.057539682539682536, 0.07341269841269842, 0.062003968253968256, 0.06845238095238096, 0.07093253968253968, 0.0625, 0.05803571428571429, 0.060515873015873016, 0.062003968253968256, 0.062003968253968256, 0.06498015873015874, 0.05853174603174603, 0.057539682539682536, 0.06299603174603174, 0.062003968253968256, 0.05406746031746032, 0.05505952380952381, 0.06299603174603174, 0.053075396825396824, 0.09970238095238096, 0.062003968253968256, 0.062003968253968256, 0.05853174603174603, 0.05853174603174603, 0.0679563492063492, 0.061507936507936505, 0.05853174603174603, 0.05853174603174603, 0.05505952380952381, 0.06349206349206349, 0.06398809523809523, 0.07093253968253968, 0.057539682539682536, 0.054563492063492064, 0.062003968253968256, 0.057539682539682536, 0.10317460317460317, 0.054563492063492064, 0.05853174603174603, 0.05853174603174603, 0.05257936507936508, 0.06349206349206349, 0.05853174603174603, 0.062003968253968256, 0.06001984126984127, 0.062003968253968256, 0.062003968253968256, 0.06398809523809523, 0.053075396825396824, 0.054563492063492064, 0.062003968253968256, 0.06845238095238096, 0.07093253968253968, 0.062003968253968256, 0.05704365079365079, 0.05704365079365079, 0.0689484126984127, 0.06349206349206349, 0.05853174603174603, 0.053075396825396824, 0.05803571428571429, 0.05853174603174603, 0.07093253968253968, 0.06349206349206349, 0.09623015873015874, 0.053075396825396824, 0.05505952380952381, 0.062003968253968256, 0.057539682539682536, 0.06696428571428571, 0.06349206349206349, 0.06299603174603174, 0.057539682539682536, 0.053075396825396824, 0.05704365079365079, 0.06398809523809523, 0.07390873015873016, 0.062003968253968256, 0.060515873015873016, 0.07837301587301587, 0.05853174603174603, 0.06299603174603174, 0.05505952380952381, 0.06349206349206349, 0.0689484126984127, 0.05704365079365079, 0.05803571428571429, 0.05505952380952381, 0.062003968253968256, 0.06349206349206349, 0.07291666666666667, 0.0625, 0.053075396825396824, 0.061507936507936505, 0.05853174603174603, 0.06349206349206349, 0.057539682539682536, 0.06349206349206349, 0.05257936507936508, 0.07341269841269842, 0.07341269841269842, 0.05505952380952381, 0.05257936507936508, 0.0689484126984127, 0.06349206349206349, 0.06349206349206349, 0.05853174603174603, 0.054563492063492064, 0.06299603174603174, 0.053075396825396824, 0.062003968253968256, 0.060515873015873016, 0.07390873015873016, 0.05853174603174603, 0.05803571428571429, 0.12251984126984126, 0.06349206349206349, 0.07341269841269842, 0.06001984126984127, 0.07093253968253968, 0.062003968253968256, 0.07093253968253968, 0.06299603174603174, 0.062003968253968256, 0.05853174603174603, 0.060515873015873016, 0.062003968253968256, 0.06845238095238096, 0.05505952380952381, 0.0625, 0.05505952380952381, 0.07093253968253968, 0.061507936507936505, 0.07390873015873016, 0.06349206349206349, 0.05803571428571429, 0.057539682539682536, 0.0689484126984127, 0.06398809523809523, 0.06845238095238096, 0.061507936507936505, 0.057539682539682536, 0.06845238095238096, 0.062003968253968256, 0.06845238095238096, 0.07341269841269842, 0.07093253968253968, 0.061507936507936505, 0.06398809523809523, 0.05853174603174603, 0.062003968253968256, 0.06845238095238096, 0.060515873015873016, 0.057539682539682536, 0.0744047619047619, 0.062003968253968256, 0.07341269841269842, 0.054563492063492064, 0.05704365079365079, 0.06349206349206349, 0.05505952380952381, 0.062003968253968256, 0.060515873015873016, 0.0679563492063492, 0.062003968253968256, 0.062003968253968256, 0.0625, 0.05257936507936508, 0.060515873015873016, 0.05803571428571429, 0.05257936507936508, 0.05853174603174603, 0.0689484126984127, 0.05704365079365079, 0.05853174603174603, 0.060515873015873016, 0.05803571428571429, 0.06845238095238096, 0.060515873015873016, 0.06845238095238096, 0.0625, 0.053075396825396824, 0.053075396825396824, 0.06845238095238096, 0.054563492063492064, 0.06349206349206349, 0.05853174603174603, 0.05853174603174603, 0.05803571428571429, 0.057539682539682536, 0.060515873015873016, 0.05704365079365079, 0.06299603174603174, 0.06101190476190476, 0.06349206349206349, 0.06845238095238096, 0.07093253968253968, 0.06001984126984127, 0.0679563492063492, 0.05853174603174603, 0.05803571428571429, 0.0625, 0.07093253968253968, 0.05505952380952381, 0.062003968253968256, 0.0689484126984127, 0.061507936507936505, 0.06349206349206349, 0.06349206349206349, 0.05853174603174603, 0.05505952380952381, 0.05505952380952381, 0.0679563492063492, 0.05704365079365079, 0.057539682539682536, 0.05853174603174603, 0.06398809523809523, 0.06349206349206349, 0.053075396825396824, 0.060515873015873016, 0.06845238095238096, 0.06299603174603174, 0.06349206349206349, 0.06349206349206349, 0.06001984126984127, 0.057539682539682536, 0.05406746031746032, 0.06845238095238096, 0.057539682539682536, 0.08134920634920635, 0.05853174603174603, 0.06101190476190476, 0.05505952380952381, 0.06349206349206349, 0.06349206349206349, 0.062003968253968256, 0.05257936507936508, 0.05853174603174603, 0.0625, 0.0689484126984127, 0.06845238095238096, 0.05257936507936508, 0.07390873015873016, 0.05505952380952381, 0.05853174603174603, 0.06349206349206349, 0.053075396825396824, 0.06001984126984127, 0.07390873015873016, 0.05853174603174603, 0.053075396825396824, 0.05853174603174603, 0.053075396825396824, 0.060515873015873016, 0.06349206349206349, 0.057539682539682536, 0.062003968253968256, 0.05803571428571429, 0.05505952380952381, 0.062003968253968256, 0.062003968253968256, 0.06299603174603174, 0.05853174603174603, 0.07390873015873016, 0.062003968253968256, 0.062003968253968256, 0.07093253968253968, 0.05505952380952381, 0.06349206349206349, 0.0689484126984127, 0.057539682539682536, 0.060515873015873016, 0.06001984126984127, 0.06845238095238096, 0.053075396825396824, 0.057539682539682536, 0.05505952380952381, 0.06398809523809523, 0.07390873015873016, 0.06299603174603174, 0.05853174603174603, 0.061507936507936505, 0.0625, 0.057539682539682536, 0.06299603174603174, 0.07390873015873016, 0.062003968253968256, 0.062003968253968256, 0.05853174603174603, 0.0689484126984127, 0.07043650793650794, 0.062003968253968256, 0.06845238095238096, 0.06349206349206349, 0.05505952380952381, 0.053075396825396824, 0.05704365079365079, 0.06349206349206349, 0.07390873015873016, 0.05505952380952381, 0.062003968253968256, 0.062003968253968256, 0.06349206349206349, 0.05853174603174603, 0.06349206349206349, 0.053075396825396824, 0.06845238095238096, 0.06349206349206349, 0.05803571428571429, 0.05853174603174603, 0.05803571428571429, 0.060515873015873016, 0.05853174603174603, 0.06845238095238096, 0.05853174603174603, 0.05257936507936508, 0.060515873015873016, 0.0625, 0.05257936507936508, 0.06349206349206349, 0.053075396825396824, 0.06349206349206349, 0.057539682539682536, 0.06845238095238096, 0.06398809523809523, 0.06299603174603174, 0.061507936507936505, 0.061507936507936505, 0.060515873015873016, 0.06001984126984127, 0.09871031746031746, 0.06101190476190476, 0.060515873015873016, 0.05853174603174603, 0.057539682539682536, 0.05704365079365079, 0.07390873015873016, 0.05853174603174603, 0.05505952380952381, 0.062003968253968256, 0.05505952380952381, 0.057539682539682536, 0.053075396825396824, 0.0625, 0.05803571428571429, 0.0689484126984127, 0.06349206349206349, 0.06845238095238096, 0.0625, 0.062003968253968256, 0.0625, 0.06349206349206349, 0.053075396825396824, 0.06349206349206349, 0.05853174603174603, 0.05853174603174603, 0.062003968253968256, 0.06349206349206349, 0.061507936507936505, 0.057539682539682536, 0.061507936507936505, 0.06845238095238096, 0.0625, 0.06349206349206349, 0.06845238095238096, 0.062003968253968256, 0.06349206349206349, 0.06398809523809523, 0.053075396825396824, 0.05505952380952381, 0.07093253968253968, 0.057539682539682536, 0.06349206349206349, 0.06845238095238096, 0.057539682539682536, 0.0689484126984127, 0.062003968253968256, 0.07341269841269842, 0.05853174603174603, 0.05853174603174603, 0.053075396825396824, 0.062003968253968256, 0.06845238095238096, 0.060515873015873016, 0.05853174603174603, 0.06746031746031746, 0.05704365079365079, 0.060515873015873016, 0.062003968253968256, 0.062003968253968256, 0.05803571428571429, 0.053075396825396824, 0.057539682539682536, 0.062003968253968256, 0.06299603174603174, 0.062003968253968256, 0.05803571428571429, 0.062003968253968256, 0.06349206349206349, 0.13640873015873015, 0.062003968253968256, 0.05853174603174603, 0.05704365079365079, 0.06845238095238096, 0.05803571428571429, 0.0625, 0.06845238095238096, 0.0625, 0.0679563492063492, 0.060515873015873016, 0.05853174603174603, 0.057539682539682536, 0.057539682539682536, 0.053075396825396824, 0.062003968253968256, 0.060515873015873016, 0.07341269841269842, 0.07093253968253968, 0.07093253968253968, 0.060515873015873016, 0.05803571428571429, 0.05803571428571429, 0.06398809523809523, 0.06299603174603174, 0.06398809523809523, 0.052083333333333336, 0.05803571428571429, 0.06845238095238096, 0.053075396825396824, 0.05853174603174603, 0.05505952380952381, 0.0679563492063492, 0.053075396825396824, 0.062003968253968256, 0.061507936507936505, 0.06845238095238096, 0.05704365079365079, 0.06349206349206349, 0.0625, 0.07043650793650794, 0.06299603174603174, 0.05853174603174603, 0.05257936507936508, 0.052083333333333336, 0.06746031746031746, 0.060515873015873016, 0.05505952380952381, 0.05654761904761905, 0.05704365079365079, 0.0689484126984127, 0.06845238095238096, 0.07093253968253968, 0.0689484126984127, 0.05853174603174603, 0.07390873015873016, 0.054563492063492064, 0.060515873015873016, 0.0625, 0.060515873015873016, 0.053075396825396824, 0.0625, 0.05853174603174603, 0.053075396825396824, 0.0689484126984127, 0.057539682539682536, 0.06845238095238096, 0.07390873015873016, 0.05505952380952381, 0.06349206349206349, 0.06398809523809523, 0.07093253968253968, 0.062003968253968256, 0.07341269841269842, 0.05853174603174603, 0.06398809523809523, 0.07291666666666667, 0.07390873015873016, 0.062003968253968256, 0.06398809523809523, 0.06398809523809523, 0.0679563492063492, 0.0679563492063492, 0.0679563492063492, 0.06101190476190476, 0.06349206349206349, 0.0, 0.29017857142857145, 0.31200396825396826, 0.30009920634920634, 0.5987103174603174, 0.6850198412698413, 0.6999007936507936, 0.6493055555555556, 0.8000992063492064, 0.7490079365079365, 0.7534722222222222, 0.7817460317460317, 0.7703373015873016, 0.7678571428571429, 0.7624007936507936, 0.7624007936507936, 0.6994047619047619, 0.7534722222222222, 0.7276785714285714, 0.7787698412698413, 0.6974206349206349, 0.7470238095238095, 0.7524801587301587, 0.748015873015873, 0.751984126984127, 0.7584325396825397, 0.6919642857142857, 0.7564484126984127, 0.7663690476190477, 0.6001984126984127, 0.753968253968254, 0.7633928571428571, 0.7127976190476191, 0.7881944444444444, 0.7336309523809523, 0.6785714285714286, 0.7301587301587301, 0.71875, 0.7336309523809523, 0.7291666666666666, 0.7420634920634921, 0.7936507936507936, 0.6850198412698413, 0.6939484126984127, 0.7648809523809523, 0.5744047619047619, 0.7430555555555556, 0.7703373015873016, 0.6696428571428571, 0.7301587301587301, 0.8194444444444444, 0.7033730158730159, 0.6845238095238095, 0.6924603174603174, 0.753968253968254, 0.7609126984126984, 0.7217261904761905, 0.7470238095238095, 0.7609126984126984, 0.8219246031746031, 0.7906746031746031, 0.8070436507936508, 0.8149801587301587, 0.7718253968253969, 0.8442460317460317, 0.7827380952380952, 0.7703373015873016, 0.7901785714285714, 0.7881944444444444, 0.7862103174603174, 0.8571428571428571, 0.7876984126984127, 0.7698412698412699, 0.8288690476190477, 0.814484126984127, 0.8715277777777778, 0.6532738095238095, 0.8060515873015873, 0.8601190476190477, 0.8308531746031746, 0.9027777777777778, 0.8834325396825397, 0.8427579365079365, 0.7485119047619048, 0.8328373015873016, 0.8516865079365079, 0.7757936507936508, 0.8516865079365079, 0.9161706349206349, 0.933531746031746, 0.8685515873015873, 0.873015873015873, 0.9255952380952381, 0.9201388888888888, 0.8864087301587301, 0.9186507936507936, 0.8988095238095238, 0.9270833333333334, 0.9801587301587301, 0.9836309523809523, 0.8963293650793651, 0.9077380952380952, 0.9771825396825397, 0.9265873015873016, 0.9866071428571429, 0.9756944444444444, 0.964781746031746, 0.9598214285714286, 0.9766865079365079, 0.9702380952380952, 0.9722222222222222, 0.9553571428571429, 0.9444444444444444, 0.9573412698412699, 0.9910714285714286, 0.8824404761904762, 0.6944444444444444, 0.941468253968254, 0.939484126984127, 0.9796626984126984, 0.7802579365079365, 0.8199404761904762, 0.8878968253968254, 0.7867063492063492, 0.8606150793650794, 0.8482142857142857, 0.7991071428571429, 0.8695436507936508, 0.9290674603174603, 0.8328373015873016, 0.902281746031746, 0.8511904761904762, 0.9221230158730159, 0.9280753968253969, 0.9494047619047619, 0.8685515873015873, 0.8874007936507936, 0.9722222222222222, 0.9880952380952381, 0.7881944444444444, 0.9345238095238095, 0.9682539682539683, 0.9732142857142857, 0.9910714285714286, 0.970734126984127, 0.9246031746031746, 0.964781746031746, 0.9861111111111112, 0.9880952380952381, 0.9955357142857143, 0.9935515873015873, 0.9861111111111112, 0.8883928571428571, 0.8432539682539683, 0.9146825396825397, 0.7881944444444444, 0.9236111111111112, 0.8943452380952381, 0.9166666666666666, 0.9221230158730159, 0.9712301587301587, 0.9384920634920635, 0.9563492063492064, 0.8194444444444444, 0.9350198412698413, 0.7757936507936508, 0.9642857142857143, 0.8993055555555556, 0.9236111111111112, 0.871031746031746, 0.9657738095238095, 0.9330357142857143, 0.9300595238095238, 0.9826388888888888, 0.9861111111111112, 0.9657738095238095, 0.9623015873015873, 0.8869047619047619, 0.910218253968254, 0.9449404761904762, 0.9950396825396826, 0.9379960317460317, 0.9424603174603174, 0.9097222222222222, 0.9851190476190477, 0.9965277777777778, 0.9712301587301587, 0.9682539682539683, 0.9890873015873016, 0.9861111111111112, 0.9796626984126984, 0.9945436507936508, 0.9940476190476191, 0.8874007936507936, 0.9791666666666666, 0.9890873015873016, 0.9766865079365079, 0.9935515873015873, 0.9831349206349206, 0.9826388888888888, 0.9885912698412699, 0.9885912698412699, 0.9761904761904762, 0.9578373015873016, 0.9885912698412699, 0.9494047619047619, 0.9737103174603174, 0.8055555555555556, 0.9821428571428571, 0.9945436507936508, 0.9672619047619048, 0.9895833333333334, 0.9796626984126984, 0.9856150793650794, 0.9751984126984127, 0.9905753968253969, 0.9910714285714286, 0.8938492063492064, 0.9201388888888888, 0.9945436507936508, 0.9742063492063492, 0.9047619047619048, 0.9895833333333334, 0.966765873015873, 0.8670634920634921, 0.9771825396825397, 0.9905753968253969, 0.966765873015873, 0.9856150793650794, 0.9890873015873016, 0.9201388888888888, 0.9603174603174603, 0.9935515873015873, 0.9652777777777778, 0.9796626984126984, 0.9801587301587301, 0.9816468253968254, 0.9890873015873016, 0.9776785714285714, 0.9871031746031746, 0.7762896825396826, 0.8680555555555556, 0.8839285714285714, 0.9117063492063492, 0.910218253968254, 0.8621031746031746, 0.9250992063492064, 0.9384920634920635, 0.9627976190476191, 0.7991071428571429, 0.9489087301587301, 0.8764880952380952, 0.8323412698412699, 0.9732142857142857, 0.8521825396825397, 0.9107142857142857, 0.9657738095238095, 0.8616071428571429, 0.9141865079365079, 0.9027777777777778, 0.8635912698412699, 0.9732142857142857, 0.8958333333333334, 0.9479166666666666, 0.9632936507936508, 0.9236111111111112, 0.9508928571428571, 0.8903769841269841, 0.876984126984127, 0.9875992063492064, 0.96875, 0.9900793650793651, 0.8834325396825397, 0.9012896825396826, 0.8541666666666666, 0.9846230158730159, 0.9389880952380952, 0.9816468253968254, 0.9424603174603174, 0.9910714285714286, 0.9866071428571429, 0.9836309523809523, 0.9682539682539683, 0.9613095238095238, 0.9662698412698413, 0.8606150793650794, 0.9955357142857143, 0.9017857142857143, 0.9851190476190477, 0.904265873015873, 0.9751984126984127, 0.9588293650793651, 0.9479166666666666, 0.9424603174603174, 0.9771825396825397, 0.9632936507936508, 0.9399801587301587, 0.9295634920634921, 0.9692460317460317, 0.7703373015873016, 0.9375, 0.8581349206349206, 0.9940476190476191, 0.783234126984127, 0.9935515873015873, 0.9618055555555556, 0.8194444444444444, 0.9598214285714286, 0.9181547619047619, 0.9761904761904762, 0.9885912698412699, 0.9285714285714286, 0.8993055555555556, 0.816468253968254, 0.9945436507936508, 0.9747023809523809, 0.9866071428571429, 0.9890873015873016, 0.9955357142857143, 0.9623015873015873, 0.9583333333333334, 0.9677579365079365, 0.9761904761904762, 0.9880952380952381, 0.9940476190476191, 0.9985119047619048, 0.7356150793650794, 0.9697420634920635, 0.9464285714285714, 0.9930555555555556, 0.9742063492063492, 0.9652777777777778, 0.9856150793650794, 0.9573412698412699, 0.90625, 0.9533730158730159, 0.9875992063492064, 0.9781746031746031, 0.9627976190476191, 0.9871031746031746, 0.9955357142857143, 0.9985119047619048, 0.9880952380952381, 0.9479166666666666, 0.9801587301587301, 0.9513888888888888, 0.9935515873015873, 0.8928571428571429, 0.9935515873015873, 0.9910714285714286, 0.9920634920634921, 0.9742063492063492, 0.9945436507936508, 0.9866071428571429, 0.9910714285714286, 0.9965277777777778, 0.9538690476190477, 0.9126984126984127, 0.9970238095238095, 0.9955357142857143, 0.9925595238095238, 0.9399801587301587, 0.9970238095238095, 0.9608134920634921, 0.904265873015873, 0.9915674603174603, 0.9945436507936508, 0.9990079365079365, 0.9885912698412699, 0.9657738095238095, 0.9945436507936508, 0.9861111111111112, 0.9871031746031746, 0.9955357142857143, 0.9925595238095238, 0.9975198412698413, 0.7976190476190477, 0.9995039682539683, 0.9920634920634921, 0.9905753968253969, 0.9945436507936508, 0.9920634920634921, 0.9880952380952381, 0.9990079365079365, 0.9851190476190477, 0.9965277777777778, 0.9439484126984127, 0.9990079365079365, 0.9766865079365079, 0.9925595238095238, 0.7886904761904762, 0.9915674603174603, 0.9836309523809523, 0.9940476190476191, 0.9940476190476191, 0.9821428571428571, 0.9880952380952381, 0.9935515873015873, 0.9895833333333334, 0.9841269841269841, 0.9856150793650794, 0.9940476190476191, 0.9945436507936508, 0.9821428571428571, 0.9900793650793651, 0.9831349206349206, 0.970734126984127, 0.9965277777777778, 0.9831349206349206, 0.9945436507936508, 0.9930555555555556, 0.9836309523809523, 0.9970238095238095, 0.9866071428571429, 0.9742063492063492, 0.9632936507936508, 0.9940476190476191, 0.9915674603174603, 0.9920634920634921, 0.9890873015873016, 0.9970238095238095, 0.9866071428571429, 0.9965277777777778, 0.9945436507936508, 0.9875992063492064, 0.9801587301587301, 0.9494047619047619, 0.9875992063492064, 0.9915674603174603, 0.9365079365079365, 0.9940476190476191, 0.9890873015873016, 0.9920634920634921, 0.9935515873015873, 0.9965277777777778, 0.9985119047619048, 0.9627976190476191, 0.9970238095238095, 0.9930555555555556, 0.964781746031746, 0.9935515873015873, 0.9950396825396826, 0.9890873015873016, 0.9851190476190477, 0.9950396825396826, 0.9950396825396826, 0.9588293650793651, 0.9915674603174603, 0.9915674603174603, 0.9950396825396826, 0.9945436507936508, 0.9900793650793651, 0.9717261904761905, 0.9945436507936508, 0.9990079365079365, 0.9965277777777778, 0.9905753968253969, 0.9945436507936508, 0.9910714285714286, 0.9955357142857143, 0.9781746031746031, 0.9930555555555556, 0.9702380952380952, 0.9464285714285714, 0.9965277777777778, 0.9722222222222222, 0.9608134920634921, 0.9618055555555556, 0.9915674603174603, 0.9905753968253969, 0.9925595238095238, 0.9866071428571429, 0.9603174603174603, 0.9905753968253969, 0.9846230158730159, 0.9920634920634921, 0.9970238095238095, 0.9935515873015873, 0.9965277777777778, 0.9226190476190477, 0.9950396825396826, 0.9915674603174603, 0.9955357142857143, 0.9955357142857143, 0.9955357142857143, 0.9791666666666666, 0.9925595238095238, 0.9826388888888888, 0.9856150793650794, 0.996031746031746, 0.9955357142857143, 0.9965277777777778, 0.9905753968253969, 0.9985119047619048, 0.9469246031746031, 0.9771825396825397, 0.9945436507936508, 0.9985119047619048, 0.9970238095238095, 0.9950396825396826, 0.9568452380952381

