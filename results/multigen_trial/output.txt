Beginning trial described in ./config/multigen_trial.json.
Experiment type: multiple generators each corresponding to 1 key.
Experiment settings:
	byte: 0
	keys: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
	key_dataset_kwargs:
		keep_data_in_memory: True
		data_path: ./data
		download: True
		extract: True
		preprocess: True
		delete_download_after_extraction: False
		delete_extracted_after_preprocess: False
		samples_to_use: 500
	dataloader_kwargs:
		batch_size: 16
		shuffle: True
	dataset_prop_for_validation: 0.2
	trace_map_constructor: None
	trace_map_kwargs:
		layers: [256]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	plaintext_map_constructor: None
	plaintext_map_kwargs:
		layers: [64]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	key_map_constructor: <function get_zero_map at 0x7fa0887473a0>
	key_map_kwargs:
	cumulative_map_constructor: None
	cumulative_map_kwargs:
		layers: [256]
		hidden_activation: <class 'torch.nn.modules.activation.ReLU'>
	discriminator_constructor: <function get_xdeepsca_discriminator at 0x7fa08529c8b0>
	discriminator_kwargs:
	discriminator_loss_constructor: <class 'torch.nn.modules.loss.CrossEntropyLoss'>
	discriminator_loss_kwargs:
	discriminator_optimizer_constructor: <class 'torch.optim.sgd.SGD'>
	discriminator_optimizer_kwargs:
		lr: 0.01
	generator_loss_constructor: <class 'loss_functions.BatchStdLoss'>
	generator_loss_kwargs:
	generator_optimizer_constructor: <class 'torch.optim.adam.Adam'>
	generator_optimizer_kwargs:
	device: cuda
	discriminator_pretraining_epochs: 0
	generator_pretraining_epochs: 0
	gan_training_epochs: 500
	discriminator_posttraining_epochs: 500
	seed: 0
Loading datasets.
AesKeyGroupDataset:
	Available keys: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
	Key transform: Compose(
    IntToBinary()
    ToTensor1D()
)
	Byte: 0
	Number of samples available: 10112
	Trace size: torch.Size([1, 500])
	Key size: torch.Size([1, 8])
	Plaintext size: torch.Size([1, 8])
	Key index size: ()
Constructing generator.
KeyOnlyGenerator(
  (key_trace_map): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=8, out_features=8, bias=False)
    (2): Linear(in_features=8, out_features=500, bias=False)
    (3): Unflatten(dim=-1, unflattened_size=torch.Size([1, 500]))
  )
)

Constructing discriminator.
Discriminator(
  (model): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=500, out_features=200, bias=True)
    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): ReLU()
    (4): Dropout(p=0.1, inplace=False)
    (5): Linear(in_features=200, out_features=200, bias=True)
    (6): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): ReLU()
    (8): Dropout(p=0.05, inplace=False)
    (9): Linear(in_features=200, out_features=256, bias=True)
  )
)

Calculating initial results.
Training results:
gen_loss: 0.017465893
disc_loss: 5.549591
disc_acc: 0.0

Validation results:
gen_loss: 0.016667297
disc_loss: 5.5523176
disc_acc: 0.0


Training discriminator and generator simultaneously.
	Epoch 1
Training results:
gen_loss: 1.6347638
disc_loss: 2.2822452
disc_acc: 0.453960396039604

Validation results:
gen_loss: 1.6154588
disc_loss: 1.3329345
disc_acc: 0.5054563492063492


	Epoch 2
Training results:
gen_loss: 1.9479733
disc_loss: 0.7395443
disc_acc: 0.8139851485148515

Validation results:
gen_loss: 1.6724025
disc_loss: 0.9704568
disc_acc: 0.6195436507936508


	Epoch 3
Training results:
gen_loss: 2.0768757
disc_loss: 0.4472633
disc_acc: 0.8909653465346534

Validation results:
gen_loss: 1.8845459
disc_loss: 0.73838574
disc_acc: 0.658234126984127


	Epoch 4
Training results:
gen_loss: 2.156952
disc_loss: 0.33755666
disc_acc: 0.9131188118811882

Validation results:
gen_loss: 1.8187927
disc_loss: 0.33885437
disc_acc: 0.9211309523809523


	Epoch 5
Training results:
gen_loss: 2.217312
disc_loss: 0.29300857
disc_acc: 0.9231435643564356

Validation results:
gen_loss: 1.6423507
disc_loss: 0.3922195
disc_acc: 0.9186507936507936


	Epoch 6
Training results:
gen_loss: 2.2676501
disc_loss: 0.24800177
disc_acc: 0.9324257425742575

Validation results:
gen_loss: 1.7629352
disc_loss: 0.817931
disc_acc: 0.6800595238095238


	Epoch 7
Training results:
gen_loss: 2.308558
disc_loss: 0.221308
disc_acc: 0.9415841584158415

Validation results:
gen_loss: 2.1016355
disc_loss: 2.0229585
disc_acc: 0.5059523809523809


	Epoch 8
Training results:
gen_loss: 2.3314872
disc_loss: 0.2180936
disc_acc: 0.9377475247524752

Validation results:
gen_loss: 1.9267058
disc_loss: 1.4305516
disc_acc: 0.5228174603174603


	Epoch 9
Training results:
gen_loss: 2.3593879
disc_loss: 0.19598812
disc_acc: 0.9475247524752475

Validation results:
gen_loss: 2.0439382
disc_loss: 0.8022578
disc_acc: 0.6964285714285714


	Epoch 10
Training results:
gen_loss: 2.373747
disc_loss: 0.18240507
disc_acc: 0.9508663366336634

Validation results:
gen_loss: 2.050364
disc_loss: 0.22715999
disc_acc: 0.9404761904761905


	Epoch 11
Training results:
gen_loss: 2.4000354
disc_loss: 0.1768146
disc_acc: 0.9492574257425742

Validation results:
gen_loss: 1.909387
disc_loss: 0.24782456
disc_acc: 0.9146825396825397


	Epoch 12
Training results:
gen_loss: 2.4126134
disc_loss: 0.16307388
disc_acc: 0.9534653465346534

Validation results:
gen_loss: 2.0618308
disc_loss: 0.10581834
disc_acc: 0.9786706349206349


	Epoch 13
Training results:
gen_loss: 2.4284458
disc_loss: 0.14852136
disc_acc: 0.9579207920792079

Validation results:
gen_loss: 2.0241745
disc_loss: 0.36021054
disc_acc: 0.8601190476190477


	Epoch 14
Training results:
gen_loss: 2.4481063
disc_loss: 0.12734367
disc_acc: 0.9641089108910891

Validation results:
gen_loss: 2.2588933
disc_loss: 0.06355046
disc_acc: 0.9875992063492064


	Epoch 15
Training results:
gen_loss: 2.4755049
disc_loss: 0.13006002
disc_acc: 0.9631188118811881

Validation results:
gen_loss: 1.776761
disc_loss: 3.1081634
disc_acc: 0.2748015873015873


	Epoch 16
Training results:
gen_loss: 2.4777532
disc_loss: 0.13549182
disc_acc: 0.9596534653465346

Validation results:
gen_loss: 2.1275544
disc_loss: 0.6265331
disc_acc: 0.7564484126984127


	Epoch 17
Training results:
gen_loss: 2.495575
disc_loss: 0.13169281
disc_acc: 0.9617574257425743

Validation results:
gen_loss: 2.1585155
disc_loss: 0.42104235
disc_acc: 0.8224206349206349


	Epoch 18
Training results:
gen_loss: 2.5140407
disc_loss: 0.10758883
disc_acc: 0.969059405940594

Validation results:
gen_loss: 2.1388557
disc_loss: 0.123530455
disc_acc: 0.9613095238095238


	Epoch 19
Training results:
gen_loss: 2.5255888
disc_loss: 0.11768438
disc_acc: 0.9665841584158416

Validation results:
gen_loss: 2.3893313
disc_loss: 0.100802384
disc_acc: 0.9662698412698413


	Epoch 20
Training results:
gen_loss: 2.5379882
disc_loss: 0.103285834
disc_acc: 0.970049504950495

Validation results:
gen_loss: 2.1528614
disc_loss: 0.35577193
disc_acc: 0.8779761904761905


	Epoch 21
Training results:
gen_loss: 2.5474706
disc_loss: 0.114677176
disc_acc: 0.967450495049505

Validation results:
gen_loss: 2.126781
disc_loss: 0.44454652
disc_acc: 0.8358134920634921


	Epoch 22
Training results:
gen_loss: 2.5500252
disc_loss: 0.10147144
disc_acc: 0.9716584158415842

Validation results:
gen_loss: 2.3570502
disc_loss: 0.38527375
disc_acc: 0.8779761904761905


	Epoch 23
Training results:
gen_loss: 2.567492
disc_loss: 0.09229551
disc_acc: 0.9731435643564357

Validation results:
gen_loss: 2.2690313
disc_loss: 0.29052928
disc_acc: 0.8754960317460317


	Epoch 24
Training results:
gen_loss: 2.5759737
disc_loss: 0.09303664
disc_acc: 0.9727722772277227

Validation results:
gen_loss: 2.2644458
disc_loss: 0.64726603
disc_acc: 0.7008928571428571


	Epoch 25
Training results:
gen_loss: 2.5747774
disc_loss: 0.09988097
disc_acc: 0.9691831683168317

Validation results:
gen_loss: 2.291135
disc_loss: 0.6103793
disc_acc: 0.8025793650793651


	Epoch 26
Training results:
gen_loss: 2.5866075
disc_loss: 0.08929931
disc_acc: 0.9711633663366337

Validation results:
gen_loss: 2.202854
disc_loss: 0.12491271
disc_acc: 0.9553571428571429


	Epoch 27
Training results:
gen_loss: 2.5981262
disc_loss: 0.0929006
disc_acc: 0.9709158415841584

Validation results:
gen_loss: 2.1732657
disc_loss: 0.7510843
disc_acc: 0.7797619047619048


	Epoch 28
Training results:
gen_loss: 2.6024232
disc_loss: 0.0823527
disc_acc: 0.9753712871287129

Validation results:
gen_loss: 1.8481793
disc_loss: 0.84660673
disc_acc: 0.6755952380952381


	Epoch 29
Training results:
gen_loss: 2.6016521
disc_loss: 0.08600796
disc_acc: 0.9747524752475247

Validation results:
gen_loss: 2.3280137
disc_loss: 0.07188285
disc_acc: 0.9747023809523809


	Epoch 30
Training results:
gen_loss: 2.618357
disc_loss: 0.07256032
disc_acc: 0.9764851485148515

Validation results:
gen_loss: 2.2919066
disc_loss: 0.22645624
disc_acc: 0.9087301587301587


	Epoch 31
Training results:
gen_loss: 2.6310465
disc_loss: 0.0809616
disc_acc: 0.975

Validation results:
gen_loss: 2.3222039
disc_loss: 0.06353553
disc_acc: 0.9786706349206349


	Epoch 32
Training results:
gen_loss: 2.627496
disc_loss: 0.07920754
disc_acc: 0.9745049504950495

Validation results:
gen_loss: 2.049247
disc_loss: 0.91817635
disc_acc: 0.7123015873015873


	Epoch 33
Training results:
gen_loss: 2.6426651
disc_loss: 0.07909089
disc_acc: 0.9758663366336634

Validation results:
gen_loss: 2.4956174
disc_loss: 0.077233545
disc_acc: 0.9846230158730159


	Epoch 34
Training results:
gen_loss: 2.6304667
disc_loss: 0.07343979
disc_acc: 0.9762376237623762

Validation results:
gen_loss: 2.1726847
disc_loss: 0.20085354
disc_acc: 0.9206349206349206


	Epoch 35
Training results:
gen_loss: 2.6514106
disc_loss: 0.06894723
disc_acc: 0.9783415841584159

Validation results:
gen_loss: 2.3074944
disc_loss: 0.03196236
disc_acc: 0.9920634920634921


	Epoch 36
Training results:
gen_loss: 2.6587195
disc_loss: 0.08045499
disc_acc: 0.9748762376237624

Validation results:
gen_loss: 2.360116
disc_loss: 0.17398018
disc_acc: 0.9449404761904762


	Epoch 37
Training results:
gen_loss: 2.6668339
disc_loss: 0.073248155
disc_acc: 0.9754950495049505

Validation results:
gen_loss: 2.3651848
disc_loss: 0.35616466
disc_acc: 0.8616071428571429


	Epoch 38
Training results:
gen_loss: 2.6781085
disc_loss: 0.06559778
disc_acc: 0.9810643564356436

Validation results:
gen_loss: 2.3287241
disc_loss: 0.033226807
disc_acc: 0.9905753968253969


	Epoch 39
Training results:
gen_loss: 2.698086
disc_loss: 0.068991326
disc_acc: 0.9777227722772277

Validation results:
gen_loss: 2.213091
disc_loss: 0.077114776
disc_acc: 0.9771825396825397


	Epoch 40
Training results:
gen_loss: 2.7086053
disc_loss: 0.07748681
disc_acc: 0.975990099009901

Validation results:
gen_loss: 2.146371
disc_loss: 0.5060598
disc_acc: 0.8447420634920635


	Epoch 41
Training results:
gen_loss: 2.7024956
disc_loss: 0.06880383
disc_acc: 0.9788366336633664

Validation results:
gen_loss: 2.249094
disc_loss: 1.1463779
disc_acc: 0.7286706349206349


	Epoch 42
Training results:
gen_loss: 2.708086
disc_loss: 0.06894822
disc_acc: 0.9785891089108911

Validation results:
gen_loss: 2.2144923
disc_loss: 0.07224146
disc_acc: 0.9781746031746031


	Epoch 43
Training results:
gen_loss: 2.7073495
disc_loss: 0.064830445
disc_acc: 0.9795792079207921

Validation results:
gen_loss: 2.4100254
disc_loss: 0.037262328
disc_acc: 0.9885912698412699


	Epoch 44
Training results:
gen_loss: 2.7148495
disc_loss: 0.065032706
disc_acc: 0.9795792079207921

Validation results:
gen_loss: 2.2415545
disc_loss: 0.119709834
disc_acc: 0.9618055555555556


	Epoch 45
Training results:
gen_loss: 2.704181
disc_loss: 0.056552358
disc_acc: 0.9834158415841584

Validation results:
gen_loss: 2.099516
disc_loss: 0.39519367
disc_acc: 0.8680555555555556


	Epoch 46
Training results:
gen_loss: 2.7193356
disc_loss: 0.062179614
disc_acc: 0.9797029702970297

Validation results:
gen_loss: 2.268545
disc_loss: 0.06640705
disc_acc: 0.9801587301587301


	Epoch 47
Training results:
gen_loss: 2.7151928
disc_loss: 0.061521877
disc_acc: 0.9800742574257426

Validation results:
gen_loss: 2.2917335
disc_loss: 0.04078181
disc_acc: 0.9905753968253969


	Epoch 48
Training results:
gen_loss: 2.734951
disc_loss: 0.058506086
disc_acc: 0.9819306930693069

Validation results:
gen_loss: 2.4949236
disc_loss: 0.036788784
disc_acc: 0.9915674603174603


	Epoch 49
Training results:
gen_loss: 2.72306
disc_loss: 0.058129624
disc_acc: 0.9816831683168317

Validation results:
gen_loss: 2.3994076
disc_loss: 0.14140159
disc_acc: 0.9404761904761905


	Epoch 50
Training results:
gen_loss: 2.7300892
disc_loss: 0.063320115
disc_acc: 0.9800742574257426

Validation results:
gen_loss: 2.3179917
disc_loss: 0.025370369
disc_acc: 0.9940476190476191


	Epoch 51
Training results:
gen_loss: 2.7419014
disc_loss: 0.052808743
disc_acc: 0.9837871287128713

Validation results:
gen_loss: 2.3620403
disc_loss: 0.07002374
disc_acc: 0.9756944444444444


	Epoch 52
Training results:
gen_loss: 2.7476811
disc_loss: 0.062318135
disc_acc: 0.9780940594059406

Validation results:
gen_loss: 2.5041418
disc_loss: 0.029025551
disc_acc: 0.9880952380952381


	Epoch 53
Training results:
gen_loss: 2.747555
disc_loss: 0.057082094
disc_acc: 0.9810643564356436

Validation results:
gen_loss: 2.3938785
disc_loss: 0.029639836
disc_acc: 0.9935515873015873


	Epoch 54
Training results:
gen_loss: 2.7425697
disc_loss: 0.06072923
disc_acc: 0.9809405940594059

Validation results:
gen_loss: 2.3789892
disc_loss: 0.31564108
disc_acc: 0.8665674603174603


	Epoch 55
Training results:
gen_loss: 2.7550743
disc_loss: 0.053519998
disc_acc: 0.9829207920792079

Validation results:
gen_loss: 2.4160657
disc_loss: 0.11074137
disc_acc: 0.9652777777777778


	Epoch 56
Training results:
gen_loss: 2.7640524
disc_loss: 0.05274349
disc_acc: 0.9814356435643564

Validation results:
gen_loss: 2.3210082
disc_loss: 0.082796045
disc_acc: 0.9712301587301587


	Epoch 57
Training results:
gen_loss: 2.7687135
disc_loss: 0.056180686
disc_acc: 0.9814356435643564

Validation results:
gen_loss: 2.3361723
disc_loss: 0.75760347
disc_acc: 0.7837301587301587


	Epoch 58
Training results:
gen_loss: 2.768176
disc_loss: 0.049527414
disc_acc: 0.9831683168316832

Validation results:
gen_loss: 2.4420936
disc_loss: 0.06287701
disc_acc: 0.9776785714285714


	Epoch 59
Training results:
gen_loss: 2.7810144
disc_loss: 0.051461894
disc_acc: 0.9819306930693069

Validation results:
gen_loss: 2.5334787
disc_loss: 0.015577922
disc_acc: 0.9955357142857143


	Epoch 60
Training results:
gen_loss: 2.7705402
disc_loss: 0.049624134
disc_acc: 0.9835396039603961

Validation results:
gen_loss: 2.426588
disc_loss: 0.02776497
disc_acc: 0.9920634920634921


	Epoch 61
Training results:
gen_loss: 2.7711656
disc_loss: 0.047438025
disc_acc: 0.9824257425742574

Validation results:
gen_loss: 2.561505
disc_loss: 0.15768985
disc_acc: 0.9499007936507936


	Epoch 62
Training results:
gen_loss: 2.7765133
disc_loss: 0.05220827
disc_acc: 0.9805693069306931

Validation results:
gen_loss: 2.4117317
disc_loss: 0.1743506
disc_acc: 0.9206349206349206


	Epoch 63
Training results:
gen_loss: 2.7894318
disc_loss: 0.048244037
disc_acc: 0.9845297029702971

Validation results:
gen_loss: 2.5514712
disc_loss: 0.043130573
disc_acc: 0.9851190476190477


	Epoch 64
Training results:
gen_loss: 2.795497
disc_loss: 0.04779005
disc_acc: 0.9836633663366336

Validation results:
gen_loss: 2.256495
disc_loss: 0.13985078
disc_acc: 0.9533730158730159


	Epoch 65
Training results:
gen_loss: 2.7993276
disc_loss: 0.043108504
disc_acc: 0.986509900990099

Validation results:
gen_loss: 2.0790198
disc_loss: 0.3668654
disc_acc: 0.8640873015873016


	Epoch 66
Training results:
gen_loss: 2.8076491
disc_loss: 0.047858316
disc_acc: 0.9845297029702971

Validation results:
gen_loss: 2.4677112
disc_loss: 0.104482375
disc_acc: 0.9593253968253969


	Epoch 67
Training results:
gen_loss: 2.8013656
disc_loss: 0.045506015
disc_acc: 0.9867574257425743

Validation results:
gen_loss: 2.421521
disc_loss: 0.055113073
disc_acc: 0.9781746031746031


	Epoch 68
Training results:
gen_loss: 2.7993166
disc_loss: 0.04609842
disc_acc: 0.9863861386138614

Validation results:
gen_loss: 2.6520991
disc_loss: 0.113721356
disc_acc: 0.9553571428571429


	Epoch 69
Training results:
gen_loss: 2.80679
disc_loss: 0.049444377
disc_acc: 0.9831683168316832

Validation results:
gen_loss: 2.4749427
disc_loss: 0.27748117
disc_acc: 0.8784722222222222


	Epoch 70
Training results:
gen_loss: 2.8076384
disc_loss: 0.04851825
disc_acc: 0.9840346534653466

Validation results:
gen_loss: 2.4302473
disc_loss: 0.065127715
disc_acc: 0.9836309523809523


	Epoch 71
Training results:
gen_loss: 2.820375
disc_loss: 0.03984587
disc_acc: 0.9873762376237624

Validation results:
gen_loss: 2.4578376
disc_loss: 0.024880236
disc_acc: 0.9925595238095238


	Epoch 72
Training results:
gen_loss: 2.8196516
disc_loss: 0.04132521
disc_acc: 0.9857673267326733

Validation results:
gen_loss: 2.467517
disc_loss: 0.030668268
disc_acc: 0.9925595238095238


	Epoch 73
Training results:
gen_loss: 2.830952
disc_loss: 0.04510196
disc_acc: 0.9846534653465346

Validation results:
gen_loss: 2.49949
disc_loss: 0.035783906
disc_acc: 0.9875992063492064


	Epoch 74
Training results:
gen_loss: 2.8329449
disc_loss: 0.047202874
disc_acc: 0.9849009900990099

Validation results:
gen_loss: 2.3951848
disc_loss: 0.09229688
disc_acc: 0.9662698412698413


	Epoch 75
Training results:
gen_loss: 2.8449636
disc_loss: 0.050035518
disc_acc: 0.9829207920792079

Validation results:
gen_loss: 2.5364857
disc_loss: 0.24222274
disc_acc: 0.9047619047619048


	Epoch 76
Training results:
gen_loss: 2.8395536
disc_loss: 0.040481273
disc_acc: 0.9875

Validation results:
gen_loss: 2.53586
disc_loss: 0.018467158
disc_acc: 0.9935515873015873


	Epoch 77
Training results:
gen_loss: 2.833643
disc_loss: 0.042530816
disc_acc: 0.9866336633663366

Validation results:
gen_loss: 2.6246054
disc_loss: 0.018718552
disc_acc: 0.9940476190476191


	Epoch 78
Training results:
gen_loss: 2.835177
disc_loss: 0.04729986
disc_acc: 0.9829207920792079

Validation results:
gen_loss: 2.695914
disc_loss: 0.14913042
disc_acc: 0.9563492063492064


	Epoch 79
Training results:
gen_loss: 2.8389106
disc_loss: 0.041365966
disc_acc: 0.986509900990099

Validation results:
gen_loss: 2.5879114
disc_loss: 0.045417234
disc_acc: 0.9851190476190477


	Epoch 80
Training results:
gen_loss: 2.8478053
disc_loss: 0.041608628
disc_acc: 0.9870049504950495

Validation results:
gen_loss: 2.4682047
disc_loss: 0.14462179
disc_acc: 0.9379960317460317


	Epoch 81
Training results:
gen_loss: 2.8454814
disc_loss: 0.040109895
disc_acc: 0.9867574257425743

Validation results:
gen_loss: 2.2535822
disc_loss: 0.7140615
disc_acc: 0.7137896825396826


	Epoch 82
Training results:
gen_loss: 2.8444476
disc_loss: 0.040381152
disc_acc: 0.9862623762376238

Validation results:
gen_loss: 2.4580975
disc_loss: 0.049078792
disc_acc: 0.9846230158730159


	Epoch 83
Training results:
gen_loss: 2.854832
disc_loss: 0.03850381
disc_acc: 0.9870049504950495

Validation results:
gen_loss: 2.5425591
disc_loss: 0.12822305
disc_acc: 0.9623015873015873


	Epoch 84
Training results:
gen_loss: 2.8730114
disc_loss: 0.033932954
disc_acc: 0.9886138613861386

Validation results:
gen_loss: 2.4531074
disc_loss: 0.35009196
disc_acc: 0.8511904761904762


	Epoch 85
Training results:
gen_loss: 2.8664365
disc_loss: 0.040512774
disc_acc: 0.9866336633663366

Validation results:
gen_loss: 2.5660899
disc_loss: 0.02797004
disc_acc: 0.9895833333333334


	Epoch 86
Training results:
gen_loss: 2.8665574
disc_loss: 0.04030952
disc_acc: 0.9857673267326733

Validation results:
gen_loss: 2.6744123
disc_loss: 0.05475673
disc_acc: 0.9806547619047619


	Epoch 87
Training results:
gen_loss: 2.8751454
disc_loss: 0.035799664
disc_acc: 0.9883663366336634

Validation results:
gen_loss: 2.3377588
disc_loss: 0.2133187
disc_acc: 0.9141865079365079


	Epoch 88
Training results:
gen_loss: 2.8752997
disc_loss: 0.044045273
disc_acc: 0.9851485148514851

Validation results:
gen_loss: 2.4757342
disc_loss: 0.056669336
disc_acc: 0.9821428571428571


	Epoch 89
Training results:
gen_loss: 2.8821754
disc_loss: 0.03965733
disc_acc: 0.986509900990099

Validation results:
gen_loss: 2.5360467
disc_loss: 0.037462562
disc_acc: 0.9900793650793651


	Epoch 90
Training results:
gen_loss: 2.884753
disc_loss: 0.040883757
disc_acc: 0.9868811881188119

Validation results:
gen_loss: 2.5506244
disc_loss: 0.064227544
disc_acc: 0.9806547619047619


	Epoch 91
Training results:
gen_loss: 2.8766959
disc_loss: 0.03823264
disc_acc: 0.9875

Validation results:
gen_loss: 2.3534327
disc_loss: 0.07666936
disc_acc: 0.9766865079365079


	Epoch 92
Training results:
gen_loss: 2.8834264
disc_loss: 0.033044163
disc_acc: 0.9877475247524753

Validation results:
gen_loss: 2.5383172
disc_loss: 0.03225076
disc_acc: 0.9885912698412699


	Epoch 93
Training results:
gen_loss: 2.8900774
disc_loss: 0.038403142
disc_acc: 0.9886138613861386

Validation results:
gen_loss: 2.5340505
disc_loss: 0.07123745
disc_acc: 0.9786706349206349


	Epoch 94
Training results:
gen_loss: 2.8796687
disc_loss: 0.036413956
disc_acc: 0.9875

Validation results:
gen_loss: 2.574745
disc_loss: 0.018933654
disc_acc: 0.9940476190476191


	Epoch 95
Training results:
gen_loss: 2.8840652
disc_loss: 0.035692994
disc_acc: 0.9873762376237624

Validation results:
gen_loss: 2.6482933
disc_loss: 0.037320554
disc_acc: 0.9875992063492064


	Epoch 96
Training results:
gen_loss: 2.8906052
disc_loss: 0.03427654
disc_acc: 0.9896039603960396

Validation results:
gen_loss: 2.5710309
disc_loss: 0.060880844
disc_acc: 0.9756944444444444


	Epoch 97
Training results:
gen_loss: 2.908801
disc_loss: 0.028384013
disc_acc: 0.9908415841584158

Validation results:
gen_loss: 2.503264
disc_loss: 0.013258977
disc_acc: 0.998015873015873


	Epoch 98
Training results:
gen_loss: 2.903699
disc_loss: 0.030664815
disc_acc: 0.989480198019802

Validation results:
gen_loss: 2.6618876
disc_loss: 0.83393455
disc_acc: 0.816468253968254


	Epoch 99
Training results:
gen_loss: 2.9147608
disc_loss: 0.029938014
disc_acc: 0.9887376237623763

Validation results:
gen_loss: 2.608151
disc_loss: 0.014771937
disc_acc: 0.9930555555555556


	Epoch 100
Training results:
gen_loss: 2.91784
disc_loss: 0.036488358
disc_acc: 0.9887376237623763

Validation results:
gen_loss: 2.5979328
disc_loss: 0.011787025
disc_acc: 0.9945436507936508


	Epoch 101
Training results:
gen_loss: 2.9185097
disc_loss: 0.03609922
disc_acc: 0.9881188118811881

Validation results:
gen_loss: 2.4659863
disc_loss: 0.03968511
disc_acc: 0.9851190476190477


	Epoch 102
Training results:
gen_loss: 2.9212198
disc_loss: 0.033909697
disc_acc: 0.9877475247524753

Validation results:
gen_loss: 2.5043688
disc_loss: 0.06496221
disc_acc: 0.9751984126984127


	Epoch 103
Training results:
gen_loss: 2.9201274
disc_loss: 0.035675637
disc_acc: 0.9883663366336634

Validation results:
gen_loss: 2.609094
disc_loss: 0.26597163
disc_acc: 0.9077380952380952


	Epoch 104
Training results:
gen_loss: 2.9210544
disc_loss: 0.033744093
disc_acc: 0.989480198019802

Validation results:
gen_loss: 2.673678
disc_loss: 0.014070201
disc_acc: 0.9955357142857143


	Epoch 105
Training results:
gen_loss: 2.928291
disc_loss: 0.02879995
disc_acc: 0.9913366336633663

Validation results:
gen_loss: 2.40281
disc_loss: 1.2531704
disc_acc: 0.6721230158730159


	Epoch 106
Training results:
gen_loss: 2.9409184
disc_loss: 0.029325351
disc_acc: 0.9905940594059406

Validation results:
gen_loss: 2.65845
disc_loss: 0.0289377
disc_acc: 0.9890873015873016


	Epoch 107
Training results:
gen_loss: 2.9356737
disc_loss: 0.035164583
disc_acc: 0.988490099009901

Validation results:
gen_loss: 2.5083408
disc_loss: 0.016286213
disc_acc: 0.9955357142857143


	Epoch 108
Training results:
gen_loss: 2.9310355
disc_loss: 0.034048248
disc_acc: 0.9893564356435643

Validation results:
gen_loss: 2.6091366
disc_loss: 0.03321228
disc_acc: 0.9890873015873016


	Epoch 109
Training results:
gen_loss: 2.9428325
disc_loss: 0.035399858
disc_acc: 0.9876237623762376

Validation results:
gen_loss: 2.6794367
disc_loss: 0.039930243
disc_acc: 0.9866071428571429


	Epoch 110
Training results:
gen_loss: 2.9398844
disc_loss: 0.027982619
disc_acc: 0.9897277227722773

Validation results:
gen_loss: 2.6108515
disc_loss: 0.017900465
disc_acc: 0.9970238095238095


	Epoch 111
Training results:
gen_loss: 2.9562821
disc_loss: 0.031189943
disc_acc: 0.9900990099009901

Validation results:
gen_loss: 2.5337844
disc_loss: 0.013413167
disc_acc: 0.9970238095238095


	Epoch 112
Training results:
gen_loss: 2.9500084
disc_loss: 0.028336067
disc_acc: 0.9905940594059406

Validation results:
gen_loss: 2.5988147
disc_loss: 0.01479272
disc_acc: 0.9945436507936508


	Epoch 113
Training results:
gen_loss: 2.9432073
disc_loss: 0.032194033
disc_acc: 0.9892326732673268

Validation results:
gen_loss: 2.552339
disc_loss: 0.17784742
disc_acc: 0.9320436507936508


	Epoch 114
Training results:
gen_loss: 2.9615345
disc_loss: 0.0340703
disc_acc: 0.9875

Validation results:
gen_loss: 2.5590324
disc_loss: 0.04863317
disc_acc: 0.9910714285714286


	Epoch 115
Training results:
gen_loss: 2.9555688
disc_loss: 0.030803647
disc_acc: 0.9908415841584158

Validation results:
gen_loss: 2.580042
disc_loss: 0.14525625
disc_acc: 0.9404761904761905


	Epoch 116
Training results:
gen_loss: 2.9504254
disc_loss: 0.03176279
disc_acc: 0.9883663366336634

Validation results:
gen_loss: 2.7294335
disc_loss: 0.015345965
disc_acc: 0.9940476190476191


	Epoch 117
Training results:
gen_loss: 2.9586148
disc_loss: 0.025709985
disc_acc: 0.9918316831683168

Validation results:
gen_loss: 2.7201107
disc_loss: 1.5480784
disc_acc: 0.7271825396825397


	Epoch 118
Training results:
gen_loss: 2.9623473
disc_loss: 0.035419274
disc_acc: 0.9877475247524753

Validation results:
gen_loss: 2.6268454
disc_loss: 0.06861708
disc_acc: 0.9771825396825397


	Epoch 119
Training results:
gen_loss: 2.969494
disc_loss: 0.027298752
disc_acc: 0.9923267326732673

Validation results:
gen_loss: 2.5753865
disc_loss: 0.009246305
disc_acc: 0.998015873015873


	Epoch 120
Training results:
gen_loss: 2.961171
disc_loss: 0.030365698
disc_acc: 0.9907178217821783

Validation results:
gen_loss: 2.4016724
disc_loss: 0.14440985
disc_acc: 0.9474206349206349


	Epoch 121
Training results:
gen_loss: 2.9674113
disc_loss: 0.030524664
disc_acc: 0.9907178217821783

Validation results:
gen_loss: 2.491059
disc_loss: 0.5771224
disc_acc: 0.7936507936507936


	Epoch 122
Training results:
gen_loss: 2.9815404
disc_loss: 0.024810402
disc_acc: 0.9930693069306931

Validation results:
gen_loss: 2.7187333
disc_loss: 0.013153699
disc_acc: 0.9945436507936508


	Epoch 123
Training results:
gen_loss: 2.9769082
disc_loss: 0.026848486
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 2.4786813
disc_loss: 0.047530103
disc_acc: 0.9861111111111112


	Epoch 124
Training results:
gen_loss: 2.9814825
disc_loss: 0.024531672
disc_acc: 0.9915841584158416

Validation results:
gen_loss: 2.588105
disc_loss: 0.06923871
disc_acc: 0.9766865079365079


	Epoch 125
Training results:
gen_loss: 2.982799
disc_loss: 0.033254303
disc_acc: 0.9892326732673268

Validation results:
gen_loss: 2.677323
disc_loss: 0.020012314
disc_acc: 0.9910714285714286


	Epoch 126
Training results:
gen_loss: 2.9763885
disc_loss: 0.03106568
disc_acc: 0.9896039603960396

Validation results:
gen_loss: 2.5288396
disc_loss: 0.018662496
disc_acc: 0.9955357142857143


	Epoch 127
Training results:
gen_loss: 2.9861033
disc_loss: 0.025708906
disc_acc: 0.992450495049505

Validation results:
gen_loss: 2.6497953
disc_loss: 0.007480527
disc_acc: 0.9985119047619048


	Epoch 128
Training results:
gen_loss: 2.9820392
disc_loss: 0.028787749
disc_acc: 0.9907178217821783

Validation results:
gen_loss: 2.6864572
disc_loss: 0.011443897
disc_acc: 0.9970238095238095


	Epoch 129
Training results:
gen_loss: 2.9911056
disc_loss: 0.033198018
disc_acc: 0.9886138613861386

Validation results:
gen_loss: 2.7451644
disc_loss: 0.10913836
disc_acc: 0.9583333333333334


	Epoch 130
Training results:
gen_loss: 2.9996424
disc_loss: 0.021130629
disc_acc: 0.9939356435643565

Validation results:
gen_loss: 2.7651713
disc_loss: 0.01069234
disc_acc: 0.996031746031746


	Epoch 131
Training results:
gen_loss: 2.9868417
disc_loss: 0.032451995
disc_acc: 0.9900990099009901

Validation results:
gen_loss: 2.532773
disc_loss: 0.014916977
disc_acc: 0.996031746031746


	Epoch 132
Training results:
gen_loss: 2.9862933
disc_loss: 0.0296326
disc_acc: 0.9910891089108911

Validation results:
gen_loss: 2.723975
disc_loss: 1.8153951
disc_acc: 0.6865079365079365


	Epoch 133
Training results:
gen_loss: 2.9989994
disc_loss: 0.032052767
disc_acc: 0.9893564356435643

Validation results:
gen_loss: 2.572498
disc_loss: 0.089559995
disc_acc: 0.9652777777777778


	Epoch 134
Training results:
gen_loss: 2.995482
disc_loss: 0.026883716
disc_acc: 0.9923267326732673

Validation results:
gen_loss: 2.4811509
disc_loss: 0.19147521
disc_acc: 0.9275793650793651


	Epoch 135
Training results:
gen_loss: 2.980237
disc_loss: 0.033801053
disc_acc: 0.9909653465346535

Validation results:
gen_loss: 2.587794
disc_loss: 0.050150014
disc_acc: 0.9856150793650794


	Epoch 136
Training results:
gen_loss: 2.9862018
disc_loss: 0.029313093
disc_acc: 0.9907178217821783

Validation results:
gen_loss: 2.5421576
disc_loss: 0.010565442
disc_acc: 0.9975198412698413


	Epoch 137
Training results:
gen_loss: 2.9944549
disc_loss: 0.03271862
disc_acc: 0.989480198019802

Validation results:
gen_loss: 2.6098723
disc_loss: 0.0121451905
disc_acc: 0.996031746031746


	Epoch 138
Training results:
gen_loss: 3.0103014
disc_loss: 0.021527663
disc_acc: 0.994059405940594

Validation results:
gen_loss: 2.5586858
disc_loss: 0.013572788
disc_acc: 0.996031746031746


	Epoch 139
Training results:
gen_loss: 3.0093172
disc_loss: 0.027254654
disc_acc: 0.990470297029703

Validation results:
gen_loss: 2.713769
disc_loss: 0.10254029
disc_acc: 0.9627976190476191


	Epoch 140
Training results:
gen_loss: 3.0126958
disc_loss: 0.023526048
disc_acc: 0.9922029702970298

Validation results:
gen_loss: 2.7115574
disc_loss: 0.01015245
disc_acc: 0.9965277777777778


	Epoch 141
Training results:
gen_loss: 3.0201476
disc_loss: 0.02956692
disc_acc: 0.9902227722772278

Validation results:
gen_loss: 2.757405
disc_loss: 0.012867278
disc_acc: 0.9975198412698413


	Epoch 142
Training results:
gen_loss: 3.0168743
disc_loss: 0.027529137
disc_acc: 0.9912128712871288

Validation results:
gen_loss: 2.6769652
disc_loss: 0.011768577
disc_acc: 0.9955357142857143


	Epoch 143
Training results:
gen_loss: 3.0059159
disc_loss: 0.032033313
disc_acc: 0.9881188118811881

Validation results:
gen_loss: 2.6392112
disc_loss: 0.011328719
disc_acc: 0.9995039682539683


	Epoch 144
Training results:
gen_loss: 3.0083
disc_loss: 0.025918175
disc_acc: 0.9913366336633663

Validation results:
gen_loss: 2.620197
disc_loss: 0.017608121
disc_acc: 0.9925595238095238


	Epoch 145
Training results:
gen_loss: 3.0189264
disc_loss: 0.02318928
disc_acc: 0.9930693069306931

Validation results:
gen_loss: 2.6408746
disc_loss: 0.012695756
disc_acc: 0.9985119047619048


	Epoch 146
Training results:
gen_loss: 3.0190618
disc_loss: 0.022466905
disc_acc: 0.9925742574257426

Validation results:
gen_loss: 2.690106
disc_loss: 0.0070418925
disc_acc: 0.9990079365079365


	Epoch 147
Training results:
gen_loss: 3.034583
disc_loss: 0.024808755
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 2.5717258
disc_loss: 0.15665123
disc_acc: 0.9404761904761905


	Epoch 148
Training results:
gen_loss: 3.0339248
disc_loss: 0.029949367
disc_acc: 0.989480198019802

Validation results:
gen_loss: 2.5440001
disc_loss: 0.016684284
disc_acc: 0.9935515873015873


	Epoch 149
Training results:
gen_loss: 3.0341177
disc_loss: 0.027408019
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 2.4845955
disc_loss: 0.021756273
disc_acc: 0.9950396825396826


	Epoch 150
Training results:
gen_loss: 3.0377824
disc_loss: 0.024933036
disc_acc: 0.9926980198019802

Validation results:
gen_loss: 2.7076166
disc_loss: 0.013300637
disc_acc: 0.9965277777777778


	Epoch 151
Training results:
gen_loss: 3.0409696
disc_loss: 0.026458887
disc_acc: 0.9912128712871288

Validation results:
gen_loss: 2.586589
disc_loss: 0.018548135
disc_acc: 0.9930555555555556


	Epoch 152
Training results:
gen_loss: 3.0435362
disc_loss: 0.021734871
disc_acc: 0.994059405940594

Validation results:
gen_loss: 2.7180665
disc_loss: 0.67690665
disc_acc: 0.7718253968253969


	Epoch 153
Training results:
gen_loss: 3.0395555
disc_loss: 0.0240221
disc_acc: 0.9920792079207921

Validation results:
gen_loss: 2.711177
disc_loss: 0.006032587
disc_acc: 0.9985119047619048


	Epoch 154
Training results:
gen_loss: 3.03664
disc_loss: 0.028090578
disc_acc: 0.9922029702970298

Validation results:
gen_loss: 2.7851748
disc_loss: 0.010084102
disc_acc: 0.9950396825396826


	Epoch 155
Training results:
gen_loss: 3.0315526
disc_loss: 0.030160675
disc_acc: 0.9896039603960396

Validation results:
gen_loss: 2.7854931
disc_loss: 0.024891466
disc_acc: 0.9915674603174603


	Epoch 156
Training results:
gen_loss: 3.0423887
disc_loss: 0.028674359
disc_acc: 0.9903465346534653

Validation results:
gen_loss: 2.7481441
disc_loss: 0.010973576
disc_acc: 0.9970238095238095


	Epoch 157
Training results:
gen_loss: 3.047834
disc_loss: 0.028972127
disc_acc: 0.9905940594059406

Validation results:
gen_loss: 2.6337328
disc_loss: 0.011710963
disc_acc: 0.9950396825396826


	Epoch 158
Training results:
gen_loss: 3.0479693
disc_loss: 0.021557117
disc_acc: 0.9935643564356436

Validation results:
gen_loss: 2.6232917
disc_loss: 0.32128724
disc_acc: 0.8779761904761905


	Epoch 159
Training results:
gen_loss: 3.0505004
disc_loss: 0.029556945
disc_acc: 0.9893564356435643

Validation results:
gen_loss: 2.6101544
disc_loss: 0.00625445
disc_acc: 0.9985119047619048


	Epoch 160
Training results:
gen_loss: 3.0495915
disc_loss: 0.024725173
disc_acc: 0.9915841584158416

Validation results:
gen_loss: 2.8352377
disc_loss: 0.008248228
disc_acc: 0.9970238095238095


	Epoch 161
Training results:
gen_loss: 3.0501142
disc_loss: 0.023428485
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 2.8040047
disc_loss: 0.035694934
disc_acc: 0.9880952380952381


	Epoch 162
Training results:
gen_loss: 3.060376
disc_loss: 0.031827547
disc_acc: 0.9898514851485148

Validation results:
gen_loss: 2.8086112
disc_loss: 0.009957212
disc_acc: 0.9955357142857143


	Epoch 163
Training results:
gen_loss: 3.0542214
disc_loss: 0.02019895
disc_acc: 0.9943069306930693

Validation results:
gen_loss: 2.6955745
disc_loss: 0.006321112
disc_acc: 0.9985119047619048


	Epoch 164
Training results:
gen_loss: 3.0597336
disc_loss: 0.018030504
disc_acc: 0.9938118811881188

Validation results:
gen_loss: 2.7364256
disc_loss: 0.025107386
disc_acc: 0.9890873015873016


	Epoch 165
Training results:
gen_loss: 3.068819
disc_loss: 0.020363623
disc_acc: 0.9920792079207921

Validation results:
gen_loss: 2.8238769
disc_loss: 0.031163707
disc_acc: 0.9890873015873016


	Epoch 166
Training results:
gen_loss: 3.054695
disc_loss: 0.027128343
disc_acc: 0.9907178217821783

Validation results:
gen_loss: 2.6826565
disc_loss: 0.01140157
disc_acc: 0.9950396825396826


	Epoch 167
Training results:
gen_loss: 3.0663733
disc_loss: 0.019546226
disc_acc: 0.994430693069307

Validation results:
gen_loss: 2.6342266
disc_loss: 0.19107811
disc_acc: 0.9295634920634921


	Epoch 168
Training results:
gen_loss: 3.0786703
disc_loss: 0.023809649
disc_acc: 0.9913366336633663

Validation results:
gen_loss: 2.7537975
disc_loss: 0.016646236
disc_acc: 0.9940476190476191


	Epoch 169
Training results:
gen_loss: 3.0773818
disc_loss: 0.022111036
disc_acc: 0.9923267326732673

Validation results:
gen_loss: 2.5164368
disc_loss: 0.07706828
disc_acc: 0.9751984126984127


	Epoch 170
Training results:
gen_loss: 3.0750785
disc_loss: 0.021393282
disc_acc: 0.9930693069306931

Validation results:
gen_loss: 2.7019744
disc_loss: 0.018906385
disc_acc: 0.9905753968253969


	Epoch 171
Training results:
gen_loss: 3.0654955
disc_loss: 0.026139613
disc_acc: 0.9912128712871288

Validation results:
gen_loss: 2.5934153
disc_loss: 0.017006855
disc_acc: 0.9970238095238095


	Epoch 172
Training results:
gen_loss: 3.0659559
disc_loss: 0.027815703
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 2.7845104
disc_loss: 1.7278978
disc_acc: 0.6190476190476191


	Epoch 173
Training results:
gen_loss: 3.0685015
disc_loss: 0.025636142
disc_acc: 0.9918316831683168

Validation results:
gen_loss: 2.7952967
disc_loss: 0.07179269
disc_acc: 0.9737103174603174


	Epoch 174
Training results:
gen_loss: 3.0654607
disc_loss: 0.024638511
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 2.636269
disc_loss: 0.18789342
disc_acc: 0.9295634920634921


	Epoch 175
Training results:
gen_loss: 3.0753016
disc_loss: 0.018050557
disc_acc: 0.994430693069307

Validation results:
gen_loss: 2.7829406
disc_loss: 0.0059963106
disc_acc: 0.9985119047619048


	Epoch 176
Training results:
gen_loss: 3.0747356
disc_loss: 0.024920877
disc_acc: 0.9912128712871288

Validation results:
gen_loss: 2.7009869
disc_loss: 0.03836256
disc_acc: 0.9851190476190477


	Epoch 177
Training results:
gen_loss: 3.0769336
disc_loss: 0.022215089
disc_acc: 0.9931930693069307

Validation results:
gen_loss: 2.9262927
disc_loss: 0.17350847
disc_acc: 0.9499007936507936


	Epoch 178
Training results:
gen_loss: 3.0797513
disc_loss: 0.022097858
disc_acc: 0.9928217821782178

Validation results:
gen_loss: 2.6959732
disc_loss: 0.0048663644
disc_acc: 1.0


	Epoch 179
Training results:
gen_loss: 3.077195
disc_loss: 0.025984418
disc_acc: 0.9915841584158416

Validation results:
gen_loss: 2.719514
disc_loss: 0.070283026
disc_acc: 0.9761904761904762


	Epoch 180
Training results:
gen_loss: 3.0754712
disc_loss: 0.019605864
disc_acc: 0.9941831683168317

Validation results:
gen_loss: 2.729608
disc_loss: 0.007470675
disc_acc: 0.9985119047619048


	Epoch 181
Training results:
gen_loss: 3.0829215
disc_loss: 0.023227567
disc_acc: 0.9928217821782178

Validation results:
gen_loss: 2.6852398
disc_loss: 0.011190748
disc_acc: 0.9965277777777778


	Epoch 182
Training results:
gen_loss: 3.0820677
disc_loss: 0.018917201
disc_acc: 0.9936881188118812

Validation results:
gen_loss: 2.7200143
disc_loss: 0.029729594
disc_acc: 0.9915674603174603


	Epoch 183
Training results:
gen_loss: 3.092214
disc_loss: 0.017092349
disc_acc: 0.9948019801980198

Validation results:
gen_loss: 2.7660286
disc_loss: 0.032553095
disc_acc: 0.9910714285714286


	Epoch 184
Training results:
gen_loss: 3.0980473
disc_loss: 0.023693955
disc_acc: 0.9910891089108911

Validation results:
gen_loss: 2.6714828
disc_loss: 0.009362028
disc_acc: 0.9970238095238095


	Epoch 185
Training results:
gen_loss: 3.0944521
disc_loss: 0.021578657
disc_acc: 0.9926980198019802

Validation results:
gen_loss: 2.665713
disc_loss: 0.010075467
disc_acc: 0.998015873015873


	Epoch 186
Training results:
gen_loss: 3.090302
disc_loss: 0.02383618
disc_acc: 0.9922029702970298

Validation results:
gen_loss: 2.8085518
disc_loss: 0.02246935
disc_acc: 0.9920634920634921


	Epoch 187
Training results:
gen_loss: 3.0910366
disc_loss: 0.02111751
disc_acc: 0.992450495049505

Validation results:
gen_loss: 2.4363766
disc_loss: 0.087378986
disc_acc: 0.9677579365079365


	Epoch 188
Training results:
gen_loss: 3.0865402
disc_loss: 0.021086928
disc_acc: 0.9936881188118812

Validation results:
gen_loss: 2.7948334
disc_loss: 0.0050034784
disc_acc: 1.0


	Epoch 189
Training results:
gen_loss: 3.1118634
disc_loss: 0.015997782
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.5770812
disc_loss: 0.025977252
disc_acc: 0.9905753968253969


	Epoch 190
Training results:
gen_loss: 3.0969827
disc_loss: 0.02474396
disc_acc: 0.991460396039604

Validation results:
gen_loss: 2.815469
disc_loss: 3.4375017
disc_acc: 0.5565476190476191


	Epoch 191
Training results:
gen_loss: 3.1021824
disc_loss: 0.02575437
disc_acc: 0.991460396039604

Validation results:
gen_loss: 2.7859566
disc_loss: 0.3767249
disc_acc: 0.8874007936507936


	Epoch 192
Training results:
gen_loss: 3.1061165
disc_loss: 0.015631724
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.879649
disc_loss: 0.010178841
disc_acc: 0.9965277777777778


	Epoch 193
Training results:
gen_loss: 3.1100879
disc_loss: 0.0220092
disc_acc: 0.9930693069306931

Validation results:
gen_loss: 2.7203362
disc_loss: 0.010628056
disc_acc: 0.996031746031746


	Epoch 194
Training results:
gen_loss: 3.1077733
disc_loss: 0.02421207
disc_acc: 0.9919554455445545

Validation results:
gen_loss: 2.662235
disc_loss: 0.37247574
disc_acc: 0.9117063492063492


	Epoch 195
Training results:
gen_loss: 3.1104536
disc_loss: 0.023252733
disc_acc: 0.9931930693069307

Validation results:
gen_loss: 2.8376842
disc_loss: 0.008664053
disc_acc: 0.9970238095238095


	Epoch 196
Training results:
gen_loss: 3.1067512
disc_loss: 0.026865058
disc_acc: 0.9910891089108911

Validation results:
gen_loss: 2.8862112
disc_loss: 1.0423061
disc_acc: 0.7881944444444444


	Epoch 197
Training results:
gen_loss: 3.1057177
disc_loss: 0.023236234
disc_acc: 0.9920792079207921

Validation results:
gen_loss: 2.8008642
disc_loss: 0.011330285
disc_acc: 0.9975198412698413


	Epoch 198
Training results:
gen_loss: 3.099824
disc_loss: 0.022816503
disc_acc: 0.9919554455445545

Validation results:
gen_loss: 2.8316345
disc_loss: 0.084411986
disc_acc: 0.9672619047619048


	Epoch 199
Training results:
gen_loss: 3.1050484
disc_loss: 0.023065839
disc_acc: 0.992450495049505

Validation results:
gen_loss: 2.8206522
disc_loss: 0.010079634
disc_acc: 0.9975198412698413


	Epoch 200
Training results:
gen_loss: 3.107762
disc_loss: 0.020665843
disc_acc: 0.9930693069306931

Validation results:
gen_loss: 2.723366
disc_loss: 1.2959005
disc_acc: 0.7311507936507936


	Epoch 201
Training results:
gen_loss: 3.1022737
disc_loss: 0.022752926
disc_acc: 0.9929455445544555

Validation results:
gen_loss: 2.7173467
disc_loss: 0.007210552
disc_acc: 0.9965277777777778


	Epoch 202
Training results:
gen_loss: 3.1093457
disc_loss: 0.023444166
disc_acc: 0.991460396039604

Validation results:
gen_loss: 2.8612916
disc_loss: 0.012421217
disc_acc: 0.9950396825396826


	Epoch 203
Training results:
gen_loss: 3.1170223
disc_loss: 0.014465898
disc_acc: 0.9955445544554455

Validation results:
gen_loss: 2.8836732
disc_loss: 0.014673067
disc_acc: 0.9945436507936508


	Epoch 204
Training results:
gen_loss: 3.121218
disc_loss: 0.023959724
disc_acc: 0.9922029702970298

Validation results:
gen_loss: 2.7322288
disc_loss: 0.08719582
disc_acc: 0.966765873015873


	Epoch 205
Training results:
gen_loss: 3.12051
disc_loss: 0.018758284
disc_acc: 0.9936881188118812

Validation results:
gen_loss: 2.7618968
disc_loss: 0.0051999087
disc_acc: 0.998015873015873


	Epoch 206
Training results:
gen_loss: 3.1255028
disc_loss: 0.02439236
disc_acc: 0.9907178217821783

Validation results:
gen_loss: 2.7134678
disc_loss: 0.014407374
disc_acc: 0.9945436507936508


	Epoch 207
Training results:
gen_loss: 3.114389
disc_loss: 0.019037787
disc_acc: 0.9925742574257426

Validation results:
gen_loss: 2.7984593
disc_loss: 0.008657761
disc_acc: 0.9985119047619048


	Epoch 208
Training results:
gen_loss: 3.1191294
disc_loss: 0.02488111
disc_acc: 0.9912128712871288

Validation results:
gen_loss: 2.6014748
disc_loss: 0.010810805
disc_acc: 0.9985119047619048


	Epoch 209
Training results:
gen_loss: 3.1264768
disc_loss: 0.019391477
disc_acc: 0.9935643564356436

Validation results:
gen_loss: 2.815548
disc_loss: 0.08288372
disc_acc: 0.9776785714285714


	Epoch 210
Training results:
gen_loss: 3.1296499
disc_loss: 0.021712463
disc_acc: 0.9930693069306931

Validation results:
gen_loss: 2.8381143
disc_loss: 1.149515
disc_acc: 0.7068452380952381


	Epoch 211
Training results:
gen_loss: 3.1345549
disc_loss: 0.018289074
disc_acc: 0.9939356435643565

Validation results:
gen_loss: 2.4569378
disc_loss: 1.7711681
disc_acc: 0.6418650793650794


	Epoch 212
Training results:
gen_loss: 3.128302
disc_loss: 0.020701682
disc_acc: 0.9933168316831683

Validation results:
gen_loss: 2.6870615
disc_loss: 0.0050327512
disc_acc: 0.998015873015873


	Epoch 213
Training results:
gen_loss: 3.1379921
disc_loss: 0.013053217
disc_acc: 0.996039603960396

Validation results:
gen_loss: 2.772867
disc_loss: 0.005411561
disc_acc: 0.9990079365079365


	Epoch 214
Training results:
gen_loss: 3.1487575
disc_loss: 0.018111048
disc_acc: 0.9938118811881188

Validation results:
gen_loss: 2.7027545
disc_loss: 0.013562018
disc_acc: 0.9945436507936508


	Epoch 215
Training results:
gen_loss: 3.1407492
disc_loss: 0.0164934
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.9158766
disc_loss: 0.012547884
disc_acc: 0.9955357142857143


	Epoch 216
Training results:
gen_loss: 3.1378431
disc_loss: 0.018629905
disc_acc: 0.994059405940594

Validation results:
gen_loss: 2.7313006
disc_loss: 0.024775265
disc_acc: 0.9900793650793651


	Epoch 217
Training results:
gen_loss: 3.1467893
disc_loss: 0.01493746
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 2.701006
disc_loss: 0.0612558
disc_acc: 0.9747023809523809


	Epoch 218
Training results:
gen_loss: 3.1466088
disc_loss: 0.016378932
disc_acc: 0.9949257425742575

Validation results:
gen_loss: 2.7097778
disc_loss: 0.013142679
disc_acc: 0.9940476190476191


	Epoch 219
Training results:
gen_loss: 3.1499329
disc_loss: 0.021857928
disc_acc: 0.9931930693069307

Validation results:
gen_loss: 2.9747071
disc_loss: 0.013934092
disc_acc: 0.9955357142857143


	Epoch 220
Training results:
gen_loss: 3.1527395
disc_loss: 0.022111032
disc_acc: 0.9920792079207921

Validation results:
gen_loss: 2.897128
disc_loss: 0.004832088
disc_acc: 0.9990079365079365


	Epoch 221
Training results:
gen_loss: 3.1511803
disc_loss: 0.0130420895
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 2.7824342
disc_loss: 0.010519603
disc_acc: 0.9975198412698413


	Epoch 222
Training results:
gen_loss: 3.1639788
disc_loss: 0.019055177
disc_acc: 0.9935643564356436

Validation results:
gen_loss: 2.796979
disc_loss: 0.0045695393
disc_acc: 0.9990079365079365


	Epoch 223
Training results:
gen_loss: 3.1571631
disc_loss: 0.021645345
disc_acc: 0.9929455445544555

Validation results:
gen_loss: 2.7453103
disc_loss: 0.004062618
disc_acc: 0.9995039682539683


	Epoch 224
Training results:
gen_loss: 3.152934
disc_loss: 0.015265462
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 2.790692
disc_loss: 0.013039308
disc_acc: 0.9950396825396826


	Epoch 225
Training results:
gen_loss: 3.1577358
disc_loss: 0.017644705
disc_acc: 0.9939356435643565

Validation results:
gen_loss: 2.7398412
disc_loss: 0.008637106
disc_acc: 0.9975198412698413


	Epoch 226
Training results:
gen_loss: 3.1608162
disc_loss: 0.012688096
disc_acc: 0.996039603960396

Validation results:
gen_loss: 2.883012
disc_loss: 0.015112293
disc_acc: 0.9945436507936508


	Epoch 227
Training results:
gen_loss: 3.1578054
disc_loss: 0.016350197
disc_acc: 0.9948019801980198

Validation results:
gen_loss: 2.8053637
disc_loss: 0.017691817
disc_acc: 0.9935515873015873


	Epoch 228
Training results:
gen_loss: 3.149919
disc_loss: 0.015728591
disc_acc: 0.994430693069307

Validation results:
gen_loss: 2.7998536
disc_loss: 0.005659415
disc_acc: 0.9985119047619048


	Epoch 229
Training results:
gen_loss: 3.1672788
disc_loss: 0.014531905
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.9677987
disc_loss: 0.017038925
disc_acc: 0.9950396825396826


	Epoch 230
Training results:
gen_loss: 3.162742
disc_loss: 0.018347643
disc_acc: 0.994059405940594

Validation results:
gen_loss: 2.6517844
disc_loss: 0.008412322
disc_acc: 0.9970238095238095


	Epoch 231
Training results:
gen_loss: 3.1630347
disc_loss: 0.016147984
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.7324347
disc_loss: 0.007669589
disc_acc: 0.9965277777777778


	Epoch 232
Training results:
gen_loss: 3.1745307
disc_loss: 0.01632986
disc_acc: 0.994430693069307

Validation results:
gen_loss: 2.801146
disc_loss: 0.009248972
disc_acc: 0.9970238095238095


	Epoch 233
Training results:
gen_loss: 3.1799102
disc_loss: 0.018777145
disc_acc: 0.9943069306930693

Validation results:
gen_loss: 2.8793592
disc_loss: 0.12836616
disc_acc: 0.9528769841269841


	Epoch 234
Training results:
gen_loss: 3.1804197
disc_loss: 0.0172328
disc_acc: 0.995049504950495

Validation results:
gen_loss: 2.7871044
disc_loss: 0.013808323
disc_acc: 0.9945436507936508


	Epoch 235
Training results:
gen_loss: 3.1815398
disc_loss: 0.02020476
disc_acc: 0.9936881188118812

Validation results:
gen_loss: 2.8717668
disc_loss: 0.010260317
disc_acc: 0.9965277777777778


	Epoch 236
Training results:
gen_loss: 3.1737125
disc_loss: 0.022890182
disc_acc: 0.9925742574257426

Validation results:
gen_loss: 2.8798852
disc_loss: 0.00692911
disc_acc: 0.998015873015873


	Epoch 237
Training results:
gen_loss: 3.1773028
disc_loss: 0.025923673
disc_acc: 0.992450495049505

Validation results:
gen_loss: 2.5173085
disc_loss: 0.0049648928
disc_acc: 0.9990079365079365


	Epoch 238
Training results:
gen_loss: 3.1614833
disc_loss: 0.02175008
disc_acc: 0.9928217821782178

Validation results:
gen_loss: 2.746122
disc_loss: 0.06700666
disc_acc: 0.9766865079365079


	Epoch 239
Training results:
gen_loss: 3.1751106
disc_loss: 0.014052382
disc_acc: 0.9956683168316832

Validation results:
gen_loss: 2.7540317
disc_loss: 0.06392333
disc_acc: 0.9732142857142857


	Epoch 240
Training results:
gen_loss: 3.177758
disc_loss: 0.025250124
disc_acc: 0.9933168316831683

Validation results:
gen_loss: 2.805145
disc_loss: 0.028836349
disc_acc: 0.9915674603174603


	Epoch 241
Training results:
gen_loss: 3.1654322
disc_loss: 0.024709884
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 2.8020275
disc_loss: 0.106387004
disc_acc: 0.9593253968253969


	Epoch 242
Training results:
gen_loss: 3.17565
disc_loss: 0.019623607
disc_acc: 0.9936881188118812

Validation results:
gen_loss: 2.8881035
disc_loss: 0.0069993436
disc_acc: 0.9970238095238095


	Epoch 243
Training results:
gen_loss: 3.1791139
disc_loss: 0.017367827
disc_acc: 0.9946782178217822

Validation results:
gen_loss: 2.7663724
disc_loss: 0.004907561
disc_acc: 0.9990079365079365


	Epoch 244
Training results:
gen_loss: 3.1773891
disc_loss: 0.0218719
disc_acc: 0.9919554455445545

Validation results:
gen_loss: 2.8836648
disc_loss: 0.12575471
disc_acc: 0.9603174603174603


	Epoch 245
Training results:
gen_loss: 3.1779983
disc_loss: 0.018957686
disc_acc: 0.9935643564356436

Validation results:
gen_loss: 2.7404208
disc_loss: 0.0059750797
disc_acc: 0.9990079365079365


	Epoch 246
Training results:
gen_loss: 3.1791263
disc_loss: 0.019241445
disc_acc: 0.9935643564356436

Validation results:
gen_loss: 2.8631196
disc_loss: 0.011117697
disc_acc: 0.9955357142857143


	Epoch 247
Training results:
gen_loss: 3.1764576
disc_loss: 0.015915202
disc_acc: 0.9943069306930693

Validation results:
gen_loss: 2.8410907
disc_loss: 0.015445966
disc_acc: 0.9945436507936508


	Epoch 248
Training results:
gen_loss: 3.1869364
disc_loss: 0.015819095
disc_acc: 0.9946782178217822

Validation results:
gen_loss: 2.7998655
disc_loss: 0.03414341
disc_acc: 0.9875992063492064


	Epoch 249
Training results:
gen_loss: 3.1806734
disc_loss: 0.018235616
disc_acc: 0.9939356435643565

Validation results:
gen_loss: 2.7774055
disc_loss: 0.007868489
disc_acc: 0.9975198412698413


	Epoch 250
Training results:
gen_loss: 3.1782646
disc_loss: 0.018858695
disc_acc: 0.9936881188118812

Validation results:
gen_loss: 2.93439
disc_loss: 0.0097548
disc_acc: 0.996031746031746


	Epoch 251
Training results:
gen_loss: 3.1800196
disc_loss: 0.013281647
disc_acc: 0.996410891089109

Validation results:
gen_loss: 2.797102
disc_loss: 0.058806982
disc_acc: 0.9801587301587301


	Epoch 252
Training results:
gen_loss: 3.1844783
disc_loss: 0.017440021
disc_acc: 0.9935643564356436

Validation results:
gen_loss: 3.020855
disc_loss: 0.1974655
disc_acc: 0.9211309523809523


	Epoch 253
Training results:
gen_loss: 3.1765053
disc_loss: 0.016693942
disc_acc: 0.9943069306930693

Validation results:
gen_loss: 2.5858335
disc_loss: 0.008092772
disc_acc: 0.998015873015873


	Epoch 254
Training results:
gen_loss: 3.1771064
disc_loss: 0.018273968
disc_acc: 0.9936881188118812

Validation results:
gen_loss: 2.8509514
disc_loss: 0.032371305
disc_acc: 0.9890873015873016


	Epoch 255
Training results:
gen_loss: 3.1821203
disc_loss: 0.0140704
disc_acc: 0.9962871287128713

Validation results:
gen_loss: 2.9115791
disc_loss: 0.0155737465
disc_acc: 0.9955357142857143


	Epoch 256
Training results:
gen_loss: 3.194276
disc_loss: 0.015708143
disc_acc: 0.9939356435643565

Validation results:
gen_loss: 2.8569775
disc_loss: 0.006205261
disc_acc: 0.998015873015873


	Epoch 257
Training results:
gen_loss: 3.1942701
disc_loss: 0.017323742
disc_acc: 0.995049504950495

Validation results:
gen_loss: 2.7529094
disc_loss: 0.005283168
disc_acc: 0.9985119047619048


	Epoch 258
Training results:
gen_loss: 3.1860662
disc_loss: 0.014783272
disc_acc: 0.9956683168316832

Validation results:
gen_loss: 2.849404
disc_loss: 0.017282719
disc_acc: 0.9955357142857143


	Epoch 259
Training results:
gen_loss: 3.1928523
disc_loss: 0.018439094
disc_acc: 0.9943069306930693

Validation results:
gen_loss: 2.9553008
disc_loss: 0.043424167
disc_acc: 0.9875992063492064


	Epoch 260
Training results:
gen_loss: 3.2020717
disc_loss: 0.014048561
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 2.8077898
disc_loss: 0.00739585
disc_acc: 0.9975198412698413


	Epoch 261
Training results:
gen_loss: 3.2085147
disc_loss: 0.010150934
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.8532834
disc_loss: 0.008774324
disc_acc: 0.9970238095238095


	Epoch 262
Training results:
gen_loss: 3.206692
disc_loss: 0.013342051
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.7824194
disc_loss: 0.011853781
disc_acc: 0.9965277777777778


	Epoch 263
Training results:
gen_loss: 3.1955452
disc_loss: 0.019182073
disc_acc: 0.994059405940594

Validation results:
gen_loss: 2.7719169
disc_loss: 0.01216487
disc_acc: 0.9950396825396826


	Epoch 264
Training results:
gen_loss: 3.2037647
disc_loss: 0.019177482
disc_acc: 0.994059405940594

Validation results:
gen_loss: 2.8937743
disc_loss: 0.068069585
disc_acc: 0.9761904761904762


	Epoch 265
Training results:
gen_loss: 3.2022867
disc_loss: 0.01249823
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 2.8901849
disc_loss: 0.012877015
disc_acc: 0.9940476190476191


	Epoch 266
Training results:
gen_loss: 3.2168162
disc_loss: 0.013897961
disc_acc: 0.9948019801980198

Validation results:
gen_loss: 2.914455
disc_loss: 0.015973017
disc_acc: 0.9925595238095238


	Epoch 267
Training results:
gen_loss: 3.2112474
disc_loss: 0.011182469
disc_acc: 0.9966584158415842

Validation results:
gen_loss: 2.8290129
disc_loss: 0.0116042
disc_acc: 0.9950396825396826


	Epoch 268
Training results:
gen_loss: 3.2038682
disc_loss: 0.013630711
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.941752
disc_loss: 0.2642349
disc_acc: 0.9156746031746031


	Epoch 269
Training results:
gen_loss: 3.2108054
disc_loss: 0.017064884
disc_acc: 0.993440594059406

Validation results:
gen_loss: 2.7060413
disc_loss: 0.11294871
disc_acc: 0.964781746031746


	Epoch 270
Training results:
gen_loss: 3.2071364
disc_loss: 0.018109903
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.929132
disc_loss: 0.006141904
disc_acc: 0.998015873015873


	Epoch 271
Training results:
gen_loss: 3.196829
disc_loss: 0.023984093
disc_acc: 0.9913366336633663

Validation results:
gen_loss: 2.7930827
disc_loss: 0.15158002
disc_acc: 0.941468253968254


	Epoch 272
Training results:
gen_loss: 3.2086184
disc_loss: 0.0098731145
disc_acc: 0.9975247524752475

Validation results:
gen_loss: 2.893389
disc_loss: 0.008193985
disc_acc: 0.9955357142857143


	Epoch 273
Training results:
gen_loss: 3.2048159
disc_loss: 0.012434752
disc_acc: 0.996410891089109

Validation results:
gen_loss: 2.806482
disc_loss: 0.0044331416
disc_acc: 0.9995039682539683


	Epoch 274
Training results:
gen_loss: 3.218865
disc_loss: 0.014728975
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 2.874082
disc_loss: 0.0071548056
disc_acc: 0.9970238095238095


	Epoch 275
Training results:
gen_loss: 3.2168555
disc_loss: 0.014355301
disc_acc: 0.9956683168316832

Validation results:
gen_loss: 2.905589
disc_loss: 0.0045040017
disc_acc: 0.9990079365079365


	Epoch 276
Training results:
gen_loss: 3.2112885
disc_loss: 0.016218638
disc_acc: 0.9946782178217822

Validation results:
gen_loss: 2.8140082
disc_loss: 0.003530592
disc_acc: 0.9990079365079365


	Epoch 277
Training results:
gen_loss: 3.2094934
disc_loss: 0.018574078
disc_acc: 0.9941831683168317

Validation results:
gen_loss: 2.9544258
disc_loss: 0.1727653
disc_acc: 0.9464285714285714


	Epoch 278
Training results:
gen_loss: 3.2170835
disc_loss: 0.021568168
disc_acc: 0.993440594059406

Validation results:
gen_loss: 2.7277157
disc_loss: 0.007296202
disc_acc: 0.9975198412698413


	Epoch 279
Training results:
gen_loss: 3.2166317
disc_loss: 0.013560979
disc_acc: 0.995420792079208

Validation results:
gen_loss: 2.9025722
disc_loss: 0.0116224475
disc_acc: 0.9935515873015873


	Epoch 280
Training results:
gen_loss: 3.2107546
disc_loss: 0.017216982
disc_acc: 0.9955445544554455

Validation results:
gen_loss: 2.914209
disc_loss: 0.0072971317
disc_acc: 0.9985119047619048


	Epoch 281
Training results:
gen_loss: 3.2125618
disc_loss: 0.01660213
disc_acc: 0.9948019801980198

Validation results:
gen_loss: 2.9983652
disc_loss: 0.010171992
disc_acc: 0.9945436507936508


	Epoch 282
Training results:
gen_loss: 3.2165444
disc_loss: 0.02163471
disc_acc: 0.9922029702970298

Validation results:
gen_loss: 2.9403343
disc_loss: 0.0060129473
disc_acc: 0.9985119047619048


	Epoch 283
Training results:
gen_loss: 3.2254138
disc_loss: 0.01633327
disc_acc: 0.9946782178217822

Validation results:
gen_loss: 2.7551293
disc_loss: 0.0057100016
disc_acc: 0.998015873015873


	Epoch 284
Training results:
gen_loss: 3.2195308
disc_loss: 0.017823705
disc_acc: 0.994430693069307

Validation results:
gen_loss: 2.8565805
disc_loss: 0.0043522594
disc_acc: 0.9995039682539683


	Epoch 285
Training results:
gen_loss: 3.223714
disc_loss: 0.016168747
disc_acc: 0.994430693069307

Validation results:
gen_loss: 2.8524568
disc_loss: 0.006929925
disc_acc: 0.9965277777777778


	Epoch 286
Training results:
gen_loss: 3.2283459
disc_loss: 0.010790079
disc_acc: 0.9972772277227723

Validation results:
gen_loss: 2.8185728
disc_loss: 0.009844982
disc_acc: 0.9965277777777778


	Epoch 287
Training results:
gen_loss: 3.2270598
disc_loss: 0.015897702
disc_acc: 0.994430693069307

Validation results:
gen_loss: 2.9262564
disc_loss: 0.044601675
disc_acc: 0.9851190476190477


	Epoch 288
Training results:
gen_loss: 3.2307315
disc_loss: 0.010885518
disc_acc: 0.99740099009901

Validation results:
gen_loss: 2.742544
disc_loss: 0.0032526853
disc_acc: 0.9995039682539683


	Epoch 289
Training results:
gen_loss: 3.2268088
disc_loss: 0.01605084
disc_acc: 0.9945544554455445

Validation results:
gen_loss: 2.8661234
disc_loss: 0.022270825
disc_acc: 0.9940476190476191


	Epoch 290
Training results:
gen_loss: 3.2412114
disc_loss: 0.012881685
disc_acc: 0.9956683168316832

Validation results:
gen_loss: 2.9032128
disc_loss: 0.010709282
disc_acc: 0.9970238095238095


	Epoch 291
Training results:
gen_loss: 3.241285
disc_loss: 0.011730057
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.8446596
disc_loss: 0.0065880036
disc_acc: 0.9975198412698413


	Epoch 292
Training results:
gen_loss: 3.2369194
disc_loss: 0.0135282595
disc_acc: 0.9956683168316832

Validation results:
gen_loss: 2.7294443
disc_loss: 0.04020929
disc_acc: 0.9851190476190477


	Epoch 293
Training results:
gen_loss: 3.233255
disc_loss: 0.012055503
disc_acc: 0.9962871287128713

Validation results:
gen_loss: 2.804701
disc_loss: 0.008871953
disc_acc: 0.9970238095238095


	Epoch 294
Training results:
gen_loss: 3.2393804
disc_loss: 0.012468327
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.6220102
disc_loss: 0.35808852
disc_acc: 0.8898809523809523


	Epoch 295
Training results:
gen_loss: 3.245163
disc_loss: 0.011221755
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 2.9029965
disc_loss: 0.0143579235
disc_acc: 0.9945436507936508


	Epoch 296
Training results:
gen_loss: 3.2489161
disc_loss: 0.010528162
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.8498821
disc_loss: 0.007382332
disc_acc: 0.998015873015873


	Epoch 297
Training results:
gen_loss: 3.2481155
disc_loss: 0.01227742
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.9217825
disc_loss: 0.0119400965
disc_acc: 0.9965277777777778


	Epoch 298
Training results:
gen_loss: 3.2389834
disc_loss: 0.015901256
disc_acc: 0.995049504950495

Validation results:
gen_loss: 2.959176
disc_loss: 0.018034404
disc_acc: 0.9930555555555556


	Epoch 299
Training results:
gen_loss: 3.2477684
disc_loss: 0.007235531
disc_acc: 0.9981435643564357

Validation results:
gen_loss: 2.8315735
disc_loss: 0.0041299514
disc_acc: 0.9985119047619048


	Epoch 300
Training results:
gen_loss: 3.2393563
disc_loss: 0.013164799
disc_acc: 0.9956683168316832

Validation results:
gen_loss: 2.860362
disc_loss: 0.002679805
disc_acc: 1.0


	Epoch 301
Training results:
gen_loss: 3.2453394
disc_loss: 0.007882824
disc_acc: 0.9978960396039604

Validation results:
gen_loss: 2.9242015
disc_loss: 0.007177988
disc_acc: 0.9975198412698413


	Epoch 302
Training results:
gen_loss: 3.2537453
disc_loss: 0.011296159
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 2.8204966
disc_loss: 1.1801786
disc_acc: 0.78125


	Epoch 303
Training results:
gen_loss: 3.251238
disc_loss: 0.013333803
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.8355663
disc_loss: 0.0053203073
disc_acc: 0.9975198412698413


	Epoch 304
Training results:
gen_loss: 3.2494822
disc_loss: 0.0137086
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.8485465
disc_loss: 1.7889746
disc_acc: 0.6641865079365079


	Epoch 305
Training results:
gen_loss: 3.247621
disc_loss: 0.014668285
disc_acc: 0.995420792079208

Validation results:
gen_loss: 2.884287
disc_loss: 0.023437224
disc_acc: 0.9925595238095238


	Epoch 306
Training results:
gen_loss: 3.248507
disc_loss: 0.015629739
disc_acc: 0.995420792079208

Validation results:
gen_loss: 2.8325212
disc_loss: 0.0029675115
disc_acc: 0.9995039682539683


	Epoch 307
Training results:
gen_loss: 3.2583146
disc_loss: 0.010356115
disc_acc: 0.997029702970297

Validation results:
gen_loss: 2.943543
disc_loss: 0.005140988
disc_acc: 0.998015873015873


	Epoch 308
Training results:
gen_loss: 3.2550907
disc_loss: 0.010685656
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.6076112
disc_loss: 0.034457184
disc_acc: 0.9900793650793651


	Epoch 309
Training results:
gen_loss: 3.2462585
disc_loss: 0.014078019
disc_acc: 0.9946782178217822

Validation results:
gen_loss: 2.8123186
disc_loss: 0.0070926556
disc_acc: 0.9985119047619048


	Epoch 310
Training results:
gen_loss: 3.2481875
disc_loss: 0.012023791
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.8680904
disc_loss: 0.0029346019
disc_acc: 0.9990079365079365


	Epoch 311
Training results:
gen_loss: 3.2433493
disc_loss: 0.014576782
disc_acc: 0.995049504950495

Validation results:
gen_loss: 2.9410717
disc_loss: 0.003364679
disc_acc: 0.9990079365079365


	Epoch 312
Training results:
gen_loss: 3.263064
disc_loss: 0.010440726
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.9702265
disc_loss: 0.018343233
disc_acc: 0.9930555555555556


	Epoch 313
Training results:
gen_loss: 3.2549057
disc_loss: 0.014676589
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 2.9000847
disc_loss: 0.0110178
disc_acc: 0.9950396825396826


	Epoch 314
Training results:
gen_loss: 3.2639167
disc_loss: 0.015588614
disc_acc: 0.994430693069307

Validation results:
gen_loss: 2.9520757
disc_loss: 0.0061323023
disc_acc: 0.9995039682539683


	Epoch 315
Training results:
gen_loss: 3.2651029
disc_loss: 0.011793184
disc_acc: 0.996410891089109

Validation results:
gen_loss: 2.9075987
disc_loss: 0.030983806
disc_acc: 0.9885912698412699


	Epoch 316
Training results:
gen_loss: 3.2650158
disc_loss: 0.015596359
disc_acc: 0.995049504950495

Validation results:
gen_loss: 2.9697316
disc_loss: 0.013019338
disc_acc: 0.996031746031746


	Epoch 317
Training results:
gen_loss: 3.2595625
disc_loss: 0.013671114
disc_acc: 0.995049504950495

Validation results:
gen_loss: 2.9240644
disc_loss: 0.004624317
disc_acc: 0.998015873015873


	Epoch 318
Training results:
gen_loss: 3.2789307
disc_loss: 0.009658097
disc_acc: 0.997029702970297

Validation results:
gen_loss: 2.6682928
disc_loss: 0.01301275
disc_acc: 0.996031746031746


	Epoch 319
Training results:
gen_loss: 3.269112
disc_loss: 0.0113601275
disc_acc: 0.9966584158415842

Validation results:
gen_loss: 3.030559
disc_loss: 0.008306324
disc_acc: 0.9955357142857143


	Epoch 320
Training results:
gen_loss: 3.2736053
disc_loss: 0.012107478
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.9977434
disc_loss: 0.014119724
disc_acc: 0.9945436507936508


	Epoch 321
Training results:
gen_loss: 3.2665744
disc_loss: 0.011405777
disc_acc: 0.9962871287128713

Validation results:
gen_loss: 2.8627028
disc_loss: 0.009607514
disc_acc: 0.9965277777777778


	Epoch 322
Training results:
gen_loss: 3.276214
disc_loss: 0.016655527
disc_acc: 0.994059405940594

Validation results:
gen_loss: 2.9425993
disc_loss: 0.008768865
disc_acc: 0.9985119047619048


	Epoch 323
Training results:
gen_loss: 3.2749581
disc_loss: 0.015305054
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.7146602
disc_loss: 0.0070346203
disc_acc: 0.9970238095238095


	Epoch 324
Training results:
gen_loss: 3.2680616
disc_loss: 0.014373389
disc_acc: 0.995049504950495

Validation results:
gen_loss: 2.9442143
disc_loss: 0.0061184415
disc_acc: 0.998015873015873


	Epoch 325
Training results:
gen_loss: 3.2665143
disc_loss: 0.0118804285
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 2.90354
disc_loss: 0.003973389
disc_acc: 0.9985119047619048


	Epoch 326
Training results:
gen_loss: 3.2810836
disc_loss: 0.009634174
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 3.0311909
disc_loss: 0.025674758
disc_acc: 0.9930555555555556


	Epoch 327
Training results:
gen_loss: 3.2643957
disc_loss: 0.015105603
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.8793924
disc_loss: 0.009527767
disc_acc: 0.996031746031746


	Epoch 328
Training results:
gen_loss: 3.270853
disc_loss: 0.010844861
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 3.0074835
disc_loss: 0.023210682
disc_acc: 0.9930555555555556


	Epoch 329
Training results:
gen_loss: 3.268723
disc_loss: 0.014357696
disc_acc: 0.9962871287128713

Validation results:
gen_loss: 2.855213
disc_loss: 0.03530704
disc_acc: 0.9866071428571429


	Epoch 330
Training results:
gen_loss: 3.2780876
disc_loss: 0.013777527
disc_acc: 0.995420792079208

Validation results:
gen_loss: 3.047562
disc_loss: 0.009437997
disc_acc: 0.9950396825396826


	Epoch 331
Training results:
gen_loss: 3.2772224
disc_loss: 0.017100127
disc_acc: 0.9939356435643565

Validation results:
gen_loss: 2.7393687
disc_loss: 0.035965014
disc_acc: 0.9875992063492064


	Epoch 332
Training results:
gen_loss: 3.276505
disc_loss: 0.011369569
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.9240644
disc_loss: 0.005273553
disc_acc: 0.998015873015873


	Epoch 333
Training results:
gen_loss: 3.2814658
disc_loss: 0.012639263
disc_acc: 0.996410891089109

Validation results:
gen_loss: 2.9298682
disc_loss: 0.010713323
disc_acc: 0.996031746031746


	Epoch 334
Training results:
gen_loss: 3.282696
disc_loss: 0.012103155
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 2.962633
disc_loss: 0.013120625
disc_acc: 0.9950396825396826


	Epoch 335
Training results:
gen_loss: 3.270338
disc_loss: 0.011310056
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.8856232
disc_loss: 0.0026101177
disc_acc: 1.0


	Epoch 336
Training results:
gen_loss: 3.2640038
disc_loss: 0.012538819
disc_acc: 0.9955445544554455

Validation results:
gen_loss: 2.7980204
disc_loss: 0.019603254
disc_acc: 0.9905753968253969


	Epoch 337
Training results:
gen_loss: 3.2501824
disc_loss: 0.018426578
disc_acc: 0.9939356435643565

Validation results:
gen_loss: 2.9048762
disc_loss: 0.0033740238
disc_acc: 0.9985119047619048


	Epoch 338
Training results:
gen_loss: 3.2576768
disc_loss: 0.010632529
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 3.0446272
disc_loss: 0.010337786
disc_acc: 0.996031746031746


	Epoch 339
Training results:
gen_loss: 3.27185
disc_loss: 0.013151154
disc_acc: 0.996410891089109

Validation results:
gen_loss: 3.0022447
disc_loss: 0.005951059
disc_acc: 0.9975198412698413


	Epoch 340
Training results:
gen_loss: 3.2803597
disc_loss: 0.00916419
disc_acc: 0.9972772277227723

Validation results:
gen_loss: 2.86687
disc_loss: 0.03816433
disc_acc: 0.9875992063492064


	Epoch 341
Training results:
gen_loss: 3.2764122
disc_loss: 0.011432804
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 2.8902934
disc_loss: 0.29379907
disc_acc: 0.9375


	Epoch 342
Training results:
gen_loss: 3.261383
disc_loss: 0.010608607
disc_acc: 0.996039603960396

Validation results:
gen_loss: 2.9928074
disc_loss: 0.0056669065
disc_acc: 0.9965277777777778


	Epoch 343
Training results:
gen_loss: 3.276022
disc_loss: 0.008632446
disc_acc: 0.99740099009901

Validation results:
gen_loss: 2.983485
disc_loss: 0.0108004045
disc_acc: 0.9950396825396826


	Epoch 344
Training results:
gen_loss: 3.2891889
disc_loss: 0.010043438
disc_acc: 0.9977722772277228

Validation results:
gen_loss: 2.8770115
disc_loss: 0.004526645
disc_acc: 0.998015873015873


	Epoch 345
Training results:
gen_loss: 3.2922788
disc_loss: 0.010358195
disc_acc: 0.997029702970297

Validation results:
gen_loss: 2.9383173
disc_loss: 0.0061851814
disc_acc: 0.9975198412698413


	Epoch 346
Training results:
gen_loss: 3.2833457
disc_loss: 0.014064129
disc_acc: 0.9949257425742575

Validation results:
gen_loss: 2.8391836
disc_loss: 0.00471371
disc_acc: 0.9985119047619048


	Epoch 347
Training results:
gen_loss: 3.289587
disc_loss: 0.010488875
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 2.9369903
disc_loss: 0.004609818
disc_acc: 0.9995039682539683


	Epoch 348
Training results:
gen_loss: 3.2935812
disc_loss: 0.011659502
disc_acc: 0.996410891089109

Validation results:
gen_loss: 2.8976123
disc_loss: 0.0061422414
disc_acc: 0.9965277777777778


	Epoch 349
Training results:
gen_loss: 3.291893
disc_loss: 0.012541761
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.9421673
disc_loss: 0.008311457
disc_acc: 0.9975198412698413


	Epoch 350
Training results:
gen_loss: 3.2959695
disc_loss: 0.012771865
disc_acc: 0.996039603960396

Validation results:
gen_loss: 2.84059
disc_loss: 0.27233303
disc_acc: 0.8958333333333334


	Epoch 351
Training results:
gen_loss: 3.3023138
disc_loss: 0.014248276
disc_acc: 0.995049504950495

Validation results:
gen_loss: 2.9100199
disc_loss: 0.00916497
disc_acc: 0.9970238095238095


	Epoch 352
Training results:
gen_loss: 3.2963078
disc_loss: 0.015127849
disc_acc: 0.9949257425742575

Validation results:
gen_loss: 3.0338197
disc_loss: 0.0032685408
disc_acc: 0.9995039682539683


	Epoch 353
Training results:
gen_loss: 3.2906518
disc_loss: 0.014815489
disc_acc: 0.9946782178217822

Validation results:
gen_loss: 2.9143217
disc_loss: 0.0035161874
disc_acc: 0.9985119047619048


	Epoch 354
Training results:
gen_loss: 3.2837846
disc_loss: 0.013139785
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 2.8996327
disc_loss: 0.011538304
disc_acc: 0.996031746031746


	Epoch 355
Training results:
gen_loss: 3.2809498
disc_loss: 0.0124451
disc_acc: 0.996039603960396

Validation results:
gen_loss: 2.9329534
disc_loss: 0.006705565
disc_acc: 1.0


	Epoch 356
Training results:
gen_loss: 3.3047316
disc_loss: 0.010461105
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 3.0507774
disc_loss: 0.006444486
disc_acc: 0.9970238095238095


	Epoch 357
Training results:
gen_loss: 3.2977097
disc_loss: 0.0116137415
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.95015
disc_loss: 0.10406708
disc_acc: 0.9568452380952381


	Epoch 358
Training results:
gen_loss: 3.302877
disc_loss: 0.010710345
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.9043865
disc_loss: 0.018255105
disc_acc: 0.9940476190476191


	Epoch 359
Training results:
gen_loss: 3.299969
disc_loss: 0.013518524
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.825931
disc_loss: 0.004990614
disc_acc: 0.998015873015873


	Epoch 360
Training results:
gen_loss: 3.3038304
disc_loss: 0.016866129
disc_acc: 0.994059405940594

Validation results:
gen_loss: 3.0342867
disc_loss: 0.022578562
disc_acc: 0.9920634920634921


	Epoch 361
Training results:
gen_loss: 3.3056736
disc_loss: 0.011321451
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.9076495
disc_loss: 0.005997262
disc_acc: 0.998015873015873


	Epoch 362
Training results:
gen_loss: 3.3100543
disc_loss: 0.010040901
disc_acc: 0.9975247524752475

Validation results:
gen_loss: 2.9093173
disc_loss: 0.0055844258
disc_acc: 0.9975198412698413


	Epoch 363
Training results:
gen_loss: 3.3208437
disc_loss: 0.008260713
disc_acc: 0.9971534653465347

Validation results:
gen_loss: 3.0157073
disc_loss: 0.0031227965
disc_acc: 0.9995039682539683


	Epoch 364
Training results:
gen_loss: 3.3147576
disc_loss: 0.010353917
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 3.020107
disc_loss: 0.0110419905
disc_acc: 0.9955357142857143


	Epoch 365
Training results:
gen_loss: 3.3143046
disc_loss: 0.010440987
disc_acc: 0.996410891089109

Validation results:
gen_loss: 2.9497383
disc_loss: 0.045943465
disc_acc: 0.9836309523809523


	Epoch 366
Training results:
gen_loss: 3.3093777
disc_loss: 0.0130149145
disc_acc: 0.996410891089109

Validation results:
gen_loss: 3.0022871
disc_loss: 0.0020493995
disc_acc: 0.9995039682539683


	Epoch 367
Training results:
gen_loss: 3.3092275
disc_loss: 0.010966556
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.931981
disc_loss: 0.0038905796
disc_acc: 0.9990079365079365


	Epoch 368
Training results:
gen_loss: 3.321741
disc_loss: 0.016273763
disc_acc: 0.995049504950495

Validation results:
gen_loss: 3.088065
disc_loss: 0.01963491
disc_acc: 0.9945436507936508


	Epoch 369
Training results:
gen_loss: 3.3041565
disc_loss: 0.009448726
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.9885695
disc_loss: 0.0076489365
disc_acc: 0.9985119047619048


	Epoch 370
Training results:
gen_loss: 3.311937
disc_loss: 0.011403588
disc_acc: 0.997029702970297

Validation results:
gen_loss: 3.0683877
disc_loss: 0.017606031
disc_acc: 0.9940476190476191


	Epoch 371
Training results:
gen_loss: 3.3123655
disc_loss: 0.013170915
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.8502917
disc_loss: 0.004121311
disc_acc: 0.9985119047619048


	Epoch 372
Training results:
gen_loss: 3.3039422
disc_loss: 0.0131255295
disc_acc: 0.995049504950495

Validation results:
gen_loss: 2.934806
disc_loss: 0.014806843
disc_acc: 0.9950396825396826


	Epoch 373
Training results:
gen_loss: 3.3199813
disc_loss: 0.00827614
disc_acc: 0.99740099009901

Validation results:
gen_loss: 3.0159156
disc_loss: 0.00593499
disc_acc: 0.9990079365079365


	Epoch 374
Training results:
gen_loss: 3.3237498
disc_loss: 0.011724746
disc_acc: 0.9955445544554455

Validation results:
gen_loss: 3.0642836
disc_loss: 0.0143013345
disc_acc: 0.9940476190476191


	Epoch 375
Training results:
gen_loss: 3.3242002
disc_loss: 0.011372012
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.9851136
disc_loss: 0.0092444755
disc_acc: 0.9955357142857143


	Epoch 376
Training results:
gen_loss: 3.3261578
disc_loss: 0.011646879
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.9436393
disc_loss: 0.004599702
disc_acc: 0.9985119047619048


	Epoch 377
Training results:
gen_loss: 3.3309748
disc_loss: 0.0062772916
disc_acc: 0.9978960396039604

Validation results:
gen_loss: 2.9753711
disc_loss: 0.19147119
disc_acc: 0.9250992063492064


	Epoch 378
Training results:
gen_loss: 3.315227
disc_loss: 0.012498465
disc_acc: 0.996410891089109

Validation results:
gen_loss: 2.7533274
disc_loss: 0.022020416
disc_acc: 0.9935515873015873


	Epoch 379
Training results:
gen_loss: 3.3148382
disc_loss: 0.008476391
disc_acc: 0.9972772277227723

Validation results:
gen_loss: 2.8884635
disc_loss: 0.0018925495
disc_acc: 1.0


	Epoch 380
Training results:
gen_loss: 3.3110888
disc_loss: 0.011617565
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 3.010224
disc_loss: 0.004748471
disc_acc: 0.998015873015873


	Epoch 381
Training results:
gen_loss: 3.3225965
disc_loss: 0.017763909
disc_acc: 0.9943069306930693

Validation results:
gen_loss: 3.081869
disc_loss: 0.010566483
disc_acc: 0.9955357142857143


	Epoch 382
Training results:
gen_loss: 3.3237987
disc_loss: 0.015619073
disc_acc: 0.9941831683168317

Validation results:
gen_loss: 2.891675
disc_loss: 0.009321054
disc_acc: 0.9970238095238095


	Epoch 383
Training results:
gen_loss: 3.320489
disc_loss: 0.0139768245
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 3.0117288
disc_loss: 0.0040943366
disc_acc: 0.9985119047619048


	Epoch 384
Training results:
gen_loss: 3.3200629
disc_loss: 0.010493357
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.9356532
disc_loss: 0.0027043351
disc_acc: 0.9990079365079365


	Epoch 385
Training results:
gen_loss: 3.3267095
disc_loss: 0.0076692384
disc_acc: 0.9977722772277228

Validation results:
gen_loss: 2.985769
disc_loss: 0.006663536
disc_acc: 0.9975198412698413


	Epoch 386
Training results:
gen_loss: 3.3194544
disc_loss: 0.012809281
disc_acc: 0.996039603960396

Validation results:
gen_loss: 2.9366863
disc_loss: 0.013748644
disc_acc: 0.9955357142857143


	Epoch 387
Training results:
gen_loss: 3.3250053
disc_loss: 0.0070061153
disc_acc: 0.998391089108911

Validation results:
gen_loss: 3.0562675
disc_loss: 0.00787711
disc_acc: 0.996031746031746


	Epoch 388
Training results:
gen_loss: 3.3331583
disc_loss: 0.008459805
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 2.9692185
disc_loss: 0.0076824133
disc_acc: 0.9965277777777778


	Epoch 389
Training results:
gen_loss: 3.316459
disc_loss: 0.010295985
disc_acc: 0.9966584158415842

Validation results:
gen_loss: 2.7520037
disc_loss: 0.0036577736
disc_acc: 0.9990079365079365


	Epoch 390
Training results:
gen_loss: 3.3280027
disc_loss: 0.010272336
disc_acc: 0.996410891089109

Validation results:
gen_loss: 2.9229727
disc_loss: 0.027894193
disc_acc: 0.9920634920634921


	Epoch 391
Training results:
gen_loss: 3.3243084
disc_loss: 0.012070142
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 2.8356457
disc_loss: 0.0038973389
disc_acc: 0.9985119047619048


	Epoch 392
Training results:
gen_loss: 3.341425
disc_loss: 0.011901472
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 3.15936
disc_loss: 0.2449846
disc_acc: 0.9315476190476191


	Epoch 393
Training results:
gen_loss: 3.3301897
disc_loss: 0.013669793
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 3.015359
disc_loss: 0.0041150977
disc_acc: 0.998015873015873


	Epoch 394
Training results:
gen_loss: 3.3421981
disc_loss: 0.0092327045
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 2.99767
disc_loss: 0.0024108547
disc_acc: 0.9990079365079365


	Epoch 395
Training results:
gen_loss: 3.3460324
disc_loss: 0.008876895
disc_acc: 0.9975247524752475

Validation results:
gen_loss: 2.9069796
disc_loss: 0.002480024
disc_acc: 0.9995039682539683


	Epoch 396
Training results:
gen_loss: 3.3436759
disc_loss: 0.008227006
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 2.8719761
disc_loss: 0.1247736
disc_acc: 0.9548611111111112


	Epoch 397
Training results:
gen_loss: 3.3433106
disc_loss: 0.010140488
disc_acc: 0.996410891089109

Validation results:
gen_loss: 3.0490706
disc_loss: 0.020746721
disc_acc: 0.9910714285714286


	Epoch 398
Training results:
gen_loss: 3.3430548
disc_loss: 0.008210492
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 3.0473278
disc_loss: 0.010032914
disc_acc: 0.9955357142857143


	Epoch 399
Training results:
gen_loss: 3.345855
disc_loss: 0.012639916
disc_acc: 0.9962871287128713

Validation results:
gen_loss: 2.9204538
disc_loss: 0.0087631475
disc_acc: 0.9965277777777778


	Epoch 400
Training results:
gen_loss: 3.3304925
disc_loss: 0.019170085
disc_acc: 0.9945544554455445

Validation results:
gen_loss: 2.9157455
disc_loss: 0.01511942
disc_acc: 0.9945436507936508


	Epoch 401
Training results:
gen_loss: 3.3232732
disc_loss: 0.012067204
disc_acc: 0.9955445544554455

Validation results:
gen_loss: 2.820597
disc_loss: 0.0045143384
disc_acc: 0.9990079365079365


	Epoch 402
Training results:
gen_loss: 3.3276734
disc_loss: 0.011357966
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.9662015
disc_loss: 0.0027086497
disc_acc: 0.9995039682539683


	Epoch 403
Training results:
gen_loss: 3.343377
disc_loss: 0.009696972
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 3.0083778
disc_loss: 0.008097087
disc_acc: 0.996031746031746


	Epoch 404
Training results:
gen_loss: 3.3348622
disc_loss: 0.013549941
disc_acc: 0.995049504950495

Validation results:
gen_loss: 3.0352197
disc_loss: 0.011470394
disc_acc: 0.9950396825396826


	Epoch 405
Training results:
gen_loss: 3.3233306
disc_loss: 0.013597197
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 2.6458232
disc_loss: 0.004448795
disc_acc: 0.9990079365079365


	Epoch 406
Training results:
gen_loss: 3.3371878
disc_loss: 0.0151514495
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 2.8615365
disc_loss: 0.014937577
disc_acc: 0.9950396825396826


	Epoch 407
Training results:
gen_loss: 3.321546
disc_loss: 0.014668165
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 3.0200405
disc_loss: 0.0068816296
disc_acc: 0.9975198412698413


	Epoch 408
Training results:
gen_loss: 3.3357055
disc_loss: 0.009240001
disc_acc: 0.9975247524752475

Validation results:
gen_loss: 3.0111675
disc_loss: 0.002226389
disc_acc: 0.9995039682539683


	Epoch 409
Training results:
gen_loss: 3.3453314
disc_loss: 0.011540435
disc_acc: 0.9966584158415842

Validation results:
gen_loss: 3.0115826
disc_loss: 0.011727481
disc_acc: 0.996031746031746


	Epoch 410
Training results:
gen_loss: 3.3432984
disc_loss: 0.009106737
disc_acc: 0.997029702970297

Validation results:
gen_loss: 2.9611216
disc_loss: 0.004523795
disc_acc: 0.9985119047619048


	Epoch 411
Training results:
gen_loss: 3.3503625
disc_loss: 0.008432588
disc_acc: 0.99740099009901

Validation results:
gen_loss: 2.9079332
disc_loss: 0.009429192
disc_acc: 0.9970238095238095


	Epoch 412
Training results:
gen_loss: 3.338995
disc_loss: 0.01351102
disc_acc: 0.9939356435643565

Validation results:
gen_loss: 2.8683245
disc_loss: 0.021678701
disc_acc: 0.9920634920634921


	Epoch 413
Training results:
gen_loss: 3.335026
disc_loss: 0.01397396
disc_acc: 0.9946782178217822

Validation results:
gen_loss: 2.988898
disc_loss: 0.024829982
disc_acc: 0.9910714285714286


	Epoch 414
Training results:
gen_loss: 3.339
disc_loss: 0.012965941
disc_acc: 0.9956683168316832

Validation results:
gen_loss: 3.0046375
disc_loss: 0.00633249
disc_acc: 0.998015873015873


	Epoch 415
Training results:
gen_loss: 3.3358345
disc_loss: 0.011121883
disc_acc: 0.996039603960396

Validation results:
gen_loss: 3.0374172
disc_loss: 0.0056189694
disc_acc: 0.9985119047619048


	Epoch 416
Training results:
gen_loss: 3.334416
disc_loss: 0.013351976
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 2.9432025
disc_loss: 0.0049280953
disc_acc: 0.9975198412698413


	Epoch 417
Training results:
gen_loss: 3.3456988
disc_loss: 0.006211813
disc_acc: 0.9982673267326733

Validation results:
gen_loss: 2.785966
disc_loss: 0.004939199
disc_acc: 0.998015873015873


	Epoch 418
Training results:
gen_loss: 3.352337
disc_loss: 0.007903385
disc_acc: 0.9975247524752475

Validation results:
gen_loss: 3.0837717
disc_loss: 0.025490763
disc_acc: 0.9925595238095238


	Epoch 419
Training results:
gen_loss: 3.3465457
disc_loss: 0.009703392
disc_acc: 0.997029702970297

Validation results:
gen_loss: 3.0008905
disc_loss: 0.0030207057
disc_acc: 0.9990079365079365


	Epoch 420
Training results:
gen_loss: 3.3512506
disc_loss: 0.011067606
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.8947864
disc_loss: 0.013552038
disc_acc: 0.9955357142857143


	Epoch 421
Training results:
gen_loss: 3.3566353
disc_loss: 0.0107033225
disc_acc: 0.996410891089109

Validation results:
gen_loss: 3.0727534
disc_loss: 0.0022343104
disc_acc: 1.0


	Epoch 422
Training results:
gen_loss: 3.3532696
disc_loss: 0.0073925788
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 3.0641427
disc_loss: 0.0040560844
disc_acc: 0.998015873015873


	Epoch 423
Training results:
gen_loss: 3.3603575
disc_loss: 0.0087707685
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 2.821864
disc_loss: 0.03472446
disc_acc: 0.9875992063492064


	Epoch 424
Training results:
gen_loss: 3.3463988
disc_loss: 0.018960724
disc_acc: 0.9931930693069307

Validation results:
gen_loss: 2.760662
disc_loss: 0.012614769
disc_acc: 0.9955357142857143


	Epoch 425
Training results:
gen_loss: 3.3483572
disc_loss: 0.01409114
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.9219887
disc_loss: 0.004176387
disc_acc: 0.9985119047619048


	Epoch 426
Training results:
gen_loss: 3.3537173
disc_loss: 0.010101423
disc_acc: 0.997029702970297

Validation results:
gen_loss: 3.0529947
disc_loss: 0.0029374827
disc_acc: 1.0


	Epoch 427
Training results:
gen_loss: 3.3529735
disc_loss: 0.008495726
disc_acc: 0.9978960396039604

Validation results:
gen_loss: 2.9443288
disc_loss: 0.0028146014
disc_acc: 0.9995039682539683


	Epoch 428
Training results:
gen_loss: 3.347828
disc_loss: 0.016058618
disc_acc: 0.9945544554455445

Validation results:
gen_loss: 2.92886
disc_loss: 0.004993747
disc_acc: 0.998015873015873


	Epoch 429
Training results:
gen_loss: 3.3552485
disc_loss: 0.010007229
disc_acc: 0.997029702970297

Validation results:
gen_loss: 3.0136304
disc_loss: 0.010970977
disc_acc: 0.9970238095238095


	Epoch 430
Training results:
gen_loss: 3.3560991
disc_loss: 0.009463171
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.9947882
disc_loss: 0.001462063
disc_acc: 1.0


	Epoch 431
Training results:
gen_loss: 3.3546224
disc_loss: 0.008970657
disc_acc: 0.997029702970297

Validation results:
gen_loss: 2.9930923
disc_loss: 0.0030459762
disc_acc: 0.9990079365079365


	Epoch 432
Training results:
gen_loss: 3.3607829
disc_loss: 0.00874461
disc_acc: 0.9975247524752475

Validation results:
gen_loss: 2.869453
disc_loss: 0.0037382783
disc_acc: 0.9995039682539683


	Epoch 433
Training results:
gen_loss: 3.3651063
disc_loss: 0.008076905
disc_acc: 0.9972772277227723

Validation results:
gen_loss: 2.99521
disc_loss: 0.007213055
disc_acc: 0.9975198412698413


	Epoch 434
Training results:
gen_loss: 3.3671215
disc_loss: 0.014135349
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 2.9135258
disc_loss: 0.008063976
disc_acc: 0.998015873015873


	Epoch 435
Training results:
gen_loss: 3.3553586
disc_loss: 0.011704649
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 2.734083
disc_loss: 0.012834592
disc_acc: 0.9945436507936508


	Epoch 436
Training results:
gen_loss: 3.3612947
disc_loss: 0.0076029957
disc_acc: 0.9981435643564357

Validation results:
gen_loss: 2.937046
disc_loss: 0.012619955
disc_acc: 0.9965277777777778


	Epoch 437
Training results:
gen_loss: 3.3629272
disc_loss: 0.009341285
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.9541311
disc_loss: 0.0118407095
disc_acc: 0.9945436507936508


	Epoch 438
Training results:
gen_loss: 3.3718755
disc_loss: 0.0075988723
disc_acc: 0.998391089108911

Validation results:
gen_loss: 2.915258
disc_loss: 0.0014438365
disc_acc: 1.0


	Epoch 439
Training results:
gen_loss: 3.3634102
disc_loss: 0.009591473
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.9739847
disc_loss: 0.012428061
disc_acc: 0.9940476190476191


	Epoch 440
Training results:
gen_loss: 3.362409
disc_loss: 0.013223452
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 3.0596743
disc_loss: 0.0041371407
disc_acc: 0.9985119047619048


	Epoch 441
Training results:
gen_loss: 3.3509953
disc_loss: 0.015659614
disc_acc: 0.994059405940594

Validation results:
gen_loss: 3.108725
disc_loss: 0.008626341
disc_acc: 0.9965277777777778


	Epoch 442
Training results:
gen_loss: 3.3652973
disc_loss: 0.010374755
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.978498
disc_loss: 0.0020417587
disc_acc: 0.9995039682539683


	Epoch 443
Training results:
gen_loss: 3.3617914
disc_loss: 0.0124775935
disc_acc: 0.9962871287128713

Validation results:
gen_loss: 3.074114
disc_loss: 0.009275018
disc_acc: 0.9970238095238095


	Epoch 444
Training results:
gen_loss: 3.3651376
disc_loss: 0.005959847
disc_acc: 0.998391089108911

Validation results:
gen_loss: 2.9560812
disc_loss: 0.0034867711
disc_acc: 0.9990079365079365


	Epoch 445
Training results:
gen_loss: 3.3495877
disc_loss: 0.010605681
disc_acc: 0.9962871287128713

Validation results:
gen_loss: 2.7854717
disc_loss: 0.008940862
disc_acc: 0.996031746031746


	Epoch 446
Training results:
gen_loss: 3.3604264
disc_loss: 0.010200099
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 3.02763
disc_loss: 0.008625221
disc_acc: 0.9955357142857143


	Epoch 447
Training results:
gen_loss: 3.3498013
disc_loss: 0.012077448
disc_acc: 0.995420792079208

Validation results:
gen_loss: 3.094358
disc_loss: 0.00510043
disc_acc: 0.9985119047619048


	Epoch 448
Training results:
gen_loss: 3.3613136
disc_loss: 0.006424203
disc_acc: 0.9978960396039604

Validation results:
gen_loss: 3.0392368
disc_loss: 0.0023701072
disc_acc: 0.9990079365079365


	Epoch 449
Training results:
gen_loss: 3.3711238
disc_loss: 0.009727522
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 3.0268822
disc_loss: 0.008717726
disc_acc: 0.9970238095238095


	Epoch 450
Training results:
gen_loss: 3.3587446
disc_loss: 0.00982806
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 2.8878846
disc_loss: 0.0017139834
disc_acc: 1.0


	Epoch 451
Training results:
gen_loss: 3.348815
disc_loss: 0.009540021
disc_acc: 0.997029702970297

Validation results:
gen_loss: 3.010075
disc_loss: 0.03247978
disc_acc: 0.9890873015873016


	Epoch 452
Training results:
gen_loss: 3.3573918
disc_loss: 0.01381434
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 3.0459075
disc_loss: 0.51548845
disc_acc: 0.8670634920634921


	Epoch 453
Training results:
gen_loss: 3.3739436
disc_loss: 0.0072958525
disc_acc: 0.9978960396039604

Validation results:
gen_loss: 3.0966027
disc_loss: 0.32899922
disc_acc: 0.9161706349206349


	Epoch 454
Training results:
gen_loss: 3.3777993
disc_loss: 0.006383059
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 3.027766
disc_loss: 0.0019533862
disc_acc: 0.9990079365079365


	Epoch 455
Training results:
gen_loss: 3.3890564
disc_loss: 0.0040383837
disc_acc: 0.9988861386138614

Validation results:
gen_loss: 3.0628269
disc_loss: 0.014604119
disc_acc: 0.9950396825396826


	Epoch 456
Training results:
gen_loss: 3.3756797
disc_loss: 0.01291178
disc_acc: 0.9955445544554455

Validation results:
gen_loss: 3.014545
disc_loss: 0.0022249245
disc_acc: 0.9995039682539683


	Epoch 457
Training results:
gen_loss: 3.3676307
disc_loss: 0.011063916
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.9678748
disc_loss: 0.004566061
disc_acc: 0.9985119047619048


	Epoch 458
Training results:
gen_loss: 3.3729806
disc_loss: 0.0055473857
disc_acc: 0.9988861386138614

Validation results:
gen_loss: 3.0140681
disc_loss: 0.0016732505
disc_acc: 1.0


	Epoch 459
Training results:
gen_loss: 3.3749526
disc_loss: 0.014127307
disc_acc: 0.995420792079208

Validation results:
gen_loss: 3.0324762
disc_loss: 0.0064916634
disc_acc: 0.9985119047619048


	Epoch 460
Training results:
gen_loss: 3.3874388
disc_loss: 0.009034232
disc_acc: 0.9966584158415842

Validation results:
gen_loss: 3.0848749
disc_loss: 0.0063556903
disc_acc: 0.998015873015873


	Epoch 461
Training results:
gen_loss: 3.3914685
disc_loss: 0.014750697
disc_acc: 0.995420792079208

Validation results:
gen_loss: 3.09896
disc_loss: 0.0092711365
disc_acc: 0.9970238095238095


	Epoch 462
Training results:
gen_loss: 3.3803108
disc_loss: 0.0105808005
disc_acc: 0.9966584158415842

Validation results:
gen_loss: 2.81046
disc_loss: 0.19168673
disc_acc: 0.9370039682539683


	Epoch 463
Training results:
gen_loss: 3.3829985
disc_loss: 0.014289178
disc_acc: 0.995420792079208

Validation results:
gen_loss: 2.7916064
disc_loss: 0.008780911
disc_acc: 0.9965277777777778


	Epoch 464
Training results:
gen_loss: 3.3783803
disc_loss: 0.0085972175
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.972022
disc_loss: 0.0032029438
disc_acc: 0.9985119047619048


	Epoch 465
Training results:
gen_loss: 3.3780375
disc_loss: 0.0045556994
disc_acc: 0.9991336633663367

Validation results:
gen_loss: 3.049188
disc_loss: 0.0068101347
disc_acc: 0.998015873015873


	Epoch 466
Training results:
gen_loss: 3.3713481
disc_loss: 0.01373716
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 2.9131038
disc_loss: 0.16765767
disc_acc: 0.9459325396825397


	Epoch 467
Training results:
gen_loss: 3.3694148
disc_loss: 0.012390166
disc_acc: 0.9955445544554455

Validation results:
gen_loss: 2.9343324
disc_loss: 0.0070127132
disc_acc: 0.9975198412698413


	Epoch 468
Training results:
gen_loss: 3.365074
disc_loss: 0.009540677
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.9392602
disc_loss: 0.004041826
disc_acc: 0.9990079365079365


	Epoch 469
Training results:
gen_loss: 3.374897
disc_loss: 0.006445891
disc_acc: 0.9978960396039604

Validation results:
gen_loss: 2.9479396
disc_loss: 0.0021927564
disc_acc: 0.9995039682539683


	Epoch 470
Training results:
gen_loss: 3.3899534
disc_loss: 0.007563046
disc_acc: 0.998019801980198

Validation results:
gen_loss: 3.0589945
disc_loss: 0.32434872
disc_acc: 0.9117063492063492


	Epoch 471
Training results:
gen_loss: 3.390221
disc_loss: 0.009015496
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.8768742
disc_loss: 0.03015702
disc_acc: 0.9935515873015873


	Epoch 472
Training results:
gen_loss: 3.3992763
disc_loss: 0.0054037906
disc_acc: 0.9988861386138614

Validation results:
gen_loss: 3.0144796
disc_loss: 0.0027539989
disc_acc: 0.9985119047619048


	Epoch 473
Training results:
gen_loss: 3.3987982
disc_loss: 0.0110758385
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.9850695
disc_loss: 0.004708285
disc_acc: 0.9985119047619048


	Epoch 474
Training results:
gen_loss: 3.3922474
disc_loss: 0.011585192
disc_acc: 0.9962871287128713

Validation results:
gen_loss: 3.1187391
disc_loss: 0.004876561
disc_acc: 0.998015873015873


	Epoch 475
Training results:
gen_loss: 3.3953023
disc_loss: 0.00869404
disc_acc: 0.9977722772277228

Validation results:
gen_loss: 3.027076
disc_loss: 0.043974433
disc_acc: 0.9841269841269841


	Epoch 476
Training results:
gen_loss: 3.395972
disc_loss: 0.0072977967
disc_acc: 0.9977722772277228

Validation results:
gen_loss: 3.05491
disc_loss: 0.0041583846
disc_acc: 0.9990079365079365


	Epoch 477
Training results:
gen_loss: 3.403037
disc_loss: 0.008842145
disc_acc: 0.997029702970297

Validation results:
gen_loss: 2.962352
disc_loss: 0.11762941
disc_acc: 0.9573412698412699


	Epoch 478
Training results:
gen_loss: 3.3972294
disc_loss: 0.011372236
disc_acc: 0.996039603960396

Validation results:
gen_loss: 2.922043
disc_loss: 0.006344992
disc_acc: 0.998015873015873


	Epoch 479
Training results:
gen_loss: 3.40126
disc_loss: 0.005272679
disc_acc: 0.998391089108911

Validation results:
gen_loss: 2.9346714
disc_loss: 0.004586671
disc_acc: 0.998015873015873


	Epoch 480
Training results:
gen_loss: 3.4011776
disc_loss: 0.007827903
disc_acc: 0.9975247524752475

Validation results:
gen_loss: 3.0122552
disc_loss: 0.00784135
disc_acc: 0.9975198412698413


	Epoch 481
Training results:
gen_loss: 3.409868
disc_loss: 0.0063258167
disc_acc: 0.9977722772277228

Validation results:
gen_loss: 3.1209962
disc_loss: 0.13511111
disc_acc: 0.9548611111111112


	Epoch 482
Training results:
gen_loss: 3.4006767
disc_loss: 0.00848913
disc_acc: 0.997029702970297

Validation results:
gen_loss: 2.9749904
disc_loss: 0.020558719
disc_acc: 0.9925595238095238


	Epoch 483
Training results:
gen_loss: 3.399838
disc_loss: 0.014309298
disc_acc: 0.995420792079208

Validation results:
gen_loss: 3.0811346
disc_loss: 0.025575364
disc_acc: 0.9915674603174603


	Epoch 484
Training results:
gen_loss: 3.4023955
disc_loss: 0.007950384
disc_acc: 0.9977722772277228

Validation results:
gen_loss: 3.0771592
disc_loss: 0.0012974142
disc_acc: 1.0


	Epoch 485
Training results:
gen_loss: 3.408649
disc_loss: 0.0068614357
disc_acc: 0.9982673267326733

Validation results:
gen_loss: 3.0116591
disc_loss: 0.005453707
disc_acc: 0.9985119047619048


	Epoch 486
Training results:
gen_loss: 3.399328
disc_loss: 0.007225272
disc_acc: 0.9978960396039604

Validation results:
gen_loss: 3.0356054
disc_loss: 0.0039100894
disc_acc: 0.9985119047619048


	Epoch 487
Training results:
gen_loss: 3.41403
disc_loss: 0.0045754197
disc_acc: 0.9987623762376238

Validation results:
gen_loss: 3.08044
disc_loss: 0.005243143
disc_acc: 0.9990079365079365


	Epoch 488
Training results:
gen_loss: 3.4104972
disc_loss: 0.0040931245
disc_acc: 0.9988861386138614

Validation results:
gen_loss: 3.0483787
disc_loss: 0.0027872608
disc_acc: 0.9990079365079365


	Epoch 489
Training results:
gen_loss: 3.421789
disc_loss: 0.004587922
disc_acc: 0.999009900990099

Validation results:
gen_loss: 3.0789785
disc_loss: 0.0010953131
disc_acc: 1.0


	Epoch 490
Training results:
gen_loss: 3.4176464
disc_loss: 0.0073359497
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 2.8787494
disc_loss: 0.26927087
disc_acc: 0.904265873015873


	Epoch 491
Training results:
gen_loss: 3.3932724
disc_loss: 0.010566666
disc_acc: 0.996410891089109

Validation results:
gen_loss: 3.042443
disc_loss: 0.0022749116
disc_acc: 0.9990079365079365


	Epoch 492
Training results:
gen_loss: 3.4121168
disc_loss: 0.008648815
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 2.9849937
disc_loss: 0.0340034
disc_acc: 0.9875992063492064


	Epoch 493
Training results:
gen_loss: 3.404828
disc_loss: 0.007271205
disc_acc: 0.9978960396039604

Validation results:
gen_loss: 3.1622458
disc_loss: 0.002612333
disc_acc: 0.9995039682539683


	Epoch 494
Training results:
gen_loss: 3.4170942
disc_loss: 0.009953194
disc_acc: 0.997029702970297

Validation results:
gen_loss: 2.9900057
disc_loss: 0.010627355
disc_acc: 0.9965277777777778


	Epoch 495
Training results:
gen_loss: 3.4028418
disc_loss: 0.00779291
disc_acc: 0.9982673267326733

Validation results:
gen_loss: 3.1270149
disc_loss: 0.0042001945
disc_acc: 0.9985119047619048


	Epoch 496
Training results:
gen_loss: 3.4043655
disc_loss: 0.00893227
disc_acc: 0.9975247524752475

Validation results:
gen_loss: 3.0501251
disc_loss: 0.0033585583
disc_acc: 0.9990079365079365


	Epoch 497
Training results:
gen_loss: 3.4019077
disc_loss: 0.0053693615
disc_acc: 0.9987623762376238

Validation results:
gen_loss: 3.0035908
disc_loss: 0.0022336894
disc_acc: 0.9995039682539683


	Epoch 498
Training results:
gen_loss: 3.4081266
disc_loss: 0.014208799
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 3.0046825
disc_loss: 0.0047371713
disc_acc: 0.9985119047619048


	Epoch 499
Training results:
gen_loss: 3.4006503
disc_loss: 0.00928357
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.9697819
disc_loss: 0.0037700625
disc_acc: 0.9990079365079365


	Epoch 500
Training results:
gen_loss: 3.408203
disc_loss: 0.008987838
disc_acc: 0.9975247524752475

Validation results:
gen_loss: 3.0590317
disc_loss: 0.0047160657
disc_acc: 0.9990079365079365



Training new discriminator on static trained discriminator.
	Initial performance
Training results:
gen_loss: 0.01795847
disc_loss: 5.537566
disc_acc: 0.0

Validation results:
gen_loss: 0.017141925
disc_loss: 5.535686
disc_acc: 0.0


	Epoch 1
Training results:
gen_loss: 1.6405356
disc_loss: 2.194394
disc_acc: 0.47376237623762374

Validation results:
gen_loss: 1.5739228
disc_loss: 1.6613144
disc_acc: 0.3834325396825397


	Epoch 2
Training results:
gen_loss: 1.9441719
disc_loss: 0.7292743
disc_acc: 0.8110148514851485

Validation results:
gen_loss: 1.5944192
disc_loss: 1.4396789
disc_acc: 0.44990079365079366


	Epoch 3
Training results:
gen_loss: 2.0781786
disc_loss: 0.44072887
disc_acc: 0.8886138613861386

Validation results:
gen_loss: 1.9234556
disc_loss: 1.6667713
disc_acc: 0.4126984126984127


	Epoch 4
Training results:
gen_loss: 2.1582906
disc_loss: 0.33651352
disc_acc: 0.9153465346534654

Validation results:
gen_loss: 1.7026368
disc_loss: 1.9840822
disc_acc: 0.3978174603174603


	Epoch 5
Training results:
gen_loss: 2.2156339
disc_loss: 0.28551018
disc_acc: 0.9238861386138614

Validation results:
gen_loss: 1.8022975
disc_loss: 3.3763282
disc_acc: 0.3149801587301587


	Epoch 6
Training results:
gen_loss: 2.2637575
disc_loss: 0.24950475
disc_acc: 0.9346534653465347

Validation results:
gen_loss: 1.5787522
disc_loss: 0.92357415
disc_acc: 0.6731150793650794


	Epoch 7
Training results:
gen_loss: 2.3035674
disc_loss: 0.22599918
disc_acc: 0.9409653465346535

Validation results:
gen_loss: 1.9279988
disc_loss: 0.7961775
disc_acc: 0.6845238095238095


	Epoch 8
Training results:
gen_loss: 2.343037
disc_loss: 0.20433912
disc_acc: 0.9439356435643564

Validation results:
gen_loss: 1.6029027
disc_loss: 0.78820986
disc_acc: 0.6364087301587301


	Epoch 9
Training results:
gen_loss: 2.3571198
disc_loss: 0.20098856
disc_acc: 0.9443069306930693

Validation results:
gen_loss: 1.8118384
disc_loss: 0.5884231
disc_acc: 0.7867063492063492


	Epoch 10
Training results:
gen_loss: 2.391047
disc_loss: 0.17972398
disc_acc: 0.9533415841584159

Validation results:
gen_loss: 2.1283307
disc_loss: 3.8871963
disc_acc: 0.3740079365079365


	Epoch 11
Training results:
gen_loss: 2.4050496
disc_loss: 0.17448163
disc_acc: 0.9493811881188119

Validation results:
gen_loss: 1.9387225
disc_loss: 1.6816523
disc_acc: 0.5223214285714286


	Epoch 12
Training results:
gen_loss: 2.4251764
disc_loss: 0.15937059
disc_acc: 0.9561881188118811

Validation results:
gen_loss: 2.211014
disc_loss: 0.73273325
disc_acc: 0.7053571428571429


	Epoch 13
Training results:
gen_loss: 2.4493728
disc_loss: 0.14602256
disc_acc: 0.9597772277227723

Validation results:
gen_loss: 1.8338948
disc_loss: 0.21215534
disc_acc: 0.9404761904761905


	Epoch 14
Training results:
gen_loss: 2.4599988
disc_loss: 0.14733726
disc_acc: 0.959529702970297

Validation results:
gen_loss: 1.9166293
disc_loss: 0.32424483
disc_acc: 0.8983134920634921


	Epoch 15
Training results:
gen_loss: 2.4829156
disc_loss: 0.1391299
disc_acc: 0.9603960396039604

Validation results:
gen_loss: 1.9993862
disc_loss: 3.399365
disc_acc: 0.3392857142857143


	Epoch 16
Training results:
gen_loss: 2.4983225
disc_loss: 0.13548292
disc_acc: 0.9596534653465346

Validation results:
gen_loss: 2.1858842
disc_loss: 1.3910501
disc_acc: 0.5719246031746031


	Epoch 17
Training results:
gen_loss: 2.504934
disc_loss: 0.12228032
disc_acc: 0.9655940594059406

Validation results:
gen_loss: 2.0847144
disc_loss: 0.5885608
disc_acc: 0.8328373015873016


	Epoch 18
Training results:
gen_loss: 2.5212672
disc_loss: 0.12020087
disc_acc: 0.9631188118811881

Validation results:
gen_loss: 2.1356363
disc_loss: 1.0103651
disc_acc: 0.6433531746031746


	Epoch 19
Training results:
gen_loss: 2.551517
disc_loss: 0.11062876
disc_acc: 0.9672029702970297

Validation results:
gen_loss: 2.0774846
disc_loss: 0.47556773
disc_acc: 0.8100198412698413


	Epoch 20
Training results:
gen_loss: 2.5563896
disc_loss: 0.10479792
disc_acc: 0.968440594059406

Validation results:
gen_loss: 2.0527833
disc_loss: 0.26331583
disc_acc: 0.8998015873015873


	Epoch 21
Training results:
gen_loss: 2.5685897
disc_loss: 0.095213994
disc_acc: 0.973019801980198

Validation results:
gen_loss: 2.0192034
disc_loss: 2.0411372
disc_acc: 0.47867063492063494


	Epoch 22
Training results:
gen_loss: 2.5831463
disc_loss: 0.09911049
disc_acc: 0.9716584158415842

Validation results:
gen_loss: 1.9530759
disc_loss: 0.28462836
disc_acc: 0.9146825396825397


	Epoch 23
Training results:
gen_loss: 2.5851548
disc_loss: 0.100083135
disc_acc: 0.9702970297029703

Validation results:
gen_loss: 2.2110412
disc_loss: 0.5130241
disc_acc: 0.8283730158730159


	Epoch 24
Training results:
gen_loss: 2.587803
disc_loss: 0.09722265
disc_acc: 0.9705445544554455

Validation results:
gen_loss: 2.261425
disc_loss: 2.7567508
disc_acc: 0.45982142857142855


	Epoch 25
Training results:
gen_loss: 2.6084132
disc_loss: 0.09575546
disc_acc: 0.9733910891089109

Validation results:
gen_loss: 2.103134
disc_loss: 0.16582681
disc_acc: 0.9384920634920635


	Epoch 26
Training results:
gen_loss: 2.613426
disc_loss: 0.087696515
disc_acc: 0.9747524752475247

Validation results:
gen_loss: 2.220617
disc_loss: 0.050690718
disc_acc: 0.9920634920634921


	Epoch 27
Training results:
gen_loss: 2.6247418
disc_loss: 0.09268208
disc_acc: 0.9725247524752475

Validation results:
gen_loss: 2.1058955
disc_loss: 0.32583818
disc_acc: 0.8591269841269841


	Epoch 28
Training results:
gen_loss: 2.6302705
disc_loss: 0.09200819
disc_acc: 0.972029702970297

Validation results:
gen_loss: 2.1460571
disc_loss: 0.26994812
disc_acc: 0.8883928571428571


	Epoch 29
Training results:
gen_loss: 2.6348956
disc_loss: 0.08220823
disc_acc: 0.9754950495049505

Validation results:
gen_loss: 1.9942992
disc_loss: 0.5253648
disc_acc: 0.8080357142857143


	Epoch 30
Training results:
gen_loss: 2.6408348
disc_loss: 0.077035174
disc_acc: 0.9775990099009901

Validation results:
gen_loss: 2.094796
disc_loss: 1.6616843
disc_acc: 0.5848214285714286


	Epoch 31
Training results:
gen_loss: 2.6506832
disc_loss: 0.07579761
disc_acc: 0.975990099009901

Validation results:
gen_loss: 2.2586815
disc_loss: 3.2410846
disc_acc: 0.4652777777777778


	Epoch 32
Training results:
gen_loss: 2.662413
disc_loss: 0.076773874
disc_acc: 0.973019801980198

Validation results:
gen_loss: 2.2793465
disc_loss: 0.03549887
disc_acc: 0.9915674603174603


	Epoch 33
Training results:
gen_loss: 2.683787
disc_loss: 0.07756968
disc_acc: 0.9752475247524752

Validation results:
gen_loss: 2.1702142
disc_loss: 0.10521133
disc_acc: 0.9642857142857143


	Epoch 34
Training results:
gen_loss: 2.6920033
disc_loss: 0.07392053
disc_acc: 0.9772277227722772

Validation results:
gen_loss: 2.147104
disc_loss: 0.5478261
disc_acc: 0.7678571428571429


	Epoch 35
Training results:
gen_loss: 2.6893134
disc_loss: 0.070289776
disc_acc: 0.9774752475247525

Validation results:
gen_loss: 2.473287
disc_loss: 0.022965208
disc_acc: 0.9945436507936508


	Epoch 36
Training results:
gen_loss: 2.6991804
disc_loss: 0.06971872
disc_acc: 0.9773514851485149

Validation results:
gen_loss: 2.2684886
disc_loss: 0.7257642
disc_acc: 0.7425595238095238


	Epoch 37
Training results:
gen_loss: 2.7062612
disc_loss: 0.07297907
disc_acc: 0.9756188118811882

Validation results:
gen_loss: 2.211228
disc_loss: 0.27492496
disc_acc: 0.8988095238095238


	Epoch 38
Training results:
gen_loss: 2.7060778
disc_loss: 0.069462284
disc_acc: 0.977970297029703

Validation results:
gen_loss: 2.0447776
disc_loss: 0.23056348
disc_acc: 0.9285714285714286


	Epoch 39
Training results:
gen_loss: 2.7173963
disc_loss: 0.06543488
disc_acc: 0.9794554455445544

Validation results:
gen_loss: 2.2186313
disc_loss: 1.0751954
disc_acc: 0.7569444444444444


	Epoch 40
Training results:
gen_loss: 2.7179298
disc_loss: 0.067294545
disc_acc: 0.9792079207920792

Validation results:
gen_loss: 2.2544558
disc_loss: 0.2232637
disc_acc: 0.9270833333333334


	Epoch 41
Training results:
gen_loss: 2.7348309
disc_loss: 0.067870684
disc_acc: 0.9778465346534654

Validation results:
gen_loss: 2.3678157
disc_loss: 0.018241128
disc_acc: 0.9970238095238095


	Epoch 42
Training results:
gen_loss: 2.7359943
disc_loss: 0.07330596
disc_acc: 0.976980198019802

Validation results:
gen_loss: 2.4271595
disc_loss: 0.09072353
disc_acc: 0.9682539682539683


	Epoch 43
Training results:
gen_loss: 2.7370124
disc_loss: 0.070009224
disc_acc: 0.9783415841584159

Validation results:
gen_loss: 2.3835635
disc_loss: 0.3829805
disc_acc: 0.8735119047619048


	Epoch 44
Training results:
gen_loss: 2.739197
disc_loss: 0.06642661
disc_acc: 0.9775990099009901

Validation results:
gen_loss: 2.26909
disc_loss: 0.2966079
disc_acc: 0.8725198412698413


	Epoch 45
Training results:
gen_loss: 2.7479818
disc_loss: 0.06428238
disc_acc: 0.9801980198019802

Validation results:
gen_loss: 2.375041
disc_loss: 2.5754683
disc_acc: 0.4632936507936508


	Epoch 46
Training results:
gen_loss: 2.7466958
disc_loss: 0.059680365
disc_acc: 0.9806930693069307

Validation results:
gen_loss: 2.1618776
disc_loss: 0.5436537
disc_acc: 0.8129960317460317


	Epoch 47
Training results:
gen_loss: 2.7459269
disc_loss: 0.058562666
disc_acc: 0.9815594059405941

Validation results:
gen_loss: 2.3209398
disc_loss: 1.76907
disc_acc: 0.6641865079365079


	Epoch 48
Training results:
gen_loss: 2.7428446
disc_loss: 0.067832574
disc_acc: 0.9775990099009901

Validation results:
gen_loss: 2.3472056
disc_loss: 0.12724315
disc_acc: 0.9573412698412699


	Epoch 49
Training results:
gen_loss: 2.7573392
disc_loss: 0.055050902
disc_acc: 0.9831683168316832

Validation results:
gen_loss: 2.2227345
disc_loss: 0.14755514
disc_acc: 0.9469246031746031


	Epoch 50
Training results:
gen_loss: 2.767941
disc_loss: 0.05465746
disc_acc: 0.9844059405940594

Validation results:
gen_loss: 2.2946167
disc_loss: 0.49853817
disc_acc: 0.7708333333333334


	Epoch 51
Training results:
gen_loss: 2.7625668
disc_loss: 0.049986277
disc_acc: 0.9852722772277228

Validation results:
gen_loss: 2.29193
disc_loss: 0.101330794
disc_acc: 0.9662698412698413


	Epoch 52
Training results:
gen_loss: 2.781034
disc_loss: 0.047873635
disc_acc: 0.9852722772277228

Validation results:
gen_loss: 2.6711175
disc_loss: 3.1285203
disc_acc: 0.5064484126984127


	Epoch 53
Training results:
gen_loss: 2.7864711
disc_loss: 0.05556371
disc_acc: 0.9820544554455446

Validation results:
gen_loss: 2.2371652
disc_loss: 0.19374119
disc_acc: 0.9330357142857143


	Epoch 54
Training results:
gen_loss: 2.7899601
disc_loss: 0.049996745
disc_acc: 0.9830445544554456

Validation results:
gen_loss: 2.3879101
disc_loss: 0.07319786
disc_acc: 0.972718253968254


	Epoch 55
Training results:
gen_loss: 2.7973175
disc_loss: 0.0573093
disc_acc: 0.9814356435643564

Validation results:
gen_loss: 2.3513749
disc_loss: 0.5919456
disc_acc: 0.8035714285714286


	Epoch 56
Training results:
gen_loss: 2.7917297
disc_loss: 0.0614607
disc_acc: 0.9789603960396039

Validation results:
gen_loss: 2.342903
disc_loss: 0.041174065
disc_acc: 0.9920634920634921


	Epoch 57
Training results:
gen_loss: 2.797899
disc_loss: 0.046659555
disc_acc: 0.9850247524752476

Validation results:
gen_loss: 2.1616707
disc_loss: 0.14147846
disc_acc: 0.9538690476190477


	Epoch 58
Training results:
gen_loss: 2.8003602
disc_loss: 0.054968268
disc_acc: 0.9819306930693069

Validation results:
gen_loss: 2.3256142
disc_loss: 2.7008898
disc_acc: 0.5545634920634921


	Epoch 59
Training results:
gen_loss: 2.8051434
disc_loss: 0.050743956
disc_acc: 0.9839108910891089

Validation results:
gen_loss: 2.2765443
disc_loss: 1.731469
disc_acc: 0.6502976190476191


	Epoch 60
Training results:
gen_loss: 2.8058412
disc_loss: 0.051339123
disc_acc: 0.9839108910891089

Validation results:
gen_loss: 2.2995698
disc_loss: 0.040665843
disc_acc: 0.9866071428571429


	Epoch 61
Training results:
gen_loss: 2.8134754
disc_loss: 0.048334114
disc_acc: 0.9845297029702971

Validation results:
gen_loss: 2.3254762
disc_loss: 0.21882313
disc_acc: 0.9136904761904762


	Epoch 62
Training results:
gen_loss: 2.8220048
disc_loss: 0.041724402
disc_acc: 0.9875

Validation results:
gen_loss: 2.4040153
disc_loss: 0.1688158
disc_acc: 0.9345238095238095


	Epoch 63
Training results:
gen_loss: 2.8208215
disc_loss: 0.051508658
disc_acc: 0.9844059405940594

Validation results:
gen_loss: 2.2603252
disc_loss: 1.3099002
disc_acc: 0.7088293650793651


	Epoch 64
Training results:
gen_loss: 2.8362248
disc_loss: 0.046121176
disc_acc: 0.9840346534653466

Validation results:
gen_loss: 2.2571642
disc_loss: 0.10600852
disc_acc: 0.9742063492063492


	Epoch 65
Training results:
gen_loss: 2.8526735
disc_loss: 0.03896456
disc_acc: 0.9866336633663366

Validation results:
gen_loss: 2.4498816
disc_loss: 0.093590505
disc_acc: 0.9652777777777778


	Epoch 66
Training results:
gen_loss: 2.8489726
disc_loss: 0.042039547
disc_acc: 0.9867574257425743

Validation results:
gen_loss: 2.2392325
disc_loss: 0.6808127
disc_acc: 0.8353174603174603


	Epoch 67
Training results:
gen_loss: 2.8506672
disc_loss: 0.04932226
disc_acc: 0.9830445544554456

Validation results:
gen_loss: 2.3716269
disc_loss: 0.027003996
disc_acc: 0.9945436507936508


	Epoch 68
Training results:
gen_loss: 2.8598964
disc_loss: 0.039336372
disc_acc: 0.9870049504950495

Validation results:
gen_loss: 2.3018816
disc_loss: 0.4410776
disc_acc: 0.8824404761904762


	Epoch 69
Training results:
gen_loss: 2.8701656
disc_loss: 0.04398621
disc_acc: 0.9856435643564356

Validation results:
gen_loss: 2.4538376
disc_loss: 0.01625021
disc_acc: 0.9975198412698413


	Epoch 70
Training results:
gen_loss: 2.8653946
disc_loss: 0.040787783
disc_acc: 0.9863861386138614

Validation results:
gen_loss: 2.4512165
disc_loss: 0.014937602
disc_acc: 0.9955357142857143


	Epoch 71
Training results:
gen_loss: 2.8698566
disc_loss: 0.039980866
disc_acc: 0.9862623762376238

Validation results:
gen_loss: 2.190132
disc_loss: 0.2692919
disc_acc: 0.9434523809523809


	Epoch 72
Training results:
gen_loss: 2.8729036
disc_loss: 0.04554919
disc_acc: 0.9845297029702971

Validation results:
gen_loss: 2.4319913
disc_loss: 0.37170142
disc_acc: 0.9077380952380952


	Epoch 73
Training results:
gen_loss: 2.8759277
disc_loss: 0.047276095
disc_acc: 0.9840346534653466

Validation results:
gen_loss: 2.5837054
disc_loss: 0.11442397
disc_acc: 0.9499007936507936


	Epoch 74
Training results:
gen_loss: 2.8751643
disc_loss: 0.044027723
disc_acc: 0.9841584158415841

Validation results:
gen_loss: 2.3490334
disc_loss: 0.9483648
disc_acc: 0.6820436507936508


	Epoch 75
Training results:
gen_loss: 2.8807864
disc_loss: 0.040340733
disc_acc: 0.9862623762376238

Validation results:
gen_loss: 2.4339173
disc_loss: 0.032125082
disc_acc: 0.9895833333333334


	Epoch 76
Training results:
gen_loss: 2.8793325
disc_loss: 0.04244446
disc_acc: 0.9862623762376238

Validation results:
gen_loss: 2.2977211
disc_loss: 0.09599833
disc_acc: 0.9672619047619048


	Epoch 77
Training results:
gen_loss: 2.8807771
disc_loss: 0.038978353
disc_acc: 0.9872524752475248

Validation results:
gen_loss: 2.5841694
disc_loss: 0.04036792
disc_acc: 0.9905753968253969


	Epoch 78
Training results:
gen_loss: 2.8755379
disc_loss: 0.04911841
disc_acc: 0.9844059405940594

Validation results:
gen_loss: 2.226256
disc_loss: 0.10333258
disc_acc: 0.9632936507936508


	Epoch 79
Training results:
gen_loss: 2.887287
disc_loss: 0.04943273
disc_acc: 0.9841584158415841

Validation results:
gen_loss: 2.5969117
disc_loss: 0.029453607
disc_acc: 0.9930555555555556


	Epoch 80
Training results:
gen_loss: 2.8823435
disc_loss: 0.050520558
disc_acc: 0.9830445544554456

Validation results:
gen_loss: 2.5170941
disc_loss: 0.05394024
disc_acc: 0.9806547619047619


	Epoch 81
Training results:
gen_loss: 2.8995156
disc_loss: 0.038065188
disc_acc: 0.9872524752475248

Validation results:
gen_loss: 2.4805648
disc_loss: 0.10411135
disc_acc: 0.9573412698412699


	Epoch 82
Training results:
gen_loss: 2.9002726
disc_loss: 0.04243119
disc_acc: 0.9871287128712871

Validation results:
gen_loss: 2.4965022
disc_loss: 0.6388549
disc_acc: 0.7906746031746031


	Epoch 83
Training results:
gen_loss: 2.9024806
disc_loss: 0.03407434
disc_acc: 0.9889851485148515

Validation results:
gen_loss: 2.5366652
disc_loss: 0.02417018
disc_acc: 0.9925595238095238


	Epoch 84
Training results:
gen_loss: 2.9080765
disc_loss: 0.03734491
disc_acc: 0.9882425742574258

Validation results:
gen_loss: 2.4206603
disc_loss: 0.059303313
disc_acc: 0.9801587301587301


	Epoch 85
Training results:
gen_loss: 2.9007876
disc_loss: 0.040117335
disc_acc: 0.9856435643564356

Validation results:
gen_loss: 2.5516973
disc_loss: 0.0969635
disc_acc: 0.9593253968253969


	Epoch 86
Training results:
gen_loss: 2.900246
disc_loss: 0.042427342
disc_acc: 0.986509900990099

Validation results:
gen_loss: 2.6682599
disc_loss: 0.093049236
disc_acc: 0.9642857142857143


	Epoch 87
Training results:
gen_loss: 2.9096708
disc_loss: 0.04041754
disc_acc: 0.9875

Validation results:
gen_loss: 2.4959536
disc_loss: 0.48650536
disc_acc: 0.8462301587301587


	Epoch 88
Training results:
gen_loss: 2.9139163
disc_loss: 0.03618585
disc_acc: 0.9889851485148515

Validation results:
gen_loss: 2.5225685
disc_loss: 0.4821463
disc_acc: 0.8834325396825397


	Epoch 89
Training results:
gen_loss: 2.9109235
disc_loss: 0.03693689
disc_acc: 0.988490099009901

Validation results:
gen_loss: 2.652713
disc_loss: 0.016483363
disc_acc: 0.9950396825396826


	Epoch 90
Training results:
gen_loss: 2.9161532
disc_loss: 0.043506302
disc_acc: 0.986509900990099

Validation results:
gen_loss: 2.5072334
disc_loss: 0.024488578
disc_acc: 0.9935515873015873


	Epoch 91
Training results:
gen_loss: 2.9256988
disc_loss: 0.03496826
disc_acc: 0.988490099009901

Validation results:
gen_loss: 2.671293
disc_loss: 1.0042
disc_acc: 0.8120039682539683


	Epoch 92
Training results:
gen_loss: 2.928791
disc_loss: 0.033526573
disc_acc: 0.9896039603960396

Validation results:
gen_loss: 2.3984835
disc_loss: 0.16815919
disc_acc: 0.9320436507936508


	Epoch 93
Training results:
gen_loss: 2.932128
disc_loss: 0.03199651
disc_acc: 0.9900990099009901

Validation results:
gen_loss: 2.5112004
disc_loss: 0.1898444
disc_acc: 0.9439484126984127


	Epoch 94
Training results:
gen_loss: 2.9318945
disc_loss: 0.04161765
disc_acc: 0.9862623762376238

Validation results:
gen_loss: 2.4795668
disc_loss: 0.31245008
disc_acc: 0.8859126984126984


	Epoch 95
Training results:
gen_loss: 2.9286814
disc_loss: 0.038439646
disc_acc: 0.9872524752475248

Validation results:
gen_loss: 2.6734002
disc_loss: 0.029241785
disc_acc: 0.9871031746031746


	Epoch 96
Training results:
gen_loss: 2.9259336
disc_loss: 0.040224917
disc_acc: 0.9872524752475248

Validation results:
gen_loss: 2.4935124
disc_loss: 0.043059353
disc_acc: 0.9871031746031746


	Epoch 97
Training results:
gen_loss: 2.9378743
disc_loss: 0.038306892
disc_acc: 0.9870049504950495

Validation results:
gen_loss: 2.327455
disc_loss: 0.15356824
disc_acc: 0.9494047619047619


	Epoch 98
Training results:
gen_loss: 2.92479
disc_loss: 0.04128899
disc_acc: 0.9849009900990099

Validation results:
gen_loss: 2.334765
disc_loss: 0.1082101
disc_acc: 0.9603174603174603


	Epoch 99
Training results:
gen_loss: 2.927512
disc_loss: 0.03785715
disc_acc: 0.9863861386138614

Validation results:
gen_loss: 2.6296961
disc_loss: 0.048614465
disc_acc: 0.9806547619047619


	Epoch 100
Training results:
gen_loss: 2.9341824
disc_loss: 0.04066425
disc_acc: 0.9860148514851486

Validation results:
gen_loss: 2.6071768
disc_loss: 0.048610095
disc_acc: 0.9846230158730159


	Epoch 101
Training results:
gen_loss: 2.9339612
disc_loss: 0.03716006
disc_acc: 0.9872524752475248

Validation results:
gen_loss: 2.596566
disc_loss: 0.07412746
disc_acc: 0.9751984126984127


	Epoch 102
Training results:
gen_loss: 2.9505758
disc_loss: 0.039764505
disc_acc: 0.986509900990099

Validation results:
gen_loss: 2.6946156
disc_loss: 0.058557503
disc_acc: 0.9761904761904762


	Epoch 103
Training results:
gen_loss: 2.9370859
disc_loss: 0.036660623
disc_acc: 0.9883663366336634

Validation results:
gen_loss: 2.5745678
disc_loss: 0.010320876
disc_acc: 0.9975198412698413


	Epoch 104
Training results:
gen_loss: 2.9522285
disc_loss: 0.036832362
disc_acc: 0.9870049504950495

Validation results:
gen_loss: 2.6374807
disc_loss: 0.06541015
disc_acc: 0.9776785714285714


	Epoch 105
Training results:
gen_loss: 2.9517827
disc_loss: 0.032824993
disc_acc: 0.9900990099009901

Validation results:
gen_loss: 2.5543864
disc_loss: 0.10640544
disc_acc: 0.9563492063492064


	Epoch 106
Training results:
gen_loss: 2.9587817
disc_loss: 0.0278676
disc_acc: 0.990470297029703

Validation results:
gen_loss: 2.4797344
disc_loss: 0.012485187
disc_acc: 0.9950396825396826


	Epoch 107
Training results:
gen_loss: 2.9534357
disc_loss: 0.035058558
disc_acc: 0.9879950495049505

Validation results:
gen_loss: 2.575977
disc_loss: 0.015712356
disc_acc: 0.9950396825396826


	Epoch 108
Training results:
gen_loss: 2.955859
disc_loss: 0.03180202
disc_acc: 0.9909653465346535

Validation results:
gen_loss: 2.4758844
disc_loss: 0.23212755
disc_acc: 0.9122023809523809


	Epoch 109
Training results:
gen_loss: 2.9624193
disc_loss: 0.03194659
disc_acc: 0.9887376237623763

Validation results:
gen_loss: 2.6396358
disc_loss: 0.020357782
disc_acc: 0.9930555555555556


	Epoch 110
Training results:
gen_loss: 2.9685812
disc_loss: 0.031079486
disc_acc: 0.989480198019802

Validation results:
gen_loss: 2.6261547
disc_loss: 0.017953748
disc_acc: 0.9920634920634921


	Epoch 111
Training results:
gen_loss: 2.9710224
disc_loss: 0.030963724
disc_acc: 0.9898514851485148

Validation results:
gen_loss: 2.4349928
disc_loss: 0.4652749
disc_acc: 0.8625992063492064


	Epoch 112
Training results:
gen_loss: 2.980315
disc_loss: 0.032832723
disc_acc: 0.9902227722772278

Validation results:
gen_loss: 2.7551742
disc_loss: 0.18042424
disc_acc: 0.9275793650793651


	Epoch 113
Training results:
gen_loss: 2.972329
disc_loss: 0.04066839
disc_acc: 0.9858910891089109

Validation results:
gen_loss: 2.69856
disc_loss: 0.031566158
disc_acc: 0.9885912698412699


	Epoch 114
Training results:
gen_loss: 2.9726367
disc_loss: 0.03810527
disc_acc: 0.9878712871287129

Validation results:
gen_loss: 2.4226089
disc_loss: 0.14884067
disc_acc: 0.9439484126984127


	Epoch 115
Training results:
gen_loss: 2.9708054
disc_loss: 0.0342978
disc_acc: 0.9889851485148515

Validation results:
gen_loss: 2.5710506
disc_loss: 0.016646732
disc_acc: 0.9945436507936508


	Epoch 116
Training results:
gen_loss: 2.9805393
disc_loss: 0.034097742
disc_acc: 0.9891089108910891

Validation results:
gen_loss: 2.6655784
disc_loss: 0.036141433
disc_acc: 0.9905753968253969


	Epoch 117
Training results:
gen_loss: 2.9783225
disc_loss: 0.027616922
disc_acc: 0.9923267326732673

Validation results:
gen_loss: 2.639742
disc_loss: 0.014303785
disc_acc: 0.9945436507936508


	Epoch 118
Training results:
gen_loss: 2.9969316
disc_loss: 0.036447816
disc_acc: 0.9877475247524753

Validation results:
gen_loss: 2.5598555
disc_loss: 0.9529134
disc_acc: 0.7316468253968254


	Epoch 119
Training results:
gen_loss: 2.9877765
disc_loss: 0.034686726
disc_acc: 0.9879950495049505

Validation results:
gen_loss: 2.4635568
disc_loss: 0.04970235
disc_acc: 0.9875992063492064


	Epoch 120
Training results:
gen_loss: 2.9915001
disc_loss: 0.03039804
disc_acc: 0.9893564356435643

Validation results:
gen_loss: 2.5902267
disc_loss: 0.01626476
disc_acc: 0.9925595238095238


	Epoch 121
Training results:
gen_loss: 3.0088334
disc_loss: 0.02134961
disc_acc: 0.9938118811881188

Validation results:
gen_loss: 2.6902633
disc_loss: 0.0068263025
disc_acc: 0.998015873015873


	Epoch 122
Training results:
gen_loss: 2.9940386
disc_loss: 0.025561841
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 2.5308356
disc_loss: 0.062134188
disc_acc: 0.9737103174603174


	Epoch 123
Training results:
gen_loss: 2.9953167
disc_loss: 0.030510688
disc_acc: 0.9912128712871288

Validation results:
gen_loss: 2.6097815
disc_loss: 0.39259866
disc_acc: 0.8482142857142857


	Epoch 124
Training results:
gen_loss: 2.9968348
disc_loss: 0.029776685
disc_acc: 0.9896039603960396

Validation results:
gen_loss: 2.4637911
disc_loss: 0.37758434
disc_acc: 0.9002976190476191


	Epoch 125
Training results:
gen_loss: 3.008176
disc_loss: 0.028866045
disc_acc: 0.990470297029703

Validation results:
gen_loss: 2.665476
disc_loss: 0.5423542
disc_acc: 0.8824404761904762


	Epoch 126
Training results:
gen_loss: 2.9975996
disc_loss: 0.033339746
disc_acc: 0.9899752475247525

Validation results:
gen_loss: 2.5836775
disc_loss: 0.008595166
disc_acc: 0.9990079365079365


	Epoch 127
Training results:
gen_loss: 3.0116246
disc_loss: 0.030404128
disc_acc: 0.9893564356435643

Validation results:
gen_loss: 2.4629757
disc_loss: 0.06479801
disc_acc: 0.9831349206349206


	Epoch 128
Training results:
gen_loss: 3.0147626
disc_loss: 0.030138684
disc_acc: 0.9899752475247525

Validation results:
gen_loss: 2.6486833
disc_loss: 0.010462033
disc_acc: 0.998015873015873


	Epoch 129
Training results:
gen_loss: 3.0070453
disc_loss: 0.032907132
disc_acc: 0.9897277227722773

Validation results:
gen_loss: 2.732239
disc_loss: 0.76185244
disc_acc: 0.8100198412698413


	Epoch 130
Training results:
gen_loss: 3.0075572
disc_loss: 0.034290425
disc_acc: 0.9889851485148515

Validation results:
gen_loss: 2.721228
disc_loss: 0.040977705
disc_acc: 0.9851190476190477


	Epoch 131
Training results:
gen_loss: 3.0225594
disc_loss: 0.025690824
disc_acc: 0.9918316831683168

Validation results:
gen_loss: 2.672242
disc_loss: 0.0075137895
disc_acc: 0.9975198412698413


	Epoch 132
Training results:
gen_loss: 3.0238116
disc_loss: 0.028822908
disc_acc: 0.9913366336633663

Validation results:
gen_loss: 2.7818115
disc_loss: 0.34813476
disc_acc: 0.9007936507936508


	Epoch 133
Training results:
gen_loss: 3.0262198
disc_loss: 0.024704814
disc_acc: 0.9915841584158416

Validation results:
gen_loss: 2.612075
disc_loss: 0.035809096
disc_acc: 0.9856150793650794


	Epoch 134
Training results:
gen_loss: 3.01624
disc_loss: 0.036374256
disc_acc: 0.9866336633663366

Validation results:
gen_loss: 2.6933918
disc_loss: 0.036580857
disc_acc: 0.9880952380952381


	Epoch 135
Training results:
gen_loss: 3.0191734
disc_loss: 0.027060436
disc_acc: 0.9915841584158416

Validation results:
gen_loss: 2.8127205
disc_loss: 0.024177006
disc_acc: 0.9910714285714286


	Epoch 136
Training results:
gen_loss: 3.0198898
disc_loss: 0.02719211
disc_acc: 0.9912128712871288

Validation results:
gen_loss: 2.875718
disc_loss: 0.077265285
disc_acc: 0.9737103174603174


	Epoch 137
Training results:
gen_loss: 3.0279915
disc_loss: 0.026962949
disc_acc: 0.9908415841584158

Validation results:
gen_loss: 2.5928018
disc_loss: 0.015703034
disc_acc: 0.996031746031746


	Epoch 138
Training results:
gen_loss: 3.0204608
disc_loss: 0.029641341
disc_acc: 0.9882425742574258

Validation results:
gen_loss: 2.66417
disc_loss: 0.027326407
disc_acc: 0.9915674603174603


	Epoch 139
Training results:
gen_loss: 3.033351
disc_loss: 0.03114501
disc_acc: 0.9900990099009901

Validation results:
gen_loss: 2.5826206
disc_loss: 0.018069992
disc_acc: 0.9950396825396826


	Epoch 140
Training results:
gen_loss: 3.0406706
disc_loss: 0.025336348
disc_acc: 0.991460396039604

Validation results:
gen_loss: 2.6787348
disc_loss: 0.27441663
disc_acc: 0.8978174603174603


	Epoch 141
Training results:
gen_loss: 3.0399384
disc_loss: 0.030751467
disc_acc: 0.989480198019802

Validation results:
gen_loss: 2.6676571
disc_loss: 0.012060548
disc_acc: 0.998015873015873


	Epoch 142
Training results:
gen_loss: 3.0485792
disc_loss: 0.025104117
disc_acc: 0.9920792079207921

Validation results:
gen_loss: 2.737063
disc_loss: 0.014724459
disc_acc: 0.9950396825396826


	Epoch 143
Training results:
gen_loss: 3.0478337
disc_loss: 0.021351611
disc_acc: 0.9931930693069307

Validation results:
gen_loss: 2.554835
disc_loss: 0.021402271
disc_acc: 0.9920634920634921


	Epoch 144
Training results:
gen_loss: 3.0514643
disc_loss: 0.029858852
disc_acc: 0.9908415841584158

Validation results:
gen_loss: 2.4100478
disc_loss: 0.097074404
disc_acc: 0.9627976190476191


	Epoch 145
Training results:
gen_loss: 3.0549123
disc_loss: 0.033062473
disc_acc: 0.9882425742574258

Validation results:
gen_loss: 2.6574335
disc_loss: 0.023212142
disc_acc: 0.9910714285714286


	Epoch 146
Training results:
gen_loss: 3.0521383
disc_loss: 0.02489738
disc_acc: 0.991460396039604

Validation results:
gen_loss: 2.6549299
disc_loss: 0.017625147
disc_acc: 0.9955357142857143


	Epoch 147
Training results:
gen_loss: 3.050524
disc_loss: 0.027592931
disc_acc: 0.9915841584158416

Validation results:
gen_loss: 2.6408439
disc_loss: 0.031336226
disc_acc: 0.9920634920634921


	Epoch 148
Training results:
gen_loss: 3.0530598
disc_loss: 0.02466343
disc_acc: 0.9920792079207921

Validation results:
gen_loss: 2.6932712
disc_loss: 0.013276444
disc_acc: 0.9965277777777778


	Epoch 149
Training results:
gen_loss: 3.059321
disc_loss: 0.02010003
disc_acc: 0.9933168316831683

Validation results:
gen_loss: 2.6238616
disc_loss: 0.013103547
disc_acc: 0.9975198412698413


	Epoch 150
Training results:
gen_loss: 3.0553346
disc_loss: 0.024196751
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 2.7012868
disc_loss: 0.024146346
disc_acc: 0.9910714285714286


	Epoch 151
Training results:
gen_loss: 3.0571585
disc_loss: 0.027510263
disc_acc: 0.9891089108910891

Validation results:
gen_loss: 2.9012442
disc_loss: 0.6118282
disc_acc: 0.8129960317460317


	Epoch 152
Training results:
gen_loss: 3.0554595
disc_loss: 0.025447687
disc_acc: 0.9913366336633663

Validation results:
gen_loss: 2.6750462
disc_loss: 0.0136224525
disc_acc: 0.9965277777777778


	Epoch 153
Training results:
gen_loss: 3.0633292
disc_loss: 0.027996413
disc_acc: 0.9920792079207921

Validation results:
gen_loss: 2.693107
disc_loss: 0.011620163
disc_acc: 0.998015873015873


	Epoch 154
Training results:
gen_loss: 3.0561635
disc_loss: 0.02758323
disc_acc: 0.9913366336633663

Validation results:
gen_loss: 2.6184025
disc_loss: 0.18288101
disc_acc: 0.9340277777777778


	Epoch 155
Training results:
gen_loss: 3.0496862
disc_loss: 0.025094952
disc_acc: 0.9909653465346535

Validation results:
gen_loss: 2.668915
disc_loss: 0.006900229
disc_acc: 0.9990079365079365


	Epoch 156
Training results:
gen_loss: 3.052484
disc_loss: 0.025754688
disc_acc: 0.9909653465346535

Validation results:
gen_loss: 2.7753224
disc_loss: 0.016359735
disc_acc: 0.996031746031746


	Epoch 157
Training results:
gen_loss: 3.0643525
disc_loss: 0.031700097
disc_acc: 0.9892326732673268

Validation results:
gen_loss: 2.729936
disc_loss: 0.061966326
disc_acc: 0.9751984126984127


	Epoch 158
Training results:
gen_loss: 3.0633116
disc_loss: 0.024701366
disc_acc: 0.9922029702970298

Validation results:
gen_loss: 2.6862478
disc_loss: 0.008278726
disc_acc: 0.9970238095238095


	Epoch 159
Training results:
gen_loss: 3.0627408
disc_loss: 0.027248254
disc_acc: 0.990470297029703

Validation results:
gen_loss: 2.7303584
disc_loss: 0.014595212
disc_acc: 0.9945436507936508


	Epoch 160
Training results:
gen_loss: 3.0749817
disc_loss: 0.024865698
disc_acc: 0.9918316831683168

Validation results:
gen_loss: 2.700065
disc_loss: 0.058366142
disc_acc: 0.9742063492063492


	Epoch 161
Training results:
gen_loss: 3.072219
disc_loss: 0.023707384
disc_acc: 0.9910891089108911

Validation results:
gen_loss: 2.7164676
disc_loss: 0.044182833
disc_acc: 0.9821428571428571


	Epoch 162
Training results:
gen_loss: 3.0862098
disc_loss: 0.023866065
disc_acc: 0.9931930693069307

Validation results:
gen_loss: 2.642744
disc_loss: 0.062330183
disc_acc: 0.9806547619047619


	Epoch 163
Training results:
gen_loss: 3.0821085
disc_loss: 0.022406323
disc_acc: 0.992450495049505

Validation results:
gen_loss: 2.6718607
disc_loss: 0.12978439
disc_acc: 0.9528769841269841


	Epoch 164
Training results:
gen_loss: 3.091915
disc_loss: 0.024908189
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 2.6945584
disc_loss: 0.21727395
disc_acc: 0.9107142857142857


	Epoch 165
Training results:
gen_loss: 3.0849004
disc_loss: 0.026007654
disc_acc: 0.9919554455445545

Validation results:
gen_loss: 2.5686624
disc_loss: 0.08892324
disc_acc: 0.9737103174603174


	Epoch 166
Training results:
gen_loss: 3.0788302
disc_loss: 0.02884419
disc_acc: 0.9897277227722773

Validation results:
gen_loss: 2.7600305
disc_loss: 0.015817799
disc_acc: 0.9935515873015873


	Epoch 167
Training results:
gen_loss: 3.0792422
disc_loss: 0.026590506
disc_acc: 0.992450495049505

Validation results:
gen_loss: 2.7508845
disc_loss: 0.007102913
disc_acc: 0.9990079365079365


	Epoch 168
Training results:
gen_loss: 3.100205
disc_loss: 0.027341971
disc_acc: 0.9907178217821783

Validation results:
gen_loss: 2.6418645
disc_loss: 0.33993483
disc_acc: 0.8898809523809523


	Epoch 169
Training results:
gen_loss: 3.1023712
disc_loss: 0.021481322
disc_acc: 0.9925742574257426

Validation results:
gen_loss: 2.6539128
disc_loss: 0.0121813975
disc_acc: 0.9955357142857143


	Epoch 170
Training results:
gen_loss: 3.0845509
disc_loss: 0.025351994
disc_acc: 0.9900990099009901

Validation results:
gen_loss: 2.6303
disc_loss: 0.17311102
disc_acc: 0.9404761904761905


	Epoch 171
Training results:
gen_loss: 3.1009016
disc_loss: 0.021129053
disc_acc: 0.9926980198019802

Validation results:
gen_loss: 2.5188186
disc_loss: 0.82653993
disc_acc: 0.7549603174603174


	Epoch 172
Training results:
gen_loss: 3.0872493
disc_loss: 0.027317135
disc_acc: 0.9926980198019802

Validation results:
gen_loss: 2.5972252
disc_loss: 0.1260252
disc_acc: 0.9518849206349206


	Epoch 173
Training results:
gen_loss: 3.095999
disc_loss: 0.02245273
disc_acc: 0.9926980198019802

Validation results:
gen_loss: 2.634257
disc_loss: 0.051464535
disc_acc: 0.9796626984126984


	Epoch 174
Training results:
gen_loss: 3.0916553
disc_loss: 0.026839798
disc_acc: 0.9907178217821783

Validation results:
gen_loss: 2.7264736
disc_loss: 0.0074274717
disc_acc: 0.9970238095238095


	Epoch 175
Training results:
gen_loss: 3.108658
disc_loss: 0.016604552
disc_acc: 0.994430693069307

Validation results:
gen_loss: 2.7982228
disc_loss: 0.006733303
disc_acc: 0.9970238095238095


	Epoch 176
Training results:
gen_loss: 3.1042092
disc_loss: 0.021494495
disc_acc: 0.9938118811881188

Validation results:
gen_loss: 2.6233182
disc_loss: 0.011871882
disc_acc: 0.9940476190476191


	Epoch 177
Training results:
gen_loss: 3.0905004
disc_loss: 0.021010635
disc_acc: 0.9928217821782178

Validation results:
gen_loss: 2.8428845
disc_loss: 0.5802694
disc_acc: 0.8784722222222222


	Epoch 178
Training results:
gen_loss: 3.1008208
disc_loss: 0.026150497
disc_acc: 0.9915841584158416

Validation results:
gen_loss: 2.657473
disc_loss: 0.083606645
disc_acc: 0.9652777777777778


	Epoch 179
Training results:
gen_loss: 3.0967498
disc_loss: 0.019158281
disc_acc: 0.994059405940594

Validation results:
gen_loss: 2.7059224
disc_loss: 0.65805066
disc_acc: 0.7872023809523809


	Epoch 180
Training results:
gen_loss: 3.1044867
disc_loss: 0.021782069
disc_acc: 0.9923267326732673

Validation results:
gen_loss: 2.746951
disc_loss: 0.065771535
disc_acc: 0.9717261904761905


	Epoch 181
Training results:
gen_loss: 3.11358
disc_loss: 0.017547166
disc_acc: 0.9941831683168317

Validation results:
gen_loss: 2.7139413
disc_loss: 0.020933129
disc_acc: 0.9935515873015873


	Epoch 182
Training results:
gen_loss: 3.1149743
disc_loss: 0.020229962
disc_acc: 0.9931930693069307

Validation results:
gen_loss: 2.7212555
disc_loss: 0.42051423
disc_acc: 0.8511904761904762


	Epoch 183
Training results:
gen_loss: 3.1118476
disc_loss: 0.018822473
disc_acc: 0.9939356435643565

Validation results:
gen_loss: 2.632757
disc_loss: 0.07209044
disc_acc: 0.9747023809523809


	Epoch 184
Training results:
gen_loss: 3.1137428
disc_loss: 0.017199654
disc_acc: 0.9946782178217822

Validation results:
gen_loss: 2.8771803
disc_loss: 0.020726392
disc_acc: 0.9915674603174603


	Epoch 185
Training results:
gen_loss: 3.1088138
disc_loss: 0.021016723
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 2.7681472
disc_loss: 0.0063117407
disc_acc: 0.9990079365079365


	Epoch 186
Training results:
gen_loss: 3.116231
disc_loss: 0.020822104
disc_acc: 0.9931930693069307

Validation results:
gen_loss: 2.758956
disc_loss: 0.0041225124
disc_acc: 0.9990079365079365


	Epoch 187
Training results:
gen_loss: 3.1133955
disc_loss: 0.018010722
disc_acc: 0.9939356435643565

Validation results:
gen_loss: 2.6193404
disc_loss: 0.008923545
disc_acc: 0.9975198412698413


	Epoch 188
Training results:
gen_loss: 3.122389
disc_loss: 0.02225809
disc_acc: 0.9923267326732673

Validation results:
gen_loss: 2.7018018
disc_loss: 0.25987548
disc_acc: 0.8893849206349206


	Epoch 189
Training results:
gen_loss: 3.112237
disc_loss: 0.020127736
disc_acc: 0.9930693069306931

Validation results:
gen_loss: 2.6079116
disc_loss: 0.29655612
disc_acc: 0.9032738095238095


	Epoch 190
Training results:
gen_loss: 3.1285403
disc_loss: 0.017065387
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.7987664
disc_loss: 0.006974464
disc_acc: 0.9995039682539683


	Epoch 191
Training results:
gen_loss: 3.1246133
disc_loss: 0.021989925
disc_acc: 0.9928217821782178

Validation results:
gen_loss: 2.5866854
disc_loss: 0.03811638
disc_acc: 0.9826388888888888


	Epoch 192
Training results:
gen_loss: 3.129325
disc_loss: 0.0225742
disc_acc: 0.9919554455445545

Validation results:
gen_loss: 2.7282653
disc_loss: 0.35033643
disc_acc: 0.878968253968254


	Epoch 193
Training results:
gen_loss: 3.1210172
disc_loss: 0.027180865
disc_acc: 0.9909653465346535

Validation results:
gen_loss: 2.5614822
disc_loss: 1.6038133
disc_acc: 0.6324404761904762


	Epoch 194
Training results:
gen_loss: 3.1231947
disc_loss: 0.025320264
disc_acc: 0.9919554455445545

Validation results:
gen_loss: 2.531574
disc_loss: 1.3108227
disc_acc: 0.7306547619047619


	Epoch 195
Training results:
gen_loss: 3.1270778
disc_loss: 0.019531526
disc_acc: 0.9939356435643565

Validation results:
gen_loss: 2.6951876
disc_loss: 0.0347943
disc_acc: 0.9875992063492064


	Epoch 196
Training results:
gen_loss: 3.1203454
disc_loss: 0.02707086
disc_acc: 0.990470297029703

Validation results:
gen_loss: 2.6997752
disc_loss: 0.32864273
disc_acc: 0.9067460317460317


	Epoch 197
Training results:
gen_loss: 3.1327317
disc_loss: 0.023725022
disc_acc: 0.9928217821782178

Validation results:
gen_loss: 2.719319
disc_loss: 0.009684207
disc_acc: 0.9970238095238095


	Epoch 198
Training results:
gen_loss: 3.1450272
disc_loss: 0.0153862545
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 2.6984982
disc_loss: 0.013336744
disc_acc: 0.9950396825396826


	Epoch 199
Training results:
gen_loss: 3.1268544
disc_loss: 0.022288203
disc_acc: 0.9922029702970298

Validation results:
gen_loss: 2.7091074
disc_loss: 0.008079506
disc_acc: 0.9970238095238095


	Epoch 200
Training results:
gen_loss: 3.1244993
disc_loss: 0.02154519
disc_acc: 0.9928217821782178

Validation results:
gen_loss: 2.7885313
disc_loss: 0.007387529
disc_acc: 0.996031746031746


	Epoch 201
Training results:
gen_loss: 3.1294754
disc_loss: 0.022102153
disc_acc: 0.9922029702970298

Validation results:
gen_loss: 2.789944
disc_loss: 0.08726782
disc_acc: 0.9742063492063492


	Epoch 202
Training results:
gen_loss: 3.129042
disc_loss: 0.023634836
disc_acc: 0.9913366336633663

Validation results:
gen_loss: 2.6187658
disc_loss: 0.1037129
disc_acc: 0.9613095238095238


	Epoch 203
Training results:
gen_loss: 3.1408672
disc_loss: 0.023231115
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 2.7387304
disc_loss: 0.011341785
disc_acc: 0.996031746031746


	Epoch 204
Training results:
gen_loss: 3.133216
disc_loss: 0.023211522
disc_acc: 0.9922029702970298

Validation results:
gen_loss: 2.7181463
disc_loss: 0.028780138
disc_acc: 0.9890873015873016


	Epoch 205
Training results:
gen_loss: 3.139145
disc_loss: 0.02129938
disc_acc: 0.9928217821782178

Validation results:
gen_loss: 2.8089051
disc_loss: 0.081413336
disc_acc: 0.9672619047619048


	Epoch 206
Training results:
gen_loss: 3.1370788
disc_loss: 0.01748559
disc_acc: 0.9939356435643565

Validation results:
gen_loss: 2.670793
disc_loss: 0.46839434
disc_acc: 0.8908730158730159


	Epoch 207
Training results:
gen_loss: 3.1515546
disc_loss: 0.017936323
disc_acc: 0.993440594059406

Validation results:
gen_loss: 2.702291
disc_loss: 0.064954385
disc_acc: 0.9766865079365079


	Epoch 208
Training results:
gen_loss: 3.1487699
disc_loss: 0.018456064
disc_acc: 0.9941831683168317

Validation results:
gen_loss: 2.8970768
disc_loss: 1.6617492
disc_acc: 0.6607142857142857


	Epoch 209
Training results:
gen_loss: 3.157053
disc_loss: 0.020341864
disc_acc: 0.9928217821782178

Validation results:
gen_loss: 2.851886
disc_loss: 0.008788457
disc_acc: 0.9975198412698413


	Epoch 210
Training results:
gen_loss: 3.15729
disc_loss: 0.019183557
disc_acc: 0.9935643564356436

Validation results:
gen_loss: 2.7881162
disc_loss: 0.080601014
disc_acc: 0.9692460317460317


	Epoch 211
Training results:
gen_loss: 3.1485734
disc_loss: 0.023760173
disc_acc: 0.9922029702970298

Validation results:
gen_loss: 2.9066684
disc_loss: 0.015589498
disc_acc: 0.9940476190476191


	Epoch 212
Training results:
gen_loss: 3.1569846
disc_loss: 0.018724736
disc_acc: 0.994059405940594

Validation results:
gen_loss: 2.5857975
disc_loss: 1.7847649
disc_acc: 0.6016865079365079


	Epoch 213
Training results:
gen_loss: 3.1558747
disc_loss: 0.025672754
disc_acc: 0.9912128712871288

Validation results:
gen_loss: 2.7722087
disc_loss: 0.038562898
disc_acc: 0.9890873015873016


	Epoch 214
Training results:
gen_loss: 3.1555657
disc_loss: 0.020251518
disc_acc: 0.993440594059406

Validation results:
gen_loss: 2.7993066
disc_loss: 0.0034400306
disc_acc: 1.0


	Epoch 215
Training results:
gen_loss: 3.1535378
disc_loss: 0.020190105
disc_acc: 0.9945544554455445

Validation results:
gen_loss: 2.8092136
disc_loss: 0.008804852
disc_acc: 0.9975198412698413


	Epoch 216
Training results:
gen_loss: 3.162486
disc_loss: 0.017480982
disc_acc: 0.9946782178217822

Validation results:
gen_loss: 2.762371
disc_loss: 0.18356577
disc_acc: 0.9310515873015873


	Epoch 217
Training results:
gen_loss: 3.1593726
disc_loss: 0.01923217
disc_acc: 0.9933168316831683

Validation results:
gen_loss: 2.7512608
disc_loss: 0.004525873
disc_acc: 0.9995039682539683


	Epoch 218
Training results:
gen_loss: 3.1604102
disc_loss: 0.014892212
disc_acc: 0.994430693069307

Validation results:
gen_loss: 2.8253536
disc_loss: 0.00722706
disc_acc: 0.9970238095238095


	Epoch 219
Training results:
gen_loss: 3.1606681
disc_loss: 0.015605169
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.6560888
disc_loss: 0.027154192
disc_acc: 0.9925595238095238


	Epoch 220
Training results:
gen_loss: 3.1651812
disc_loss: 0.017872052
disc_acc: 0.994430693069307

Validation results:
gen_loss: 2.8282301
disc_loss: 0.015038712
disc_acc: 0.9940476190476191


	Epoch 221
Training results:
gen_loss: 3.1677976
disc_loss: 0.019587269
disc_acc: 0.9931930693069307

Validation results:
gen_loss: 2.764629
disc_loss: 0.04875054
disc_acc: 0.9811507936507936


	Epoch 222
Training results:
gen_loss: 3.1721742
disc_loss: 0.019334473
disc_acc: 0.9949257425742575

Validation results:
gen_loss: 2.733604
disc_loss: 0.012681859
disc_acc: 0.9955357142857143


	Epoch 223
Training results:
gen_loss: 3.1747718
disc_loss: 0.015652416
disc_acc: 0.9949257425742575

Validation results:
gen_loss: 2.7557063
disc_loss: 0.084801465
disc_acc: 0.9702380952380952


	Epoch 224
Training results:
gen_loss: 3.1833205
disc_loss: 0.01391226
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.7001941
disc_loss: 0.011811204
disc_acc: 0.9965277777777778


	Epoch 225
Training results:
gen_loss: 3.1684613
disc_loss: 0.02115432
disc_acc: 0.993440594059406

Validation results:
gen_loss: 2.7330346
disc_loss: 0.0076667042
disc_acc: 0.9975198412698413


	Epoch 226
Training results:
gen_loss: 3.165348
disc_loss: 0.024984032
disc_acc: 0.9917079207920793

Validation results:
gen_loss: 2.784176
disc_loss: 0.045249637
disc_acc: 0.9826388888888888


	Epoch 227
Training results:
gen_loss: 3.1716876
disc_loss: 0.020338146
disc_acc: 0.9925742574257426

Validation results:
gen_loss: 2.640752
disc_loss: 0.028786154
disc_acc: 0.9910714285714286


	Epoch 228
Training results:
gen_loss: 3.1744993
disc_loss: 0.019639364
disc_acc: 0.993440594059406

Validation results:
gen_loss: 2.8346462
disc_loss: 0.003765659
disc_acc: 0.9995039682539683


	Epoch 229
Training results:
gen_loss: 3.1809754
disc_loss: 0.016881492
disc_acc: 0.995420792079208

Validation results:
gen_loss: 2.7821455
disc_loss: 0.004833069
disc_acc: 0.9990079365079365


	Epoch 230
Training results:
gen_loss: 3.196768
disc_loss: 0.0146569675
disc_acc: 0.996039603960396

Validation results:
gen_loss: 2.8891912
disc_loss: 0.0055310866
disc_acc: 0.998015873015873


	Epoch 231
Training results:
gen_loss: 3.189409
disc_loss: 0.01804436
disc_acc: 0.9941831683168317

Validation results:
gen_loss: 2.866688
disc_loss: 0.009858744
disc_acc: 0.9955357142857143


	Epoch 232
Training results:
gen_loss: 3.2034075
disc_loss: 0.0154909
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.8873732
disc_loss: 0.03962873
disc_acc: 0.9861111111111112


	Epoch 233
Training results:
gen_loss: 3.1928658
disc_loss: 0.017806526
disc_acc: 0.9946782178217822

Validation results:
gen_loss: 2.8152783
disc_loss: 0.0042684874
disc_acc: 0.9995039682539683


	Epoch 234
Training results:
gen_loss: 3.202567
disc_loss: 0.016918445
disc_acc: 0.9941831683168317

Validation results:
gen_loss: 2.9348109
disc_loss: 0.020644108
disc_acc: 0.9930555555555556


	Epoch 235
Training results:
gen_loss: 3.1984546
disc_loss: 0.018489074
disc_acc: 0.993440594059406

Validation results:
gen_loss: 2.8515875
disc_loss: 0.009833939
disc_acc: 0.9965277777777778


	Epoch 236
Training results:
gen_loss: 3.1906202
disc_loss: 0.018151479
disc_acc: 0.994430693069307

Validation results:
gen_loss: 2.8358579
disc_loss: 0.13911231
disc_acc: 0.9543650793650794


	Epoch 237
Training results:
gen_loss: 3.1930804
disc_loss: 0.021294381
disc_acc: 0.9931930693069307

Validation results:
gen_loss: 2.7584925
disc_loss: 0.020021128
disc_acc: 0.9930555555555556


	Epoch 238
Training results:
gen_loss: 3.1809976
disc_loss: 0.018147705
disc_acc: 0.9949257425742575

Validation results:
gen_loss: 2.7377565
disc_loss: 0.017926242
disc_acc: 0.9945436507936508


	Epoch 239
Training results:
gen_loss: 3.1890202
disc_loss: 0.01778771
disc_acc: 0.9935643564356436

Validation results:
gen_loss: 2.7693214
disc_loss: 0.009199865
disc_acc: 0.996031746031746


	Epoch 240
Training results:
gen_loss: 3.1987824
disc_loss: 0.017517157
disc_acc: 0.9945544554455445

Validation results:
gen_loss: 2.8259254
disc_loss: 0.0045006797
disc_acc: 0.9995039682539683


	Epoch 241
Training results:
gen_loss: 3.197867
disc_loss: 0.014663443
disc_acc: 0.996039603960396

Validation results:
gen_loss: 2.7852464
disc_loss: 0.0041252896
disc_acc: 0.9990079365079365


	Epoch 242
Training results:
gen_loss: 3.2031918
disc_loss: 0.014180606
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.606518
disc_loss: 0.17099547
disc_acc: 0.9365079365079365


	Epoch 243
Training results:
gen_loss: 3.2026227
disc_loss: 0.016305402
disc_acc: 0.9946782178217822

Validation results:
gen_loss: 2.7226892
disc_loss: 0.07800824
disc_acc: 0.9737103174603174


	Epoch 244
Training results:
gen_loss: 3.2038531
disc_loss: 0.018102579
disc_acc: 0.994059405940594

Validation results:
gen_loss: 2.9052882
disc_loss: 0.007595123
disc_acc: 0.9975198412698413


	Epoch 245
Training results:
gen_loss: 3.2089033
disc_loss: 0.020046147
disc_acc: 0.9926980198019802

Validation results:
gen_loss: 2.7804406
disc_loss: 0.015955213
disc_acc: 0.9950396825396826


	Epoch 246
Training results:
gen_loss: 3.21108
disc_loss: 0.014097664
disc_acc: 0.996039603960396

Validation results:
gen_loss: 2.6145563
disc_loss: 0.02907416
disc_acc: 0.9905753968253969


	Epoch 247
Training results:
gen_loss: 3.1979654
disc_loss: 0.015978256
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.8963528
disc_loss: 0.032124676
disc_acc: 0.9851190476190477


	Epoch 248
Training results:
gen_loss: 3.2173722
disc_loss: 0.0143584395
disc_acc: 0.995049504950495

Validation results:
gen_loss: 2.846176
disc_loss: 0.0039958893
disc_acc: 0.9990079365079365


	Epoch 249
Training results:
gen_loss: 3.2103174
disc_loss: 0.02086795
disc_acc: 0.9919554455445545

Validation results:
gen_loss: 2.8752863
disc_loss: 0.33740973
disc_acc: 0.8854166666666666


	Epoch 250
Training results:
gen_loss: 3.2125528
disc_loss: 0.015051828
disc_acc: 0.9945544554455445

Validation results:
gen_loss: 2.7496204
disc_loss: 0.010438402
disc_acc: 0.9970238095238095


	Epoch 251
Training results:
gen_loss: 3.2080355
disc_loss: 0.019699346
disc_acc: 0.9943069306930693

Validation results:
gen_loss: 2.751553
disc_loss: 0.0060592378
disc_acc: 0.9975198412698413


	Epoch 252
Training results:
gen_loss: 3.1964462
disc_loss: 0.014172168
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 2.9592507
disc_loss: 0.007365869
disc_acc: 0.9975198412698413


	Epoch 253
Training results:
gen_loss: 3.20865
disc_loss: 0.012331293
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 3.0077674
disc_loss: 0.17446955
disc_acc: 0.935515873015873


	Epoch 254
Training results:
gen_loss: 3.2124681
disc_loss: 0.014778683
disc_acc: 0.9955445544554455

Validation results:
gen_loss: 2.9215662
disc_loss: 0.0031424654
disc_acc: 1.0


	Epoch 255
Training results:
gen_loss: 3.216165
disc_loss: 0.016872266
disc_acc: 0.9943069306930693

Validation results:
gen_loss: 2.9187272
disc_loss: 0.0042683342
disc_acc: 0.9990079365079365


	Epoch 256
Training results:
gen_loss: 3.2152028
disc_loss: 0.012848708
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.90061
disc_loss: 0.011903118
disc_acc: 0.9945436507936508


	Epoch 257
Training results:
gen_loss: 3.2321932
disc_loss: 0.0123759145
disc_acc: 0.996039603960396

Validation results:
gen_loss: 3.083372
disc_loss: 0.20787705
disc_acc: 0.9265873015873016


	Epoch 258
Training results:
gen_loss: 3.2289553
disc_loss: 0.014709458
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.8660288
disc_loss: 0.07364881
disc_acc: 0.9781746031746031


	Epoch 259
Training results:
gen_loss: 3.2275293
disc_loss: 0.018670239
disc_acc: 0.9935643564356436

Validation results:
gen_loss: 2.978552
disc_loss: 0.007164935
disc_acc: 0.998015873015873


	Epoch 260
Training results:
gen_loss: 3.2169883
disc_loss: 0.021538794
disc_acc: 0.9928217821782178

Validation results:
gen_loss: 2.8045824
disc_loss: 0.006062567
disc_acc: 0.9990079365079365


	Epoch 261
Training results:
gen_loss: 3.2312284
disc_loss: 0.018817443
disc_acc: 0.9935643564356436

Validation results:
gen_loss: 2.8394027
disc_loss: 0.008611876
disc_acc: 0.9965277777777778


	Epoch 262
Training results:
gen_loss: 3.2431514
disc_loss: 0.00997407
disc_acc: 0.9971534653465347

Validation results:
gen_loss: 2.6449716
disc_loss: 0.07800521
disc_acc: 0.964781746031746


	Epoch 263
Training results:
gen_loss: 3.2349584
disc_loss: 0.016512645
disc_acc: 0.9946782178217822

Validation results:
gen_loss: 2.693637
disc_loss: 0.02945523
disc_acc: 0.9890873015873016


	Epoch 264
Training results:
gen_loss: 3.240054
disc_loss: 0.0144866565
disc_acc: 0.995420792079208

Validation results:
gen_loss: 2.9042816
disc_loss: 0.0063473466
disc_acc: 0.9965277777777778


	Epoch 265
Training results:
gen_loss: 3.2422285
disc_loss: 0.015366431
disc_acc: 0.9946782178217822

Validation results:
gen_loss: 2.911604
disc_loss: 0.0063687963
disc_acc: 0.9990079365079365


	Epoch 266
Training results:
gen_loss: 3.2347605
disc_loss: 0.014374265
disc_acc: 0.9949257425742575

Validation results:
gen_loss: 2.9094045
disc_loss: 0.006035898
disc_acc: 0.9975198412698413


	Epoch 267
Training results:
gen_loss: 3.2379313
disc_loss: 0.014759889
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.8360832
disc_loss: 0.01265569
disc_acc: 0.9955357142857143


	Epoch 268
Training results:
gen_loss: 3.233724
disc_loss: 0.009753677
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.9032302
disc_loss: 0.006488164
disc_acc: 0.998015873015873


	Epoch 269
Training results:
gen_loss: 3.2451897
disc_loss: 0.014337999
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 2.8838668
disc_loss: 0.017131787
disc_acc: 0.9940476190476191


	Epoch 270
Training results:
gen_loss: 3.2363918
disc_loss: 0.013342251
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 2.868636
disc_loss: 0.0043612234
disc_acc: 0.9990079365079365


	Epoch 271
Training results:
gen_loss: 3.2502022
disc_loss: 0.012204116
disc_acc: 0.996039603960396

Validation results:
gen_loss: 2.850638
disc_loss: 0.017290322
disc_acc: 0.9935515873015873


	Epoch 272
Training results:
gen_loss: 3.243451
disc_loss: 0.011813514
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.7883887
disc_loss: 0.03247696
disc_acc: 0.9866071428571429


	Epoch 273
Training results:
gen_loss: 3.2357802
disc_loss: 0.0154084675
disc_acc: 0.9955445544554455

Validation results:
gen_loss: 2.920663
disc_loss: 0.04459317
disc_acc: 0.9836309523809523


	Epoch 274
Training results:
gen_loss: 3.2392926
disc_loss: 0.013654613
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 2.868096
disc_loss: 0.4157695
disc_acc: 0.8829365079365079


	Epoch 275
Training results:
gen_loss: 3.244136
disc_loss: 0.019084835
disc_acc: 0.9931930693069307

Validation results:
gen_loss: 2.940671
disc_loss: 0.17338946
disc_acc: 0.9484126984126984


	Epoch 276
Training results:
gen_loss: 3.2447748
disc_loss: 0.013488648
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.9396703
disc_loss: 0.0056677843
disc_acc: 0.998015873015873


	Epoch 277
Training results:
gen_loss: 3.2449431
disc_loss: 0.013539504
disc_acc: 0.9948019801980198

Validation results:
gen_loss: 2.9003198
disc_loss: 0.020685043
disc_acc: 0.9935515873015873


	Epoch 278
Training results:
gen_loss: 3.2462862
disc_loss: 0.016215596
disc_acc: 0.9948019801980198

Validation results:
gen_loss: 2.8846526
disc_loss: 0.013700438
disc_acc: 0.9945436507936508


	Epoch 279
Training results:
gen_loss: 3.2366834
disc_loss: 0.023281278
disc_acc: 0.9919554455445545

Validation results:
gen_loss: 2.8718283
disc_loss: 0.009521392
disc_acc: 0.9970238095238095


	Epoch 280
Training results:
gen_loss: 3.2237716
disc_loss: 0.020582102
disc_acc: 0.9931930693069307

Validation results:
gen_loss: 2.821631
disc_loss: 0.00904126
disc_acc: 0.9955357142857143


	Epoch 281
Training results:
gen_loss: 3.2479455
disc_loss: 0.01144023
disc_acc: 0.9962871287128713

Validation results:
gen_loss: 2.8522236
disc_loss: 0.60355556
disc_acc: 0.8368055555555556


	Epoch 282
Training results:
gen_loss: 3.2465203
disc_loss: 0.014963232
disc_acc: 0.9949257425742575

Validation results:
gen_loss: 2.7129552
disc_loss: 0.013584604
disc_acc: 0.9965277777777778


	Epoch 283
Training results:
gen_loss: 3.245752
disc_loss: 0.01171838
disc_acc: 0.9955445544554455

Validation results:
gen_loss: 2.7093644
disc_loss: 0.006025716
disc_acc: 0.9990079365079365


	Epoch 284
Training results:
gen_loss: 3.2526774
disc_loss: 0.017784405
disc_acc: 0.9945544554455445

Validation results:
gen_loss: 2.8759692
disc_loss: 0.01231268
disc_acc: 0.996031746031746


	Epoch 285
Training results:
gen_loss: 3.248599
disc_loss: 0.014861429
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.9539793
disc_loss: 0.004119468
disc_acc: 0.9995039682539683


	Epoch 286
Training results:
gen_loss: 3.2604039
disc_loss: 0.01195663
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 2.6938894
disc_loss: 0.007107089
disc_acc: 0.9985119047619048


	Epoch 287
Training results:
gen_loss: 3.2618732
disc_loss: 0.012510773
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.887145
disc_loss: 0.00440295
disc_acc: 0.9985119047619048


	Epoch 288
Training results:
gen_loss: 3.2664466
disc_loss: 0.008639497
disc_acc: 0.99740099009901

Validation results:
gen_loss: 2.923261
disc_loss: 0.0035521123
disc_acc: 0.9995039682539683


	Epoch 289
Training results:
gen_loss: 3.2658792
disc_loss: 0.0106685925
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.767638
disc_loss: 0.025193056
disc_acc: 0.9880952380952381


	Epoch 290
Training results:
gen_loss: 3.2527082
disc_loss: 0.013204431
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.8432984
disc_loss: 1.5620099
disc_acc: 0.7177579365079365


	Epoch 291
Training results:
gen_loss: 3.2647152
disc_loss: 0.013298227
disc_acc: 0.9972772277227723

Validation results:
gen_loss: 2.9866233
disc_loss: 0.019428879
disc_acc: 0.9920634920634921


	Epoch 292
Training results:
gen_loss: 3.2635858
disc_loss: 0.014027176
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.9030805
disc_loss: 0.0063859555
disc_acc: 0.998015873015873


	Epoch 293
Training results:
gen_loss: 3.2669713
disc_loss: 0.011108717
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 2.8759968
disc_loss: 0.010612319
disc_acc: 0.9950396825396826


	Epoch 294
Training results:
gen_loss: 3.2667756
disc_loss: 0.01477565
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.8056984
disc_loss: 0.04065966
disc_acc: 0.9846230158730159


	Epoch 295
Training results:
gen_loss: 3.2574317
disc_loss: 0.013316592
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.871492
disc_loss: 0.0033402652
disc_acc: 0.9995039682539683


	Epoch 296
Training results:
gen_loss: 3.2602484
disc_loss: 0.015475414
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.8073666
disc_loss: 0.004243902
disc_acc: 0.9990079365079365


	Epoch 297
Training results:
gen_loss: 3.2711642
disc_loss: 0.014333942
disc_acc: 0.995420792079208

Validation results:
gen_loss: 2.8738344
disc_loss: 0.009210031
disc_acc: 0.9955357142857143


	Epoch 298
Training results:
gen_loss: 3.279987
disc_loss: 0.01192284
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 2.8497405
disc_loss: 0.007347471
disc_acc: 0.9975198412698413


	Epoch 299
Training results:
gen_loss: 3.2724411
disc_loss: 0.018518444
disc_acc: 0.9945544554455445

Validation results:
gen_loss: 2.8237832
disc_loss: 0.06393761
disc_acc: 0.972718253968254


	Epoch 300
Training results:
gen_loss: 3.2737958
disc_loss: 0.013109643
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 2.600683
disc_loss: 0.123650275
disc_acc: 0.9508928571428571


	Epoch 301
Training results:
gen_loss: 3.2586656
disc_loss: 0.015570635
disc_acc: 0.9949257425742575

Validation results:
gen_loss: 2.9056091
disc_loss: 0.07429131
disc_acc: 0.96875


	Epoch 302
Training results:
gen_loss: 3.2608783
disc_loss: 0.016667875
disc_acc: 0.9948019801980198

Validation results:
gen_loss: 2.999797
disc_loss: 0.011357207
disc_acc: 0.9950396825396826


	Epoch 303
Training results:
gen_loss: 3.2713199
disc_loss: 0.0117487265
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 2.929847
disc_loss: 0.00927188
disc_acc: 0.9985119047619048


	Epoch 304
Training results:
gen_loss: 3.2733402
disc_loss: 0.015890956
disc_acc: 0.9949257425742575

Validation results:
gen_loss: 2.9597704
disc_loss: 0.005096867
disc_acc: 0.9975198412698413


	Epoch 305
Training results:
gen_loss: 3.281785
disc_loss: 0.010358728
disc_acc: 0.9971534653465347

Validation results:
gen_loss: 2.9046757
disc_loss: 0.0036758354
disc_acc: 0.9990079365079365


	Epoch 306
Training results:
gen_loss: 3.2924287
disc_loss: 0.013598092
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 2.9559736
disc_loss: 0.017988972
disc_acc: 0.9935515873015873


	Epoch 307
Training results:
gen_loss: 3.286205
disc_loss: 0.013291163
disc_acc: 0.9946782178217822

Validation results:
gen_loss: 2.885755
disc_loss: 0.017917497
disc_acc: 0.9940476190476191


	Epoch 308
Training results:
gen_loss: 3.2779093
disc_loss: 0.012580695
disc_acc: 0.9966584158415842

Validation results:
gen_loss: 2.9530697
disc_loss: 0.002580792
disc_acc: 0.9990079365079365


	Epoch 309
Training results:
gen_loss: 3.2779582
disc_loss: 0.012204261
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 3.0091312
disc_loss: 0.020531636
disc_acc: 0.9925595238095238


	Epoch 310
Training results:
gen_loss: 3.287454
disc_loss: 0.012058572
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 2.9224582
disc_loss: 0.0031470784
disc_acc: 1.0


	Epoch 311
Training results:
gen_loss: 3.2908816
disc_loss: 0.011961973
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.922177
disc_loss: 0.048227593
disc_acc: 0.9821428571428571


	Epoch 312
Training results:
gen_loss: 3.2867222
disc_loss: 0.012086098
disc_acc: 0.995420792079208

Validation results:
gen_loss: 2.9224722
disc_loss: 0.4109127
disc_acc: 0.9295634920634921


	Epoch 313
Training results:
gen_loss: 3.2801402
disc_loss: 0.019978477
disc_acc: 0.9941831683168317

Validation results:
gen_loss: 2.9173086
disc_loss: 0.008232698
disc_acc: 0.998015873015873


	Epoch 314
Training results:
gen_loss: 3.290494
disc_loss: 0.014428806
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 2.858161
disc_loss: 0.0077320933
disc_acc: 0.9970238095238095


	Epoch 315
Training results:
gen_loss: 3.2882476
disc_loss: 0.010608248
disc_acc: 0.9962871287128713

Validation results:
gen_loss: 2.8978856
disc_loss: 0.0038842051
disc_acc: 0.9990079365079365


	Epoch 316
Training results:
gen_loss: 3.2847657
disc_loss: 0.016564433
disc_acc: 0.994059405940594

Validation results:
gen_loss: 2.8991718
disc_loss: 0.0023313188
disc_acc: 1.0


	Epoch 317
Training results:
gen_loss: 3.2760026
disc_loss: 0.012794823
disc_acc: 0.9956683168316832

Validation results:
gen_loss: 2.8667445
disc_loss: 0.004124164
disc_acc: 0.9995039682539683


	Epoch 318
Training results:
gen_loss: 3.2735486
disc_loss: 0.009849598
disc_acc: 0.9971534653465347

Validation results:
gen_loss: 2.9706814
disc_loss: 0.004477923
disc_acc: 0.9975198412698413


	Epoch 319
Training results:
gen_loss: 3.2937965
disc_loss: 0.00675636
disc_acc: 0.9986386138613862

Validation results:
gen_loss: 2.9181607
disc_loss: 0.0057283207
disc_acc: 0.9990079365079365


	Epoch 320
Training results:
gen_loss: 3.293648
disc_loss: 0.011153584
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.886494
disc_loss: 0.0019287922
disc_acc: 1.0


	Epoch 321
Training results:
gen_loss: 3.279522
disc_loss: 0.016455028
disc_acc: 0.994430693069307

Validation results:
gen_loss: 2.856941
disc_loss: 0.0061972914
disc_acc: 0.9990079365079365


	Epoch 322
Training results:
gen_loss: 3.2850308
disc_loss: 0.011749944
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.9736433
disc_loss: 0.0037883795
disc_acc: 0.9990079365079365


	Epoch 323
Training results:
gen_loss: 3.285591
disc_loss: 0.009948934
disc_acc: 0.997029702970297

Validation results:
gen_loss: 2.896835
disc_loss: 0.0025213694
disc_acc: 0.9995039682539683


	Epoch 324
Training results:
gen_loss: 3.2965734
disc_loss: 0.011031438
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.899297
disc_loss: 0.007591928
disc_acc: 0.9970238095238095


	Epoch 325
Training results:
gen_loss: 3.275684
disc_loss: 0.012972137
disc_acc: 0.995420792079208

Validation results:
gen_loss: 2.896695
disc_loss: 0.0026369458
disc_acc: 0.9995039682539683


	Epoch 326
Training results:
gen_loss: 3.2900658
disc_loss: 0.012425389
disc_acc: 0.995049504950495

Validation results:
gen_loss: 3.1154814
disc_loss: 2.392905
disc_acc: 0.5803571428571429


	Epoch 327
Training results:
gen_loss: 3.3002496
disc_loss: 0.010905312
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.8937526
disc_loss: 0.009026051
disc_acc: 0.9970238095238095


	Epoch 328
Training results:
gen_loss: 3.2987623
disc_loss: 0.010213271
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.9003701
disc_loss: 0.008550156
disc_acc: 0.996031746031746


	Epoch 329
Training results:
gen_loss: 3.294776
disc_loss: 0.0122204395
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 2.9168308
disc_loss: 0.0106812995
disc_acc: 0.9970238095238095


	Epoch 330
Training results:
gen_loss: 3.3077493
disc_loss: 0.009139962
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.8812532
disc_loss: 0.03583684
disc_acc: 0.9905753968253969


	Epoch 331
Training results:
gen_loss: 3.2964163
disc_loss: 0.015561818
disc_acc: 0.995049504950495

Validation results:
gen_loss: 2.7820876
disc_loss: 0.03407713
disc_acc: 0.9885912698412699


	Epoch 332
Training results:
gen_loss: 3.2878568
disc_loss: 0.01512198
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.9008162
disc_loss: 0.018134162
disc_acc: 0.9920634920634921


	Epoch 333
Training results:
gen_loss: 3.2922945
disc_loss: 0.008860039
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 2.9299803
disc_loss: 0.008631903
disc_acc: 0.998015873015873


	Epoch 334
Training results:
gen_loss: 3.3049984
disc_loss: 0.011509493
disc_acc: 0.996039603960396

Validation results:
gen_loss: 2.94217
disc_loss: 0.0061387573
disc_acc: 0.9985119047619048


	Epoch 335
Training results:
gen_loss: 3.2989917
disc_loss: 0.0121796
disc_acc: 0.996410891089109

Validation results:
gen_loss: 2.9820035
disc_loss: 0.004353674
disc_acc: 0.998015873015873


	Epoch 336
Training results:
gen_loss: 3.3070061
disc_loss: 0.0121255275
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.9901788
disc_loss: 0.004420659
disc_acc: 0.9985119047619048


	Epoch 337
Training results:
gen_loss: 3.2966774
disc_loss: 0.018027382
disc_acc: 0.994430693069307

Validation results:
gen_loss: 2.927505
disc_loss: 0.013256229
disc_acc: 0.9950396825396826


	Epoch 338
Training results:
gen_loss: 3.3034236
disc_loss: 0.015064999
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 2.928758
disc_loss: 0.0026910142
disc_acc: 0.9995039682539683


	Epoch 339
Training results:
gen_loss: 3.3137066
disc_loss: 0.010997517
disc_acc: 0.996410891089109

Validation results:
gen_loss: 2.9616287
disc_loss: 0.0036846406
disc_acc: 0.9990079365079365


	Epoch 340
Training results:
gen_loss: 3.3216329
disc_loss: 0.013139715
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 2.823578
disc_loss: 0.020414798
disc_acc: 0.9920634920634921


	Epoch 341
Training results:
gen_loss: 3.318326
disc_loss: 0.0097455615
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 2.8723354
disc_loss: 0.014549963
disc_acc: 0.9945436507936508


	Epoch 342
Training results:
gen_loss: 3.3243966
disc_loss: 0.010318333
disc_acc: 0.9966584158415842

Validation results:
gen_loss: 3.0030854
disc_loss: 0.00406423
disc_acc: 0.9985119047619048


	Epoch 343
Training results:
gen_loss: 3.3282168
disc_loss: 0.011249217
disc_acc: 0.9966584158415842

Validation results:
gen_loss: 2.8771105
disc_loss: 0.005542257
disc_acc: 0.9975198412698413


	Epoch 344
Training results:
gen_loss: 3.3114083
disc_loss: 0.010395632
disc_acc: 0.9971534653465347

Validation results:
gen_loss: 2.9828749
disc_loss: 0.0037962333
disc_acc: 0.9990079365079365


	Epoch 345
Training results:
gen_loss: 3.3054335
disc_loss: 0.009082155
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 2.8863044
disc_loss: 0.013895693
disc_acc: 0.9950396825396826


	Epoch 346
Training results:
gen_loss: 3.3166306
disc_loss: 0.008936863
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 2.966065
disc_loss: 0.0020162934
disc_acc: 0.9990079365079365


	Epoch 347
Training results:
gen_loss: 3.317076
disc_loss: 0.0117905745
disc_acc: 0.996410891089109

Validation results:
gen_loss: 2.851241
disc_loss: 0.0022940505
disc_acc: 0.9995039682539683


	Epoch 348
Training results:
gen_loss: 3.312866
disc_loss: 0.0071957665
disc_acc: 0.9977722772277228

Validation results:
gen_loss: 2.9702828
disc_loss: 0.0036504986
disc_acc: 0.9990079365079365


	Epoch 349
Training results:
gen_loss: 3.3127296
disc_loss: 0.012477476
disc_acc: 0.996039603960396

Validation results:
gen_loss: 3.1175423
disc_loss: 0.14289504
disc_acc: 0.9439484126984127


	Epoch 350
Training results:
gen_loss: 3.3091211
disc_loss: 0.011128101
disc_acc: 0.996410891089109

Validation results:
gen_loss: 2.9542575
disc_loss: 0.0056839753
disc_acc: 0.998015873015873


	Epoch 351
Training results:
gen_loss: 3.3142662
disc_loss: 0.016110666
disc_acc: 0.9946782178217822

Validation results:
gen_loss: 2.7015917
disc_loss: 0.05627775
disc_acc: 0.9761904761904762


	Epoch 352
Training results:
gen_loss: 3.307096
disc_loss: 0.015183261
disc_acc: 0.994430693069307

Validation results:
gen_loss: 3.0232458
disc_loss: 0.006050127
disc_acc: 0.9975198412698413


	Epoch 353
Training results:
gen_loss: 3.3150153
disc_loss: 0.009351207
disc_acc: 0.9971534653465347

Validation results:
gen_loss: 2.8666828
disc_loss: 0.08362845
disc_acc: 0.9751984126984127


	Epoch 354
Training results:
gen_loss: 3.3061683
disc_loss: 0.013879317
disc_acc: 0.9956683168316832

Validation results:
gen_loss: 2.9041445
disc_loss: 0.01040866
disc_acc: 0.9965277777777778


	Epoch 355
Training results:
gen_loss: 3.3168812
disc_loss: 0.015451108
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.926137
disc_loss: 0.0045064855
disc_acc: 0.9995039682539683


	Epoch 356
Training results:
gen_loss: 3.326118
disc_loss: 0.009330136
disc_acc: 0.9971534653465347

Validation results:
gen_loss: 2.9359953
disc_loss: 0.0034555814
disc_acc: 0.9995039682539683


	Epoch 357
Training results:
gen_loss: 3.3283517
disc_loss: 0.01204603
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.9898086
disc_loss: 0.005962646
disc_acc: 0.9985119047619048


	Epoch 358
Training results:
gen_loss: 3.333338
disc_loss: 0.016573306
disc_acc: 0.9938118811881188

Validation results:
gen_loss: 3.1460848
disc_loss: 0.004059214
disc_acc: 0.9995039682539683


	Epoch 359
Training results:
gen_loss: 3.3331747
disc_loss: 0.011966678
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 3.018724
disc_loss: 0.015181171
disc_acc: 0.9955357142857143


	Epoch 360
Training results:
gen_loss: 3.3356776
disc_loss: 0.012516475
disc_acc: 0.996039603960396

Validation results:
gen_loss: 2.96365
disc_loss: 0.009001896
disc_acc: 0.9975198412698413


	Epoch 361
Training results:
gen_loss: 3.3309774
disc_loss: 0.011400894
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.9506524
disc_loss: 0.004546265
disc_acc: 0.9985119047619048


	Epoch 362
Training results:
gen_loss: 3.3324914
disc_loss: 0.008349301
disc_acc: 0.9971534653465347

Validation results:
gen_loss: 3.1083534
disc_loss: 0.07929414
disc_acc: 0.966765873015873


	Epoch 363
Training results:
gen_loss: 3.3281898
disc_loss: 0.008632086
disc_acc: 0.9972772277227723

Validation results:
gen_loss: 2.935282
disc_loss: 0.009643676
disc_acc: 0.9975198412698413


	Epoch 364
Training results:
gen_loss: 3.328432
disc_loss: 0.014256051
disc_acc: 0.9949257425742575

Validation results:
gen_loss: 2.933263
disc_loss: 0.04189089
disc_acc: 0.9861111111111112


	Epoch 365
Training results:
gen_loss: 3.335934
disc_loss: 0.00832634
disc_acc: 0.9972772277227723

Validation results:
gen_loss: 2.9227161
disc_loss: 0.004543393
disc_acc: 0.998015873015873


	Epoch 366
Training results:
gen_loss: 3.3262978
disc_loss: 0.012775765
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 2.9705021
disc_loss: 0.028642263
disc_acc: 0.9885912698412699


	Epoch 367
Training results:
gen_loss: 3.3294318
disc_loss: 0.009362034
disc_acc: 0.99740099009901

Validation results:
gen_loss: 2.903924
disc_loss: 0.002318327
disc_acc: 0.9990079365079365


	Epoch 368
Training results:
gen_loss: 3.3309624
disc_loss: 0.014355468
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.9534757
disc_loss: 0.0020029526
disc_acc: 1.0


	Epoch 369
Training results:
gen_loss: 3.3245397
disc_loss: 0.010498452
disc_acc: 0.9966584158415842

Validation results:
gen_loss: 2.887501
disc_loss: 0.0062705744
disc_acc: 0.9970238095238095


	Epoch 370
Training results:
gen_loss: 3.3295226
disc_loss: 0.00907518
disc_acc: 0.9972772277227723

Validation results:
gen_loss: 2.9904993
disc_loss: 0.005202969
disc_acc: 0.9985119047619048


	Epoch 371
Training results:
gen_loss: 3.328107
disc_loss: 0.009180753
disc_acc: 0.99740099009901

Validation results:
gen_loss: 2.936929
disc_loss: 0.0029305767
disc_acc: 0.9995039682539683


	Epoch 372
Training results:
gen_loss: 3.33667
disc_loss: 0.007416961
disc_acc: 0.998391089108911

Validation results:
gen_loss: 2.9687893
disc_loss: 0.002605878
disc_acc: 0.9995039682539683


	Epoch 373
Training results:
gen_loss: 3.3250113
disc_loss: 0.010679798
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 2.8895288
disc_loss: 0.0026068636
disc_acc: 0.9995039682539683


	Epoch 374
Training results:
gen_loss: 3.329035
disc_loss: 0.013088511
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 2.8636165
disc_loss: 0.9717214
disc_acc: 0.7872023809523809


	Epoch 375
Training results:
gen_loss: 3.3254201
disc_loss: 0.01020398
disc_acc: 0.997029702970297

Validation results:
gen_loss: 3.003675
disc_loss: 1.0548309
disc_acc: 0.7931547619047619


	Epoch 376
Training results:
gen_loss: 3.3176577
disc_loss: 0.012235362
disc_acc: 0.996039603960396

Validation results:
gen_loss: 2.9142559
disc_loss: 0.0041391063
disc_acc: 0.9985119047619048


	Epoch 377
Training results:
gen_loss: 3.3235
disc_loss: 0.0094345035
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 2.9691298
disc_loss: 0.0030952084
disc_acc: 0.9985119047619048


	Epoch 378
Training results:
gen_loss: 3.332289
disc_loss: 0.009271284
disc_acc: 0.9972772277227723

Validation results:
gen_loss: 3.0188434
disc_loss: 0.006900788
disc_acc: 0.9975198412698413


	Epoch 379
Training results:
gen_loss: 3.3418622
disc_loss: 0.0065053026
disc_acc: 0.998391089108911

Validation results:
gen_loss: 2.8632143
disc_loss: 0.043741036
disc_acc: 0.9846230158730159


	Epoch 380
Training results:
gen_loss: 3.345211
disc_loss: 0.010315789
disc_acc: 0.997029702970297

Validation results:
gen_loss: 2.9716744
disc_loss: 0.0049275327
disc_acc: 0.998015873015873


	Epoch 381
Training results:
gen_loss: 3.3478425
disc_loss: 0.01172163
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 2.8886251
disc_loss: 0.002424498
disc_acc: 0.9990079365079365


	Epoch 382
Training results:
gen_loss: 3.3588636
disc_loss: 0.008466663
disc_acc: 0.9982673267326733

Validation results:
gen_loss: 2.9522176
disc_loss: 0.004462586
disc_acc: 0.9985119047619048


	Epoch 383
Training results:
gen_loss: 3.358661
disc_loss: 0.013190942
disc_acc: 0.995420792079208

Validation results:
gen_loss: 2.9704323
disc_loss: 0.023238866
disc_acc: 0.9910714285714286


	Epoch 384
Training results:
gen_loss: 3.3444457
disc_loss: 0.017796816
disc_acc: 0.994430693069307

Validation results:
gen_loss: 2.8219657
disc_loss: 0.03889506
disc_acc: 0.9841269841269841


	Epoch 385
Training results:
gen_loss: 3.3481812
disc_loss: 0.017123139
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 3.1019142
disc_loss: 0.7184381
disc_acc: 0.8809523809523809


	Epoch 386
Training results:
gen_loss: 3.3438122
disc_loss: 0.010003361
disc_acc: 0.9971534653465347

Validation results:
gen_loss: 2.908087
disc_loss: 0.0027794188
disc_acc: 0.9990079365079365


	Epoch 387
Training results:
gen_loss: 3.3437726
disc_loss: 0.011327409
disc_acc: 0.9971534653465347

Validation results:
gen_loss: 2.9797783
disc_loss: 0.0048787035
disc_acc: 0.9975198412698413


	Epoch 388
Training results:
gen_loss: 3.3494358
disc_loss: 0.008010991
disc_acc: 0.99740099009901

Validation results:
gen_loss: 3.0353427
disc_loss: 0.005883029
disc_acc: 0.998015873015873


	Epoch 389
Training results:
gen_loss: 3.3608298
disc_loss: 0.009149191
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.9216585
disc_loss: 0.0022269047
disc_acc: 0.9995039682539683


	Epoch 390
Training results:
gen_loss: 3.3541312
disc_loss: 0.009048933
disc_acc: 0.9975247524752475

Validation results:
gen_loss: 2.9138763
disc_loss: 0.0034148672
disc_acc: 0.9990079365079365


	Epoch 391
Training results:
gen_loss: 3.3548458
disc_loss: 0.008256879
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 2.9020457
disc_loss: 2.9489093
disc_acc: 0.5094246031746031


	Epoch 392
Training results:
gen_loss: 3.3486884
disc_loss: 0.011827513
disc_acc: 0.996410891089109

Validation results:
gen_loss: 2.859671
disc_loss: 0.07513078
disc_acc: 0.9761904761904762


	Epoch 393
Training results:
gen_loss: 3.3451238
disc_loss: 0.007803478
disc_acc: 0.998019801980198

Validation results:
gen_loss: 2.9699652
disc_loss: 0.0017088089
disc_acc: 1.0


	Epoch 394
Training results:
gen_loss: 3.3532743
disc_loss: 0.010508002
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 2.9919274
disc_loss: 0.0024253076
disc_acc: 0.9990079365079365


	Epoch 395
Training results:
gen_loss: 3.343326
disc_loss: 0.016121035
disc_acc: 0.9948019801980198

Validation results:
gen_loss: 3.0295298
disc_loss: 0.00509702
disc_acc: 0.9990079365079365


	Epoch 396
Training results:
gen_loss: 3.3608027
disc_loss: 0.00928324
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.7923863
disc_loss: 0.018176608
disc_acc: 0.9940476190476191


	Epoch 397
Training results:
gen_loss: 3.3495867
disc_loss: 0.012683993
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.9292533
disc_loss: 0.008738866
disc_acc: 0.996031746031746


	Epoch 398
Training results:
gen_loss: 3.348153
disc_loss: 0.009304147
disc_acc: 0.9977722772277228

Validation results:
gen_loss: 3.0043917
disc_loss: 0.11064769
disc_acc: 0.9558531746031746


	Epoch 399
Training results:
gen_loss: 3.3540373
disc_loss: 0.010691858
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 3.0514903
disc_loss: 0.003649333
disc_acc: 0.9990079365079365


	Epoch 400
Training results:
gen_loss: 3.3654883
disc_loss: 0.00792034
disc_acc: 0.9978960396039604

Validation results:
gen_loss: 2.9059546
disc_loss: 0.008356426
disc_acc: 0.9965277777777778


	Epoch 401
Training results:
gen_loss: 3.3587759
disc_loss: 0.012149511
disc_acc: 0.996410891089109

Validation results:
gen_loss: 2.9646707
disc_loss: 0.0013663649
disc_acc: 1.0


	Epoch 402
Training results:
gen_loss: 3.35475
disc_loss: 0.018317025
disc_acc: 0.994059405940594

Validation results:
gen_loss: 3.0277126
disc_loss: 0.0038277442
disc_acc: 0.9990079365079365


	Epoch 403
Training results:
gen_loss: 3.366648
disc_loss: 0.008311881
disc_acc: 0.99740099009901

Validation results:
gen_loss: 2.9916203
disc_loss: 0.0035433292
disc_acc: 0.9995039682539683


	Epoch 404
Training results:
gen_loss: 3.3573828
disc_loss: 0.014667685
disc_acc: 0.9949257425742575

Validation results:
gen_loss: 3.0052795
disc_loss: 0.026068684
disc_acc: 0.9910714285714286


	Epoch 405
Training results:
gen_loss: 3.3423665
disc_loss: 0.012773901
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.89346
disc_loss: 0.44825807
disc_acc: 0.8784722222222222


	Epoch 406
Training results:
gen_loss: 3.3405132
disc_loss: 0.011823549
disc_acc: 0.9955445544554455

Validation results:
gen_loss: 2.979345
disc_loss: 0.005761936
disc_acc: 0.9975198412698413


	Epoch 407
Training results:
gen_loss: 3.351504
disc_loss: 0.011006675
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.9325612
disc_loss: 0.005514969
disc_acc: 0.9985119047619048


	Epoch 408
Training results:
gen_loss: 3.3492613
disc_loss: 0.012479403
disc_acc: 0.9955445544554455

Validation results:
gen_loss: 2.7813056
disc_loss: 0.009738282
disc_acc: 0.9970238095238095


	Epoch 409
Training results:
gen_loss: 3.3723662
disc_loss: 0.0070627
disc_acc: 0.99740099009901

Validation results:
gen_loss: 3.0332098
disc_loss: 0.0069525805
disc_acc: 0.9970238095238095


	Epoch 410
Training results:
gen_loss: 3.371661
disc_loss: 0.012467677
disc_acc: 0.9966584158415842

Validation results:
gen_loss: 2.8987203
disc_loss: 0.019541983
disc_acc: 0.9905753968253969


	Epoch 411
Training results:
gen_loss: 3.3394973
disc_loss: 0.012613693
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 3.0477958
disc_loss: 0.005202016
disc_acc: 0.998015873015873


	Epoch 412
Training results:
gen_loss: 3.3578885
disc_loss: 0.009247797
disc_acc: 0.9972772277227723

Validation results:
gen_loss: 2.9945977
disc_loss: 0.006348603
disc_acc: 0.9975198412698413


	Epoch 413
Training results:
gen_loss: 3.362417
disc_loss: 0.0073046717
disc_acc: 0.9981435643564357

Validation results:
gen_loss: 3.01999
disc_loss: 0.0018677579
disc_acc: 1.0


	Epoch 414
Training results:
gen_loss: 3.3664393
disc_loss: 0.008150505
disc_acc: 0.9977722772277228

Validation results:
gen_loss: 2.9584014
disc_loss: 0.013322646
disc_acc: 0.9945436507936508


	Epoch 415
Training results:
gen_loss: 3.3712559
disc_loss: 0.0119471615
disc_acc: 0.996410891089109

Validation results:
gen_loss: 3.0588043
disc_loss: 0.023302652
disc_acc: 0.9935515873015873


	Epoch 416
Training results:
gen_loss: 3.369872
disc_loss: 0.011865642
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.9242702
disc_loss: 0.6778711
disc_acc: 0.8125


	Epoch 417
Training results:
gen_loss: 3.3618548
disc_loss: 0.011519769
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 3.0735464
disc_loss: 0.0057863034
disc_acc: 0.9985119047619048


	Epoch 418
Training results:
gen_loss: 3.3663507
disc_loss: 0.006554946
disc_acc: 0.9982673267326733

Validation results:
gen_loss: 2.9538362
disc_loss: 0.00414656
disc_acc: 0.9985119047619048


	Epoch 419
Training results:
gen_loss: 3.3727238
disc_loss: 0.007580611
disc_acc: 0.9977722772277228

Validation results:
gen_loss: 2.8644207
disc_loss: 0.0039414666
disc_acc: 0.998015873015873


	Epoch 420
Training results:
gen_loss: 3.369215
disc_loss: 0.0077664205
disc_acc: 0.9978960396039604

Validation results:
gen_loss: 3.0803323
disc_loss: 0.0077437973
disc_acc: 0.9975198412698413


	Epoch 421
Training results:
gen_loss: 3.3614244
disc_loss: 0.013964881
disc_acc: 0.995049504950495

Validation results:
gen_loss: 2.934069
disc_loss: 0.0028582015
disc_acc: 0.998015873015873


	Epoch 422
Training results:
gen_loss: 3.3718977
disc_loss: 0.008926477
disc_acc: 0.9972772277227723

Validation results:
gen_loss: 2.8936095
disc_loss: 0.00564345
disc_acc: 0.998015873015873


	Epoch 423
Training results:
gen_loss: 3.3734534
disc_loss: 0.009073599
disc_acc: 0.9971534653465347

Validation results:
gen_loss: 3.0541728
disc_loss: 0.0038991484
disc_acc: 0.9990079365079365


	Epoch 424
Training results:
gen_loss: 3.3796084
disc_loss: 0.008356936
disc_acc: 0.99740099009901

Validation results:
gen_loss: 2.8825877
disc_loss: 0.0034817955
disc_acc: 0.9990079365079365


	Epoch 425
Training results:
gen_loss: 3.3754008
disc_loss: 0.010522635
disc_acc: 0.996410891089109

Validation results:
gen_loss: 3.1360652
disc_loss: 0.008413944
disc_acc: 0.9965277777777778


	Epoch 426
Training results:
gen_loss: 3.3759985
disc_loss: 0.006724473
disc_acc: 0.998019801980198

Validation results:
gen_loss: 3.0257456
disc_loss: 0.0032318353
disc_acc: 0.9990079365079365


	Epoch 427
Training results:
gen_loss: 3.3817189
disc_loss: 0.00940387
disc_acc: 0.997029702970297

Validation results:
gen_loss: 3.0101783
disc_loss: 0.00405654
disc_acc: 0.9975198412698413


	Epoch 428
Training results:
gen_loss: 3.3885708
disc_loss: 0.0119214
disc_acc: 0.996410891089109

Validation results:
gen_loss: 3.0184388
disc_loss: 0.023462815
disc_acc: 0.9915674603174603


	Epoch 429
Training results:
gen_loss: 3.3787487
disc_loss: 0.009262844
disc_acc: 0.997029702970297

Validation results:
gen_loss: 2.85344
disc_loss: 0.26495293
disc_acc: 0.9330357142857143


	Epoch 430
Training results:
gen_loss: 3.3890438
disc_loss: 0.011007553
disc_acc: 0.996410891089109

Validation results:
gen_loss: 3.0788157
disc_loss: 0.0028277829
disc_acc: 0.9995039682539683


	Epoch 431
Training results:
gen_loss: 3.3896542
disc_loss: 0.011539894
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 2.762362
disc_loss: 0.03962329
disc_acc: 0.9885912698412699


	Epoch 432
Training results:
gen_loss: 3.388863
disc_loss: 0.009130899
disc_acc: 0.9966584158415842

Validation results:
gen_loss: 2.9559572
disc_loss: 0.0032546502
disc_acc: 0.9995039682539683


	Epoch 433
Training results:
gen_loss: 3.3898423
disc_loss: 0.009656304
disc_acc: 0.9972772277227723

Validation results:
gen_loss: 2.9791036
disc_loss: 0.027270762
disc_acc: 0.9885912698412699


	Epoch 434
Training results:
gen_loss: 3.377626
disc_loss: 0.013081845
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.904169
disc_loss: 0.007105444
disc_acc: 0.9970238095238095


	Epoch 435
Training results:
gen_loss: 3.3864675
disc_loss: 0.00982868
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.9779267
disc_loss: 0.003641618
disc_acc: 0.9995039682539683


	Epoch 436
Training results:
gen_loss: 3.3906622
disc_loss: 0.0102492245
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 3.0376852
disc_loss: 0.0093521755
disc_acc: 0.9970238095238095


	Epoch 437
Training results:
gen_loss: 3.3857567
disc_loss: 0.012806692
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.939138
disc_loss: 0.005333793
disc_acc: 0.9985119047619048


	Epoch 438
Training results:
gen_loss: 3.3659692
disc_loss: 0.019008297
disc_acc: 0.9933168316831683

Validation results:
gen_loss: 2.9656913
disc_loss: 0.0033719258
disc_acc: 0.9985119047619048


	Epoch 439
Training results:
gen_loss: 3.3727279
disc_loss: 0.009510126
disc_acc: 0.9971534653465347

Validation results:
gen_loss: 3.0388653
disc_loss: 0.0046050153
disc_acc: 0.9985119047619048


	Epoch 440
Training results:
gen_loss: 3.3870864
disc_loss: 0.007844019
disc_acc: 0.9975247524752475

Validation results:
gen_loss: 3.099847
disc_loss: 0.025711132
disc_acc: 0.9920634920634921


	Epoch 441
Training results:
gen_loss: 3.4004424
disc_loss: 0.014662889
disc_acc: 0.9955445544554455

Validation results:
gen_loss: 2.913528
disc_loss: 0.007039959
disc_acc: 0.998015873015873


	Epoch 442
Training results:
gen_loss: 3.3918495
disc_loss: 0.01588691
disc_acc: 0.9943069306930693

Validation results:
gen_loss: 3.0129108
disc_loss: 0.009875693
disc_acc: 0.996031746031746


	Epoch 443
Training results:
gen_loss: 3.3997278
disc_loss: 0.010845222
disc_acc: 0.996410891089109

Validation results:
gen_loss: 3.008543
disc_loss: 0.008482292
disc_acc: 0.998015873015873


	Epoch 444
Training results:
gen_loss: 3.397902
disc_loss: 0.014026354
disc_acc: 0.9952970297029703

Validation results:
gen_loss: 2.9920232
disc_loss: 0.0067875944
disc_acc: 0.9975198412698413


	Epoch 445
Training results:
gen_loss: 3.3921947
disc_loss: 0.0066192816
disc_acc: 0.9978960396039604

Validation results:
gen_loss: 2.9800427
disc_loss: 0.0022365702
disc_acc: 1.0


	Epoch 446
Training results:
gen_loss: 3.377907
disc_loss: 0.012007235
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 3.0116718
disc_loss: 0.0059089353
disc_acc: 0.998015873015873


	Epoch 447
Training results:
gen_loss: 3.3938024
disc_loss: 0.0052060205
disc_acc: 0.999009900990099

Validation results:
gen_loss: 2.8756492
disc_loss: 0.018675284
disc_acc: 0.9930555555555556


	Epoch 448
Training results:
gen_loss: 3.38799
disc_loss: 0.0151636675
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 3.007304
disc_loss: 0.014105346
disc_acc: 0.996031746031746


	Epoch 449
Training results:
gen_loss: 3.3973134
disc_loss: 0.0095566865
disc_acc: 0.997029702970297

Validation results:
gen_loss: 3.0162477
disc_loss: 0.0024874173
disc_acc: 0.9990079365079365


	Epoch 450
Training results:
gen_loss: 3.4057052
disc_loss: 0.00890539
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 3.033598
disc_loss: 0.011340143
disc_acc: 0.9965277777777778


	Epoch 451
Training results:
gen_loss: 3.397775
disc_loss: 0.0110741155
disc_acc: 0.996039603960396

Validation results:
gen_loss: 2.9517722
disc_loss: 0.001898924
disc_acc: 0.9995039682539683


	Epoch 452
Training results:
gen_loss: 3.391573
disc_loss: 0.0150392195
disc_acc: 0.9951732673267327

Validation results:
gen_loss: 2.8846192
disc_loss: 0.0046482896
disc_acc: 0.9985119047619048


	Epoch 453
Training results:
gen_loss: 3.372769
disc_loss: 0.0111010065
disc_acc: 0.9965346534653465

Validation results:
gen_loss: 3.1110563
disc_loss: 0.06025879
disc_acc: 0.9756944444444444


	Epoch 454
Training results:
gen_loss: 3.3821893
disc_loss: 0.0121169565
disc_acc: 0.995420792079208

Validation results:
gen_loss: 3.0542855
disc_loss: 0.0037407456
disc_acc: 0.998015873015873


	Epoch 455
Training results:
gen_loss: 3.4007068
disc_loss: 0.0052232374
disc_acc: 0.9986386138613862

Validation results:
gen_loss: 2.9405005
disc_loss: 0.0024694127
disc_acc: 0.9995039682539683


	Epoch 456
Training results:
gen_loss: 3.3882933
disc_loss: 0.0067212475
disc_acc: 0.9975247524752475

Validation results:
gen_loss: 3.0061004
disc_loss: 0.0039070323
disc_acc: 0.9985119047619048


	Epoch 457
Training results:
gen_loss: 3.4064384
disc_loss: 0.004313167
disc_acc: 0.9985148514851485

Validation results:
gen_loss: 2.9033108
disc_loss: 0.12482734
disc_acc: 0.9558531746031746


	Epoch 458
Training results:
gen_loss: 3.420269
disc_loss: 0.00488926
disc_acc: 0.9986386138613862

Validation results:
gen_loss: 3.0680141
disc_loss: 0.008143632
disc_acc: 0.9970238095238095


	Epoch 459
Training results:
gen_loss: 3.4237556
disc_loss: 0.0040867445
disc_acc: 0.999009900990099

Validation results:
gen_loss: 2.8446243
disc_loss: 0.009129151
disc_acc: 0.9985119047619048


	Epoch 460
Training results:
gen_loss: 3.4166007
disc_loss: 0.006307252
disc_acc: 0.9985148514851485

Validation results:
gen_loss: 2.9823334
disc_loss: 0.0056498223
disc_acc: 0.9975198412698413


	Epoch 461
Training results:
gen_loss: 3.3861697
disc_loss: 0.009870946
disc_acc: 0.9966584158415842

Validation results:
gen_loss: 2.8551412
disc_loss: 0.009158312
disc_acc: 0.9970238095238095


	Epoch 462
Training results:
gen_loss: 3.4006433
disc_loss: 0.0067242202
disc_acc: 0.9982673267326733

Validation results:
gen_loss: 3.058037
disc_loss: 0.033533137
disc_acc: 0.9885912698412699


	Epoch 463
Training results:
gen_loss: 3.407748
disc_loss: 0.005398856
disc_acc: 0.9986386138613862

Validation results:
gen_loss: 2.8146043
disc_loss: 0.01871056
disc_acc: 0.9935515873015873


	Epoch 464
Training results:
gen_loss: 3.4101944
disc_loss: 0.011437675
disc_acc: 0.9956683168316832

Validation results:
gen_loss: 2.879002
disc_loss: 0.0043057627
disc_acc: 0.9985119047619048


	Epoch 465
Training results:
gen_loss: 3.4136767
disc_loss: 0.0068776743
disc_acc: 0.998391089108911

Validation results:
gen_loss: 2.9036267
disc_loss: 0.0033376454
disc_acc: 0.9990079365079365


	Epoch 466
Training results:
gen_loss: 3.4111407
disc_loss: 0.0049705044
disc_acc: 0.9992574257425743

Validation results:
gen_loss: 2.9439986
disc_loss: 0.0024226967
disc_acc: 0.9995039682539683


	Epoch 467
Training results:
gen_loss: 3.4206073
disc_loss: 0.010696342
disc_acc: 0.9967821782178218

Validation results:
gen_loss: 2.8696582
disc_loss: 0.02479997
disc_acc: 0.9910714285714286


	Epoch 468
Training results:
gen_loss: 3.404203
disc_loss: 0.011193519
disc_acc: 0.9961633663366337

Validation results:
gen_loss: 2.9610076
disc_loss: 0.01125556
disc_acc: 0.9955357142857143


	Epoch 469
Training results:
gen_loss: 3.416788
disc_loss: 0.0063082785
disc_acc: 0.998391089108911

Validation results:
gen_loss: 3.0658028
disc_loss: 0.022485053
disc_acc: 0.9920634920634921


	Epoch 470
Training results:
gen_loss: 3.4271889
disc_loss: 0.0057698796
disc_acc: 0.998391089108911

Validation results:
gen_loss: 2.9750657
disc_loss: 0.0066788895
disc_acc: 0.9975198412698413


	Epoch 471
Training results:
gen_loss: 3.4247515
disc_loss: 0.00635914
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 3.171487
disc_loss: 0.35351172
disc_acc: 0.9489087301587301


	Epoch 472
Training results:
gen_loss: 3.417851
disc_loss: 0.00650324
disc_acc: 0.9981435643564357

Validation results:
gen_loss: 2.9301286
disc_loss: 0.10519993
disc_acc: 0.9627976190476191


	Epoch 473
Training results:
gen_loss: 3.4156764
disc_loss: 0.0075097564
disc_acc: 0.9975247524752475

Validation results:
gen_loss: 3.0550058
disc_loss: 0.0032257095
disc_acc: 0.9995039682539683


	Epoch 474
Training results:
gen_loss: 3.4267554
disc_loss: 0.004147693
disc_acc: 0.9987623762376238

Validation results:
gen_loss: 2.9816384
disc_loss: 0.004056416
disc_acc: 0.9985119047619048


	Epoch 475
Training results:
gen_loss: 3.423574
disc_loss: 0.007529898
disc_acc: 0.9977722772277228

Validation results:
gen_loss: 3.0182796
disc_loss: 0.55743116
disc_acc: 0.8501984126984127


	Epoch 476
Training results:
gen_loss: 3.4157836
disc_loss: 0.0127927065
disc_acc: 0.9959158415841585

Validation results:
gen_loss: 3.0251582
disc_loss: 0.036834426
disc_acc: 0.9880952380952381


	Epoch 477
Training results:
gen_loss: 3.4129872
disc_loss: 0.011446008
disc_acc: 0.996039603960396

Validation results:
gen_loss: 3.0633516
disc_loss: 0.35362378
disc_acc: 0.9107142857142857


	Epoch 478
Training results:
gen_loss: 3.412388
disc_loss: 0.010654997
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 3.015969
disc_loss: 0.0030411582
disc_acc: 0.9985119047619048


	Epoch 479
Training results:
gen_loss: 3.4262369
disc_loss: 0.011395094
disc_acc: 0.9969059405940595

Validation results:
gen_loss: 3.015931
disc_loss: 0.005050739
disc_acc: 0.9990079365079365


	Epoch 480
Training results:
gen_loss: 3.422289
disc_loss: 0.009298923
disc_acc: 0.998019801980198

Validation results:
gen_loss: 3.1011298
disc_loss: 0.0029885333
disc_acc: 0.9985119047619048


	Epoch 481
Training results:
gen_loss: 3.4059565
disc_loss: 0.011184656
disc_acc: 0.9962871287128713

Validation results:
gen_loss: 3.0289757
disc_loss: 0.0025662237
disc_acc: 0.9985119047619048


	Epoch 482
Training results:
gen_loss: 3.4143522
disc_loss: 0.013003842
disc_acc: 0.9957920792079208

Validation results:
gen_loss: 3.0169234
disc_loss: 0.006778239
disc_acc: 0.9970238095238095


	Epoch 483
Training results:
gen_loss: 3.4163535
disc_loss: 0.009005207
disc_acc: 0.99740099009901

Validation results:
gen_loss: 2.9827318
disc_loss: 0.016018089
disc_acc: 0.9955357142857143


	Epoch 484
Training results:
gen_loss: 3.4113984
disc_loss: 0.010773586
disc_acc: 0.996410891089109

Validation results:
gen_loss: 3.039045
disc_loss: 0.0028642411
disc_acc: 0.9995039682539683


	Epoch 485
Training results:
gen_loss: 3.4274108
disc_loss: 0.005636502
disc_acc: 0.9981435643564357

Validation results:
gen_loss: 2.966118
disc_loss: 0.011937535
disc_acc: 0.996031746031746


	Epoch 486
Training results:
gen_loss: 3.4328387
disc_loss: 0.00570358
disc_acc: 0.9982673267326733

Validation results:
gen_loss: 3.023822
disc_loss: 0.0033087172
disc_acc: 0.9990079365079365


	Epoch 487
Training results:
gen_loss: 3.4221442
disc_loss: 0.004175942
disc_acc: 0.9991336633663367

Validation results:
gen_loss: 3.0097678
disc_loss: 0.004811202
disc_acc: 0.9985119047619048


	Epoch 488
Training results:
gen_loss: 3.427673
disc_loss: 0.005991026
disc_acc: 0.9981435643564357

Validation results:
gen_loss: 3.0215201
disc_loss: 0.0037277893
disc_acc: 0.998015873015873


	Epoch 489
Training results:
gen_loss: 3.4261432
disc_loss: 0.009153034
disc_acc: 0.9978960396039604

Validation results:
gen_loss: 3.0577712
disc_loss: 0.11259581
disc_acc: 0.9548611111111112


	Epoch 490
Training results:
gen_loss: 3.419609
disc_loss: 0.008738939
disc_acc: 0.997029702970297

Validation results:
gen_loss: 3.0027413
disc_loss: 0.0023839413
disc_acc: 1.0


	Epoch 491
Training results:
gen_loss: 3.4268236
disc_loss: 0.0072033955
disc_acc: 0.9981435643564357

Validation results:
gen_loss: 2.960436
disc_loss: 0.0029963427
disc_acc: 0.9990079365079365


	Epoch 492
Training results:
gen_loss: 3.437016
disc_loss: 0.003800195
disc_acc: 0.9992574257425743

Validation results:
gen_loss: 3.096222
disc_loss: 0.005512958
disc_acc: 0.998015873015873


	Epoch 493
Training results:
gen_loss: 3.4397364
disc_loss: 0.0031959482
disc_acc: 0.9996287128712872

Validation results:
gen_loss: 3.060681
disc_loss: 0.006443179
disc_acc: 0.9975198412698413


	Epoch 494
Training results:
gen_loss: 3.4500928
disc_loss: 0.005081951
disc_acc: 0.998019801980198

Validation results:
gen_loss: 3.088489
disc_loss: 0.007161726
disc_acc: 0.9975198412698413


	Epoch 495
Training results:
gen_loss: 3.4259813
disc_loss: 0.01354467
disc_acc: 0.9956683168316832

Validation results:
gen_loss: 2.8636708
disc_loss: 0.00350103
disc_acc: 0.9995039682539683


	Epoch 496
Training results:
gen_loss: 3.422358
disc_loss: 0.00665294
disc_acc: 0.998019801980198

Validation results:
gen_loss: 2.984683
disc_loss: 0.0038702546
disc_acc: 0.9995039682539683


	Epoch 497
Training results:
gen_loss: 3.429218
disc_loss: 0.0061802226
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 3.1429794
disc_loss: 0.0067297365
disc_acc: 0.9970238095238095


	Epoch 498
Training results:
gen_loss: 3.4431243
disc_loss: 0.005286048
disc_acc: 0.998391089108911

Validation results:
gen_loss: 3.0546346
disc_loss: 0.008020083
disc_acc: 0.9970238095238095


	Epoch 499
Training results:
gen_loss: 3.4359484
disc_loss: 0.007665828
disc_acc: 0.9976485148514852

Validation results:
gen_loss: 2.8774328
disc_loss: 0.9948644
disc_acc: 0.8115079365079365


	Epoch 500
Training results:
gen_loss: 3.4286432
disc_loss: 0.005906226
disc_acc: 0.9982673267326733

Validation results:
gen_loss: 3.0183218
disc_loss: 0.0025328754
disc_acc: 0.9995039682539683



gen_train_loss: 0.017465893, 1.6347638, 1.9479733, 2.0768757, 2.156952, 2.217312, 2.2676501, 2.308558, 2.3314872, 2.3593879, 2.373747, 2.4000354, 2.4126134, 2.4284458, 2.4481063, 2.4755049, 2.4777532, 2.495575, 2.5140407, 2.5255888, 2.5379882, 2.5474706, 2.5500252, 2.567492, 2.5759737, 2.5747774, 2.5866075, 2.5981262, 2.6024232, 2.6016521, 2.618357, 2.6310465, 2.627496, 2.6426651, 2.6304667, 2.6514106, 2.6587195, 2.6668339, 2.6781085, 2.698086, 2.7086053, 2.7024956, 2.708086, 2.7073495, 2.7148495, 2.704181, 2.7193356, 2.7151928, 2.734951, 2.72306, 2.7300892, 2.7419014, 2.7476811, 2.747555, 2.7425697, 2.7550743, 2.7640524, 2.7687135, 2.768176, 2.7810144, 2.7705402, 2.7711656, 2.7765133, 2.7894318, 2.795497, 2.7993276, 2.8076491, 2.8013656, 2.7993166, 2.80679, 2.8076384, 2.820375, 2.8196516, 2.830952, 2.8329449, 2.8449636, 2.8395536, 2.833643, 2.835177, 2.8389106, 2.8478053, 2.8454814, 2.8444476, 2.854832, 2.8730114, 2.8664365, 2.8665574, 2.8751454, 2.8752997, 2.8821754, 2.884753, 2.8766959, 2.8834264, 2.8900774, 2.8796687, 2.8840652, 2.8906052, 2.908801, 2.903699, 2.9147608, 2.91784, 2.9185097, 2.9212198, 2.9201274, 2.9210544, 2.928291, 2.9409184, 2.9356737, 2.9310355, 2.9428325, 2.9398844, 2.9562821, 2.9500084, 2.9432073, 2.9615345, 2.9555688, 2.9504254, 2.9586148, 2.9623473, 2.969494, 2.961171, 2.9674113, 2.9815404, 2.9769082, 2.9814825, 2.982799, 2.9763885, 2.9861033, 2.9820392, 2.9911056, 2.9996424, 2.9868417, 2.9862933, 2.9989994, 2.995482, 2.980237, 2.9862018, 2.9944549, 3.0103014, 3.0093172, 3.0126958, 3.0201476, 3.0168743, 3.0059159, 3.0083, 3.0189264, 3.0190618, 3.034583, 3.0339248, 3.0341177, 3.0377824, 3.0409696, 3.0435362, 3.0395555, 3.03664, 3.0315526, 3.0423887, 3.047834, 3.0479693, 3.0505004, 3.0495915, 3.0501142, 3.060376, 3.0542214, 3.0597336, 3.068819, 3.054695, 3.0663733, 3.0786703, 3.0773818, 3.0750785, 3.0654955, 3.0659559, 3.0685015, 3.0654607, 3.0753016, 3.0747356, 3.0769336, 3.0797513, 3.077195, 3.0754712, 3.0829215, 3.0820677, 3.092214, 3.0980473, 3.0944521, 3.090302, 3.0910366, 3.0865402, 3.1118634, 3.0969827, 3.1021824, 3.1061165, 3.1100879, 3.1077733, 3.1104536, 3.1067512, 3.1057177, 3.099824, 3.1050484, 3.107762, 3.1022737, 3.1093457, 3.1170223, 3.121218, 3.12051, 3.1255028, 3.114389, 3.1191294, 3.1264768, 3.1296499, 3.1345549, 3.128302, 3.1379921, 3.1487575, 3.1407492, 3.1378431, 3.1467893, 3.1466088, 3.1499329, 3.1527395, 3.1511803, 3.1639788, 3.1571631, 3.152934, 3.1577358, 3.1608162, 3.1578054, 3.149919, 3.1672788, 3.162742, 3.1630347, 3.1745307, 3.1799102, 3.1804197, 3.1815398, 3.1737125, 3.1773028, 3.1614833, 3.1751106, 3.177758, 3.1654322, 3.17565, 3.1791139, 3.1773891, 3.1779983, 3.1791263, 3.1764576, 3.1869364, 3.1806734, 3.1782646, 3.1800196, 3.1844783, 3.1765053, 3.1771064, 3.1821203, 3.194276, 3.1942701, 3.1860662, 3.1928523, 3.2020717, 3.2085147, 3.206692, 3.1955452, 3.2037647, 3.2022867, 3.2168162, 3.2112474, 3.2038682, 3.2108054, 3.2071364, 3.196829, 3.2086184, 3.2048159, 3.218865, 3.2168555, 3.2112885, 3.2094934, 3.2170835, 3.2166317, 3.2107546, 3.2125618, 3.2165444, 3.2254138, 3.2195308, 3.223714, 3.2283459, 3.2270598, 3.2307315, 3.2268088, 3.2412114, 3.241285, 3.2369194, 3.233255, 3.2393804, 3.245163, 3.2489161, 3.2481155, 3.2389834, 3.2477684, 3.2393563, 3.2453394, 3.2537453, 3.251238, 3.2494822, 3.247621, 3.248507, 3.2583146, 3.2550907, 3.2462585, 3.2481875, 3.2433493, 3.263064, 3.2549057, 3.2639167, 3.2651029, 3.2650158, 3.2595625, 3.2789307, 3.269112, 3.2736053, 3.2665744, 3.276214, 3.2749581, 3.2680616, 3.2665143, 3.2810836, 3.2643957, 3.270853, 3.268723, 3.2780876, 3.2772224, 3.276505, 3.2814658, 3.282696, 3.270338, 3.2640038, 3.2501824, 3.2576768, 3.27185, 3.2803597, 3.2764122, 3.261383, 3.276022, 3.2891889, 3.2922788, 3.2833457, 3.289587, 3.2935812, 3.291893, 3.2959695, 3.3023138, 3.2963078, 3.2906518, 3.2837846, 3.2809498, 3.3047316, 3.2977097, 3.302877, 3.299969, 3.3038304, 3.3056736, 3.3100543, 3.3208437, 3.3147576, 3.3143046, 3.3093777, 3.3092275, 3.321741, 3.3041565, 3.311937, 3.3123655, 3.3039422, 3.3199813, 3.3237498, 3.3242002, 3.3261578, 3.3309748, 3.315227, 3.3148382, 3.3110888, 3.3225965, 3.3237987, 3.320489, 3.3200629, 3.3267095, 3.3194544, 3.3250053, 3.3331583, 3.316459, 3.3280027, 3.3243084, 3.341425, 3.3301897, 3.3421981, 3.3460324, 3.3436759, 3.3433106, 3.3430548, 3.345855, 3.3304925, 3.3232732, 3.3276734, 3.343377, 3.3348622, 3.3233306, 3.3371878, 3.321546, 3.3357055, 3.3453314, 3.3432984, 3.3503625, 3.338995, 3.335026, 3.339, 3.3358345, 3.334416, 3.3456988, 3.352337, 3.3465457, 3.3512506, 3.3566353, 3.3532696, 3.3603575, 3.3463988, 3.3483572, 3.3537173, 3.3529735, 3.347828, 3.3552485, 3.3560991, 3.3546224, 3.3607829, 3.3651063, 3.3671215, 3.3553586, 3.3612947, 3.3629272, 3.3718755, 3.3634102, 3.362409, 3.3509953, 3.3652973, 3.3617914, 3.3651376, 3.3495877, 3.3604264, 3.3498013, 3.3613136, 3.3711238, 3.3587446, 3.348815, 3.3573918, 3.3739436, 3.3777993, 3.3890564, 3.3756797, 3.3676307, 3.3729806, 3.3749526, 3.3874388, 3.3914685, 3.3803108, 3.3829985, 3.3783803, 3.3780375, 3.3713481, 3.3694148, 3.365074, 3.374897, 3.3899534, 3.390221, 3.3992763, 3.3987982, 3.3922474, 3.3953023, 3.395972, 3.403037, 3.3972294, 3.40126, 3.4011776, 3.409868, 3.4006767, 3.399838, 3.4023955, 3.408649, 3.399328, 3.41403, 3.4104972, 3.421789, 3.4176464, 3.3932724, 3.4121168, 3.404828, 3.4170942, 3.4028418, 3.4043655, 3.4019077, 3.4081266, 3.4006503, 3.408203, 0.01795847, 1.6405356, 1.9441719, 2.0781786, 2.1582906, 2.2156339, 2.2637575, 2.3035674, 2.343037, 2.3571198, 2.391047, 2.4050496, 2.4251764, 2.4493728, 2.4599988, 2.4829156, 2.4983225, 2.504934, 2.5212672, 2.551517, 2.5563896, 2.5685897, 2.5831463, 2.5851548, 2.587803, 2.6084132, 2.613426, 2.6247418, 2.6302705, 2.6348956, 2.6408348, 2.6506832, 2.662413, 2.683787, 2.6920033, 2.6893134, 2.6991804, 2.7062612, 2.7060778, 2.7173963, 2.7179298, 2.7348309, 2.7359943, 2.7370124, 2.739197, 2.7479818, 2.7466958, 2.7459269, 2.7428446, 2.7573392, 2.767941, 2.7625668, 2.781034, 2.7864711, 2.7899601, 2.7973175, 2.7917297, 2.797899, 2.8003602, 2.8051434, 2.8058412, 2.8134754, 2.8220048, 2.8208215, 2.8362248, 2.8526735, 2.8489726, 2.8506672, 2.8598964, 2.8701656, 2.8653946, 2.8698566, 2.8729036, 2.8759277, 2.8751643, 2.8807864, 2.8793325, 2.8807771, 2.8755379, 2.887287, 2.8823435, 2.8995156, 2.9002726, 2.9024806, 2.9080765, 2.9007876, 2.900246, 2.9096708, 2.9139163, 2.9109235, 2.9161532, 2.9256988, 2.928791, 2.932128, 2.9318945, 2.9286814, 2.9259336, 2.9378743, 2.92479, 2.927512, 2.9341824, 2.9339612, 2.9505758, 2.9370859, 2.9522285, 2.9517827, 2.9587817, 2.9534357, 2.955859, 2.9624193, 2.9685812, 2.9710224, 2.980315, 2.972329, 2.9726367, 2.9708054, 2.9805393, 2.9783225, 2.9969316, 2.9877765, 2.9915001, 3.0088334, 2.9940386, 2.9953167, 2.9968348, 3.008176, 2.9975996, 3.0116246, 3.0147626, 3.0070453, 3.0075572, 3.0225594, 3.0238116, 3.0262198, 3.01624, 3.0191734, 3.0198898, 3.0279915, 3.0204608, 3.033351, 3.0406706, 3.0399384, 3.0485792, 3.0478337, 3.0514643, 3.0549123, 3.0521383, 3.050524, 3.0530598, 3.059321, 3.0553346, 3.0571585, 3.0554595, 3.0633292, 3.0561635, 3.0496862, 3.052484, 3.0643525, 3.0633116, 3.0627408, 3.0749817, 3.072219, 3.0862098, 3.0821085, 3.091915, 3.0849004, 3.0788302, 3.0792422, 3.100205, 3.1023712, 3.0845509, 3.1009016, 3.0872493, 3.095999, 3.0916553, 3.108658, 3.1042092, 3.0905004, 3.1008208, 3.0967498, 3.1044867, 3.11358, 3.1149743, 3.1118476, 3.1137428, 3.1088138, 3.116231, 3.1133955, 3.122389, 3.112237, 3.1285403, 3.1246133, 3.129325, 3.1210172, 3.1231947, 3.1270778, 3.1203454, 3.1327317, 3.1450272, 3.1268544, 3.1244993, 3.1294754, 3.129042, 3.1408672, 3.133216, 3.139145, 3.1370788, 3.1515546, 3.1487699, 3.157053, 3.15729, 3.1485734, 3.1569846, 3.1558747, 3.1555657, 3.1535378, 3.162486, 3.1593726, 3.1604102, 3.1606681, 3.1651812, 3.1677976, 3.1721742, 3.1747718, 3.1833205, 3.1684613, 3.165348, 3.1716876, 3.1744993, 3.1809754, 3.196768, 3.189409, 3.2034075, 3.1928658, 3.202567, 3.1984546, 3.1906202, 3.1930804, 3.1809976, 3.1890202, 3.1987824, 3.197867, 3.2031918, 3.2026227, 3.2038531, 3.2089033, 3.21108, 3.1979654, 3.2173722, 3.2103174, 3.2125528, 3.2080355, 3.1964462, 3.20865, 3.2124681, 3.216165, 3.2152028, 3.2321932, 3.2289553, 3.2275293, 3.2169883, 3.2312284, 3.2431514, 3.2349584, 3.240054, 3.2422285, 3.2347605, 3.2379313, 3.233724, 3.2451897, 3.2363918, 3.2502022, 3.243451, 3.2357802, 3.2392926, 3.244136, 3.2447748, 3.2449431, 3.2462862, 3.2366834, 3.2237716, 3.2479455, 3.2465203, 3.245752, 3.2526774, 3.248599, 3.2604039, 3.2618732, 3.2664466, 3.2658792, 3.2527082, 3.2647152, 3.2635858, 3.2669713, 3.2667756, 3.2574317, 3.2602484, 3.2711642, 3.279987, 3.2724411, 3.2737958, 3.2586656, 3.2608783, 3.2713199, 3.2733402, 3.281785, 3.2924287, 3.286205, 3.2779093, 3.2779582, 3.287454, 3.2908816, 3.2867222, 3.2801402, 3.290494, 3.2882476, 3.2847657, 3.2760026, 3.2735486, 3.2937965, 3.293648, 3.279522, 3.2850308, 3.285591, 3.2965734, 3.275684, 3.2900658, 3.3002496, 3.2987623, 3.294776, 3.3077493, 3.2964163, 3.2878568, 3.2922945, 3.3049984, 3.2989917, 3.3070061, 3.2966774, 3.3034236, 3.3137066, 3.3216329, 3.318326, 3.3243966, 3.3282168, 3.3114083, 3.3054335, 3.3166306, 3.317076, 3.312866, 3.3127296, 3.3091211, 3.3142662, 3.307096, 3.3150153, 3.3061683, 3.3168812, 3.326118, 3.3283517, 3.333338, 3.3331747, 3.3356776, 3.3309774, 3.3324914, 3.3281898, 3.328432, 3.335934, 3.3262978, 3.3294318, 3.3309624, 3.3245397, 3.3295226, 3.328107, 3.33667, 3.3250113, 3.329035, 3.3254201, 3.3176577, 3.3235, 3.332289, 3.3418622, 3.345211, 3.3478425, 3.3588636, 3.358661, 3.3444457, 3.3481812, 3.3438122, 3.3437726, 3.3494358, 3.3608298, 3.3541312, 3.3548458, 3.3486884, 3.3451238, 3.3532743, 3.343326, 3.3608027, 3.3495867, 3.348153, 3.3540373, 3.3654883, 3.3587759, 3.35475, 3.366648, 3.3573828, 3.3423665, 3.3405132, 3.351504, 3.3492613, 3.3723662, 3.371661, 3.3394973, 3.3578885, 3.362417, 3.3664393, 3.3712559, 3.369872, 3.3618548, 3.3663507, 3.3727238, 3.369215, 3.3614244, 3.3718977, 3.3734534, 3.3796084, 3.3754008, 3.3759985, 3.3817189, 3.3885708, 3.3787487, 3.3890438, 3.3896542, 3.388863, 3.3898423, 3.377626, 3.3864675, 3.3906622, 3.3857567, 3.3659692, 3.3727279, 3.3870864, 3.4004424, 3.3918495, 3.3997278, 3.397902, 3.3921947, 3.377907, 3.3938024, 3.38799, 3.3973134, 3.4057052, 3.397775, 3.391573, 3.372769, 3.3821893, 3.4007068, 3.3882933, 3.4064384, 3.420269, 3.4237556, 3.4166007, 3.3861697, 3.4006433, 3.407748, 3.4101944, 3.4136767, 3.4111407, 3.4206073, 3.404203, 3.416788, 3.4271889, 3.4247515, 3.417851, 3.4156764, 3.4267554, 3.423574, 3.4157836, 3.4129872, 3.412388, 3.4262369, 3.422289, 3.4059565, 3.4143522, 3.4163535, 3.4113984, 3.4274108, 3.4328387, 3.4221442, 3.427673, 3.4261432, 3.419609, 3.4268236, 3.437016, 3.4397364, 3.4500928, 3.4259813, 3.422358, 3.429218, 3.4431243, 3.4359484, 3.4286432
disc_train_loss: 5.549591, 2.2822452, 0.7395443, 0.4472633, 0.33755666, 0.29300857, 0.24800177, 0.221308, 0.2180936, 0.19598812, 0.18240507, 0.1768146, 0.16307388, 0.14852136, 0.12734367, 0.13006002, 0.13549182, 0.13169281, 0.10758883, 0.11768438, 0.103285834, 0.114677176, 0.10147144, 0.09229551, 0.09303664, 0.09988097, 0.08929931, 0.0929006, 0.0823527, 0.08600796, 0.07256032, 0.0809616, 0.07920754, 0.07909089, 0.07343979, 0.06894723, 0.08045499, 0.073248155, 0.06559778, 0.068991326, 0.07748681, 0.06880383, 0.06894822, 0.064830445, 0.065032706, 0.056552358, 0.062179614, 0.061521877, 0.058506086, 0.058129624, 0.063320115, 0.052808743, 0.062318135, 0.057082094, 0.06072923, 0.053519998, 0.05274349, 0.056180686, 0.049527414, 0.051461894, 0.049624134, 0.047438025, 0.05220827, 0.048244037, 0.04779005, 0.043108504, 0.047858316, 0.045506015, 0.04609842, 0.049444377, 0.04851825, 0.03984587, 0.04132521, 0.04510196, 0.047202874, 0.050035518, 0.040481273, 0.042530816, 0.04729986, 0.041365966, 0.041608628, 0.040109895, 0.040381152, 0.03850381, 0.033932954, 0.040512774, 0.04030952, 0.035799664, 0.044045273, 0.03965733, 0.040883757, 0.03823264, 0.033044163, 0.038403142, 0.036413956, 0.035692994, 0.03427654, 0.028384013, 0.030664815, 0.029938014, 0.036488358, 0.03609922, 0.033909697, 0.035675637, 0.033744093, 0.02879995, 0.029325351, 0.035164583, 0.034048248, 0.035399858, 0.027982619, 0.031189943, 0.028336067, 0.032194033, 0.0340703, 0.030803647, 0.03176279, 0.025709985, 0.035419274, 0.027298752, 0.030365698, 0.030524664, 0.024810402, 0.026848486, 0.024531672, 0.033254303, 0.03106568, 0.025708906, 0.028787749, 0.033198018, 0.021130629, 0.032451995, 0.0296326, 0.032052767, 0.026883716, 0.033801053, 0.029313093, 0.03271862, 0.021527663, 0.027254654, 0.023526048, 0.02956692, 0.027529137, 0.032033313, 0.025918175, 0.02318928, 0.022466905, 0.024808755, 0.029949367, 0.027408019, 0.024933036, 0.026458887, 0.021734871, 0.0240221, 0.028090578, 0.030160675, 0.028674359, 0.028972127, 0.021557117, 0.029556945, 0.024725173, 0.023428485, 0.031827547, 0.02019895, 0.018030504, 0.020363623, 0.027128343, 0.019546226, 0.023809649, 0.022111036, 0.021393282, 0.026139613, 0.027815703, 0.025636142, 0.024638511, 0.018050557, 0.024920877, 0.022215089, 0.022097858, 0.025984418, 0.019605864, 0.023227567, 0.018917201, 0.017092349, 0.023693955, 0.021578657, 0.02383618, 0.02111751, 0.021086928, 0.015997782, 0.02474396, 0.02575437, 0.015631724, 0.0220092, 0.02421207, 0.023252733, 0.026865058, 0.023236234, 0.022816503, 0.023065839, 0.020665843, 0.022752926, 0.023444166, 0.014465898, 0.023959724, 0.018758284, 0.02439236, 0.019037787, 0.02488111, 0.019391477, 0.021712463, 0.018289074, 0.020701682, 0.013053217, 0.018111048, 0.0164934, 0.018629905, 0.01493746, 0.016378932, 0.021857928, 0.022111032, 0.0130420895, 0.019055177, 0.021645345, 0.015265462, 0.017644705, 0.012688096, 0.016350197, 0.015728591, 0.014531905, 0.018347643, 0.016147984, 0.01632986, 0.018777145, 0.0172328, 0.02020476, 0.022890182, 0.025923673, 0.02175008, 0.014052382, 0.025250124, 0.024709884, 0.019623607, 0.017367827, 0.0218719, 0.018957686, 0.019241445, 0.015915202, 0.015819095, 0.018235616, 0.018858695, 0.013281647, 0.017440021, 0.016693942, 0.018273968, 0.0140704, 0.015708143, 0.017323742, 0.014783272, 0.018439094, 0.014048561, 0.010150934, 0.013342051, 0.019182073, 0.019177482, 0.01249823, 0.013897961, 0.011182469, 0.013630711, 0.017064884, 0.018109903, 0.023984093, 0.0098731145, 0.012434752, 0.014728975, 0.014355301, 0.016218638, 0.018574078, 0.021568168, 0.013560979, 0.017216982, 0.01660213, 0.02163471, 0.01633327, 0.017823705, 0.016168747, 0.010790079, 0.015897702, 0.010885518, 0.01605084, 0.012881685, 0.011730057, 0.0135282595, 0.012055503, 0.012468327, 0.011221755, 0.010528162, 0.01227742, 0.015901256, 0.007235531, 0.013164799, 0.007882824, 0.011296159, 0.013333803, 0.0137086, 0.014668285, 0.015629739, 0.010356115, 0.010685656, 0.014078019, 0.012023791, 0.014576782, 0.010440726, 0.014676589, 0.015588614, 0.011793184, 0.015596359, 0.013671114, 0.009658097, 0.0113601275, 0.012107478, 0.011405777, 0.016655527, 0.015305054, 0.014373389, 0.0118804285, 0.009634174, 0.015105603, 0.010844861, 0.014357696, 0.013777527, 0.017100127, 0.011369569, 0.012639263, 0.012103155, 0.011310056, 0.012538819, 0.018426578, 0.010632529, 0.013151154, 0.00916419, 0.011432804, 0.010608607, 0.008632446, 0.010043438, 0.010358195, 0.014064129, 0.010488875, 0.011659502, 0.012541761, 0.012771865, 0.014248276, 0.015127849, 0.014815489, 0.013139785, 0.0124451, 0.010461105, 0.0116137415, 0.010710345, 0.013518524, 0.016866129, 0.011321451, 0.010040901, 0.008260713, 0.010353917, 0.010440987, 0.0130149145, 0.010966556, 0.016273763, 0.009448726, 0.011403588, 0.013170915, 0.0131255295, 0.00827614, 0.011724746, 0.011372012, 0.011646879, 0.0062772916, 0.012498465, 0.008476391, 0.011617565, 0.017763909, 0.015619073, 0.0139768245, 0.010493357, 0.0076692384, 0.012809281, 0.0070061153, 0.008459805, 0.010295985, 0.010272336, 0.012070142, 0.011901472, 0.013669793, 0.0092327045, 0.008876895, 0.008227006, 0.010140488, 0.008210492, 0.012639916, 0.019170085, 0.012067204, 0.011357966, 0.009696972, 0.013549941, 0.013597197, 0.0151514495, 0.014668165, 0.009240001, 0.011540435, 0.009106737, 0.008432588, 0.01351102, 0.01397396, 0.012965941, 0.011121883, 0.013351976, 0.006211813, 0.007903385, 0.009703392, 0.011067606, 0.0107033225, 0.0073925788, 0.0087707685, 0.018960724, 0.01409114, 0.010101423, 0.008495726, 0.016058618, 0.010007229, 0.009463171, 0.008970657, 0.00874461, 0.008076905, 0.014135349, 0.011704649, 0.0076029957, 0.009341285, 0.0075988723, 0.009591473, 0.013223452, 0.015659614, 0.010374755, 0.0124775935, 0.005959847, 0.010605681, 0.010200099, 0.012077448, 0.006424203, 0.009727522, 0.00982806, 0.009540021, 0.01381434, 0.0072958525, 0.006383059, 0.0040383837, 0.01291178, 0.011063916, 0.0055473857, 0.014127307, 0.009034232, 0.014750697, 0.0105808005, 0.014289178, 0.0085972175, 0.0045556994, 0.01373716, 0.012390166, 0.009540677, 0.006445891, 0.007563046, 0.009015496, 0.0054037906, 0.0110758385, 0.011585192, 0.00869404, 0.0072977967, 0.008842145, 0.011372236, 0.005272679, 0.007827903, 0.0063258167, 0.00848913, 0.014309298, 0.007950384, 0.0068614357, 0.007225272, 0.0045754197, 0.0040931245, 0.004587922, 0.0073359497, 0.010566666, 0.008648815, 0.007271205, 0.009953194, 0.00779291, 0.00893227, 0.0053693615, 0.014208799, 0.00928357, 0.008987838, 5.537566, 2.194394, 0.7292743, 0.44072887, 0.33651352, 0.28551018, 0.24950475, 0.22599918, 0.20433912, 0.20098856, 0.17972398, 0.17448163, 0.15937059, 0.14602256, 0.14733726, 0.1391299, 0.13548292, 0.12228032, 0.12020087, 0.11062876, 0.10479792, 0.095213994, 0.09911049, 0.100083135, 0.09722265, 0.09575546, 0.087696515, 0.09268208, 0.09200819, 0.08220823, 0.077035174, 0.07579761, 0.076773874, 0.07756968, 0.07392053, 0.070289776, 0.06971872, 0.07297907, 0.069462284, 0.06543488, 0.067294545, 0.067870684, 0.07330596, 0.070009224, 0.06642661, 0.06428238, 0.059680365, 0.058562666, 0.067832574, 0.055050902, 0.05465746, 0.049986277, 0.047873635, 0.05556371, 0.049996745, 0.0573093, 0.0614607, 0.046659555, 0.054968268, 0.050743956, 0.051339123, 0.048334114, 0.041724402, 0.051508658, 0.046121176, 0.03896456, 0.042039547, 0.04932226, 0.039336372, 0.04398621, 0.040787783, 0.039980866, 0.04554919, 0.047276095, 0.044027723, 0.040340733, 0.04244446, 0.038978353, 0.04911841, 0.04943273, 0.050520558, 0.038065188, 0.04243119, 0.03407434, 0.03734491, 0.040117335, 0.042427342, 0.04041754, 0.03618585, 0.03693689, 0.043506302, 0.03496826, 0.033526573, 0.03199651, 0.04161765, 0.038439646, 0.040224917, 0.038306892, 0.04128899, 0.03785715, 0.04066425, 0.03716006, 0.039764505, 0.036660623, 0.036832362, 0.032824993, 0.0278676, 0.035058558, 0.03180202, 0.03194659, 0.031079486, 0.030963724, 0.032832723, 0.04066839, 0.03810527, 0.0342978, 0.034097742, 0.027616922, 0.036447816, 0.034686726, 0.03039804, 0.02134961, 0.025561841, 0.030510688, 0.029776685, 0.028866045, 0.033339746, 0.030404128, 0.030138684, 0.032907132, 0.034290425, 0.025690824, 0.028822908, 0.024704814, 0.036374256, 0.027060436, 0.02719211, 0.026962949, 0.029641341, 0.03114501, 0.025336348, 0.030751467, 0.025104117, 0.021351611, 0.029858852, 0.033062473, 0.02489738, 0.027592931, 0.02466343, 0.02010003, 0.024196751, 0.027510263, 0.025447687, 0.027996413, 0.02758323, 0.025094952, 0.025754688, 0.031700097, 0.024701366, 0.027248254, 0.024865698, 0.023707384, 0.023866065, 0.022406323, 0.024908189, 0.026007654, 0.02884419, 0.026590506, 0.027341971, 0.021481322, 0.025351994, 0.021129053, 0.027317135, 0.02245273, 0.026839798, 0.016604552, 0.021494495, 0.021010635, 0.026150497, 0.019158281, 0.021782069, 0.017547166, 0.020229962, 0.018822473, 0.017199654, 0.021016723, 0.020822104, 0.018010722, 0.02225809, 0.020127736, 0.017065387, 0.021989925, 0.0225742, 0.027180865, 0.025320264, 0.019531526, 0.02707086, 0.023725022, 0.0153862545, 0.022288203, 0.02154519, 0.022102153, 0.023634836, 0.023231115, 0.023211522, 0.02129938, 0.01748559, 0.017936323, 0.018456064, 0.020341864, 0.019183557, 0.023760173, 0.018724736, 0.025672754, 0.020251518, 0.020190105, 0.017480982, 0.01923217, 0.014892212, 0.015605169, 0.017872052, 0.019587269, 0.019334473, 0.015652416, 0.01391226, 0.02115432, 0.024984032, 0.020338146, 0.019639364, 0.016881492, 0.0146569675, 0.01804436, 0.0154909, 0.017806526, 0.016918445, 0.018489074, 0.018151479, 0.021294381, 0.018147705, 0.01778771, 0.017517157, 0.014663443, 0.014180606, 0.016305402, 0.018102579, 0.020046147, 0.014097664, 0.015978256, 0.0143584395, 0.02086795, 0.015051828, 0.019699346, 0.014172168, 0.012331293, 0.014778683, 0.016872266, 0.012848708, 0.0123759145, 0.014709458, 0.018670239, 0.021538794, 0.018817443, 0.00997407, 0.016512645, 0.0144866565, 0.015366431, 0.014374265, 0.014759889, 0.009753677, 0.014337999, 0.013342251, 0.012204116, 0.011813514, 0.0154084675, 0.013654613, 0.019084835, 0.013488648, 0.013539504, 0.016215596, 0.023281278, 0.020582102, 0.01144023, 0.014963232, 0.01171838, 0.017784405, 0.014861429, 0.01195663, 0.012510773, 0.008639497, 0.0106685925, 0.013204431, 0.013298227, 0.014027176, 0.011108717, 0.01477565, 0.013316592, 0.015475414, 0.014333942, 0.01192284, 0.018518444, 0.013109643, 0.015570635, 0.016667875, 0.0117487265, 0.015890956, 0.010358728, 0.013598092, 0.013291163, 0.012580695, 0.012204261, 0.012058572, 0.011961973, 0.012086098, 0.019978477, 0.014428806, 0.010608248, 0.016564433, 0.012794823, 0.009849598, 0.00675636, 0.011153584, 0.016455028, 0.011749944, 0.009948934, 0.011031438, 0.012972137, 0.012425389, 0.010905312, 0.010213271, 0.0122204395, 0.009139962, 0.015561818, 0.01512198, 0.008860039, 0.011509493, 0.0121796, 0.0121255275, 0.018027382, 0.015064999, 0.010997517, 0.013139715, 0.0097455615, 0.010318333, 0.011249217, 0.010395632, 0.009082155, 0.008936863, 0.0117905745, 0.0071957665, 0.012477476, 0.011128101, 0.016110666, 0.015183261, 0.009351207, 0.013879317, 0.015451108, 0.009330136, 0.01204603, 0.016573306, 0.011966678, 0.012516475, 0.011400894, 0.008349301, 0.008632086, 0.014256051, 0.00832634, 0.012775765, 0.009362034, 0.014355468, 0.010498452, 0.00907518, 0.009180753, 0.007416961, 0.010679798, 0.013088511, 0.01020398, 0.012235362, 0.0094345035, 0.009271284, 0.0065053026, 0.010315789, 0.01172163, 0.008466663, 0.013190942, 0.017796816, 0.017123139, 0.010003361, 0.011327409, 0.008010991, 0.009149191, 0.009048933, 0.008256879, 0.011827513, 0.007803478, 0.010508002, 0.016121035, 0.00928324, 0.012683993, 0.009304147, 0.010691858, 0.00792034, 0.012149511, 0.018317025, 0.008311881, 0.014667685, 0.012773901, 0.011823549, 0.011006675, 0.012479403, 0.0070627, 0.012467677, 0.012613693, 0.009247797, 0.0073046717, 0.008150505, 0.0119471615, 0.011865642, 0.011519769, 0.006554946, 0.007580611, 0.0077664205, 0.013964881, 0.008926477, 0.009073599, 0.008356936, 0.010522635, 0.006724473, 0.00940387, 0.0119214, 0.009262844, 0.011007553, 0.011539894, 0.009130899, 0.009656304, 0.013081845, 0.00982868, 0.0102492245, 0.012806692, 0.019008297, 0.009510126, 0.007844019, 0.014662889, 0.01588691, 0.010845222, 0.014026354, 0.0066192816, 0.012007235, 0.0052060205, 0.0151636675, 0.0095566865, 0.00890539, 0.0110741155, 0.0150392195, 0.0111010065, 0.0121169565, 0.0052232374, 0.0067212475, 0.004313167, 0.00488926, 0.0040867445, 0.006307252, 0.009870946, 0.0067242202, 0.005398856, 0.011437675, 0.0068776743, 0.0049705044, 0.010696342, 0.011193519, 0.0063082785, 0.0057698796, 0.00635914, 0.00650324, 0.0075097564, 0.004147693, 0.007529898, 0.0127927065, 0.011446008, 0.010654997, 0.011395094, 0.009298923, 0.011184656, 0.013003842, 0.009005207, 0.010773586, 0.005636502, 0.00570358, 0.004175942, 0.005991026, 0.009153034, 0.008738939, 0.0072033955, 0.003800195, 0.0031959482, 0.005081951, 0.01354467, 0.00665294, 0.0061802226, 0.005286048, 0.007665828, 0.005906226
disc_train_acc: 0.0, 0.453960396039604, 0.8139851485148515, 0.8909653465346534, 0.9131188118811882, 0.9231435643564356, 0.9324257425742575, 0.9415841584158415, 0.9377475247524752, 0.9475247524752475, 0.9508663366336634, 0.9492574257425742, 0.9534653465346534, 0.9579207920792079, 0.9641089108910891, 0.9631188118811881, 0.9596534653465346, 0.9617574257425743, 0.969059405940594, 0.9665841584158416, 0.970049504950495, 0.967450495049505, 0.9716584158415842, 0.9731435643564357, 0.9727722772277227, 0.9691831683168317, 0.9711633663366337, 0.9709158415841584, 0.9753712871287129, 0.9747524752475247, 0.9764851485148515, 0.975, 0.9745049504950495, 0.9758663366336634, 0.9762376237623762, 0.9783415841584159, 0.9748762376237624, 0.9754950495049505, 0.9810643564356436, 0.9777227722772277, 0.975990099009901, 0.9788366336633664, 0.9785891089108911, 0.9795792079207921, 0.9795792079207921, 0.9834158415841584, 0.9797029702970297, 0.9800742574257426, 0.9819306930693069, 0.9816831683168317, 0.9800742574257426, 0.9837871287128713, 0.9780940594059406, 0.9810643564356436, 0.9809405940594059, 0.9829207920792079, 0.9814356435643564, 0.9814356435643564, 0.9831683168316832, 0.9819306930693069, 0.9835396039603961, 0.9824257425742574, 0.9805693069306931, 0.9845297029702971, 0.9836633663366336, 0.986509900990099, 0.9845297029702971, 0.9867574257425743, 0.9863861386138614, 0.9831683168316832, 0.9840346534653466, 0.9873762376237624, 0.9857673267326733, 0.9846534653465346, 0.9849009900990099, 0.9829207920792079, 0.9875, 0.9866336633663366, 0.9829207920792079, 0.986509900990099, 0.9870049504950495, 0.9867574257425743, 0.9862623762376238, 0.9870049504950495, 0.9886138613861386, 0.9866336633663366, 0.9857673267326733, 0.9883663366336634, 0.9851485148514851, 0.986509900990099, 0.9868811881188119, 0.9875, 0.9877475247524753, 0.9886138613861386, 0.9875, 0.9873762376237624, 0.9896039603960396, 0.9908415841584158, 0.989480198019802, 0.9887376237623763, 0.9887376237623763, 0.9881188118811881, 0.9877475247524753, 0.9883663366336634, 0.989480198019802, 0.9913366336633663, 0.9905940594059406, 0.988490099009901, 0.9893564356435643, 0.9876237623762376, 0.9897277227722773, 0.9900990099009901, 0.9905940594059406, 0.9892326732673268, 0.9875, 0.9908415841584158, 0.9883663366336634, 0.9918316831683168, 0.9877475247524753, 0.9923267326732673, 0.9907178217821783, 0.9907178217821783, 0.9930693069306931, 0.9917079207920793, 0.9915841584158416, 0.9892326732673268, 0.9896039603960396, 0.992450495049505, 0.9907178217821783, 0.9886138613861386, 0.9939356435643565, 0.9900990099009901, 0.9910891089108911, 0.9893564356435643, 0.9923267326732673, 0.9909653465346535, 0.9907178217821783, 0.989480198019802, 0.994059405940594, 0.990470297029703, 0.9922029702970298, 0.9902227722772278, 0.9912128712871288, 0.9881188118811881, 0.9913366336633663, 0.9930693069306931, 0.9925742574257426, 0.9917079207920793, 0.989480198019802, 0.9917079207920793, 0.9926980198019802, 0.9912128712871288, 0.994059405940594, 0.9920792079207921, 0.9922029702970298, 0.9896039603960396, 0.9903465346534653, 0.9905940594059406, 0.9935643564356436, 0.9893564356435643, 0.9915841584158416, 0.9917079207920793, 0.9898514851485148, 0.9943069306930693, 0.9938118811881188, 0.9920792079207921, 0.9907178217821783, 0.994430693069307, 0.9913366336633663, 0.9923267326732673, 0.9930693069306931, 0.9912128712871288, 0.9917079207920793, 0.9918316831683168, 0.9917079207920793, 0.994430693069307, 0.9912128712871288, 0.9931930693069307, 0.9928217821782178, 0.9915841584158416, 0.9941831683168317, 0.9928217821782178, 0.9936881188118812, 0.9948019801980198, 0.9910891089108911, 0.9926980198019802, 0.9922029702970298, 0.992450495049505, 0.9936881188118812, 0.9951732673267327, 0.991460396039604, 0.991460396039604, 0.9951732673267327, 0.9930693069306931, 0.9919554455445545, 0.9931930693069307, 0.9910891089108911, 0.9920792079207921, 0.9919554455445545, 0.992450495049505, 0.9930693069306931, 0.9929455445544555, 0.991460396039604, 0.9955445544554455, 0.9922029702970298, 0.9936881188118812, 0.9907178217821783, 0.9925742574257426, 0.9912128712871288, 0.9935643564356436, 0.9930693069306931, 0.9939356435643565, 0.9933168316831683, 0.996039603960396, 0.9938118811881188, 0.9957920792079208, 0.994059405940594, 0.9959158415841585, 0.9949257425742575, 0.9931930693069307, 0.9920792079207921, 0.9965346534653465, 0.9935643564356436, 0.9929455445544555, 0.9959158415841585, 0.9939356435643565, 0.996039603960396, 0.9948019801980198, 0.994430693069307, 0.9957920792079208, 0.994059405940594, 0.9951732673267327, 0.994430693069307, 0.9943069306930693, 0.995049504950495, 0.9936881188118812, 0.9925742574257426, 0.992450495049505, 0.9928217821782178, 0.9956683168316832, 0.9933168316831683, 0.9917079207920793, 0.9936881188118812, 0.9946782178217822, 0.9919554455445545, 0.9935643564356436, 0.9935643564356436, 0.9943069306930693, 0.9946782178217822, 0.9939356435643565, 0.9936881188118812, 0.996410891089109, 0.9935643564356436, 0.9943069306930693, 0.9936881188118812, 0.9962871287128713, 0.9939356435643565, 0.995049504950495, 0.9956683168316832, 0.9943069306930693, 0.9952970297029703, 0.9967821782178218, 0.9957920792079208, 0.994059405940594, 0.994059405940594, 0.9965346534653465, 0.9948019801980198, 0.9966584158415842, 0.9951732673267327, 0.993440594059406, 0.9951732673267327, 0.9913366336633663, 0.9975247524752475, 0.996410891089109, 0.9952970297029703, 0.9956683168316832, 0.9946782178217822, 0.9941831683168317, 0.993440594059406, 0.995420792079208, 0.9955445544554455, 0.9948019801980198, 0.9922029702970298, 0.9946782178217822, 0.994430693069307, 0.994430693069307, 0.9972772277227723, 0.994430693069307, 0.99740099009901, 0.9945544554455445, 0.9956683168316832, 0.9961633663366337, 0.9956683168316832, 0.9962871287128713, 0.9961633663366337, 0.9965346534653465, 0.9969059405940595, 0.9961633663366337, 0.995049504950495, 0.9981435643564357, 0.9956683168316832, 0.9978960396039604, 0.9965346534653465, 0.9957920792079208, 0.9961633663366337, 0.995420792079208, 0.995420792079208, 0.997029702970297, 0.9969059405940595, 0.9946782178217822, 0.9961633663366337, 0.995049504950495, 0.9967821782178218, 0.9959158415841585, 0.994430693069307, 0.996410891089109, 0.995049504950495, 0.995049504950495, 0.997029702970297, 0.9966584158415842, 0.9969059405940595, 0.9962871287128713, 0.994059405940594, 0.9957920792079208, 0.995049504950495, 0.9965346534653465, 0.9965346534653465, 0.9951732673267327, 0.9965346534653465, 0.9962871287128713, 0.995420792079208, 0.9939356435643565, 0.9967821782178218, 0.996410891089109, 0.9965346534653465, 0.9967821782178218, 0.9955445544554455, 0.9939356435643565, 0.9965346534653465, 0.996410891089109, 0.9972772277227723, 0.9959158415841585, 0.996039603960396, 0.99740099009901, 0.9977722772277228, 0.997029702970297, 0.9949257425742575, 0.9965346534653465, 0.996410891089109, 0.9961633663366337, 0.996039603960396, 0.995049504950495, 0.9949257425742575, 0.9946782178217822, 0.9952970297029703, 0.996039603960396, 0.9967821782178218, 0.9961633663366337, 0.9967821782178218, 0.9957920792079208, 0.994059405940594, 0.9969059405940595, 0.9975247524752475, 0.9971534653465347, 0.9967821782178218, 0.996410891089109, 0.996410891089109, 0.9969059405940595, 0.995049504950495, 0.9969059405940595, 0.997029702970297, 0.9957920792079208, 0.995049504950495, 0.99740099009901, 0.9955445544554455, 0.9961633663366337, 0.9969059405940595, 0.9978960396039604, 0.996410891089109, 0.9972772277227723, 0.9961633663366337, 0.9943069306930693, 0.9941831683168317, 0.9951732673267327, 0.9967821782178218, 0.9977722772277228, 0.996039603960396, 0.998391089108911, 0.9976485148514852, 0.9966584158415842, 0.996410891089109, 0.9952970297029703, 0.9959158415841585, 0.9951732673267327, 0.9976485148514852, 0.9975247524752475, 0.9976485148514852, 0.996410891089109, 0.9969059405940595, 0.9962871287128713, 0.9945544554455445, 0.9955445544554455, 0.9961633663366337, 0.9959158415841585, 0.995049504950495, 0.9952970297029703, 0.9952970297029703, 0.9957920792079208, 0.9975247524752475, 0.9966584158415842, 0.997029702970297, 0.99740099009901, 0.9939356435643565, 0.9946782178217822, 0.9956683168316832, 0.996039603960396, 0.9959158415841585, 0.9982673267326733, 0.9975247524752475, 0.997029702970297, 0.9967821782178218, 0.996410891089109, 0.9976485148514852, 0.9976485148514852, 0.9931930693069307, 0.9951732673267327, 0.997029702970297, 0.9978960396039604, 0.9945544554455445, 0.997029702970297, 0.9969059405940595, 0.997029702970297, 0.9975247524752475, 0.9972772277227723, 0.9952970297029703, 0.9959158415841585, 0.9981435643564357, 0.9969059405940595, 0.998391089108911, 0.9967821782178218, 0.9957920792079208, 0.994059405940594, 0.9969059405940595, 0.9962871287128713, 0.998391089108911, 0.9962871287128713, 0.9967821782178218, 0.995420792079208, 0.9978960396039604, 0.9967821782178218, 0.9976485148514852, 0.997029702970297, 0.9952970297029703, 0.9978960396039604, 0.9976485148514852, 0.9988861386138614, 0.9955445544554455, 0.9967821782178218, 0.9988861386138614, 0.995420792079208, 0.9966584158415842, 0.995420792079208, 0.9966584158415842, 0.995420792079208, 0.9967821782178218, 0.9991336633663367, 0.9952970297029703, 0.9955445544554455, 0.9967821782178218, 0.9978960396039604, 0.998019801980198, 0.9969059405940595, 0.9988861386138614, 0.9961633663366337, 0.9962871287128713, 0.9977722772277228, 0.9977722772277228, 0.997029702970297, 0.996039603960396, 0.998391089108911, 0.9975247524752475, 0.9977722772277228, 0.997029702970297, 0.995420792079208, 0.9977722772277228, 0.9982673267326733, 0.9978960396039604, 0.9987623762376238, 0.9988861386138614, 0.999009900990099, 0.9976485148514852, 0.996410891089109, 0.9976485148514852, 0.9978960396039604, 0.997029702970297, 0.9982673267326733, 0.9975247524752475, 0.9987623762376238, 0.9957920792079208, 0.9967821782178218, 0.9975247524752475, 0.0, 0.47376237623762374, 0.8110148514851485, 0.8886138613861386, 0.9153465346534654, 0.9238861386138614, 0.9346534653465347, 0.9409653465346535, 0.9439356435643564, 0.9443069306930693, 0.9533415841584159, 0.9493811881188119, 0.9561881188118811, 0.9597772277227723, 0.959529702970297, 0.9603960396039604, 0.9596534653465346, 0.9655940594059406, 0.9631188118811881, 0.9672029702970297, 0.968440594059406, 0.973019801980198, 0.9716584158415842, 0.9702970297029703, 0.9705445544554455, 0.9733910891089109, 0.9747524752475247, 0.9725247524752475, 0.972029702970297, 0.9754950495049505, 0.9775990099009901, 0.975990099009901, 0.973019801980198, 0.9752475247524752, 0.9772277227722772, 0.9774752475247525, 0.9773514851485149, 0.9756188118811882, 0.977970297029703, 0.9794554455445544, 0.9792079207920792, 0.9778465346534654, 0.976980198019802, 0.9783415841584159, 0.9775990099009901, 0.9801980198019802, 0.9806930693069307, 0.9815594059405941, 0.9775990099009901, 0.9831683168316832, 0.9844059405940594, 0.9852722772277228, 0.9852722772277228, 0.9820544554455446, 0.9830445544554456, 0.9814356435643564, 0.9789603960396039, 0.9850247524752476, 0.9819306930693069, 0.9839108910891089, 0.9839108910891089, 0.9845297029702971, 0.9875, 0.9844059405940594, 0.9840346534653466, 0.9866336633663366, 0.9867574257425743, 0.9830445544554456, 0.9870049504950495, 0.9856435643564356, 0.9863861386138614, 0.9862623762376238, 0.9845297029702971, 0.9840346534653466, 0.9841584158415841, 0.9862623762376238, 0.9862623762376238, 0.9872524752475248, 0.9844059405940594, 0.9841584158415841, 0.9830445544554456, 0.9872524752475248, 0.9871287128712871, 0.9889851485148515, 0.9882425742574258, 0.9856435643564356, 0.986509900990099, 0.9875, 0.9889851485148515, 0.988490099009901, 0.986509900990099, 0.988490099009901, 0.9896039603960396, 0.9900990099009901, 0.9862623762376238, 0.9872524752475248, 0.9872524752475248, 0.9870049504950495, 0.9849009900990099, 0.9863861386138614, 0.9860148514851486, 0.9872524752475248, 0.986509900990099, 0.9883663366336634, 0.9870049504950495, 0.9900990099009901, 0.990470297029703, 0.9879950495049505, 0.9909653465346535, 0.9887376237623763, 0.989480198019802, 0.9898514851485148, 0.9902227722772278, 0.9858910891089109, 0.9878712871287129, 0.9889851485148515, 0.9891089108910891, 0.9923267326732673, 0.9877475247524753, 0.9879950495049505, 0.9893564356435643, 0.9938118811881188, 0.9917079207920793, 0.9912128712871288, 0.9896039603960396, 0.990470297029703, 0.9899752475247525, 0.9893564356435643, 0.9899752475247525, 0.9897277227722773, 0.9889851485148515, 0.9918316831683168, 0.9913366336633663, 0.9915841584158416, 0.9866336633663366, 0.9915841584158416, 0.9912128712871288, 0.9908415841584158, 0.9882425742574258, 0.9900990099009901, 0.991460396039604, 0.989480198019802, 0.9920792079207921, 0.9931930693069307, 0.9908415841584158, 0.9882425742574258, 0.991460396039604, 0.9915841584158416, 0.9920792079207921, 0.9933168316831683, 0.9917079207920793, 0.9891089108910891, 0.9913366336633663, 0.9920792079207921, 0.9913366336633663, 0.9909653465346535, 0.9909653465346535, 0.9892326732673268, 0.9922029702970298, 0.990470297029703, 0.9918316831683168, 0.9910891089108911, 0.9931930693069307, 0.992450495049505, 0.9917079207920793, 0.9919554455445545, 0.9897277227722773, 0.992450495049505, 0.9907178217821783, 0.9925742574257426, 0.9900990099009901, 0.9926980198019802, 0.9926980198019802, 0.9926980198019802, 0.9907178217821783, 0.994430693069307, 0.9938118811881188, 0.9928217821782178, 0.9915841584158416, 0.994059405940594, 0.9923267326732673, 0.9941831683168317, 0.9931930693069307, 0.9939356435643565, 0.9946782178217822, 0.9917079207920793, 0.9931930693069307, 0.9939356435643565, 0.9923267326732673, 0.9930693069306931, 0.9957920792079208, 0.9928217821782178, 0.9919554455445545, 0.9909653465346535, 0.9919554455445545, 0.9939356435643565, 0.990470297029703, 0.9928217821782178, 0.9952970297029703, 0.9922029702970298, 0.9928217821782178, 0.9922029702970298, 0.9913366336633663, 0.9917079207920793, 0.9922029702970298, 0.9928217821782178, 0.9939356435643565, 0.993440594059406, 0.9941831683168317, 0.9928217821782178, 0.9935643564356436, 0.9922029702970298, 0.994059405940594, 0.9912128712871288, 0.993440594059406, 0.9945544554455445, 0.9946782178217822, 0.9933168316831683, 0.994430693069307, 0.9951732673267327, 0.994430693069307, 0.9931930693069307, 0.9949257425742575, 0.9949257425742575, 0.9957920792079208, 0.993440594059406, 0.9917079207920793, 0.9925742574257426, 0.993440594059406, 0.995420792079208, 0.996039603960396, 0.9941831683168317, 0.9951732673267327, 0.9946782178217822, 0.9941831683168317, 0.993440594059406, 0.994430693069307, 0.9931930693069307, 0.9949257425742575, 0.9935643564356436, 0.9945544554455445, 0.996039603960396, 0.9957920792079208, 0.9946782178217822, 0.994059405940594, 0.9926980198019802, 0.996039603960396, 0.9951732673267327, 0.995049504950495, 0.9919554455445545, 0.9945544554455445, 0.9943069306930693, 0.9959158415841585, 0.9957920792079208, 0.9955445544554455, 0.9943069306930693, 0.9967821782178218, 0.996039603960396, 0.9957920792079208, 0.9935643564356436, 0.9928217821782178, 0.9935643564356436, 0.9971534653465347, 0.9946782178217822, 0.995420792079208, 0.9946782178217822, 0.9949257425742575, 0.9957920792079208, 0.9967821782178218, 0.9959158415841585, 0.9959158415841585, 0.996039603960396, 0.9957920792079208, 0.9955445544554455, 0.9952970297029703, 0.9931930693069307, 0.9957920792079208, 0.9948019801980198, 0.9948019801980198, 0.9919554455445545, 0.9931930693069307, 0.9962871287128713, 0.9949257425742575, 0.9955445544554455, 0.9945544554455445, 0.9951732673267327, 0.9965346534653465, 0.9967821782178218, 0.99740099009901, 0.9969059405940595, 0.9957920792079208, 0.9972772277227723, 0.9957920792079208, 0.9965346534653465, 0.9951732673267327, 0.9957920792079208, 0.9951732673267327, 0.995420792079208, 0.9965346534653465, 0.9945544554455445, 0.9959158415841585, 0.9949257425742575, 0.9948019801980198, 0.9965346534653465, 0.9949257425742575, 0.9971534653465347, 0.9952970297029703, 0.9946782178217822, 0.9966584158415842, 0.9965346534653465, 0.9965346534653465, 0.9957920792079208, 0.995420792079208, 0.9941831683168317, 0.9959158415841585, 0.9962871287128713, 0.994059405940594, 0.9956683168316832, 0.9971534653465347, 0.9986386138613862, 0.9967821782178218, 0.994430693069307, 0.9967821782178218, 0.997029702970297, 0.9961633663366337, 0.995420792079208, 0.995049504950495, 0.9967821782178218, 0.9969059405940595, 0.9959158415841585, 0.9967821782178218, 0.995049504950495, 0.9961633663366337, 0.9976485148514852, 0.996039603960396, 0.996410891089109, 0.9969059405940595, 0.994430693069307, 0.9952970297029703, 0.996410891089109, 0.9965346534653465, 0.9976485148514852, 0.9966584158415842, 0.9966584158415842, 0.9971534653465347, 0.9976485148514852, 0.9976485148514852, 0.996410891089109, 0.9977722772277228, 0.996039603960396, 0.996410891089109, 0.9946782178217822, 0.994430693069307, 0.9971534653465347, 0.9956683168316832, 0.9951732673267327, 0.9971534653465347, 0.9957920792079208, 0.9938118811881188, 0.9967821782178218, 0.996039603960396, 0.9967821782178218, 0.9971534653465347, 0.9972772277227723, 0.9949257425742575, 0.9972772277227723, 0.9952970297029703, 0.99740099009901, 0.9957920792079208, 0.9966584158415842, 0.9972772277227723, 0.99740099009901, 0.998391089108911, 0.9965346534653465, 0.9959158415841585, 0.997029702970297, 0.996039603960396, 0.9976485148514852, 0.9972772277227723, 0.998391089108911, 0.997029702970297, 0.9957920792079208, 0.9982673267326733, 0.995420792079208, 0.994430693069307, 0.9952970297029703, 0.9971534653465347, 0.9971534653465347, 0.99740099009901, 0.9969059405940595, 0.9975247524752475, 0.9976485148514852, 0.996410891089109, 0.998019801980198, 0.9969059405940595, 0.9948019801980198, 0.9967821782178218, 0.9961633663366337, 0.9977722772277228, 0.9965346534653465, 0.9978960396039604, 0.996410891089109, 0.994059405940594, 0.99740099009901, 0.9949257425742575, 0.9951732673267327, 0.9955445544554455, 0.9961633663366337, 0.9955445544554455, 0.99740099009901, 0.9966584158415842, 0.9961633663366337, 0.9972772277227723, 0.9981435643564357, 0.9977722772277228, 0.996410891089109, 0.9961633663366337, 0.9969059405940595, 0.9982673267326733, 0.9977722772277228, 0.9978960396039604, 0.995049504950495, 0.9972772277227723, 0.9971534653465347, 0.99740099009901, 0.996410891089109, 0.998019801980198, 0.997029702970297, 0.996410891089109, 0.997029702970297, 0.996410891089109, 0.9959158415841585, 0.9966584158415842, 0.9972772277227723, 0.9961633663366337, 0.9967821782178218, 0.9967821782178218, 0.9961633663366337, 0.9933168316831683, 0.9971534653465347, 0.9975247524752475, 0.9955445544554455, 0.9943069306930693, 0.996410891089109, 0.9952970297029703, 0.9978960396039604, 0.9959158415841585, 0.999009900990099, 0.9951732673267327, 0.997029702970297, 0.9967821782178218, 0.996039603960396, 0.9951732673267327, 0.9965346534653465, 0.995420792079208, 0.9986386138613862, 0.9975247524752475, 0.9985148514851485, 0.9986386138613862, 0.999009900990099, 0.9985148514851485, 0.9966584158415842, 0.9982673267326733, 0.9986386138613862, 0.9956683168316832, 0.998391089108911, 0.9992574257425743, 0.9967821782178218, 0.9961633663366337, 0.998391089108911, 0.998391089108911, 0.9976485148514852, 0.9981435643564357, 0.9975247524752475, 0.9987623762376238, 0.9977722772277228, 0.9959158415841585, 0.996039603960396, 0.9957920792079208, 0.9969059405940595, 0.998019801980198, 0.9962871287128713, 0.9957920792079208, 0.99740099009901, 0.996410891089109, 0.9981435643564357, 0.9982673267326733, 0.9991336633663367, 0.9981435643564357, 0.9978960396039604, 0.997029702970297, 0.9981435643564357, 0.9992574257425743, 0.9996287128712872, 0.998019801980198, 0.9956683168316832, 0.998019801980198, 0.9976485148514852, 0.998391089108911, 0.9976485148514852, 0.9982673267326733
gen_val_loss: 0.016667297, 1.6154588, 1.6724025, 1.8845459, 1.8187927, 1.6423507, 1.7629352, 2.1016355, 1.9267058, 2.0439382, 2.050364, 1.909387, 2.0618308, 2.0241745, 2.2588933, 1.776761, 2.1275544, 2.1585155, 2.1388557, 2.3893313, 2.1528614, 2.126781, 2.3570502, 2.2690313, 2.2644458, 2.291135, 2.202854, 2.1732657, 1.8481793, 2.3280137, 2.2919066, 2.3222039, 2.049247, 2.4956174, 2.1726847, 2.3074944, 2.360116, 2.3651848, 2.3287241, 2.213091, 2.146371, 2.249094, 2.2144923, 2.4100254, 2.2415545, 2.099516, 2.268545, 2.2917335, 2.4949236, 2.3994076, 2.3179917, 2.3620403, 2.5041418, 2.3938785, 2.3789892, 2.4160657, 2.3210082, 2.3361723, 2.4420936, 2.5334787, 2.426588, 2.561505, 2.4117317, 2.5514712, 2.256495, 2.0790198, 2.4677112, 2.421521, 2.6520991, 2.4749427, 2.4302473, 2.4578376, 2.467517, 2.49949, 2.3951848, 2.5364857, 2.53586, 2.6246054, 2.695914, 2.5879114, 2.4682047, 2.2535822, 2.4580975, 2.5425591, 2.4531074, 2.5660899, 2.6744123, 2.3377588, 2.4757342, 2.5360467, 2.5506244, 2.3534327, 2.5383172, 2.5340505, 2.574745, 2.6482933, 2.5710309, 2.503264, 2.6618876, 2.608151, 2.5979328, 2.4659863, 2.5043688, 2.609094, 2.673678, 2.40281, 2.65845, 2.5083408, 2.6091366, 2.6794367, 2.6108515, 2.5337844, 2.5988147, 2.552339, 2.5590324, 2.580042, 2.7294335, 2.7201107, 2.6268454, 2.5753865, 2.4016724, 2.491059, 2.7187333, 2.4786813, 2.588105, 2.677323, 2.5288396, 2.6497953, 2.6864572, 2.7451644, 2.7651713, 2.532773, 2.723975, 2.572498, 2.4811509, 2.587794, 2.5421576, 2.6098723, 2.5586858, 2.713769, 2.7115574, 2.757405, 2.6769652, 2.6392112, 2.620197, 2.6408746, 2.690106, 2.5717258, 2.5440001, 2.4845955, 2.7076166, 2.586589, 2.7180665, 2.711177, 2.7851748, 2.7854931, 2.7481441, 2.6337328, 2.6232917, 2.6101544, 2.8352377, 2.8040047, 2.8086112, 2.6955745, 2.7364256, 2.8238769, 2.6826565, 2.6342266, 2.7537975, 2.5164368, 2.7019744, 2.5934153, 2.7845104, 2.7952967, 2.636269, 2.7829406, 2.7009869, 2.9262927, 2.6959732, 2.719514, 2.729608, 2.6852398, 2.7200143, 2.7660286, 2.6714828, 2.665713, 2.8085518, 2.4363766, 2.7948334, 2.5770812, 2.815469, 2.7859566, 2.879649, 2.7203362, 2.662235, 2.8376842, 2.8862112, 2.8008642, 2.8316345, 2.8206522, 2.723366, 2.7173467, 2.8612916, 2.8836732, 2.7322288, 2.7618968, 2.7134678, 2.7984593, 2.6014748, 2.815548, 2.8381143, 2.4569378, 2.6870615, 2.772867, 2.7027545, 2.9158766, 2.7313006, 2.701006, 2.7097778, 2.9747071, 2.897128, 2.7824342, 2.796979, 2.7453103, 2.790692, 2.7398412, 2.883012, 2.8053637, 2.7998536, 2.9677987, 2.6517844, 2.7324347, 2.801146, 2.8793592, 2.7871044, 2.8717668, 2.8798852, 2.5173085, 2.746122, 2.7540317, 2.805145, 2.8020275, 2.8881035, 2.7663724, 2.8836648, 2.7404208, 2.8631196, 2.8410907, 2.7998655, 2.7774055, 2.93439, 2.797102, 3.020855, 2.5858335, 2.8509514, 2.9115791, 2.8569775, 2.7529094, 2.849404, 2.9553008, 2.8077898, 2.8532834, 2.7824194, 2.7719169, 2.8937743, 2.8901849, 2.914455, 2.8290129, 2.941752, 2.7060413, 2.929132, 2.7930827, 2.893389, 2.806482, 2.874082, 2.905589, 2.8140082, 2.9544258, 2.7277157, 2.9025722, 2.914209, 2.9983652, 2.9403343, 2.7551293, 2.8565805, 2.8524568, 2.8185728, 2.9262564, 2.742544, 2.8661234, 2.9032128, 2.8446596, 2.7294443, 2.804701, 2.6220102, 2.9029965, 2.8498821, 2.9217825, 2.959176, 2.8315735, 2.860362, 2.9242015, 2.8204966, 2.8355663, 2.8485465, 2.884287, 2.8325212, 2.943543, 2.6076112, 2.8123186, 2.8680904, 2.9410717, 2.9702265, 2.9000847, 2.9520757, 2.9075987, 2.9697316, 2.9240644, 2.6682928, 3.030559, 2.9977434, 2.8627028, 2.9425993, 2.7146602, 2.9442143, 2.90354, 3.0311909, 2.8793924, 3.0074835, 2.855213, 3.047562, 2.7393687, 2.9240644, 2.9298682, 2.962633, 2.8856232, 2.7980204, 2.9048762, 3.0446272, 3.0022447, 2.86687, 2.8902934, 2.9928074, 2.983485, 2.8770115, 2.9383173, 2.8391836, 2.9369903, 2.8976123, 2.9421673, 2.84059, 2.9100199, 3.0338197, 2.9143217, 2.8996327, 2.9329534, 3.0507774, 2.95015, 2.9043865, 2.825931, 3.0342867, 2.9076495, 2.9093173, 3.0157073, 3.020107, 2.9497383, 3.0022871, 2.931981, 3.088065, 2.9885695, 3.0683877, 2.8502917, 2.934806, 3.0159156, 3.0642836, 2.9851136, 2.9436393, 2.9753711, 2.7533274, 2.8884635, 3.010224, 3.081869, 2.891675, 3.0117288, 2.9356532, 2.985769, 2.9366863, 3.0562675, 2.9692185, 2.7520037, 2.9229727, 2.8356457, 3.15936, 3.015359, 2.99767, 2.9069796, 2.8719761, 3.0490706, 3.0473278, 2.9204538, 2.9157455, 2.820597, 2.9662015, 3.0083778, 3.0352197, 2.6458232, 2.8615365, 3.0200405, 3.0111675, 3.0115826, 2.9611216, 2.9079332, 2.8683245, 2.988898, 3.0046375, 3.0374172, 2.9432025, 2.785966, 3.0837717, 3.0008905, 2.8947864, 3.0727534, 3.0641427, 2.821864, 2.760662, 2.9219887, 3.0529947, 2.9443288, 2.92886, 3.0136304, 2.9947882, 2.9930923, 2.869453, 2.99521, 2.9135258, 2.734083, 2.937046, 2.9541311, 2.915258, 2.9739847, 3.0596743, 3.108725, 2.978498, 3.074114, 2.9560812, 2.7854717, 3.02763, 3.094358, 3.0392368, 3.0268822, 2.8878846, 3.010075, 3.0459075, 3.0966027, 3.027766, 3.0628269, 3.014545, 2.9678748, 3.0140681, 3.0324762, 3.0848749, 3.09896, 2.81046, 2.7916064, 2.972022, 3.049188, 2.9131038, 2.9343324, 2.9392602, 2.9479396, 3.0589945, 2.8768742, 3.0144796, 2.9850695, 3.1187391, 3.027076, 3.05491, 2.962352, 2.922043, 2.9346714, 3.0122552, 3.1209962, 2.9749904, 3.0811346, 3.0771592, 3.0116591, 3.0356054, 3.08044, 3.0483787, 3.0789785, 2.8787494, 3.042443, 2.9849937, 3.1622458, 2.9900057, 3.1270149, 3.0501251, 3.0035908, 3.0046825, 2.9697819, 3.0590317, 0.017141925, 1.5739228, 1.5944192, 1.9234556, 1.7026368, 1.8022975, 1.5787522, 1.9279988, 1.6029027, 1.8118384, 2.1283307, 1.9387225, 2.211014, 1.8338948, 1.9166293, 1.9993862, 2.1858842, 2.0847144, 2.1356363, 2.0774846, 2.0527833, 2.0192034, 1.9530759, 2.2110412, 2.261425, 2.103134, 2.220617, 2.1058955, 2.1460571, 1.9942992, 2.094796, 2.2586815, 2.2793465, 2.1702142, 2.147104, 2.473287, 2.2684886, 2.211228, 2.0447776, 2.2186313, 2.2544558, 2.3678157, 2.4271595, 2.3835635, 2.26909, 2.375041, 2.1618776, 2.3209398, 2.3472056, 2.2227345, 2.2946167, 2.29193, 2.6711175, 2.2371652, 2.3879101, 2.3513749, 2.342903, 2.1616707, 2.3256142, 2.2765443, 2.2995698, 2.3254762, 2.4040153, 2.2603252, 2.2571642, 2.4498816, 2.2392325, 2.3716269, 2.3018816, 2.4538376, 2.4512165, 2.190132, 2.4319913, 2.5837054, 2.3490334, 2.4339173, 2.2977211, 2.5841694, 2.226256, 2.5969117, 2.5170941, 2.4805648, 2.4965022, 2.5366652, 2.4206603, 2.5516973, 2.6682599, 2.4959536, 2.5225685, 2.652713, 2.5072334, 2.671293, 2.3984835, 2.5112004, 2.4795668, 2.6734002, 2.4935124, 2.327455, 2.334765, 2.6296961, 2.6071768, 2.596566, 2.6946156, 2.5745678, 2.6374807, 2.5543864, 2.4797344, 2.575977, 2.4758844, 2.6396358, 2.6261547, 2.4349928, 2.7551742, 2.69856, 2.4226089, 2.5710506, 2.6655784, 2.639742, 2.5598555, 2.4635568, 2.5902267, 2.6902633, 2.5308356, 2.6097815, 2.4637911, 2.665476, 2.5836775, 2.4629757, 2.6486833, 2.732239, 2.721228, 2.672242, 2.7818115, 2.612075, 2.6933918, 2.8127205, 2.875718, 2.5928018, 2.66417, 2.5826206, 2.6787348, 2.6676571, 2.737063, 2.554835, 2.4100478, 2.6574335, 2.6549299, 2.6408439, 2.6932712, 2.6238616, 2.7012868, 2.9012442, 2.6750462, 2.693107, 2.6184025, 2.668915, 2.7753224, 2.729936, 2.6862478, 2.7303584, 2.700065, 2.7164676, 2.642744, 2.6718607, 2.6945584, 2.5686624, 2.7600305, 2.7508845, 2.6418645, 2.6539128, 2.6303, 2.5188186, 2.5972252, 2.634257, 2.7264736, 2.7982228, 2.6233182, 2.8428845, 2.657473, 2.7059224, 2.746951, 2.7139413, 2.7212555, 2.632757, 2.8771803, 2.7681472, 2.758956, 2.6193404, 2.7018018, 2.6079116, 2.7987664, 2.5866854, 2.7282653, 2.5614822, 2.531574, 2.6951876, 2.6997752, 2.719319, 2.6984982, 2.7091074, 2.7885313, 2.789944, 2.6187658, 2.7387304, 2.7181463, 2.8089051, 2.670793, 2.702291, 2.8970768, 2.851886, 2.7881162, 2.9066684, 2.5857975, 2.7722087, 2.7993066, 2.8092136, 2.762371, 2.7512608, 2.8253536, 2.6560888, 2.8282301, 2.764629, 2.733604, 2.7557063, 2.7001941, 2.7330346, 2.784176, 2.640752, 2.8346462, 2.7821455, 2.8891912, 2.866688, 2.8873732, 2.8152783, 2.9348109, 2.8515875, 2.8358579, 2.7584925, 2.7377565, 2.7693214, 2.8259254, 2.7852464, 2.606518, 2.7226892, 2.9052882, 2.7804406, 2.6145563, 2.8963528, 2.846176, 2.8752863, 2.7496204, 2.751553, 2.9592507, 3.0077674, 2.9215662, 2.9187272, 2.90061, 3.083372, 2.8660288, 2.978552, 2.8045824, 2.8394027, 2.6449716, 2.693637, 2.9042816, 2.911604, 2.9094045, 2.8360832, 2.9032302, 2.8838668, 2.868636, 2.850638, 2.7883887, 2.920663, 2.868096, 2.940671, 2.9396703, 2.9003198, 2.8846526, 2.8718283, 2.821631, 2.8522236, 2.7129552, 2.7093644, 2.8759692, 2.9539793, 2.6938894, 2.887145, 2.923261, 2.767638, 2.8432984, 2.9866233, 2.9030805, 2.8759968, 2.8056984, 2.871492, 2.8073666, 2.8738344, 2.8497405, 2.8237832, 2.600683, 2.9056091, 2.999797, 2.929847, 2.9597704, 2.9046757, 2.9559736, 2.885755, 2.9530697, 3.0091312, 2.9224582, 2.922177, 2.9224722, 2.9173086, 2.858161, 2.8978856, 2.8991718, 2.8667445, 2.9706814, 2.9181607, 2.886494, 2.856941, 2.9736433, 2.896835, 2.899297, 2.896695, 3.1154814, 2.8937526, 2.9003701, 2.9168308, 2.8812532, 2.7820876, 2.9008162, 2.9299803, 2.94217, 2.9820035, 2.9901788, 2.927505, 2.928758, 2.9616287, 2.823578, 2.8723354, 3.0030854, 2.8771105, 2.9828749, 2.8863044, 2.966065, 2.851241, 2.9702828, 3.1175423, 2.9542575, 2.7015917, 3.0232458, 2.8666828, 2.9041445, 2.926137, 2.9359953, 2.9898086, 3.1460848, 3.018724, 2.96365, 2.9506524, 3.1083534, 2.935282, 2.933263, 2.9227161, 2.9705021, 2.903924, 2.9534757, 2.887501, 2.9904993, 2.936929, 2.9687893, 2.8895288, 2.8636165, 3.003675, 2.9142559, 2.9691298, 3.0188434, 2.8632143, 2.9716744, 2.8886251, 2.9522176, 2.9704323, 2.8219657, 3.1019142, 2.908087, 2.9797783, 3.0353427, 2.9216585, 2.9138763, 2.9020457, 2.859671, 2.9699652, 2.9919274, 3.0295298, 2.7923863, 2.9292533, 3.0043917, 3.0514903, 2.9059546, 2.9646707, 3.0277126, 2.9916203, 3.0052795, 2.89346, 2.979345, 2.9325612, 2.7813056, 3.0332098, 2.8987203, 3.0477958, 2.9945977, 3.01999, 2.9584014, 3.0588043, 2.9242702, 3.0735464, 2.9538362, 2.8644207, 3.0803323, 2.934069, 2.8936095, 3.0541728, 2.8825877, 3.1360652, 3.0257456, 3.0101783, 3.0184388, 2.85344, 3.0788157, 2.762362, 2.9559572, 2.9791036, 2.904169, 2.9779267, 3.0376852, 2.939138, 2.9656913, 3.0388653, 3.099847, 2.913528, 3.0129108, 3.008543, 2.9920232, 2.9800427, 3.0116718, 2.8756492, 3.007304, 3.0162477, 3.033598, 2.9517722, 2.8846192, 3.1110563, 3.0542855, 2.9405005, 3.0061004, 2.9033108, 3.0680141, 2.8446243, 2.9823334, 2.8551412, 3.058037, 2.8146043, 2.879002, 2.9036267, 2.9439986, 2.8696582, 2.9610076, 3.0658028, 2.9750657, 3.171487, 2.9301286, 3.0550058, 2.9816384, 3.0182796, 3.0251582, 3.0633516, 3.015969, 3.015931, 3.1011298, 3.0289757, 3.0169234, 2.9827318, 3.039045, 2.966118, 3.023822, 3.0097678, 3.0215201, 3.0577712, 3.0027413, 2.960436, 3.096222, 3.060681, 3.088489, 2.8636708, 2.984683, 3.1429794, 3.0546346, 2.8774328, 3.0183218
disc_val_loss: 5.5523176, 1.3329345, 0.9704568, 0.73838574, 0.33885437, 0.3922195, 0.817931, 2.0229585, 1.4305516, 0.8022578, 0.22715999, 0.24782456, 0.10581834, 0.36021054, 0.06355046, 3.1081634, 0.6265331, 0.42104235, 0.123530455, 0.100802384, 0.35577193, 0.44454652, 0.38527375, 0.29052928, 0.64726603, 0.6103793, 0.12491271, 0.7510843, 0.84660673, 0.07188285, 0.22645624, 0.06353553, 0.91817635, 0.077233545, 0.20085354, 0.03196236, 0.17398018, 0.35616466, 0.033226807, 0.077114776, 0.5060598, 1.1463779, 0.07224146, 0.037262328, 0.119709834, 0.39519367, 0.06640705, 0.04078181, 0.036788784, 0.14140159, 0.025370369, 0.07002374, 0.029025551, 0.029639836, 0.31564108, 0.11074137, 0.082796045, 0.75760347, 0.06287701, 0.015577922, 0.02776497, 0.15768985, 0.1743506, 0.043130573, 0.13985078, 0.3668654, 0.104482375, 0.055113073, 0.113721356, 0.27748117, 0.065127715, 0.024880236, 0.030668268, 0.035783906, 0.09229688, 0.24222274, 0.018467158, 0.018718552, 0.14913042, 0.045417234, 0.14462179, 0.7140615, 0.049078792, 0.12822305, 0.35009196, 0.02797004, 0.05475673, 0.2133187, 0.056669336, 0.037462562, 0.064227544, 0.07666936, 0.03225076, 0.07123745, 0.018933654, 0.037320554, 0.060880844, 0.013258977, 0.83393455, 0.014771937, 0.011787025, 0.03968511, 0.06496221, 0.26597163, 0.014070201, 1.2531704, 0.0289377, 0.016286213, 0.03321228, 0.039930243, 0.017900465, 0.013413167, 0.01479272, 0.17784742, 0.04863317, 0.14525625, 0.015345965, 1.5480784, 0.06861708, 0.009246305, 0.14440985, 0.5771224, 0.013153699, 0.047530103, 0.06923871, 0.020012314, 0.018662496, 0.007480527, 0.011443897, 0.10913836, 0.01069234, 0.014916977, 1.8153951, 0.089559995, 0.19147521, 0.050150014, 0.010565442, 0.0121451905, 0.013572788, 0.10254029, 0.01015245, 0.012867278, 0.011768577, 0.011328719, 0.017608121, 0.012695756, 0.0070418925, 0.15665123, 0.016684284, 0.021756273, 0.013300637, 0.018548135, 0.67690665, 0.006032587, 0.010084102, 0.024891466, 0.010973576, 0.011710963, 0.32128724, 0.00625445, 0.008248228, 0.035694934, 0.009957212, 0.006321112, 0.025107386, 0.031163707, 0.01140157, 0.19107811, 0.016646236, 0.07706828, 0.018906385, 0.017006855, 1.7278978, 0.07179269, 0.18789342, 0.0059963106, 0.03836256, 0.17350847, 0.0048663644, 0.070283026, 0.007470675, 0.011190748, 0.029729594, 0.032553095, 0.009362028, 0.010075467, 0.02246935, 0.087378986, 0.0050034784, 0.025977252, 3.4375017, 0.3767249, 0.010178841, 0.010628056, 0.37247574, 0.008664053, 1.0423061, 0.011330285, 0.084411986, 0.010079634, 1.2959005, 0.007210552, 0.012421217, 0.014673067, 0.08719582, 0.0051999087, 0.014407374, 0.008657761, 0.010810805, 0.08288372, 1.149515, 1.7711681, 0.0050327512, 0.005411561, 0.013562018, 0.012547884, 0.024775265, 0.0612558, 0.013142679, 0.013934092, 0.004832088, 0.010519603, 0.0045695393, 0.004062618, 0.013039308, 0.008637106, 0.015112293, 0.017691817, 0.005659415, 0.017038925, 0.008412322, 0.007669589, 0.009248972, 0.12836616, 0.013808323, 0.010260317, 0.00692911, 0.0049648928, 0.06700666, 0.06392333, 0.028836349, 0.106387004, 0.0069993436, 0.004907561, 0.12575471, 0.0059750797, 0.011117697, 0.015445966, 0.03414341, 0.007868489, 0.0097548, 0.058806982, 0.1974655, 0.008092772, 0.032371305, 0.0155737465, 0.006205261, 0.005283168, 0.017282719, 0.043424167, 0.00739585, 0.008774324, 0.011853781, 0.01216487, 0.068069585, 0.012877015, 0.015973017, 0.0116042, 0.2642349, 0.11294871, 0.006141904, 0.15158002, 0.008193985, 0.0044331416, 0.0071548056, 0.0045040017, 0.003530592, 0.1727653, 0.007296202, 0.0116224475, 0.0072971317, 0.010171992, 0.0060129473, 0.0057100016, 0.0043522594, 0.006929925, 0.009844982, 0.044601675, 0.0032526853, 0.022270825, 0.010709282, 0.0065880036, 0.04020929, 0.008871953, 0.35808852, 0.0143579235, 0.007382332, 0.0119400965, 0.018034404, 0.0041299514, 0.002679805, 0.007177988, 1.1801786, 0.0053203073, 1.7889746, 0.023437224, 0.0029675115, 0.005140988, 0.034457184, 0.0070926556, 0.0029346019, 0.003364679, 0.018343233, 0.0110178, 0.0061323023, 0.030983806, 0.013019338, 0.004624317, 0.01301275, 0.008306324, 0.014119724, 0.009607514, 0.008768865, 0.0070346203, 0.0061184415, 0.003973389, 0.025674758, 0.009527767, 0.023210682, 0.03530704, 0.009437997, 0.035965014, 0.005273553, 0.010713323, 0.013120625, 0.0026101177, 0.019603254, 0.0033740238, 0.010337786, 0.005951059, 0.03816433, 0.29379907, 0.0056669065, 0.0108004045, 0.004526645, 0.0061851814, 0.00471371, 0.004609818, 0.0061422414, 0.008311457, 0.27233303, 0.00916497, 0.0032685408, 0.0035161874, 0.011538304, 0.006705565, 0.006444486, 0.10406708, 0.018255105, 0.004990614, 0.022578562, 0.005997262, 0.0055844258, 0.0031227965, 0.0110419905, 0.045943465, 0.0020493995, 0.0038905796, 0.01963491, 0.0076489365, 0.017606031, 0.004121311, 0.014806843, 0.00593499, 0.0143013345, 0.0092444755, 0.004599702, 0.19147119, 0.022020416, 0.0018925495, 0.004748471, 0.010566483, 0.009321054, 0.0040943366, 0.0027043351, 0.006663536, 0.013748644, 0.00787711, 0.0076824133, 0.0036577736, 0.027894193, 0.0038973389, 0.2449846, 0.0041150977, 0.0024108547, 0.002480024, 0.1247736, 0.020746721, 0.010032914, 0.0087631475, 0.01511942, 0.0045143384, 0.0027086497, 0.008097087, 0.011470394, 0.004448795, 0.014937577, 0.0068816296, 0.002226389, 0.011727481, 0.004523795, 0.009429192, 0.021678701, 0.024829982, 0.00633249, 0.0056189694, 0.0049280953, 0.004939199, 0.025490763, 0.0030207057, 0.013552038, 0.0022343104, 0.0040560844, 0.03472446, 0.012614769, 0.004176387, 0.0029374827, 0.0028146014, 0.004993747, 0.010970977, 0.001462063, 0.0030459762, 0.0037382783, 0.007213055, 0.008063976, 0.012834592, 0.012619955, 0.0118407095, 0.0014438365, 0.012428061, 0.0041371407, 0.008626341, 0.0020417587, 0.009275018, 0.0034867711, 0.008940862, 0.008625221, 0.00510043, 0.0023701072, 0.008717726, 0.0017139834, 0.03247978, 0.51548845, 0.32899922, 0.0019533862, 0.014604119, 0.0022249245, 0.004566061, 0.0016732505, 0.0064916634, 0.0063556903, 0.0092711365, 0.19168673, 0.008780911, 0.0032029438, 0.0068101347, 0.16765767, 0.0070127132, 0.004041826, 0.0021927564, 0.32434872, 0.03015702, 0.0027539989, 0.004708285, 0.004876561, 0.043974433, 0.0041583846, 0.11762941, 0.006344992, 0.004586671, 0.00784135, 0.13511111, 0.020558719, 0.025575364, 0.0012974142, 0.005453707, 0.0039100894, 0.005243143, 0.0027872608, 0.0010953131, 0.26927087, 0.0022749116, 0.0340034, 0.002612333, 0.010627355, 0.0042001945, 0.0033585583, 0.0022336894, 0.0047371713, 0.0037700625, 0.0047160657, 5.535686, 1.6613144, 1.4396789, 1.6667713, 1.9840822, 3.3763282, 0.92357415, 0.7961775, 0.78820986, 0.5884231, 3.8871963, 1.6816523, 0.73273325, 0.21215534, 0.32424483, 3.399365, 1.3910501, 0.5885608, 1.0103651, 0.47556773, 0.26331583, 2.0411372, 0.28462836, 0.5130241, 2.7567508, 0.16582681, 0.050690718, 0.32583818, 0.26994812, 0.5253648, 1.6616843, 3.2410846, 0.03549887, 0.10521133, 0.5478261, 0.022965208, 0.7257642, 0.27492496, 0.23056348, 1.0751954, 0.2232637, 0.018241128, 0.09072353, 0.3829805, 0.2966079, 2.5754683, 0.5436537, 1.76907, 0.12724315, 0.14755514, 0.49853817, 0.101330794, 3.1285203, 0.19374119, 0.07319786, 0.5919456, 0.041174065, 0.14147846, 2.7008898, 1.731469, 0.040665843, 0.21882313, 0.1688158, 1.3099002, 0.10600852, 0.093590505, 0.6808127, 0.027003996, 0.4410776, 0.01625021, 0.014937602, 0.2692919, 0.37170142, 0.11442397, 0.9483648, 0.032125082, 0.09599833, 0.04036792, 0.10333258, 0.029453607, 0.05394024, 0.10411135, 0.6388549, 0.02417018, 0.059303313, 0.0969635, 0.093049236, 0.48650536, 0.4821463, 0.016483363, 0.024488578, 1.0042, 0.16815919, 0.1898444, 0.31245008, 0.029241785, 0.043059353, 0.15356824, 0.1082101, 0.048614465, 0.048610095, 0.07412746, 0.058557503, 0.010320876, 0.06541015, 0.10640544, 0.012485187, 0.015712356, 0.23212755, 0.020357782, 0.017953748, 0.4652749, 0.18042424, 0.031566158, 0.14884067, 0.016646732, 0.036141433, 0.014303785, 0.9529134, 0.04970235, 0.01626476, 0.0068263025, 0.062134188, 0.39259866, 0.37758434, 0.5423542, 0.008595166, 0.06479801, 0.010462033, 0.76185244, 0.040977705, 0.0075137895, 0.34813476, 0.035809096, 0.036580857, 0.024177006, 0.077265285, 0.015703034, 0.027326407, 0.018069992, 0.27441663, 0.012060548, 0.014724459, 0.021402271, 0.097074404, 0.023212142, 0.017625147, 0.031336226, 0.013276444, 0.013103547, 0.024146346, 0.6118282, 0.0136224525, 0.011620163, 0.18288101, 0.006900229, 0.016359735, 0.061966326, 0.008278726, 0.014595212, 0.058366142, 0.044182833, 0.062330183, 0.12978439, 0.21727395, 0.08892324, 0.015817799, 0.007102913, 0.33993483, 0.0121813975, 0.17311102, 0.82653993, 0.1260252, 0.051464535, 0.0074274717, 0.006733303, 0.011871882, 0.5802694, 0.083606645, 0.65805066, 0.065771535, 0.020933129, 0.42051423, 0.07209044, 0.020726392, 0.0063117407, 0.0041225124, 0.008923545, 0.25987548, 0.29655612, 0.006974464, 0.03811638, 0.35033643, 1.6038133, 1.3108227, 0.0347943, 0.32864273, 0.009684207, 0.013336744, 0.008079506, 0.007387529, 0.08726782, 0.1037129, 0.011341785, 0.028780138, 0.081413336, 0.46839434, 0.064954385, 1.6617492, 0.008788457, 0.080601014, 0.015589498, 1.7847649, 0.038562898, 0.0034400306, 0.008804852, 0.18356577, 0.004525873, 0.00722706, 0.027154192, 0.015038712, 0.04875054, 0.012681859, 0.084801465, 0.011811204, 0.0076667042, 0.045249637, 0.028786154, 0.003765659, 0.004833069, 0.0055310866, 0.009858744, 0.03962873, 0.0042684874, 0.020644108, 0.009833939, 0.13911231, 0.020021128, 0.017926242, 0.009199865, 0.0045006797, 0.0041252896, 0.17099547, 0.07800824, 0.007595123, 0.015955213, 0.02907416, 0.032124676, 0.0039958893, 0.33740973, 0.010438402, 0.0060592378, 0.007365869, 0.17446955, 0.0031424654, 0.0042683342, 0.011903118, 0.20787705, 0.07364881, 0.007164935, 0.006062567, 0.008611876, 0.07800521, 0.02945523, 0.0063473466, 0.0063687963, 0.006035898, 0.01265569, 0.006488164, 0.017131787, 0.0043612234, 0.017290322, 0.03247696, 0.04459317, 0.4157695, 0.17338946, 0.0056677843, 0.020685043, 0.013700438, 0.009521392, 0.00904126, 0.60355556, 0.013584604, 0.006025716, 0.01231268, 0.004119468, 0.007107089, 0.00440295, 0.0035521123, 0.025193056, 1.5620099, 0.019428879, 0.0063859555, 0.010612319, 0.04065966, 0.0033402652, 0.004243902, 0.009210031, 0.007347471, 0.06393761, 0.123650275, 0.07429131, 0.011357207, 0.00927188, 0.005096867, 0.0036758354, 0.017988972, 0.017917497, 0.002580792, 0.020531636, 0.0031470784, 0.048227593, 0.4109127, 0.008232698, 0.0077320933, 0.0038842051, 0.0023313188, 0.004124164, 0.004477923, 0.0057283207, 0.0019287922, 0.0061972914, 0.0037883795, 0.0025213694, 0.007591928, 0.0026369458, 2.392905, 0.009026051, 0.008550156, 0.0106812995, 0.03583684, 0.03407713, 0.018134162, 0.008631903, 0.0061387573, 0.004353674, 0.004420659, 0.013256229, 0.0026910142, 0.0036846406, 0.020414798, 0.014549963, 0.00406423, 0.005542257, 0.0037962333, 0.013895693, 0.0020162934, 0.0022940505, 0.0036504986, 0.14289504, 0.0056839753, 0.05627775, 0.006050127, 0.08362845, 0.01040866, 0.0045064855, 0.0034555814, 0.005962646, 0.004059214, 0.015181171, 0.009001896, 0.004546265, 0.07929414, 0.009643676, 0.04189089, 0.004543393, 0.028642263, 0.002318327, 0.0020029526, 0.0062705744, 0.005202969, 0.0029305767, 0.002605878, 0.0026068636, 0.9717214, 1.0548309, 0.0041391063, 0.0030952084, 0.006900788, 0.043741036, 0.0049275327, 0.002424498, 0.004462586, 0.023238866, 0.03889506, 0.7184381, 0.0027794188, 0.0048787035, 0.005883029, 0.0022269047, 0.0034148672, 2.9489093, 0.07513078, 0.0017088089, 0.0024253076, 0.00509702, 0.018176608, 0.008738866, 0.11064769, 0.003649333, 0.008356426, 0.0013663649, 0.0038277442, 0.0035433292, 0.026068684, 0.44825807, 0.005761936, 0.005514969, 0.009738282, 0.0069525805, 0.019541983, 0.005202016, 0.006348603, 0.0018677579, 0.013322646, 0.023302652, 0.6778711, 0.0057863034, 0.00414656, 0.0039414666, 0.0077437973, 0.0028582015, 0.00564345, 0.0038991484, 0.0034817955, 0.008413944, 0.0032318353, 0.00405654, 0.023462815, 0.26495293, 0.0028277829, 0.03962329, 0.0032546502, 0.027270762, 0.007105444, 0.003641618, 0.0093521755, 0.005333793, 0.0033719258, 0.0046050153, 0.025711132, 0.007039959, 0.009875693, 0.008482292, 0.0067875944, 0.0022365702, 0.0059089353, 0.018675284, 0.014105346, 0.0024874173, 0.011340143, 0.001898924, 0.0046482896, 0.06025879, 0.0037407456, 0.0024694127, 0.0039070323, 0.12482734, 0.008143632, 0.009129151, 0.0056498223, 0.009158312, 0.033533137, 0.01871056, 0.0043057627, 0.0033376454, 0.0024226967, 0.02479997, 0.01125556, 0.022485053, 0.0066788895, 0.35351172, 0.10519993, 0.0032257095, 0.004056416, 0.55743116, 0.036834426, 0.35362378, 0.0030411582, 0.005050739, 0.0029885333, 0.0025662237, 0.006778239, 0.016018089, 0.0028642411, 0.011937535, 0.0033087172, 0.004811202, 0.0037277893, 0.11259581, 0.0023839413, 0.0029963427, 0.005512958, 0.006443179, 0.007161726, 0.00350103, 0.0038702546, 0.0067297365, 0.008020083, 0.9948644, 0.0025328754
disc_val_acc: 0.0, 0.5054563492063492, 0.6195436507936508, 0.658234126984127, 0.9211309523809523, 0.9186507936507936, 0.6800595238095238, 0.5059523809523809, 0.5228174603174603, 0.6964285714285714, 0.9404761904761905, 0.9146825396825397, 0.9786706349206349, 0.8601190476190477, 0.9875992063492064, 0.2748015873015873, 0.7564484126984127, 0.8224206349206349, 0.9613095238095238, 0.9662698412698413, 0.8779761904761905, 0.8358134920634921, 0.8779761904761905, 0.8754960317460317, 0.7008928571428571, 0.8025793650793651, 0.9553571428571429, 0.7797619047619048, 0.6755952380952381, 0.9747023809523809, 0.9087301587301587, 0.9786706349206349, 0.7123015873015873, 0.9846230158730159, 0.9206349206349206, 0.9920634920634921, 0.9449404761904762, 0.8616071428571429, 0.9905753968253969, 0.9771825396825397, 0.8447420634920635, 0.7286706349206349, 0.9781746031746031, 0.9885912698412699, 0.9618055555555556, 0.8680555555555556, 0.9801587301587301, 0.9905753968253969, 0.9915674603174603, 0.9404761904761905, 0.9940476190476191, 0.9756944444444444, 0.9880952380952381, 0.9935515873015873, 0.8665674603174603, 0.9652777777777778, 0.9712301587301587, 0.7837301587301587, 0.9776785714285714, 0.9955357142857143, 0.9920634920634921, 0.9499007936507936, 0.9206349206349206, 0.9851190476190477, 0.9533730158730159, 0.8640873015873016, 0.9593253968253969, 0.9781746031746031, 0.9553571428571429, 0.8784722222222222, 0.9836309523809523, 0.9925595238095238, 0.9925595238095238, 0.9875992063492064, 0.9662698412698413, 0.9047619047619048, 0.9935515873015873, 0.9940476190476191, 0.9563492063492064, 0.9851190476190477, 0.9379960317460317, 0.7137896825396826, 0.9846230158730159, 0.9623015873015873, 0.8511904761904762, 0.9895833333333334, 0.9806547619047619, 0.9141865079365079, 0.9821428571428571, 0.9900793650793651, 0.9806547619047619, 0.9766865079365079, 0.9885912698412699, 0.9786706349206349, 0.9940476190476191, 0.9875992063492064, 0.9756944444444444, 0.998015873015873, 0.816468253968254, 0.9930555555555556, 0.9945436507936508, 0.9851190476190477, 0.9751984126984127, 0.9077380952380952, 0.9955357142857143, 0.6721230158730159, 0.9890873015873016, 0.9955357142857143, 0.9890873015873016, 0.9866071428571429, 0.9970238095238095, 0.9970238095238095, 0.9945436507936508, 0.9320436507936508, 0.9910714285714286, 0.9404761904761905, 0.9940476190476191, 0.7271825396825397, 0.9771825396825397, 0.998015873015873, 0.9474206349206349, 0.7936507936507936, 0.9945436507936508, 0.9861111111111112, 0.9766865079365079, 0.9910714285714286, 0.9955357142857143, 0.9985119047619048, 0.9970238095238095, 0.9583333333333334, 0.996031746031746, 0.996031746031746, 0.6865079365079365, 0.9652777777777778, 0.9275793650793651, 0.9856150793650794, 0.9975198412698413, 0.996031746031746, 0.996031746031746, 0.9627976190476191, 0.9965277777777778, 0.9975198412698413, 0.9955357142857143, 0.9995039682539683, 0.9925595238095238, 0.9985119047619048, 0.9990079365079365, 0.9404761904761905, 0.9935515873015873, 0.9950396825396826, 0.9965277777777778, 0.9930555555555556, 0.7718253968253969, 0.9985119047619048, 0.9950396825396826, 0.9915674603174603, 0.9970238095238095, 0.9950396825396826, 0.8779761904761905, 0.9985119047619048, 0.9970238095238095, 0.9880952380952381, 0.9955357142857143, 0.9985119047619048, 0.9890873015873016, 0.9890873015873016, 0.9950396825396826, 0.9295634920634921, 0.9940476190476191, 0.9751984126984127, 0.9905753968253969, 0.9970238095238095, 0.6190476190476191, 0.9737103174603174, 0.9295634920634921, 0.9985119047619048, 0.9851190476190477, 0.9499007936507936, 1.0, 0.9761904761904762, 0.9985119047619048, 0.9965277777777778, 0.9915674603174603, 0.9910714285714286, 0.9970238095238095, 0.998015873015873, 0.9920634920634921, 0.9677579365079365, 1.0, 0.9905753968253969, 0.5565476190476191, 0.8874007936507936, 0.9965277777777778, 0.996031746031746, 0.9117063492063492, 0.9970238095238095, 0.7881944444444444, 0.9975198412698413, 0.9672619047619048, 0.9975198412698413, 0.7311507936507936, 0.9965277777777778, 0.9950396825396826, 0.9945436507936508, 0.966765873015873, 0.998015873015873, 0.9945436507936508, 0.9985119047619048, 0.9985119047619048, 0.9776785714285714, 0.7068452380952381, 0.6418650793650794, 0.998015873015873, 0.9990079365079365, 0.9945436507936508, 0.9955357142857143, 0.9900793650793651, 0.9747023809523809, 0.9940476190476191, 0.9955357142857143, 0.9990079365079365, 0.9975198412698413, 0.9990079365079365, 0.9995039682539683, 0.9950396825396826, 0.9975198412698413, 0.9945436507936508, 0.9935515873015873, 0.9985119047619048, 0.9950396825396826, 0.9970238095238095, 0.9965277777777778, 0.9970238095238095, 0.9528769841269841, 0.9945436507936508, 0.9965277777777778, 0.998015873015873, 0.9990079365079365, 0.9766865079365079, 0.9732142857142857, 0.9915674603174603, 0.9593253968253969, 0.9970238095238095, 0.9990079365079365, 0.9603174603174603, 0.9990079365079365, 0.9955357142857143, 0.9945436507936508, 0.9875992063492064, 0.9975198412698413, 0.996031746031746, 0.9801587301587301, 0.9211309523809523, 0.998015873015873, 0.9890873015873016, 0.9955357142857143, 0.998015873015873, 0.9985119047619048, 0.9955357142857143, 0.9875992063492064, 0.9975198412698413, 0.9970238095238095, 0.9965277777777778, 0.9950396825396826, 0.9761904761904762, 0.9940476190476191, 0.9925595238095238, 0.9950396825396826, 0.9156746031746031, 0.964781746031746, 0.998015873015873, 0.941468253968254, 0.9955357142857143, 0.9995039682539683, 0.9970238095238095, 0.9990079365079365, 0.9990079365079365, 0.9464285714285714, 0.9975198412698413, 0.9935515873015873, 0.9985119047619048, 0.9945436507936508, 0.9985119047619048, 0.998015873015873, 0.9995039682539683, 0.9965277777777778, 0.9965277777777778, 0.9851190476190477, 0.9995039682539683, 0.9940476190476191, 0.9970238095238095, 0.9975198412698413, 0.9851190476190477, 0.9970238095238095, 0.8898809523809523, 0.9945436507936508, 0.998015873015873, 0.9965277777777778, 0.9930555555555556, 0.9985119047619048, 1.0, 0.9975198412698413, 0.78125, 0.9975198412698413, 0.6641865079365079, 0.9925595238095238, 0.9995039682539683, 0.998015873015873, 0.9900793650793651, 0.9985119047619048, 0.9990079365079365, 0.9990079365079365, 0.9930555555555556, 0.9950396825396826, 0.9995039682539683, 0.9885912698412699, 0.996031746031746, 0.998015873015873, 0.996031746031746, 0.9955357142857143, 0.9945436507936508, 0.9965277777777778, 0.9985119047619048, 0.9970238095238095, 0.998015873015873, 0.9985119047619048, 0.9930555555555556, 0.996031746031746, 0.9930555555555556, 0.9866071428571429, 0.9950396825396826, 0.9875992063492064, 0.998015873015873, 0.996031746031746, 0.9950396825396826, 1.0, 0.9905753968253969, 0.9985119047619048, 0.996031746031746, 0.9975198412698413, 0.9875992063492064, 0.9375, 0.9965277777777778, 0.9950396825396826, 0.998015873015873, 0.9975198412698413, 0.9985119047619048, 0.9995039682539683, 0.9965277777777778, 0.9975198412698413, 0.8958333333333334, 0.9970238095238095, 0.9995039682539683, 0.9985119047619048, 0.996031746031746, 1.0, 0.9970238095238095, 0.9568452380952381, 0.9940476190476191, 0.998015873015873, 0.9920634920634921, 0.998015873015873, 0.9975198412698413, 0.9995039682539683, 0.9955357142857143, 0.9836309523809523, 0.9995039682539683, 0.9990079365079365, 0.9945436507936508, 0.9985119047619048, 0.9940476190476191, 0.9985119047619048, 0.9950396825396826, 0.9990079365079365, 0.9940476190476191, 0.9955357142857143, 0.9985119047619048, 0.9250992063492064, 0.9935515873015873, 1.0, 0.998015873015873, 0.9955357142857143, 0.9970238095238095, 0.9985119047619048, 0.9990079365079365, 0.9975198412698413, 0.9955357142857143, 0.996031746031746, 0.9965277777777778, 0.9990079365079365, 0.9920634920634921, 0.9985119047619048, 0.9315476190476191, 0.998015873015873, 0.9990079365079365, 0.9995039682539683, 0.9548611111111112, 0.9910714285714286, 0.9955357142857143, 0.9965277777777778, 0.9945436507936508, 0.9990079365079365, 0.9995039682539683, 0.996031746031746, 0.9950396825396826, 0.9990079365079365, 0.9950396825396826, 0.9975198412698413, 0.9995039682539683, 0.996031746031746, 0.9985119047619048, 0.9970238095238095, 0.9920634920634921, 0.9910714285714286, 0.998015873015873, 0.9985119047619048, 0.9975198412698413, 0.998015873015873, 0.9925595238095238, 0.9990079365079365, 0.9955357142857143, 1.0, 0.998015873015873, 0.9875992063492064, 0.9955357142857143, 0.9985119047619048, 1.0, 0.9995039682539683, 0.998015873015873, 0.9970238095238095, 1.0, 0.9990079365079365, 0.9995039682539683, 0.9975198412698413, 0.998015873015873, 0.9945436507936508, 0.9965277777777778, 0.9945436507936508, 1.0, 0.9940476190476191, 0.9985119047619048, 0.9965277777777778, 0.9995039682539683, 0.9970238095238095, 0.9990079365079365, 0.996031746031746, 0.9955357142857143, 0.9985119047619048, 0.9990079365079365, 0.9970238095238095, 1.0, 0.9890873015873016, 0.8670634920634921, 0.9161706349206349, 0.9990079365079365, 0.9950396825396826, 0.9995039682539683, 0.9985119047619048, 1.0, 0.9985119047619048, 0.998015873015873, 0.9970238095238095, 0.9370039682539683, 0.9965277777777778, 0.9985119047619048, 0.998015873015873, 0.9459325396825397, 0.9975198412698413, 0.9990079365079365, 0.9995039682539683, 0.9117063492063492, 0.9935515873015873, 0.9985119047619048, 0.9985119047619048, 0.998015873015873, 0.9841269841269841, 0.9990079365079365, 0.9573412698412699, 0.998015873015873, 0.998015873015873, 0.9975198412698413, 0.9548611111111112, 0.9925595238095238, 0.9915674603174603, 1.0, 0.9985119047619048, 0.9985119047619048, 0.9990079365079365, 0.9990079365079365, 1.0, 0.904265873015873, 0.9990079365079365, 0.9875992063492064, 0.9995039682539683, 0.9965277777777778, 0.9985119047619048, 0.9990079365079365, 0.9995039682539683, 0.9985119047619048, 0.9990079365079365, 0.9990079365079365, 0.0, 0.3834325396825397, 0.44990079365079366, 0.4126984126984127, 0.3978174603174603, 0.3149801587301587, 0.6731150793650794, 0.6845238095238095, 0.6364087301587301, 0.7867063492063492, 0.3740079365079365, 0.5223214285714286, 0.7053571428571429, 0.9404761904761905, 0.8983134920634921, 0.3392857142857143, 0.5719246031746031, 0.8328373015873016, 0.6433531746031746, 0.8100198412698413, 0.8998015873015873, 0.47867063492063494, 0.9146825396825397, 0.8283730158730159, 0.45982142857142855, 0.9384920634920635, 0.9920634920634921, 0.8591269841269841, 0.8883928571428571, 0.8080357142857143, 0.5848214285714286, 0.4652777777777778, 0.9915674603174603, 0.9642857142857143, 0.7678571428571429, 0.9945436507936508, 0.7425595238095238, 0.8988095238095238, 0.9285714285714286, 0.7569444444444444, 0.9270833333333334, 0.9970238095238095, 0.9682539682539683, 0.8735119047619048, 0.8725198412698413, 0.4632936507936508, 0.8129960317460317, 0.6641865079365079, 0.9573412698412699, 0.9469246031746031, 0.7708333333333334, 0.9662698412698413, 0.5064484126984127, 0.9330357142857143, 0.972718253968254, 0.8035714285714286, 0.9920634920634921, 0.9538690476190477, 0.5545634920634921, 0.6502976190476191, 0.9866071428571429, 0.9136904761904762, 0.9345238095238095, 0.7088293650793651, 0.9742063492063492, 0.9652777777777778, 0.8353174603174603, 0.9945436507936508, 0.8824404761904762, 0.9975198412698413, 0.9955357142857143, 0.9434523809523809, 0.9077380952380952, 0.9499007936507936, 0.6820436507936508, 0.9895833333333334, 0.9672619047619048, 0.9905753968253969, 0.9632936507936508, 0.9930555555555556, 0.9806547619047619, 0.9573412698412699, 0.7906746031746031, 0.9925595238095238, 0.9801587301587301, 0.9593253968253969, 0.9642857142857143, 0.8462301587301587, 0.8834325396825397, 0.9950396825396826, 0.9935515873015873, 0.8120039682539683, 0.9320436507936508, 0.9439484126984127, 0.8859126984126984, 0.9871031746031746, 0.9871031746031746, 0.9494047619047619, 0.9603174603174603, 0.9806547619047619, 0.9846230158730159, 0.9751984126984127, 0.9761904761904762, 0.9975198412698413, 0.9776785714285714, 0.9563492063492064, 0.9950396825396826, 0.9950396825396826, 0.9122023809523809, 0.9930555555555556, 0.9920634920634921, 0.8625992063492064, 0.9275793650793651, 0.9885912698412699, 0.9439484126984127, 0.9945436507936508, 0.9905753968253969, 0.9945436507936508, 0.7316468253968254, 0.9875992063492064, 0.9925595238095238, 0.998015873015873, 0.9737103174603174, 0.8482142857142857, 0.9002976190476191, 0.8824404761904762, 0.9990079365079365, 0.9831349206349206, 0.998015873015873, 0.8100198412698413, 0.9851190476190477, 0.9975198412698413, 0.9007936507936508, 0.9856150793650794, 0.9880952380952381, 0.9910714285714286, 0.9737103174603174, 0.996031746031746, 0.9915674603174603, 0.9950396825396826, 0.8978174603174603, 0.998015873015873, 0.9950396825396826, 0.9920634920634921, 0.9627976190476191, 0.9910714285714286, 0.9955357142857143, 0.9920634920634921, 0.9965277777777778, 0.9975198412698413, 0.9910714285714286, 0.8129960317460317, 0.9965277777777778, 0.998015873015873, 0.9340277777777778, 0.9990079365079365, 0.996031746031746, 0.9751984126984127, 0.9970238095238095, 0.9945436507936508, 0.9742063492063492, 0.9821428571428571, 0.9806547619047619, 0.9528769841269841, 0.9107142857142857, 0.9737103174603174, 0.9935515873015873, 0.9990079365079365, 0.8898809523809523, 0.9955357142857143, 0.9404761904761905, 0.7549603174603174, 0.9518849206349206, 0.9796626984126984, 0.9970238095238095, 0.9970238095238095, 0.9940476190476191, 0.8784722222222222, 0.9652777777777778, 0.7872023809523809, 0.9717261904761905, 0.9935515873015873, 0.8511904761904762, 0.9747023809523809, 0.9915674603174603, 0.9990079365079365, 0.9990079365079365, 0.9975198412698413, 0.8893849206349206, 0.9032738095238095, 0.9995039682539683, 0.9826388888888888, 0.878968253968254, 0.6324404761904762, 0.7306547619047619, 0.9875992063492064, 0.9067460317460317, 0.9970238095238095, 0.9950396825396826, 0.9970238095238095, 0.996031746031746, 0.9742063492063492, 0.9613095238095238, 0.996031746031746, 0.9890873015873016, 0.9672619047619048, 0.8908730158730159, 0.9766865079365079, 0.6607142857142857, 0.9975198412698413, 0.9692460317460317, 0.9940476190476191, 0.6016865079365079, 0.9890873015873016, 1.0, 0.9975198412698413, 0.9310515873015873, 0.9995039682539683, 0.9970238095238095, 0.9925595238095238, 0.9940476190476191, 0.9811507936507936, 0.9955357142857143, 0.9702380952380952, 0.9965277777777778, 0.9975198412698413, 0.9826388888888888, 0.9910714285714286, 0.9995039682539683, 0.9990079365079365, 0.998015873015873, 0.9955357142857143, 0.9861111111111112, 0.9995039682539683, 0.9930555555555556, 0.9965277777777778, 0.9543650793650794, 0.9930555555555556, 0.9945436507936508, 0.996031746031746, 0.9995039682539683, 0.9990079365079365, 0.9365079365079365, 0.9737103174603174, 0.9975198412698413, 0.9950396825396826, 0.9905753968253969, 0.9851190476190477, 0.9990079365079365, 0.8854166666666666, 0.9970238095238095, 0.9975198412698413, 0.9975198412698413, 0.935515873015873, 1.0, 0.9990079365079365, 0.9945436507936508, 0.9265873015873016, 0.9781746031746031, 0.998015873015873, 0.9990079365079365, 0.9965277777777778, 0.964781746031746, 0.9890873015873016, 0.9965277777777778, 0.9990079365079365, 0.9975198412698413, 0.9955357142857143, 0.998015873015873, 0.9940476190476191, 0.9990079365079365, 0.9935515873015873, 0.9866071428571429, 0.9836309523809523, 0.8829365079365079, 0.9484126984126984, 0.998015873015873, 0.9935515873015873, 0.9945436507936508, 0.9970238095238095, 0.9955357142857143, 0.8368055555555556, 0.9965277777777778, 0.9990079365079365, 0.996031746031746, 0.9995039682539683, 0.9985119047619048, 0.9985119047619048, 0.9995039682539683, 0.9880952380952381, 0.7177579365079365, 0.9920634920634921, 0.998015873015873, 0.9950396825396826, 0.9846230158730159, 0.9995039682539683, 0.9990079365079365, 0.9955357142857143, 0.9975198412698413, 0.972718253968254, 0.9508928571428571, 0.96875, 0.9950396825396826, 0.9985119047619048, 0.9975198412698413, 0.9990079365079365, 0.9935515873015873, 0.9940476190476191, 0.9990079365079365, 0.9925595238095238, 1.0, 0.9821428571428571, 0.9295634920634921, 0.998015873015873, 0.9970238095238095, 0.9990079365079365, 1.0, 0.9995039682539683, 0.9975198412698413, 0.9990079365079365, 1.0, 0.9990079365079365, 0.9990079365079365, 0.9995039682539683, 0.9970238095238095, 0.9995039682539683, 0.5803571428571429, 0.9970238095238095, 0.996031746031746, 0.9970238095238095, 0.9905753968253969, 0.9885912698412699, 0.9920634920634921, 0.998015873015873, 0.9985119047619048, 0.998015873015873, 0.9985119047619048, 0.9950396825396826, 0.9995039682539683, 0.9990079365079365, 0.9920634920634921, 0.9945436507936508, 0.9985119047619048, 0.9975198412698413, 0.9990079365079365, 0.9950396825396826, 0.9990079365079365, 0.9995039682539683, 0.9990079365079365, 0.9439484126984127, 0.998015873015873, 0.9761904761904762, 0.9975198412698413, 0.9751984126984127, 0.9965277777777778, 0.9995039682539683, 0.9995039682539683, 0.9985119047619048, 0.9995039682539683, 0.9955357142857143, 0.9975198412698413, 0.9985119047619048, 0.966765873015873, 0.9975198412698413, 0.9861111111111112, 0.998015873015873, 0.9885912698412699, 0.9990079365079365, 1.0, 0.9970238095238095, 0.9985119047619048, 0.9995039682539683, 0.9995039682539683, 0.9995039682539683, 0.7872023809523809, 0.7931547619047619, 0.9985119047619048, 0.9985119047619048, 0.9975198412698413, 0.9846230158730159, 0.998015873015873, 0.9990079365079365, 0.9985119047619048, 0.9910714285714286, 0.9841269841269841, 0.8809523809523809, 0.9990079365079365, 0.9975198412698413, 0.998015873015873, 0.9995039682539683, 0.9990079365079365, 0.5094246031746031, 0.9761904761904762, 1.0, 0.9990079365079365, 0.9990079365079365, 0.9940476190476191, 0.996031746031746, 0.9558531746031746, 0.9990079365079365, 0.9965277777777778, 1.0, 0.9990079365079365, 0.9995039682539683, 0.9910714285714286, 0.8784722222222222, 0.9975198412698413, 0.9985119047619048, 0.9970238095238095, 0.9970238095238095, 0.9905753968253969, 0.998015873015873, 0.9975198412698413, 1.0, 0.9945436507936508, 0.9935515873015873, 0.8125, 0.9985119047619048, 0.9985119047619048, 0.998015873015873, 0.9975198412698413, 0.998015873015873, 0.998015873015873, 0.9990079365079365, 0.9990079365079365, 0.9965277777777778, 0.9990079365079365, 0.9975198412698413, 0.9915674603174603, 0.9330357142857143, 0.9995039682539683, 0.9885912698412699, 0.9995039682539683, 0.9885912698412699, 0.9970238095238095, 0.9995039682539683, 0.9970238095238095, 0.9985119047619048, 0.9985119047619048, 0.9985119047619048, 0.9920634920634921, 0.998015873015873, 0.996031746031746, 0.998015873015873, 0.9975198412698413, 1.0, 0.998015873015873, 0.9930555555555556, 0.996031746031746, 0.9990079365079365, 0.9965277777777778, 0.9995039682539683, 0.9985119047619048, 0.9756944444444444, 0.998015873015873, 0.9995039682539683, 0.9985119047619048, 0.9558531746031746, 0.9970238095238095, 0.9985119047619048, 0.9975198412698413, 0.9970238095238095, 0.9885912698412699, 0.9935515873015873, 0.9985119047619048, 0.9990079365079365, 0.9995039682539683, 0.9910714285714286, 0.9955357142857143, 0.9920634920634921, 0.9975198412698413, 0.9489087301587301, 0.9627976190476191, 0.9995039682539683, 0.9985119047619048, 0.8501984126984127, 0.9880952380952381, 0.9107142857142857, 0.9985119047619048, 0.9990079365079365, 0.9985119047619048, 0.9985119047619048, 0.9970238095238095, 0.9955357142857143, 0.9995039682539683, 0.996031746031746, 0.9990079365079365, 0.9985119047619048, 0.998015873015873, 0.9548611111111112, 1.0, 0.9990079365079365, 0.998015873015873, 0.9975198412698413, 0.9975198412698413, 0.9995039682539683, 0.9995039682539683, 0.9970238095238095, 0.9970238095238095, 0.8115079365079365, 0.9995039682539683

