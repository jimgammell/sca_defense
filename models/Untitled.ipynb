{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79bd00c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "from simple_gan_1d import LeNet5Generator1d, LeNet5Discriminator1d\n",
    "from common import get_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b3bd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen: torch.Size([16, 64]) x torch.Size([16]) x torch.Size([16, 1, 20000]) -> torch.Size([16, 1, 20000])\n",
      "Generator parameters: 636265\n",
      "LeNet5Generator1d(\n",
      "  (feature_encoder): Sequential(\n",
      "    (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): Conv1d(1, 16, kernel_size=(5,), stride=(5,), padding=(2,), bias=False)\n",
      "    (2): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU()\n",
      "    (4): Conv1d(16, 32, kernel_size=(5,), stride=(5,), padding=(2,), bias=False)\n",
      "    (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Conv1d(32, 64, kernel_size=(5,), stride=(5,), padding=(2,))\n",
      "  )\n",
      "  (latent_encoder): Sequential(\n",
      "    (0): Conv1d(64, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv1d(512, 64, kernel_size=(1,), stride=(1,))\n",
      "    (4): ConvTranspose1d(64, 64, kernel_size=(40,), stride=(1,))\n",
      "  )\n",
      "  (label_embedding): Embedding(256, 64)\n",
      "  (label_encoder): Sequential(\n",
      "    (0): Conv1d(64, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv1d(512, 64, kernel_size=(1,), stride=(1,))\n",
      "    (4): ConvTranspose1d(64, 64, kernel_size=(40,), stride=(1,))\n",
      "  )\n",
      "  (output_decoder): Sequential(\n",
      "    (0): Conv1d(192, 512, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv1d(512, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "    (6): ConvTranspose1d(64, 32, kernel_size=(5,), stride=(5,), bias=False)\n",
      "    (7): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU()\n",
      "    (9): ConvTranspose1d(32, 16, kernel_size=(5,), stride=(5,), bias=False)\n",
      "    (10): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU()\n",
      "    (12): ConvTranspose1d(16, 8, kernel_size=(5,), stride=(5,), bias=False)\n",
      "    (13): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU()\n",
      "    (15): Conv1d(8, 1, kernel_size=(1,), stride=(1,))\n",
      "    (16): Upsample(scale_factor=4.0, mode=nearest)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "output_classes = 256\n",
    "latent_dims = 64\n",
    "label_dims = 64\n",
    "feature_dims = 64\n",
    "latent_shape = (batch_size, latent_dims)\n",
    "label_shape = (batch_size,)\n",
    "output_shape = (batch_size, 1, 20000)\n",
    "\n",
    "gen = LeNet5Generator1d(\n",
    "    latent_dims=latent_dims,\n",
    "    label_dims=label_dims,\n",
    "    output_shape=output_shape,\n",
    "    feature_dims=feature_dims,\n",
    "    output_classes=output_classes\n",
    ")\n",
    "\n",
    "eg_latent = torch.randn(latent_shape)\n",
    "eg_label = torch.randint(0, output_classes, label_shape)\n",
    "eg_image = torch.randn(output_shape)\n",
    "eg_output = gen(eg_latent, eg_label, eg_image)\n",
    "print('Gen:', eg_latent.shape, 'x', eg_label.shape, 'x', eg_image.shape, '->', eg_output.shape)\n",
    "print('Generator parameters:', get_param_count(gen))\n",
    "print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31cff9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disc: (16, 1, 20000) -> torch.Size([16, 256])\n",
      "Discriminator param count: 379526\n",
      "LeNet5Discriminator1d(\n",
      "  (output_transform): Identity()\n",
      "  (feature_encoder): Sequential(\n",
      "    (0): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    (1): Conv1d(1, 2, kernel_size=(5,), stride=(3,), bias=False)\n",
      "    (2): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Conv1d(2, 4, kernel_size=(5,), stride=(3,), bias=False)\n",
      "    (5): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): LeakyReLU(negative_slope=0.2)\n",
      "    (7): Conv1d(4, 8, kernel_size=(5,), stride=(3,))\n",
      "    (8): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): LeakyReLU(negative_slope=0.2)\n",
      "    (10): Conv1d(8, 16, kernel_size=(5,), stride=(3,))\n",
      "  )\n",
      "  (mlp_probe): Sequential(\n",
      "    (0): Linear(in_features=960, out_features=256, bias=True)\n",
      "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (4): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): LeakyReLU(negative_slope=0.2)\n",
      "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "disc = LeNet5Discriminator1d(output_shape)\n",
    "\n",
    "eg_input = torch.randn(output_shape)\n",
    "print('Disc:', output_shape, '->', disc(eg_input).shape)\n",
    "print('Discriminator param count:', get_param_count(disc))\n",
    "print(disc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6752c",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "from resnet1d_gan import ResNet1dDiscriminator, ResNet1dGenerator\n",
    "from common import get_param_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28a55ea",
   "metadata": {},
   "source": [
    "input_shape = (64, 1, 20000)\n",
    "filters = 8\n",
    "disc = ResNet1dDiscriminator(input_shape, 8)\n",
    "print(disc)\n",
    "\n",
    "eg_input = torch.randn(input_shape)\n",
    "eg_output = disc(eg_input)\n",
    "print('Input shape:', eg_input.shape, '-> Output shape:', eg_output.shape)\n",
    "print('Param count:', get_param_count(disc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d4f32",
   "metadata": {},
   "source": [
    "label_dims = 256\n",
    "latent_dims = 100\n",
    "output_shape = (64, 1, 20000)\n",
    "\n",
    "gen = ResNet1dGenerator(latent_dims, label_dims, output_shape)\n",
    "print(gen)\n",
    "\n",
    "eg_label = torch.randint(0, 256, (64,))\n",
    "eg_latent = torch.randn(64, latent_dims)\n",
    "eg_trace = torch.randn(64, *output_shape[1:])\n",
    "eg_output = gen(eg_latent, eg_label, eg_trace)\n",
    "print('Label shape:', eg_label.shape.__repr__()+',', 'Latent shape:', eg_latent.shape, '-> Output shape:', eg_output.shape)\n",
    "print('Param count:', get_param_count(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411ae56",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from lenet_gan import LeNet5Gen, LeNet5Disc\n",
    "from common import get_param_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c32d22",
   "metadata": {},
   "source": [
    "input_shape = (64, 1, 28, 28)\n",
    "disc = LeNet5Disc(input_shape)\n",
    "print(disc)\n",
    "print('Disc param count:', get_param_count(disc))\n",
    "\n",
    "eg_input = torch.randn(input_shape)\n",
    "eg_output = disc(eg_input)\n",
    "print('Map dimensions: ({}) -> ({})'.format(eg_input.shape, eg_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7b7c75",
   "metadata": {},
   "source": [
    "latent_dims = 100\n",
    "label_dims = 10\n",
    "feature_dims = 0\n",
    "output_shape = (64, 1, 28, 28)\n",
    "gen = LeNet5Gen(latent_dims, label_dims, feature_dims, output_shape)\n",
    "print(gen)\n",
    "print('Gen param count:', get_param_count(gen))\n",
    "\n",
    "eg_latent = torch.randn((64, latent_dims))\n",
    "eg_label = torch.randint(0, 10, (64,))\n",
    "eg_output = gen(eg_latent, eg_label)\n",
    "print('Map dimensions: ({}) x ({}) -> ({})'.format(eg_latent.shape, eg_label.shape, eg_output.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
