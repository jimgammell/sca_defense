{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc96c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import torch\n",
    "from resnet1d_gan import ResNet1dDiscriminator, ResNet1dGenerator\n",
    "from common import get_param_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32d3a7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet1dDiscriminator(\n",
      "  (output_transform): Identity()\n",
      "  (input_transform): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Stack(\n",
      "      (model): Sequential(\n",
      "        (0): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "          )\n",
      "          (shortcut): Conv1d(1, 64, kernel_size=(1,), stride=(1,))\n",
      "          (residual): Sequential(\n",
      "            (0): Conv1d(1, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.2)\n",
      "            (3): ConstantPad1d(padding=(1, 1), value=0)\n",
      "            (4): Conv1d(16, 16, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.2)\n",
      "            (7): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (1): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (residual): Sequential(\n",
      "            (0): Conv1d(64, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.2)\n",
      "            (3): ConstantPad1d(padding=(1, 1), value=0)\n",
      "            (4): Conv1d(16, 16, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.2)\n",
      "            (7): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (2): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "          )\n",
      "          (shortcut): MaxPool1d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (residual): Sequential(\n",
      "            (0): Conv1d(64, 16, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.2)\n",
      "            (3): ConstantPad1d(padding=(1, 1), value=0)\n",
      "            (4): Conv1d(16, 16, kernel_size=(3,), stride=(2,), bias=False)\n",
      "            (5): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.2)\n",
      "            (7): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Stack(\n",
      "      (model): Sequential(\n",
      "        (0): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "          )\n",
      "          (shortcut): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "          (residual): Sequential(\n",
      "            (0): Conv1d(64, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.2)\n",
      "            (3): ConstantPad1d(padding=(1, 1), value=0)\n",
      "            (4): Conv1d(32, 32, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.2)\n",
      "            (7): Conv1d(32, 128, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (1): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (residual): Sequential(\n",
      "            (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.2)\n",
      "            (3): ConstantPad1d(padding=(1, 1), value=0)\n",
      "            (4): Conv1d(32, 32, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.2)\n",
      "            (7): Conv1d(32, 128, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (2): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (residual): Sequential(\n",
      "            (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.2)\n",
      "            (3): ConstantPad1d(padding=(1, 1), value=0)\n",
      "            (4): Conv1d(32, 32, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.2)\n",
      "            (7): Conv1d(32, 128, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (3): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "          )\n",
      "          (shortcut): MaxPool1d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (residual): Sequential(\n",
      "            (0): Conv1d(128, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.2)\n",
      "            (3): ConstantPad1d(padding=(1, 1), value=0)\n",
      "            (4): Conv1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "            (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.2)\n",
      "            (7): Conv1d(32, 128, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Stack(\n",
      "      (model): Sequential(\n",
      "        (0): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "          )\n",
      "          (shortcut): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
      "          (residual): Sequential(\n",
      "            (0): Conv1d(128, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.2)\n",
      "            (3): ConstantPad1d(padding=(1, 1), value=0)\n",
      "            (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.2)\n",
      "            (7): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (1): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (residual): Sequential(\n",
      "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.2)\n",
      "            (3): ConstantPad1d(padding=(1, 1), value=0)\n",
      "            (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.2)\n",
      "            (7): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (2): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (residual): Sequential(\n",
      "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.2)\n",
      "            (3): ConstantPad1d(padding=(1, 1), value=0)\n",
      "            (4): Conv1d(64, 64, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.2)\n",
      "            (7): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (3): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "          )\n",
      "          (shortcut): MaxPool1d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (residual): Sequential(\n",
      "            (0): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.2)\n",
      "            (3): ConstantPad1d(padding=(1, 1), value=0)\n",
      "            (4): Conv1d(64, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "            (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.2)\n",
      "            (7): Conv1d(64, 256, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Stack(\n",
      "      (model): Sequential(\n",
      "        (0): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "          )\n",
      "          (shortcut): Conv1d(256, 512, kernel_size=(1,), stride=(1,))\n",
      "          (residual): Sequential(\n",
      "            (0): Conv1d(256, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.2)\n",
      "            (3): ConstantPad1d(padding=(1, 1), value=0)\n",
      "            (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.2)\n",
      "            (7): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (1): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "          )\n",
      "          (shortcut): Identity()\n",
      "          (residual): Sequential(\n",
      "            (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.2)\n",
      "            (3): ConstantPad1d(padding=(1, 1), value=0)\n",
      "            (4): Conv1d(128, 128, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.2)\n",
      "            (7): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (2): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): LeakyReLU(negative_slope=0.2)\n",
      "          )\n",
      "          (shortcut): MaxPool1d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "          (residual): Sequential(\n",
      "            (0): Conv1d(512, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): LeakyReLU(negative_slope=0.2)\n",
      "            (3): ConstantPad1d(padding=(1, 1), value=0)\n",
      "            (4): Conv1d(128, 128, kernel_size=(3,), stride=(2,), bias=False)\n",
      "            (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): LeakyReLU(negative_slope=0.2)\n",
      "            (7): Conv1d(128, 512, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pooling_layer): AvgPool1d(kernel_size=(157,), stride=(157,), padding=(0,))\n",
      "  (dense_probe): Sequential(\n",
      "    (0): Dropout(p=0.1, inplace=False)\n",
      "    (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): LeakyReLU(negative_slope=0.2)\n",
      "    (4): Linear(in_features=256, out_features=256, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([64, 1, 20000]) -> Output shape: torch.Size([64, 256])\n",
      "Param count: 1113106\n"
     ]
    }
   ],
   "source": [
    "input_shape = (64, 1, 20000)\n",
    "filters = 8\n",
    "disc = ResNet1dDiscriminator(input_shape, 8)\n",
    "print(disc)\n",
    "\n",
    "eg_input = torch.randn(input_shape)\n",
    "eg_output = disc(eg_input)\n",
    "print('Input shape:', eg_input.shape, '-> Output shape:', eg_output.shape)\n",
    "print('Param count:', get_param_count(disc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bf942e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet1dGenerator(\n",
      "  (output_transform): Hardtanh(min_val=-1.0, max_val=1.0)\n",
      "  (feature_encoder): FeatureEncoder(\n",
      "    (input_downsampler): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "    (output_transform): Sequential(\n",
      "      (0): Conv1d(128, 100, kernel_size=(1,), stride=(1,))\n",
      "      (1): AvgPool1d(kernel_size=(157,), stride=(157,), padding=(0,))\n",
      "    )\n",
      "  )\n",
      "  (label_embedding): Embedding(256, 256)\n",
      "  (input_upscaling): Sequential(\n",
      "    (0): ConvTranspose1d(456, 456, kernel_size=(1,), stride=(1,), bias=False)\n",
      "    (1): BatchNorm1d(456, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): ConvTranspose1d(456, 456, kernel_size=(10,), stride=(1,))\n",
      "    (4): Upsample(scale_factor=125.0, mode=nearest)\n",
      "    (5): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (feature_creator): Sequential(\n",
      "    (0): Stack(\n",
      "      (model): Sequential(\n",
      "        (0): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(456, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "          (shortcut): Sequential(\n",
      "            (0): ConvTranspose1d(456, 64, kernel_size=(1,), stride=(1,))\n",
      "            (1): ConstantPad1d(padding=(0, 0), value=0)\n",
      "          )\n",
      "          (residual): Sequential(\n",
      "            (0): ConvTranspose1d(456, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): ConvTranspose1d(256, 256, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (4): ConstantPad1d(padding=(0, 0), value=0)\n",
      "            (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): ReLU()\n",
      "            (7): ConvTranspose1d(256, 64, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (1): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "          (shortcut): Sequential(\n",
      "            (0): ConvTranspose1d(64, 64, kernel_size=(1,), stride=(1,))\n",
      "            (1): ConstantPad1d(padding=(0, 0), value=0)\n",
      "          )\n",
      "          (residual): Sequential(\n",
      "            (0): ConvTranspose1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): ConvTranspose1d(256, 256, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (4): ConstantPad1d(padding=(0, 0), value=0)\n",
      "            (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): ReLU()\n",
      "            (7): ConvTranspose1d(256, 64, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (2): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "          (shortcut): Sequential(\n",
      "            (0): ConvTranspose1d(64, 64, kernel_size=(1,), stride=(2,))\n",
      "            (1): ConstantPad1d(padding=(0, 1), value=0)\n",
      "          )\n",
      "          (residual): Sequential(\n",
      "            (0): ConvTranspose1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): ConvTranspose1d(256, 256, kernel_size=(3,), stride=(2,), bias=False)\n",
      "            (4): ConstantPad1d(padding=(0, 1), value=0)\n",
      "            (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): ReLU()\n",
      "            (7): ConvTranspose1d(256, 64, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Stack(\n",
      "      (model): Sequential(\n",
      "        (0): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "          (shortcut): Sequential(\n",
      "            (0): ConvTranspose1d(64, 32, kernel_size=(1,), stride=(1,))\n",
      "            (1): ConstantPad1d(padding=(0, 0), value=0)\n",
      "          )\n",
      "          (residual): Sequential(\n",
      "            (0): ConvTranspose1d(64, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): ConvTranspose1d(128, 128, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (4): ConstantPad1d(padding=(0, 0), value=0)\n",
      "            (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): ReLU()\n",
      "            (7): ConvTranspose1d(128, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (1): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "          (shortcut): Sequential(\n",
      "            (0): ConvTranspose1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "            (1): ConstantPad1d(padding=(0, 0), value=0)\n",
      "          )\n",
      "          (residual): Sequential(\n",
      "            (0): ConvTranspose1d(32, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): ConvTranspose1d(128, 128, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (4): ConstantPad1d(padding=(0, 0), value=0)\n",
      "            (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): ReLU()\n",
      "            (7): ConvTranspose1d(128, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (2): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "          (shortcut): Sequential(\n",
      "            (0): ConvTranspose1d(32, 32, kernel_size=(1,), stride=(1,))\n",
      "            (1): ConstantPad1d(padding=(0, 0), value=0)\n",
      "          )\n",
      "          (residual): Sequential(\n",
      "            (0): ConvTranspose1d(32, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): ConvTranspose1d(128, 128, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (4): ConstantPad1d(padding=(0, 0), value=0)\n",
      "            (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): ReLU()\n",
      "            (7): ConvTranspose1d(128, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (3): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "          (shortcut): Sequential(\n",
      "            (0): ConvTranspose1d(32, 32, kernel_size=(1,), stride=(2,))\n",
      "            (1): ConstantPad1d(padding=(0, 1), value=0)\n",
      "          )\n",
      "          (residual): Sequential(\n",
      "            (0): ConvTranspose1d(32, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): ConvTranspose1d(128, 128, kernel_size=(3,), stride=(2,), bias=False)\n",
      "            (4): ConstantPad1d(padding=(0, 1), value=0)\n",
      "            (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): ReLU()\n",
      "            (7): ConvTranspose1d(128, 32, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Stack(\n",
      "      (model): Sequential(\n",
      "        (0): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "          (shortcut): Sequential(\n",
      "            (0): ConvTranspose1d(32, 16, kernel_size=(1,), stride=(1,))\n",
      "            (1): ConstantPad1d(padding=(0, 0), value=0)\n",
      "          )\n",
      "          (residual): Sequential(\n",
      "            (0): ConvTranspose1d(32, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): ConvTranspose1d(64, 64, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (4): ConstantPad1d(padding=(0, 0), value=0)\n",
      "            (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): ReLU()\n",
      "            (7): ConvTranspose1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (1): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "          (shortcut): Sequential(\n",
      "            (0): ConvTranspose1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "            (1): ConstantPad1d(padding=(0, 0), value=0)\n",
      "          )\n",
      "          (residual): Sequential(\n",
      "            (0): ConvTranspose1d(16, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): ConvTranspose1d(64, 64, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (4): ConstantPad1d(padding=(0, 0), value=0)\n",
      "            (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): ReLU()\n",
      "            (7): ConvTranspose1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (2): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "          (shortcut): Sequential(\n",
      "            (0): ConvTranspose1d(16, 16, kernel_size=(1,), stride=(1,))\n",
      "            (1): ConstantPad1d(padding=(0, 0), value=0)\n",
      "          )\n",
      "          (residual): Sequential(\n",
      "            (0): ConvTranspose1d(16, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): ConvTranspose1d(64, 64, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (4): ConstantPad1d(padding=(0, 0), value=0)\n",
      "            (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): ReLU()\n",
      "            (7): ConvTranspose1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (3): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "          (shortcut): Sequential(\n",
      "            (0): ConvTranspose1d(16, 16, kernel_size=(1,), stride=(2,))\n",
      "            (1): ConstantPad1d(padding=(0, 1), value=0)\n",
      "          )\n",
      "          (residual): Sequential(\n",
      "            (0): ConvTranspose1d(16, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): ConvTranspose1d(64, 64, kernel_size=(3,), stride=(2,), bias=False)\n",
      "            (4): ConstantPad1d(padding=(0, 1), value=0)\n",
      "            (5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): ReLU()\n",
      "            (7): ConvTranspose1d(64, 16, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Stack(\n",
      "      (model): Sequential(\n",
      "        (0): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "          (shortcut): Sequential(\n",
      "            (0): ConvTranspose1d(16, 8, kernel_size=(1,), stride=(1,))\n",
      "            (1): ConstantPad1d(padding=(0, 0), value=0)\n",
      "          )\n",
      "          (residual): Sequential(\n",
      "            (0): ConvTranspose1d(16, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): ConvTranspose1d(32, 32, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (4): ConstantPad1d(padding=(0, 0), value=0)\n",
      "            (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): ReLU()\n",
      "            (7): ConvTranspose1d(32, 8, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (1): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "          (shortcut): Sequential(\n",
      "            (0): ConvTranspose1d(8, 8, kernel_size=(1,), stride=(1,))\n",
      "            (1): ConstantPad1d(padding=(0, 0), value=0)\n",
      "          )\n",
      "          (residual): Sequential(\n",
      "            (0): ConvTranspose1d(8, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): ConvTranspose1d(32, 32, kernel_size=(3,), stride=(1,), bias=False)\n",
      "            (4): ConstantPad1d(padding=(0, 0), value=0)\n",
      "            (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): ReLU()\n",
      "            (7): ConvTranspose1d(32, 8, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "        (2): Block(\n",
      "          (input_transform): Sequential(\n",
      "            (0): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (1): ReLU()\n",
      "          )\n",
      "          (shortcut): Sequential(\n",
      "            (0): ConvTranspose1d(8, 8, kernel_size=(1,), stride=(2,))\n",
      "            (1): ConstantPad1d(padding=(0, 1), value=0)\n",
      "          )\n",
      "          (residual): Sequential(\n",
      "            (0): ConvTranspose1d(8, 32, kernel_size=(1,), stride=(1,), bias=False)\n",
      "            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "            (3): ConvTranspose1d(32, 32, kernel_size=(3,), stride=(2,), bias=False)\n",
      "            (4): ConstantPad1d(padding=(0, 1), value=0)\n",
      "            (5): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (6): ReLU()\n",
      "            (7): ConvTranspose1d(32, 8, kernel_size=(1,), stride=(1,))\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): ConvTranspose1d(8, 1, kernel_size=(1,), stride=(1,))\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label shape: torch.Size([64]), Latent shape: torch.Size([64, 100]) -> Output shape: torch.Size([64, 1, 20000])\n",
      "Param count: 3511525\n"
     ]
    }
   ],
   "source": [
    "label_dims = 256\n",
    "latent_dims = 100\n",
    "output_shape = (64, 1, 20000)\n",
    "\n",
    "gen = ResNet1dGenerator(latent_dims, label_dims, output_shape)\n",
    "print(gen)\n",
    "\n",
    "eg_label = torch.randint(0, 256, (64,))\n",
    "eg_latent = torch.randn(64, latent_dims)\n",
    "eg_trace = torch.randn(64, *output_shape[1:])\n",
    "eg_output = gen(eg_latent, eg_label, eg_trace)\n",
    "print('Label shape:', eg_label.shape.__repr__()+',', 'Latent shape:', eg_latent.shape, '-> Output shape:', eg_output.shape)\n",
    "print('Param count:', get_param_count(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411ae56",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from lenet_gan import LeNet5Gen, LeNet5Disc\n",
    "from common import get_param_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c32d22",
   "metadata": {},
   "source": [
    "input_shape = (64, 1, 28, 28)\n",
    "disc = LeNet5Disc(input_shape)\n",
    "print(disc)\n",
    "print('Disc param count:', get_param_count(disc))\n",
    "\n",
    "eg_input = torch.randn(input_shape)\n",
    "eg_output = disc(eg_input)\n",
    "print('Map dimensions: ({}) -> ({})'.format(eg_input.shape, eg_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7b7c75",
   "metadata": {},
   "source": [
    "latent_dims = 100\n",
    "label_dims = 10\n",
    "feature_dims = 0\n",
    "output_shape = (64, 1, 28, 28)\n",
    "gen = LeNet5Gen(latent_dims, label_dims, feature_dims, output_shape)\n",
    "print(gen)\n",
    "print('Gen param count:', get_param_count(gen))\n",
    "\n",
    "eg_latent = torch.randn((64, latent_dims))\n",
    "eg_label = torch.randint(0, 10, (64,))\n",
    "eg_output = gen(eg_latent, eg_label)\n",
    "print('Map dimensions: ({}) x ({}) -> ({})'.format(eg_latent.shape, eg_label.shape, eg_output.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
