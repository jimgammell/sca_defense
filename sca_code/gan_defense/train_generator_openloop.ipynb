{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f66e655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "(32, 20000)\n",
      "(32, 8)\n",
      "(32, 256)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def int_to_ohbinary(y_int):\n",
    "    y = [np.zeros((1, 8)) for _ in range(len(y_int))]\n",
    "    for (idx, yy) in enumerate(y_int):\n",
    "        bit = -1\n",
    "        base = 256\n",
    "        while base > 1:\n",
    "            base /= 2\n",
    "            bit += 1\n",
    "            if yy >= base:\n",
    "                yy -= base\n",
    "                y[idx][0, bit] = 1.0\n",
    "            else:\n",
    "                y[idx][0, bit] = 0.0\n",
    "        assert yy == 0\n",
    "    y = [tf.convert_to_tensor(yy, dtype='float32') for yy in y]\n",
    "    y = tf.stack(y, axis=0)\n",
    "    return y\n",
    "\n",
    "n_traces = 16\n",
    "base_path = os.path.join(os.getcwd(), 'datasets', 'tinyaes', 'train')\n",
    "files = [f for f in os.listdir(base_path)\n",
    "         if os.path.isfile(os.path.join(base_path, f))]\n",
    "\n",
    "X, Y = [], []\n",
    "for (idx, f) in enumerate(files[0:2]):\n",
    "    print(idx)\n",
    "    shard = np.load(os.path.join(base_path, f))\n",
    "    x = shard['traces'][:n_traces, :20000, :]\n",
    "    x = tf.convert_to_tensor(x, dtype='float32')\n",
    "    y_int = shard['sub_bytes_in'][0][:n_traces]\n",
    "    y = int_to_ohbinary(y_int)\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "traces = tf.concat(X, axis=0)\n",
    "traces = tf.squeeze(traces)\n",
    "keys = tf.concat(Y, axis=0)\n",
    "keys = tf.squeeze(keys)\n",
    "targets = tf.ones((len(keys), 256))/256\n",
    "targets = tf.squeeze(targets)\n",
    "print(traces.shape)\n",
    "print(keys.shape)\n",
    "print(targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adb72f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 10:30:26.051536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-19 10:30:30.625392: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-19 10:30:30.627976: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-19 10:30:30.679506: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 10:30:30.680063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 6GB computeCapability: 6.1\n",
      "coreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-01-19 10:30:30.680097: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-19 10:30:30.685803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-19 10:30:30.685894: I tensorflow/stream_executo"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8, 1)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose (Conv1DTranspo (None, 32, 8)        32          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 8)        32          conv1d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 32, 8)        0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTrans (None, 128, 8)       200         re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 8)       32          conv1d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 128, 8)       0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_2 (Conv1DTrans (None, 512, 8)       200         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512, 8)       32          conv1d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 512, 8)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512, 20000)   180000      re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid (TFOpLambda)    (None, 512, 20000)   0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 512, 20000)   0           tf.math.sigmoid[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 512, 20000)   0           tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 20000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 512, 20000)   0           tf.__operators__.add[0][0]       \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 512, 20000)   0           add[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 180,528\n",
      "Trainable params: 180,480\n",
      "Non-trainable params: 48\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "r/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-19 10:30:30.689699: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-19 10:30:30.691225: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-19 10:30:30.696033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-19 10:30:30.699103: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-19 10:30:30.707803: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-19 10:30:30.708030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 10:30:30.708760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 10:30:30.709316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-19 10:30:30.710512: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-19 10:30:30.712439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 10:30:30.713046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 6GB computeCapability: 6.1\n",
      "coreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-01-19 10:30:30.713088: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-19 10:30:30.713128: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-19 10:30:30.713158: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-19 10:30:30.713186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-19 10:30:30.713214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-19 10:30:30.713243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-19 10:30:30.713272: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-19 10:30:30.713301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-19 10:30:30.713412: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 10:30:30.714057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 10:30:30.714606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-19 10:30:30.714659: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-19 10:30:31.075237: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-19 10:30:31.075262: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-01-19 10:30:31.075267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-01-19 10:30:31.075413: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 10:30:31.075687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 10:30:31.075935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 10:30:31.076158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4784 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2022-01-19 10:30:31.076364: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    }
   ],
   "source": [
    "from generator import CnnTransposeGenerator\n",
    "\n",
    "generator = CnnTransposeGenerator(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0fa0343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-19 11:12:50.635637: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-19 11:12:55.675715: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-01-19 11:12:55.676891: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-01-19 11:12:55.723385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 11:12:55.723870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 6GB computeCapability: 6.1\n",
      "coreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-01-19 11:12:55.723899: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-19 11:12:55.729072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-19 11:12:55.729151: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-19 11:12:55.732682: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-19 11:12:55.734085: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-19 11:12:55.737900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-19 11:12:55.740479: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-19 11:12:55.747547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-19 11:12:55.747725: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 11:12:55.748329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 11:12:55.748788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-19 11:12:55.749300: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-19 11:12:55.750511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 11:12:55.751028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: NVIDIA GeForce GTX 1060 6GB computeCapability: 6.1\n",
      "coreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2022-01-19 11:12:55.751064: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-19 11:12:55.751095: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-01-19 11:12:55.751119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-01-19 11:12:55.751141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-01-19 11:12:55.751164: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-01-19 11:12:55.751187: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-01-19 11:12:55.751211: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-01-19 11:12:55.751234: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-01-19 11:12:55.751326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 11:12:55.751858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 11:12:55.752311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-01-19 11:12:55.752364: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-01-19 11:12:56.116388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-01-19 11:12:56.116412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-01-19 11:12:56.116418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-01-19 11:12:56.116574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 11:12:56.116862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 11:12:56.117105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-19 11:12:56.117329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4784 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2022-01-19 11:12:56.117599: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          4608        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 512)          4608        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 512)          0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          4608        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 100)          51300       re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 100)          51300       re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid_1 (TFOpLambda)  (None, 100)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 20000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid_2 (TFOpLambda)  (None, 100)          0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          51300       re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 100)          0           tf.math.sigmoid_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_3 (RepeatVector)  (None, 100, 20000)   0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_2 (TFOpLambda) (None, 100)          0           tf.math.sigmoid_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid (TFOpLambda)    (None, 100)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 20000, 100)   0           tf.math.multiply_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambd None                 0           repeat_vector_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 100)          0           tf.math.multiply_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 100)          0           tf.math.sigmoid[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_3 (TFOpLambda) None                 0           repeat_vector_1[0][0]            \n",
      "                                                                 tf.compat.v1.squeeze[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_2 (RepeatVector)  (None, 20000, 100)   0           tf.math.subtract[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 100)          0           tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam None                 0           tf.math.multiply_3[0][0]         \n",
      "                                                                 repeat_vector_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector (RepeatVector)    (None, 20000, 100)   0           tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 None                 0           tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_4 (TFOpLambda) None                 0           repeat_vector[0][0]              \n",
      "                                                                 lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) None                 0           tf.math.multiply_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 20000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_5 (TFOpLambda) None                 0           tf.math.reduce_sum[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 167,724\n",
      "Trainable params: 167,724\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_keras_history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24536/1893010983.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFourierGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0mThis\u001b[0m \u001b[0menables\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mline\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mplots\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnotebooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m   \"\"\"\n\u001b[0;32m--> 324\u001b[0;31m   dot = model_to_dot(\n\u001b[0m\u001b[1;32m    325\u001b[0m       \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m       \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0mnode_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_ib-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mnode_key\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minbound_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minbound_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m           \u001b[0minbound_layer_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minbound_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexpand_nested\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/node.py\u001b[0m in \u001b[0;36minbound_layers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\n\u001b[0m\u001b[1;32m    262\u001b[0m                                         self.call_args[0])\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/node.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     inbound_layers = nest.map_structure(lambda t: t._keras_history.layer,\n\u001b[0m\u001b[1;32m    262\u001b[0m                                         self.call_args[0])\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minbound_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_keras_history'"
     ]
    }
   ],
   "source": [
    "from generator import FourierGenerator\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "generator = FourierGenerator(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c338a5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading discriminator...\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 20000, 1)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 5000, 1)      0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 5000, 1)      4           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 5000, 1)      0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 5000, 16)     16          activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 5000, 16)     64          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 5000, 16)     0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 5000, 16)     768         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 5000, 16)     64          conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 5000, 16)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 5000, 64)     128         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 5000, 64)     1088        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 5000, 64)     0           conv1d[0][0]                     \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 5000, 64)     256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 5000, 64)     0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 5000, 16)     1024        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 5000, 16)     64          conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 5000, 16)     0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 5000, 16)     768         activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 5000, 16)     64          conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 5000, 16)     0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 5000, 64)     1088        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 5000, 64)     0           activation_3[0][0]               \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 5000, 64)     256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 5000, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 5000, 16)     1024        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 5000, 16)     64          conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 5000, 16)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 2500, 16)     768         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 2500, 16)     64          conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 2500, 16)     0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 2500, 64)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 2500, 64)     1088        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 2500, 64)     0           max_pooling1d_1[0][0]            \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 2500, 64)     256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 2500, 64)     0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 2500, 32)     2048        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 2500, 32)     128         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 2500, 32)     0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 2500, 32)     3072        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 2500, 32)     128         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 2500, 32)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 2500, 128)    8320        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 2500, 128)    4224        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 2500, 128)    0           conv1d_10[0][0]                  \n",
      "                                                                 conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 2500, 128)    512         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 2500, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 2500, 32)     4096        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 2500, 32)     128         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 2500, 32)     0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 2500, 32)     3072        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 2500, 32)     128         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 2500, 32)     0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 2500, 128)    4224        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 2500, 128)    0           activation_12[0][0]              \n",
      "                                                                 conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 2500, 128)    512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 2500, 128)    0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 2500, 32)     4096        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 2500, 32)     128         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 2500, 32)     0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 2500, 32)     3072        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 2500, 32)     128         conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 2500, 32)     0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 2500, 128)    4224        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 2500, 128)    0           activation_15[0][0]              \n",
      "                                                                 conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 2500, 128)    512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 2500, 128)    0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 2500, 32)     4096        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 2500, 32)     128         conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 2500, 32)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 1250, 32)     3072        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 1250, 32)     128         conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1250, 32)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 1250, 128)    0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 1250, 128)    4224        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 1250, 128)    0           max_pooling1d_2[0][0]            \n",
      "                                                                 conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 1250, 128)    512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 1250, 128)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 1250, 64)     8192        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 1250, 64)     256         conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 1250, 64)     0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1250, 64)     12288       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 1250, 64)     256         conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 1250, 64)     0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 1250, 256)    33024       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 1250, 256)    16640       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 1250, 256)    0           conv1d_23[0][0]                  \n",
      "                                                                 conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1250, 256)    1024        add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 1250, 256)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1250, 64)     16384       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 1250, 64)     256         conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 1250, 64)     0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 1250, 64)     12288       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 1250, 64)     256         conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 1250, 64)     0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 1250, 256)    16640       activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 1250, 256)    0           activation_24[0][0]              \n",
      "                                                                 conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1250, 256)    1024        add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 1250, 256)    0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 1250, 64)     16384       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 1250, 64)     256         conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 1250, 64)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 1250, 64)     12288       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 1250, 64)     256         conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 1250, 64)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 1250, 256)    16640       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 1250, 256)    0           activation_27[0][0]              \n",
      "                                                                 conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 1250, 256)    1024        add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 1250, 256)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 1250, 64)     16384       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 1250, 64)     256         conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 1250, 64)     0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 625, 64)      12288       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 625, 64)      256         conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 625, 64)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 625, 256)     0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 625, 256)     16640       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 625, 256)     0           max_pooling1d_3[0][0]            \n",
      "                                                                 conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 625, 256)     1024        add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 625, 256)     0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 625, 128)     32768       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 625, 128)     512         conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 625, 128)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 625, 128)     49152       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 625, 128)     512         conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 625, 128)     0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 625, 512)     131584      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 625, 512)     66048       activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 625, 512)     0           conv1d_36[0][0]                  \n",
      "                                                                 conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 625, 512)     2048        add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 625, 512)     0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 625, 128)     65536       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 625, 128)     512         conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 625, 128)     0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 625, 128)     49152       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 625, 128)     512         conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 625, 128)     0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 625, 512)     66048       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 625, 512)     0           activation_36[0][0]              \n",
      "                                                                 conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 625, 512)     2048        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 625, 512)     0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 625, 128)     65536       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 625, 128)     512         conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 625, 128)     0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 313, 128)     49152       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 313, 128)     512         conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 313, 128)     0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 313, 512)     0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 313, 512)     66048       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 313, 512)     0           max_pooling1d_4[0][0]            \n",
      "                                                                 conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 512)          0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 256)          131328      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 256)          1024        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 256)          0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       activation_42[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,122,388\n",
      "Trainable params: 1,113,106\n",
      "Non-trainable params: 9,282\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Loading generator...\n",
      "Model: \"Generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 20000)        180000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.sigmoid (TFOpLambda)    (None, 20000)        0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply (TFOpLambda)   (None, 20000)        0           tf.math.sigmoid[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 20000)        0           tf.math.multiply[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 20000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 20000)        0           tf.__operators__.add[0][0]       \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.multiply_1 (TFOpLambda) (None, 20000)        0           add[0][0]                        \n",
      "==================================================================================================\n",
      "Total params: 180,000\n",
      "Trainable params: 180,000\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Loading full model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 20000)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Generator (Functional)          (None, 20000)        180000      input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 256)          1122388     Generator[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,302,388\n",
      "Trainable params: 180,000\n",
      "Non-trainable params: 1,122,388\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from discriminator import PretrainedDiscriminator\n",
    "from generator import LinearGenerator\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "print('Loading discriminator...')\n",
    "discriminator = PretrainedDiscriminator(0, 'sub_bytes_in')\n",
    "discriminator.trainable = False\n",
    "print('\\n\\n\\n')\n",
    "print('Loading generator...')\n",
    "generator = LinearGenerator(-1, 1)\n",
    "\n",
    "def cumulative_model():\n",
    "    ap_inp = layers.Input(shape=(8,))\n",
    "    trace_inp = layers.Input(shape=(20000,))\n",
    "    ap = ap_inp\n",
    "    trace = trace_inp\n",
    "    \n",
    "    visible_trace = generator([ap, trace])\n",
    "    softmax_prediction = discriminator(visible_trace)\n",
    "    \n",
    "    cumulative_model = Model(inputs=[ap_inp, trace_inp], outputs=softmax_prediction)\n",
    "    return cumulative_model\n",
    "\n",
    "print('\\n\\n\\n')\n",
    "print('Loading full model...')\n",
    "mdl = cumulative_model()\n",
    "mdl.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edd5dd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "128/128 [==============================] - 30s 202ms/step - loss: 6.3435\n",
      "Epoch 2/100\n",
      "128/128 [==============================] - 26s 202ms/step - loss: 5.9643\n",
      "Epoch 3/100\n",
      "128/128 [==============================] - 26s 202ms/step - loss: 5.8682\n",
      "Epoch 4/100\n",
      "128/128 [==============================] - 26s 202ms/step - loss: 5.8200\n",
      "Epoch 5/100\n",
      "128/128 [==============================] - 26s 203ms/step - loss: 5.7944\n",
      "Epoch 6/100\n",
      "128/128 [==============================] - 26s 202ms/step - loss: 5.7657\n",
      "Epoch 7/100\n",
      "128/128 [==============================] - 26s 204ms/step - loss: 5.7498\n",
      "Epoch 8/100\n",
      "128/128 [==============================] - 26s 204ms/step - loss: 5.7413\n",
      "Epoch 9/100\n",
      "128/128 [==============================] - 26s 205ms/step - loss: 5.7294\n",
      "Epoch 10/100\n",
      "128/128 [==============================] - 26s 204ms/step - loss: 5.7229\n",
      "Epoch 11/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.7152\n",
      "Epoch 12/100\n",
      "128/128 [==============================] - 26s 205ms/step - loss: 5.7093\n",
      "Epoch 13/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.7057\n",
      "Epoch 14/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6997\n",
      "Epoch 15/100\n",
      "128/128 [==============================] - 26s 205ms/step - loss: 5.6966\n",
      "Epoch 16/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6942\n",
      "Epoch 17/100\n",
      "128/128 [==============================] - 26s 205ms/step - loss: 5.6902\n",
      "Epoch 18/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6876\n",
      "Epoch 19/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6865\n",
      "Epoch 20/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6817\n",
      "Epoch 21/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6815\n",
      "Epoch 22/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6787\n",
      "Epoch 23/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6774\n",
      "Epoch 24/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6737\n",
      "Epoch 25/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6720\n",
      "Epoch 26/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6710\n",
      "Epoch 27/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6722\n",
      "Epoch 28/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6671\n",
      "Epoch 29/100\n",
      "128/128 [==============================] - 27s 207ms/step - loss: 5.6660\n",
      "Epoch 30/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6663\n",
      "Epoch 31/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6635\n",
      "Epoch 32/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6632\n",
      "Epoch 33/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6612\n",
      "Epoch 34/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6603\n",
      "Epoch 35/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6600\n",
      "Epoch 36/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6578\n",
      "Epoch 37/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6564\n",
      "Epoch 38/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6570\n",
      "Epoch 39/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6555\n",
      "Epoch 40/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6547\n",
      "Epoch 41/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6545\n",
      "Epoch 42/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6531\n",
      "Epoch 43/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6514\n",
      "Epoch 44/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6511\n",
      "Epoch 45/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6505\n",
      "Epoch 46/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6516\n",
      "Epoch 47/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6500\n",
      "Epoch 48/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6485\n",
      "Epoch 49/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6489\n",
      "Epoch 50/100\n",
      "128/128 [==============================] - 27s 207ms/step - loss: 5.6482\n",
      "Epoch 51/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6464\n",
      "Epoch 52/100\n",
      "128/128 [==============================] - 27s 207ms/step - loss: 5.6464\n",
      "Epoch 53/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6451\n",
      "Epoch 54/100\n",
      "128/128 [==============================] - 27s 208ms/step - loss: 5.6461\n",
      "Epoch 55/100\n",
      "128/128 [==============================] - 27s 207ms/step - loss: 5.6453\n",
      "Epoch 56/100\n",
      "128/128 [==============================] - 27s 207ms/step - loss: 5.6431\n",
      "Epoch 57/100\n",
      "128/128 [==============================] - 27s 208ms/step - loss: 5.6436\n",
      "Epoch 58/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6412\n",
      "Epoch 59/100\n",
      "128/128 [==============================] - 27s 208ms/step - loss: 5.6422\n",
      "Epoch 60/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6408\n",
      "Epoch 61/100\n",
      "128/128 [==============================] - 27s 208ms/step - loss: 5.6415\n",
      "Epoch 62/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6409\n",
      "Epoch 63/100\n",
      "128/128 [==============================] - 27s 208ms/step - loss: 5.6407\n",
      "Epoch 64/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6402\n",
      "Epoch 65/100\n",
      "128/128 [==============================] - 27s 207ms/step - loss: 5.6387\n",
      "Epoch 66/100\n",
      "128/128 [==============================] - 27s 208ms/step - loss: 5.6384\n",
      "Epoch 67/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6392\n",
      "Epoch 68/100\n",
      "128/128 [==============================] - 27s 208ms/step - loss: 5.6389\n",
      "Epoch 69/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6383\n",
      "Epoch 70/100\n",
      "128/128 [==============================] - 27s 208ms/step - loss: 5.6385\n",
      "Epoch 71/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6374\n",
      "Epoch 72/100\n",
      "128/128 [==============================] - 27s 208ms/step - loss: 5.6374\n",
      "Epoch 73/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6365\n",
      "Epoch 74/100\n",
      "128/128 [==============================] - 27s 207ms/step - loss: 5.6366\n",
      "Epoch 75/100\n",
      "128/128 [==============================] - 27s 207ms/step - loss: 5.6366\n",
      "Epoch 76/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6348\n",
      "Epoch 77/100\n",
      "128/128 [==============================] - 27s 207ms/step - loss: 5.6333\n",
      "Epoch 78/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6347\n",
      "Epoch 79/100\n",
      "128/128 [==============================] - 27s 208ms/step - loss: 5.6339\n",
      "Epoch 80/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6347\n",
      "Epoch 81/100\n",
      "128/128 [==============================] - 27s 207ms/step - loss: 5.6352\n",
      "Epoch 82/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6353\n",
      "Epoch 83/100\n",
      "128/128 [==============================] - 27s 207ms/step - loss: 5.6333\n",
      "Epoch 84/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6342\n",
      "Epoch 85/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6326\n",
      "Epoch 86/100\n",
      "128/128 [==============================] - 27s 207ms/step - loss: 5.6334\n",
      "Epoch 87/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6331\n",
      "Epoch 88/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6325\n",
      "Epoch 89/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6325\n",
      "Epoch 90/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6328\n",
      "Epoch 91/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6319\n",
      "Epoch 92/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6310\n",
      "Epoch 93/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6317\n",
      "Epoch 94/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6309\n",
      "Epoch 95/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6305\n",
      "Epoch 96/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6295\n",
      "Epoch 97/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6299\n",
      "Epoch 98/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6289\n",
      "Epoch 99/100\n",
      "128/128 [==============================] - 26s 207ms/step - loss: 5.6302\n",
      "Epoch 100/100\n",
      "128/128 [==============================] - 26s 206ms/step - loss: 5.6284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fee7182adf0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "mdl.compile(loss=CategoricalCrossentropy())\n",
    "history = mdl.fit([keys, traces], targets, shuffle=True, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1658bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9886810d34a1449d912dae953cab73d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recovering bytes:   0%|          | 0/256 [00:00<?, ?shards/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history['loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "from tensorflow.keras import metrics\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from scaaml.aes import ap_preds_to_key_preds\n",
    "from scaaml.plot import plot_trace, plot_confusion_matrix\n",
    "from scaaml.utils import tf_cap_memory, from_categorical\n",
    "from scaaml.model import get_models_by_attack_point, get_models_list, load_model_from_disk\n",
    "from scaaml.intro.generator import list_shards, load_attack_shard\n",
    "from scaaml.utils import hex_display, bytelist_to_hex\n",
    "\n",
    "DATASET_GLOB = \"datasets/%s/test/*\" % ('tinyaes')\n",
    "shard_paths  = list_shards(DATASET_GLOB, 256)\n",
    "np.load(shard_paths[2])\n",
    "\n",
    "ATTACK_BYTE = 0\n",
    "ATTACK_POINT = 'sub_bytes_in'\n",
    "TRACE_LEN = 20000\n",
    "\n",
    "NUM_TRACES = 8  # maximum number of traces to use to recover a given key byte. 10 is already overkill\n",
    "correct_prediction_rank = defaultdict(list)\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for shard in tqdm(shard_paths, desc='Recovering bytes', unit='shards'):\n",
    "    keys, pts, x, y = load_attack_shard(shard, ATTACK_BYTE, ATTACK_POINT, TRACE_LEN, num_traces=NUM_TRACES)\n",
    "\n",
    "    p = tf.unstack(pts, axis=0)\n",
    "    p = [np.argmax(pp.numpy()) for pp in p]\n",
    "    p = int_to_ohbinary(p)\n",
    "    p = tf.squeeze(p)\n",
    "    \n",
    "    x = tf.squeeze(x)\n",
    "    \n",
    "    # prediction\n",
    "    predictions = mdl.predict([p, x])\n",
    "    c_preds = from_categorical(predictions)\n",
    "    c_y = from_categorical(y)\n",
    "    y_pred.extend(c_preds)\n",
    "    y_true.extend(c_y)\n",
    "    \n",
    "    # computing byte prediction from intermediate predictions\n",
    "    key_preds = ap_preds_to_key_preds(predictions, pts, ATTACK_POINT)\n",
    "\n",
    "    \n",
    "    key = keys[0] # all the same in the same shard - not used in real attack\n",
    "    vals = np.zeros((256))\n",
    "    for trace_count, kp in enumerate(key_preds):\n",
    "        vals = vals  + np.log10(kp + 1e-22) \n",
    "        guess_ranks = (np.argsort(vals, )[-256:][::-1])\n",
    "        byte_rank = list(guess_ranks).index(key)\n",
    "        correct_prediction_rank[trace_count].append(byte_rank)\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred, normalize=True, title=\"%s byte %s prediction confusion matrix\" % (ATTACK_POINT, ATTACK_BYTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a5d7466f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89, 61, 192, 92, 61, 196, 89, 134, 0, 105, 78, 105, 105, 67, 105, 78, 75, 105, 67, 0, 126, 61, 64, 228, 105, 67, 89, 0, 14, 13, 61, 57, 232, 57, 105, 230, 235, 189, 61, 148, 196, 128, 161, 233, 89, 185, 77, 195, 91, 235, 88, 105, 52, 61, 192, 105, 61, 16, 105, 196, 200, 95, 105, 105, 200, 78, 61, 105, 98, 195, 61, 152, 143, 61, 105, 105, 105, 225, 61, 105, 225, 105, 141, 132, 144, 105, 61, 78, 52, 61, 105, 105, 61, 105, 118, 195, 61, 105, 105, 105, 89, 61, 254, 105, 105, 13, 52, 89, 115, 89, 105, 105, 107, 8, 105, 148, 64, 144, 77, 105, 16, 148, 225, 105, 105, 137, 88, 105, 105, 115, 105, 16, 138, 50, 132, 61, 52, 105, 78, 152, 61, 89, 0, 61, 61, 25, 163, 115, 195, 0, 192, 105, 168, 61, 61, 105, 61, 67, 213, 196, 196, 105, 61, 195, 78, 192, 89, 89, 105, 105, 88, 14, 189, 92, 148, 105, 228, 243, 0, 89, 105, 89, 105, 89, 61, 88, 200, 148, 0, 186, 16, 192, 134, 115, 89, 61, 238, 105, 61, 0, 213, 189, 61, 61, 105, 89, 64, 164, 0, 113, 192, 88, 67, 13, 61, 61, 105, 105, 104, 105, 105, 89, 67, 61, 75, 151, 195, 67, 105, 67, 89, 105, 67, 67, 105, 10, 168, 89, 110, 192, 89, 105, 88, 87, 144, 110, 196, 61, 14, 87, 61, 195, 105, 31, 126, 230, 61, 78, 61, 61, 105, 105, 230, 189, 205, 61, 105, 163, 105, 123, 126, 163, 14, 67, 105, 148, 61, 16, 67, 89, 61, 61, 134, 105, 105, 87, 64, 61, 148, 243, 105, 105, 105, 148, 61, 195, 89, 8, 160, 163, 105, 61, 89, 61, 61, 77, 88, 182, 134, 57, 195, 61, 168, 115, 105, 0, 105, 8, 230, 230, 0, 57, 78, 78, 144, 196, 92, 132, 171, 105, 61, 89, 16, 105, 61, 57, 61, 196, 61, 144, 105, 0, 105, 67, 61, 105, 61, 105, 195, 148, 195, 105, 61, 61, 105, 16, 89, 134, 61, 195, 88, 192, 61, 0, 105, 105, 105, 89, 89, 61, 31, 105, 105, 61, 105, 61, 254, 105, 88, 61, 67, 61, 0, 67, 105, 89, 134, 105, 196, 105, 67, 105, 16, 61, 88, 105, 105, 115, 181, 208, 61, 138, 144, 16, 105, 61, 61, 61, 87, 105, 67, 61, 144, 2, 89, 78, 61, 168, 212, 98, 164, 195, 105, 0, 61, 238, 57, 61, 144, 88, 168, 64, 230, 61, 105, 31, 113, 195, 143, 105, 105, 61, 105, 105, 19, 192, 115, 61, 67, 14, 61, 0, 105, 195, 105, 105, 144, 105, 195, 75, 75, 64, 64, 105, 61, 89, 105, 195, 61, 69, 195, 67, 196, 192, 50, 61, 148, 61, 168, 105, 61, 88, 130, 61, 61, 89, 88, 75, 61, 208, 78, 105, 110, 61, 0, 68, 105, 105, 195, 105, 105, 67, 67, 67, 228, 105, 192, 132, 105, 14, 115, 61, 61, 196, 192, 61, 105, 64, 89, 57, 78, 105, 98, 254, 89, 64, 61, 61, 120, 57, 0, 67, 61, 61, 67, 105, 64, 89, 61, 61, 254, 105, 13, 57, 61, 0, 68, 92, 128, 192, 89, 208, 105, 88, 61, 225, 160, 89, 89, 67, 105, 196, 143, 195, 89, 208, 122, 0, 61, 67, 208, 118, 115, 148, 105, 131, 13, 168, 105, 168, 64, 0, 195, 186, 61, 148, 61, 196, 105, 148, 64, 195, 89, 196, 57, 89, 67, 192, 87, 105, 164, 105, 61, 105, 61, 61, 105, 225, 8, 64, 212, 192, 192, 78, 105, 105, 217, 148, 88, 192, 157, 105, 8, 61, 192, 208, 235, 61, 61, 168, 78, 192, 105, 105, 105, 238, 8, 67, 144, 148, 168, 11, 195, 20, 196, 105, 72, 0, 163, 132, 13, 105, 105, 235, 105, 98, 232, 230, 105, 61, 135, 134, 61, 89, 254, 61, 105, 105, 16, 143, 61, 148, 16, 67, 61, 89, 105, 105, 0, 57, 105, 144, 208, 160, 225, 208, 110, 16, 91, 105, 89, 61, 105, 0, 168, 235, 0, 195, 19, 0, 200, 135, 89, 89, 105, 192, 88, 92, 105, 113, 0, 134, 105, 78, 78, 61, 67, 195, 105, 89, 88, 254, 105, 105, 88, 192, 107, 230, 195, 105, 67, 61, 2, 61, 144, 61, 105, 181, 148, 105, 115, 107, 13, 61, 89, 134, 102, 105, 163, 152, 0, 67, 57, 105, 152, 13, 16, 115, 89, 57, 75, 89, 130, 163, 144, 148, 16, 68, 105, 105, 105, 171, 192, 61, 131, 196, 105, 151, 19, 89, 89, 208, 105, 57, 105, 67, 98, 105, 69, 0, 16, 131, 105, 61, 87, 179, 105, 91, 163, 61, 164, 195, 105, 182, 105, 89, 192, 117, 61, 144, 105, 105, 0, 0, 0, 0, 185, 30, 105, 192, 192, 192, 107, 16, 105, 64, 105, 69, 0, 195, 105, 0, 61, 105, 21, 61, 107, 61, 105, 61, 89, 105, 57, 105, 61, 14, 105, 89, 134, 75, 195, 0, 88, 57, 105, 88, 61, 105, 61, 192, 67, 163, 0, 61, 89, 61, 225, 64, 78, 0, 195, 57, 61, 105, 67, 202, 254, 105, 61, 254, 61, 61, 88, 61, 105, 52, 192, 61, 192, 195, 105, 115, 195, 61, 61, 105, 111, 105, 192, 126, 195, 68, 196, 105, 105, 88, 88, 105, 89, 61, 57, 61, 16, 61, 160, 105, 196, 0, 105, 61, 13, 61, 254, 67, 134, 105, 16, 105, 61, 105, 70, 195, 61, 105, 105, 105, 105, 75, 64, 163, 89, 59, 105, 89, 0, 168, 57, 88, 40, 132, 78, 105, 57, 192, 196, 89, 61, 61, 61, 75, 105, 57, 61, 67, 78, 16, 61, 61, 254, 61, 105, 105, 89, 105, 105, 108, 89, 105, 105, 105, 105, 89, 105, 61, 13, 196, 128, 61, 67, 105, 61, 61, 192, 105, 105, 107, 88, 105, 14, 195, 161, 196, 132, 40, 0, 64, 195, 105, 57, 195, 105, 67, 110, 129, 195, 105, 14, 196, 67, 208, 57, 212, 75, 61, 61, 105, 89, 171, 67, 89, 105, 61, 192, 132, 196, 61, 195, 196, 67, 89, 61, 105, 105, 105, 105, 235, 228, 134, 192, 105, 105, 68, 88, 78, 115, 67, 75, 50, 212, 68, 0, 148, 23, 92, 105, 195, 189, 0, 61, 61, 105, 61, 61, 149, 88, 105, 108, 105, 88, 20, 61, 13, 44, 107, 77, 61, 54, 105, 123, 0, 57, 64, 21, 148, 186, 105, 64, 105, 57, 185, 64, 0, 208, 0, 105, 151, 247, 52, 195, 105, 105, 105, 61, 144, 189, 192, 168, 16, 61, 75, 105, 2, 105, 88, 163, 89, 98, 195, 105, 115, 235, 67, 67, 19, 105, 254, 105, 105, 92, 61, 171, 105, 115, 115, 105, 61, 88, 61, 105, 105, 105, 105, 130, 61, 88, 61, 61, 0, 64, 61, 225, 105, 81, 134, 105, 61, 130, 148, 148, 131, 135, 67, 105, 144, 196, 105, 144, 208, 105, 61, 192, 61, 248, 88, 105, 148, 192, 105, 105, 254, 64, 88, 61, 61, 105, 105, 61, 88, 0, 98, 23, 195, 78, 105, 128, 208, 105, 128, 89, 163, 191, 225, 57, 192, 131, 67, 89, 148, 105, 61, 67, 146, 89, 78, 105, 163, 135, 16, 1, 195, 13, 89, 196, 196, 61, 57, 67, 67, 192, 138, 16, 89, 61, 13, 61, 0, 168, 89, 189, 105, 89, 118, 16, 54, 64, 78, 75, 128, 61, 61, 105, 132, 134, 105, 57, 163, 67, 192, 105, 232, 67, 105, 61, 105, 110, 78, 78, 195, 41, 41, 105, 105, 105, 105, 105, 61, 89, 195, 61, 61, 195, 144, 88, 67, 164, 14, 144, 67, 105, 61, 192, 105, 168, 105, 105, 105, 105, 168, 61, 0, 195, 61, 105, 185, 61, 226, 64, 89, 16, 148, 197, 193, 118, 61, 238, 196, 0, 192, 105, 52, 0, 254, 75, 105, 98, 61, 105, 61, 61, 119, 115, 87, 105, 105, 61, 192, 191, 61, 67, 67, 88, 61, 196, 208, 2, 16, 19, 105, 69, 192, 144, 105, 78, 247, 87, 67, 0, 52, 196, 21, 88, 13, 105, 105, 57, 196, 67, 186, 192, 88, 88, 61, 57, 115, 195, 61, 16, 105, 61, 132, 134, 67, 88, 225, 61, 61, 61, 105, 105, 75, 196, 192, 105, 0, 105, 152, 238, 61, 61, 139, 0, 61, 89, 160, 89, 247, 195, 225, 160, 203, 225, 0, 105, 152, 61, 105, 192, 105, 105, 0, 61, 132, 89, 92, 0, 61, 61, 105, 61, 92, 148, 89, 105, 208, 16, 105, 192, 61, 105, 64, 105, 88, 192, 0, 0, 89, 163, 235, 105, 61, 89, 105, 148, 168, 105, 196, 16, 0, 196, 88, 40, 61, 195, 61, 61, 130, 61, 64, 0, 61, 78, 87, 14, 192, 61, 61, 105, 192, 61, 89, 105, 105, 105, 105, 2, 253, 196, 61, 105, 208, 95, 163, 144, 64, 163, 105, 148, 61, 192, 61, 105, 171, 189, 105, 89, 208, 105, 105, 163, 254, 163, 117, 105, 0, 67, 61, 61, 61, 105, 61, 196, 195, 204, 64, 89, 130, 105, 105, 105, 131, 105, 226, 106, 105, 105, 75, 64, 105, 61, 89, 208, 61, 61, 89, 105, 98, 168, 189, 105, 67, 10, 61, 105, 61, 10, 191, 105, 129, 98, 91, 61, 89, 164, 144, 98, 67, 69, 105, 71, 61, 64, 105, 57, 191, 89, 202, 61, 228, 89, 195, 192, 10, 105, 195, 185, 105, 192, 196, 52, 134, 139, 61, 61, 132, 92, 89, 16, 148, 181, 192, 105, 67, 105, 0, 230, 152, 107, 61, 61, 208, 89, 75, 148, 105, 61, 16, 196, 105, 134, 19, 192, 151, 8, 75, 67, 148, 105, 105, 189, 16, 168, 191, 254, 232, 13, 61, 0, 105, 105, 134, 61, 67, 195, 148, 89, 105, 14, 20, 89, 195, 105, 192, 163, 144, 105, 75, 195, 89, 148, 134, 57, 105, 163, 61, 67, 61, 115, 89, 122, 192, 61, 2, 105, 16, 13, 232, 81, 192, 105, 105, 89, 196, 115, 61, 61, 88, 61, 0, 134, 230, 61, 105, 57, 105, 78, 192, 128, 105, 8, 52, 145, 115, 107, 61, 105, 208, 61, 144, 152, 192, 88, 144, 192, 115, 67, 0, 105, 105, 61, 115, 105, 110, 105, 89, 61, 144, 64, 89, 61, 132, 67, 105, 61, 105, 105, 61, 192, 115, 61, 195, 88, 144, 89, 131, 200, 195, 228, 89, 67, 56, 89, 168, 105, 105, 0, 89, 238, 88, 64, 61, 61, 126, 192, 105, 105, 163, 61, 254, 105, 67, 54, 105, 93, 61, 105, 67, 61, 67, 75, 57, 105, 105, 105, 61, 88, 94, 88, 105, 88, 105, 67, 105, 238, 75, 195, 144, 105, 126, 144, 81, 192, 148, 13, 105, 192, 61, 61, 192, 105, 61, 195, 0, 105, 67, 105, 192, 57, 61, 39, 195, 89, 168, 81, 192, 105, 89, 89, 149, 75, 88, 61, 105, 171, 115, 0, 87, 61, 164, 67, 110, 105, 226, 181, 225, 143, 89, 195, 130, 61, 208, 105, 105, 105, 105, 61, 61, 88, 89, 105, 105, 75, 61, 105, 88, 128, 78, 16, 196, 225, 89, 61, 105, 168, 67, 105, 0, 105, 105, 118, 89, 105, 192, 143, 143, 61, 134, 130, 192, 196, 192, 20, 61, 61, 16, 69, 163, 196, 148, 105, 202, 89, 89, 105, 88, 195, 13, 0, 192, 87, 61, 91, 105, 105, 192, 61, 13, 105, 89, 19, 192, 105, 105, 105, 196, 57, 195, 89, 186, 98, 208, 163, 68, 61, 61, 126, 0, 89, 0, 57, 195, 61, 61, 88, 105, 105, 67, 105, 235, 192, 105, 89, 105, 225, 132, 192, 105, 69, 16, 132, 151, 61, 171, 105, 14, 238, 88, 238, 89, 144, 105, 16, 67, 105, 134, 20, 61, 163, 0, 61, 105, 61, 16, 105, 132, 105, 105, 208, 217, 89, 225, 61, 148, 148, 61, 61, 208, 61, 118, 61, 61, 105, 148, 191, 152, 105, 89, 8, 105, 69, 105, 89, 61, 105, 105, 181, 144, 61, 67, 94, 78, 254, 64, 132, 105, 87, 88, 164, 2, 64, 89, 105, 105, 89, 88, 225, 238, 190, 61]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)\n",
    "print(y_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
