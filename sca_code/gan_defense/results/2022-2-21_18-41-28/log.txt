(main): Beginning experiments.
(main): 	Config path: '/local/scratch/a/jgammell/sca_defense/sca_code/gan_defense/config/template.json'
(main): 	Output path: '/local/scratch/a/jgammell/sca_defense/sca_code/gan_defense/results/2022-2-21_18-41-28'
(main): 
(main): Setting random seed to 1775552941.
(main): 	Done.
(main): Loading dataset.
(datasets): Loading dataset: 'google_scaaml'
(datasets): 	Number of keys: 16
(datasets): 	Attack point: 'sub_bytes_in'
(datasets): 	Byte: 7
(datasets): 	Trace length: 10000
(datasets): 	Loading data from '/local/scratch/a/jgammell/sca_defense/sca_code/gan_defense/datasets/tinyaes/train'
(datasets): 	Keys to be used:
(datasets): 		0x11c7cc36e2d3a5ebcf1db6b3f6c290ee
(datasets): 		0x888e765fec331e1f5d638130641350f
(datasets): 		0xe506a06d14b9b7b5a3ff85321b55dba1
(datasets): 		0x56d3cb2ac365d89f211fe0fc63979b3a
(datasets): 		0x9ec3830fc568c912964052226dd4ebcd
(datasets): 		0x25caf07f86a5923f08c45bf165014abc
(datasets): 		0xa55b9202258da88da080f31007829cb4
(datasets): 		0x8b4bf7928abadb3de2d980de3faa0cad
(datasets): 		0xa9d2f9d01158a62f168c5b84f696afd8
(datasets): 		0xe9094ab53304413510c46b460ad263a4
(datasets): 		0x2ee9f3bc488d00ad29df031b043e55c4
(datasets): 		0xfdfd2963948c3c7d076c675a1e39749f
(datasets): 		0x556ba9d263cfe23c5e2be64b406c4164
(datasets): 		0x36b954fb5f248ad1c950cc3cfe1c8ba6
(datasets): 		0xdde8fb500596ff8ff4c093b822d42588
(datasets): 		0x70b086804b30d0259fb4218a6aceea02
(datasets): 	Constructing dataset.
(datasets): 		Done.
(main): 	Done.
(main): 
(main): Loading generators.
(models): Generating multilayer perceptron model.
(models): 	Key: 0x11c7cc36e2d3a5ebcf1db6b3f6c290ee
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0x11c7cc36e2d3a5ebcf1db6b3f6c290ee"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense (Dense)                (None, 64)                576       
(models): _________________________________________________________________
(models): dense_1 (Dense)              (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_2 (Dense)              (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_3 (Dense)              (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape (Reshape)            (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(models): Generating multilayer perceptron model.
(models): 	Key: 0x888e765fec331e1f5d638130641350f
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0x888e765fec331e1f5d638130641350f"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense_4 (Dense)              (None, 64)                576       
(models): _________________________________________________________________
(models): dense_5 (Dense)              (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_6 (Dense)              (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_7 (Dense)              (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape_1 (Reshape)          (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(models): Generating multilayer perceptron model.
(models): 	Key: 0xe506a06d14b9b7b5a3ff85321b55dba1
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0xe506a06d14b9b7b5a3ff85321b55dba1"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense_8 (Dense)              (None, 64)                576       
(models): _________________________________________________________________
(models): dense_9 (Dense)              (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_10 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_11 (Dense)             (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape_2 (Reshape)          (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(models): Generating multilayer perceptron model.
(models): 	Key: 0x56d3cb2ac365d89f211fe0fc63979b3a
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0x56d3cb2ac365d89f211fe0fc63979b3a"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense_12 (Dense)             (None, 64)                576       
(models): _________________________________________________________________
(models): dense_13 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_14 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_15 (Dense)             (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape_3 (Reshape)          (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(models): Generating multilayer perceptron model.
(models): 	Key: 0x9ec3830fc568c912964052226dd4ebcd
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0x9ec3830fc568c912964052226dd4ebcd"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense_16 (Dense)             (None, 64)                576       
(models): _________________________________________________________________
(models): dense_17 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_18 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_19 (Dense)             (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape_4 (Reshape)          (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(models): Generating multilayer perceptron model.
(models): 	Key: 0x25caf07f86a5923f08c45bf165014abc
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0x25caf07f86a5923f08c45bf165014abc"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense_20 (Dense)             (None, 64)                576       
(models): _________________________________________________________________
(models): dense_21 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_22 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_23 (Dense)             (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape_5 (Reshape)          (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(models): Generating multilayer perceptron model.
(models): 	Key: 0xa55b9202258da88da080f31007829cb4
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0xa55b9202258da88da080f31007829cb4"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense_24 (Dense)             (None, 64)                576       
(models): _________________________________________________________________
(models): dense_25 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_26 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_27 (Dense)             (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape_6 (Reshape)          (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(models): Generating multilayer perceptron model.
(models): 	Key: 0x8b4bf7928abadb3de2d980de3faa0cad
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0x8b4bf7928abadb3de2d980de3faa0cad"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense_28 (Dense)             (None, 64)                576       
(models): _________________________________________________________________
(models): dense_29 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_30 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_31 (Dense)             (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape_7 (Reshape)          (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(models): Generating multilayer perceptron model.
(models): 	Key: 0xa9d2f9d01158a62f168c5b84f696afd8
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0xa9d2f9d01158a62f168c5b84f696afd8"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense_32 (Dense)             (None, 64)                576       
(models): _________________________________________________________________
(models): dense_33 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_34 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_35 (Dense)             (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape_8 (Reshape)          (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(models): Generating multilayer perceptron model.
(models): 	Key: 0xe9094ab53304413510c46b460ad263a4
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0xe9094ab53304413510c46b460ad263a4"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense_36 (Dense)             (None, 64)                576       
(models): _________________________________________________________________
(models): dense_37 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_38 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_39 (Dense)             (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape_9 (Reshape)          (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(models): Generating multilayer perceptron model.
(models): 	Key: 0x2ee9f3bc488d00ad29df031b043e55c4
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0x2ee9f3bc488d00ad29df031b043e55c4"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense_40 (Dense)             (None, 64)                576       
(models): _________________________________________________________________
(models): dense_41 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_42 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_43 (Dense)             (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape_10 (Reshape)         (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(models): Generating multilayer perceptron model.
(models): 	Key: 0xfdfd2963948c3c7d076c675a1e39749f
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0xfdfd2963948c3c7d076c675a1e39749f"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense_44 (Dense)             (None, 64)                576       
(models): _________________________________________________________________
(models): dense_45 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_46 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_47 (Dense)             (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape_11 (Reshape)         (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(models): Generating multilayer perceptron model.
(models): 	Key: 0x556ba9d263cfe23c5e2be64b406c4164
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0x556ba9d263cfe23c5e2be64b406c4164"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense_48 (Dense)             (None, 64)                576       
(models): _________________________________________________________________
(models): dense_49 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_50 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_51 (Dense)             (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape_12 (Reshape)         (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(models): Generating multilayer perceptron model.
(models): 	Key: 0x36b954fb5f248ad1c950cc3cfe1c8ba6
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0x36b954fb5f248ad1c950cc3cfe1c8ba6"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense_52 (Dense)             (None, 64)                576       
(models): _________________________________________________________________
(models): dense_53 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_54 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_55 (Dense)             (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape_13 (Reshape)         (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(models): Generating multilayer perceptron model.
(models): 	Key: 0xdde8fb500596ff8ff4c093b822d42588
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0xdde8fb500596ff8ff4c093b822d42588"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense_56 (Dense)             (None, 64)                576       
(models): _________________________________________________________________
(models): dense_57 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_58 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_59 (Dense)             (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape_14 (Reshape)         (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(models): Generating multilayer perceptron model.
(models): 	Key: 0x70b086804b30d0259fb4218a6aceea02
(models): 	Trace length: 10000
(models): 	Hidden activation: relu
(models): 	Output activation: sigmoid
(models): 	Plaintext encoding format: binary
(models): 	Done.
(models): Model: "Generator_0x70b086804b30d0259fb4218a6aceea02"
(models): _________________________________________________________________
(models): Layer (type)                 Output Shape              Param #   
(models): =================================================================
(models): dense_60 (Dense)             (None, 64)                576       
(models): _________________________________________________________________
(models): dense_61 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_62 (Dense)             (None, 64)                4160      
(models): _________________________________________________________________
(models): dense_63 (Dense)             (None, 10000)             650000    
(models): _________________________________________________________________
(models): reshape_15 (Reshape)         (None, 10000, 1)          0         
(models): =================================================================
(models): Total params: 658,896
(models): Trainable params: 658,896
(models): Non-trainable params: 0
(models): _________________________________________________________________
(main): 	Done.
(main): 
(main): Loading discriminator.
(models): Model: "model"
(models): __________________________________________________________________________________________________
(models): Layer (type)                    Output Shape         Param #     Connected to                     
(models): ==================================================================================================
(models): input_17 (InputLayer)           [(None, 10000, 1)]   0                                            
(models): __________________________________________________________________________________________________
(models): max_pooling1d (MaxPooling1D)    (None, 2500, 1)      0           input_17[0][0]                   
(models): __________________________________________________________________________________________________
(models): batch_normalization (BatchNorma (None, 2500, 1)      4           max_pooling1d[0][0]              
(models): __________________________________________________________________________________________________
(models): activation (Activation)         (None, 2500, 1)      0           batch_normalization[0][0]        
(models): __________________________________________________________________________________________________
(models): conv1d_1 (Conv1D)               (None, 2500, 16)     16          activation[0][0]                 
(models): __________________________________________________________________________________________________
(models): batch_normalization_1 (BatchNor (None, 2500, 16)     64          conv1d_1[0][0]                   
(models): __________________________________________________________________________________________________
(models): activation_1 (Activation)       (None, 2500, 16)     0           batch_normalization_1[0][0]      
(models): __________________________________________________________________________________________________
(models): conv1d_2 (Conv1D)               (None, 2500, 16)     768         activation_1[0][0]               
(models): __________________________________________________________________________________________________
(models): batch_normalization_2 (BatchNor (None, 2500, 16)     64          conv1d_2[0][0]                   
(models): __________________________________________________________________________________________________
(models): activation_2 (Activation)       (None, 2500, 16)     0           batch_normalization_2[0][0]      
(models): __________________________________________________________________________________________________
(models): conv1d (Conv1D)                 (None, 2500, 64)     128         activation[0][0]                 
(models): __________________________________________________________________________________________________
(models): conv1d_3 (Conv1D)               (None, 2500, 64)     1088        activation_2[0][0]               
(models): __________________________________________________________________________________________________
(models): add (Add)                       (None, 2500, 64)     0           conv1d[0][0]                     
(models):                                                                  conv1d_3[0][0]                   
(models): __________________________________________________________________________________________________
(models): batch_normalization_3 (BatchNor (None, 2500, 64)     256         add[0][0]                        
(models): __________________________________________________________________________________________________
(models): activation_3 (Activation)       (None, 2500, 64)     0           batch_normalization_3[0][0]      
(models): __________________________________________________________________________________________________
(models): conv1d_4 (Conv1D)               (None, 2500, 16)     1024        activation_3[0][0]               
(models): __________________________________________________________________________________________________
(models): batch_normalization_4 (BatchNor (None, 2500, 16)     64          conv1d_4[0][0]                   
(models): __________________________________________________________________________________________________
(models): activation_4 (Activation)       (None, 2500, 16)     0           batch_normalization_4[0][0]      
(models): __________________________________________________________________________________________________
(models): conv1d_5 (Conv1D)               (None, 2500, 16)     768         activation_4[0][0]               
(models): __________________________________________________________________________________________________
(models): batch_normalization_5 (BatchNor (None, 2500, 16)     64          conv1d_5[0][0]                   
(models): __________________________________________________________________________________________________
(models): activation_5 (Activation)       (None, 2500, 16)     0           batch_normalization_5[0][0]      
(models): __________________________________________________________________________________________________
(models): conv1d_6 (Conv1D)               (None, 2500, 64)     1088        activation_5[0][0]               
(models): __________________________________________________________________________________________________
(models): add_1 (Add)                     (None, 2500, 64)     0           activation_3[0][0]               
(models):                                                                  conv1d_6[0][0]                   
(models): __________________________________________________________________________________________________
(models): batch_normalization_6 (BatchNor (None, 2500, 64)     256         add_1[0][0]                      
(models): __________________________________________________________________________________________________
(models): activation_6 (Activation)       (None, 2500, 64)     0           batch_normalization_6[0][0]      
(models): __________________________________________________________________________________________________
(models): conv1d_7 (Conv1D)               (None, 2500, 16)     1024        activation_6[0][0]               
(models): __________________________________________________________________________________________________
(models): batch_normalization_7 (BatchNor (None, 2500, 16)     64          conv1d_7[0][0]                   
(models): __________________________________________________________________________________________________
(models): activation_7 (Activation)       (None, 2500, 16)     0           batch_normalization_7[0][0]      
(models): __________________________________________________________________________________________________
(models): conv1d_8 (Conv1D)               (None, 1250, 16)     768         activation_7[0][0]               
(models): __________________________________________________________________________________________________
(models): batch_normalization_8 (BatchNor (None, 1250, 16)     64          conv1d_8[0][0]                   
(models): __________________________________________________________________________________________________
(models): activation_8 (Activation)       (None, 1250, 16)     0           batch_normalization_8[0][0]      
(models): __________________________________________________________________________________________________
(models): max_pooling1d_1 (MaxPooling1D)  (None, 1250, 64)     0           activation_6[0][0]               
(models): __________________________________________________________________________________________________
(models): conv1d_9 (Conv1D)               (None, 1250, 64)     1088        activation_8[0][0]               
(models): __________________________________________________________________________________________________
(models): add_2 (Add)                     (None, 1250, 64)     0           max_pooling1d_1[0][0]            
(models):                                                                  conv1d_9[0][0]                   
(models): __________________________________________________________________________________________________
(models): batch_normalization_9 (BatchNor (None, 1250, 64)     256         add_2[0][0]                      
(models): __________________________________________________________________________________________________
(models): activation_9 (Activation)       (None, 1250, 64)     0           batch_normalization_9[0][0]      
(models): __________________________________________________________________________________________________
(models): conv1d_11 (Conv1D)              (None, 1250, 32)     2048        activation_9[0][0]               
(models): __________________________________________________________________________________________________
(models): batch_normalization_10 (BatchNo (None, 1250, 32)     128         conv1d_11[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_10 (Activation)      (None, 1250, 32)     0           batch_normalization_10[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_12 (Conv1D)              (None, 1250, 32)     3072        activation_10[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_11 (BatchNo (None, 1250, 32)     128         conv1d_12[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_11 (Activation)      (None, 1250, 32)     0           batch_normalization_11[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_10 (Conv1D)              (None, 1250, 128)    8320        activation_9[0][0]               
(models): __________________________________________________________________________________________________
(models): conv1d_13 (Conv1D)              (None, 1250, 128)    4224        activation_11[0][0]              
(models): __________________________________________________________________________________________________
(models): add_3 (Add)                     (None, 1250, 128)    0           conv1d_10[0][0]                  
(models):                                                                  conv1d_13[0][0]                  
(models): __________________________________________________________________________________________________
(models): batch_normalization_12 (BatchNo (None, 1250, 128)    512         add_3[0][0]                      
(models): __________________________________________________________________________________________________
(models): activation_12 (Activation)      (None, 1250, 128)    0           batch_normalization_12[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_14 (Conv1D)              (None, 1250, 32)     4096        activation_12[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_13 (BatchNo (None, 1250, 32)     128         conv1d_14[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_13 (Activation)      (None, 1250, 32)     0           batch_normalization_13[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_15 (Conv1D)              (None, 1250, 32)     3072        activation_13[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_14 (BatchNo (None, 1250, 32)     128         conv1d_15[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_14 (Activation)      (None, 1250, 32)     0           batch_normalization_14[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_16 (Conv1D)              (None, 1250, 128)    4224        activation_14[0][0]              
(models): __________________________________________________________________________________________________
(models): add_4 (Add)                     (None, 1250, 128)    0           activation_12[0][0]              
(models):                                                                  conv1d_16[0][0]                  
(models): __________________________________________________________________________________________________
(models): batch_normalization_15 (BatchNo (None, 1250, 128)    512         add_4[0][0]                      
(models): __________________________________________________________________________________________________
(models): activation_15 (Activation)      (None, 1250, 128)    0           batch_normalization_15[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_17 (Conv1D)              (None, 1250, 32)     4096        activation_15[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_16 (BatchNo (None, 1250, 32)     128         conv1d_17[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_16 (Activation)      (None, 1250, 32)     0           batch_normalization_16[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_18 (Conv1D)              (None, 1250, 32)     3072        activation_16[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_17 (BatchNo (None, 1250, 32)     128         conv1d_18[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_17 (Activation)      (None, 1250, 32)     0           batch_normalization_17[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_19 (Conv1D)              (None, 1250, 128)    4224        activation_17[0][0]              
(models): __________________________________________________________________________________________________
(models): add_5 (Add)                     (None, 1250, 128)    0           activation_15[0][0]              
(models):                                                                  conv1d_19[0][0]                  
(models): __________________________________________________________________________________________________
(models): batch_normalization_18 (BatchNo (None, 1250, 128)    512         add_5[0][0]                      
(models): __________________________________________________________________________________________________
(models): activation_18 (Activation)      (None, 1250, 128)    0           batch_normalization_18[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_20 (Conv1D)              (None, 1250, 32)     4096        activation_18[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_19 (BatchNo (None, 1250, 32)     128         conv1d_20[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_19 (Activation)      (None, 1250, 32)     0           batch_normalization_19[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_21 (Conv1D)              (None, 625, 32)      3072        activation_19[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_20 (BatchNo (None, 625, 32)      128         conv1d_21[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_20 (Activation)      (None, 625, 32)      0           batch_normalization_20[0][0]     
(models): __________________________________________________________________________________________________
(models): max_pooling1d_2 (MaxPooling1D)  (None, 625, 128)     0           activation_18[0][0]              
(models): __________________________________________________________________________________________________
(models): conv1d_22 (Conv1D)              (None, 625, 128)     4224        activation_20[0][0]              
(models): __________________________________________________________________________________________________
(models): add_6 (Add)                     (None, 625, 128)     0           max_pooling1d_2[0][0]            
(models):                                                                  conv1d_22[0][0]                  
(models): __________________________________________________________________________________________________
(models): batch_normalization_21 (BatchNo (None, 625, 128)     512         add_6[0][0]                      
(models): __________________________________________________________________________________________________
(models): activation_21 (Activation)      (None, 625, 128)     0           batch_normalization_21[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_24 (Conv1D)              (None, 625, 64)      8192        activation_21[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_22 (BatchNo (None, 625, 64)      256         conv1d_24[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_22 (Activation)      (None, 625, 64)      0           batch_normalization_22[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_25 (Conv1D)              (None, 625, 64)      12288       activation_22[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_23 (BatchNo (None, 625, 64)      256         conv1d_25[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_23 (Activation)      (None, 625, 64)      0           batch_normalization_23[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_23 (Conv1D)              (None, 625, 256)     33024       activation_21[0][0]              
(models): __________________________________________________________________________________________________
(models): conv1d_26 (Conv1D)              (None, 625, 256)     16640       activation_23[0][0]              
(models): __________________________________________________________________________________________________
(models): add_7 (Add)                     (None, 625, 256)     0           conv1d_23[0][0]                  
(models):                                                                  conv1d_26[0][0]                  
(models): __________________________________________________________________________________________________
(models): batch_normalization_24 (BatchNo (None, 625, 256)     1024        add_7[0][0]                      
(models): __________________________________________________________________________________________________
(models): activation_24 (Activation)      (None, 625, 256)     0           batch_normalization_24[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_27 (Conv1D)              (None, 625, 64)      16384       activation_24[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_25 (BatchNo (None, 625, 64)      256         conv1d_27[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_25 (Activation)      (None, 625, 64)      0           batch_normalization_25[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_28 (Conv1D)              (None, 625, 64)      12288       activation_25[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_26 (BatchNo (None, 625, 64)      256         conv1d_28[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_26 (Activation)      (None, 625, 64)      0           batch_normalization_26[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_29 (Conv1D)              (None, 625, 256)     16640       activation_26[0][0]              
(models): __________________________________________________________________________________________________
(models): add_8 (Add)                     (None, 625, 256)     0           activation_24[0][0]              
(models):                                                                  conv1d_29[0][0]                  
(models): __________________________________________________________________________________________________
(models): batch_normalization_27 (BatchNo (None, 625, 256)     1024        add_8[0][0]                      
(models): __________________________________________________________________________________________________
(models): activation_27 (Activation)      (None, 625, 256)     0           batch_normalization_27[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_30 (Conv1D)              (None, 625, 64)      16384       activation_27[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_28 (BatchNo (None, 625, 64)      256         conv1d_30[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_28 (Activation)      (None, 625, 64)      0           batch_normalization_28[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_31 (Conv1D)              (None, 625, 64)      12288       activation_28[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_29 (BatchNo (None, 625, 64)      256         conv1d_31[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_29 (Activation)      (None, 625, 64)      0           batch_normalization_29[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_32 (Conv1D)              (None, 625, 256)     16640       activation_29[0][0]              
(models): __________________________________________________________________________________________________
(models): add_9 (Add)                     (None, 625, 256)     0           activation_27[0][0]              
(models):                                                                  conv1d_32[0][0]                  
(models): __________________________________________________________________________________________________
(models): batch_normalization_30 (BatchNo (None, 625, 256)     1024        add_9[0][0]                      
(models): __________________________________________________________________________________________________
(models): activation_30 (Activation)      (None, 625, 256)     0           batch_normalization_30[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_33 (Conv1D)              (None, 625, 64)      16384       activation_30[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_31 (BatchNo (None, 625, 64)      256         conv1d_33[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_31 (Activation)      (None, 625, 64)      0           batch_normalization_31[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_34 (Conv1D)              (None, 313, 64)      12288       activation_31[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_32 (BatchNo (None, 313, 64)      256         conv1d_34[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_32 (Activation)      (None, 313, 64)      0           batch_normalization_32[0][0]     
(models): __________________________________________________________________________________________________
(models): max_pooling1d_3 (MaxPooling1D)  (None, 313, 256)     0           activation_30[0][0]              
(models): __________________________________________________________________________________________________
(models): conv1d_35 (Conv1D)              (None, 313, 256)     16640       activation_32[0][0]              
(models): __________________________________________________________________________________________________
(models): add_10 (Add)                    (None, 313, 256)     0           max_pooling1d_3[0][0]            
(models):                                                                  conv1d_35[0][0]                  
(models): __________________________________________________________________________________________________
(models): batch_normalization_33 (BatchNo (None, 313, 256)     1024        add_10[0][0]                     
(models): __________________________________________________________________________________________________
(models): activation_33 (Activation)      (None, 313, 256)     0           batch_normalization_33[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_37 (Conv1D)              (None, 313, 128)     32768       activation_33[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_34 (BatchNo (None, 313, 128)     512         conv1d_37[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_34 (Activation)      (None, 313, 128)     0           batch_normalization_34[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_38 (Conv1D)              (None, 313, 128)     49152       activation_34[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_35 (BatchNo (None, 313, 128)     512         conv1d_38[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_35 (Activation)      (None, 313, 128)     0           batch_normalization_35[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_36 (Conv1D)              (None, 313, 512)     131584      activation_33[0][0]              
(models): __________________________________________________________________________________________________
(models): conv1d_39 (Conv1D)              (None, 313, 512)     66048       activation_35[0][0]              
(models): __________________________________________________________________________________________________
(models): add_11 (Add)                    (None, 313, 512)     0           conv1d_36[0][0]                  
(models):                                                                  conv1d_39[0][0]                  
(models): __________________________________________________________________________________________________
(models): batch_normalization_36 (BatchNo (None, 313, 512)     2048        add_11[0][0]                     
(models): __________________________________________________________________________________________________
(models): activation_36 (Activation)      (None, 313, 512)     0           batch_normalization_36[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_40 (Conv1D)              (None, 313, 128)     65536       activation_36[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_37 (BatchNo (None, 313, 128)     512         conv1d_40[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_37 (Activation)      (None, 313, 128)     0           batch_normalization_37[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_41 (Conv1D)              (None, 313, 128)     49152       activation_37[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_38 (BatchNo (None, 313, 128)     512         conv1d_41[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_38 (Activation)      (None, 313, 128)     0           batch_normalization_38[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_42 (Conv1D)              (None, 313, 512)     66048       activation_38[0][0]              
(models): __________________________________________________________________________________________________
(models): add_12 (Add)                    (None, 313, 512)     0           activation_36[0][0]              
(models):                                                                  conv1d_42[0][0]                  
(models): __________________________________________________________________________________________________
(models): batch_normalization_39 (BatchNo (None, 313, 512)     2048        add_12[0][0]                     
(models): __________________________________________________________________________________________________
(models): activation_39 (Activation)      (None, 313, 512)     0           batch_normalization_39[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_43 (Conv1D)              (None, 313, 128)     65536       activation_39[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_40 (BatchNo (None, 313, 128)     512         conv1d_43[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_40 (Activation)      (None, 313, 128)     0           batch_normalization_40[0][0]     
(models): __________________________________________________________________________________________________
(models): conv1d_44 (Conv1D)              (None, 157, 128)     49152       activation_40[0][0]              
(models): __________________________________________________________________________________________________
(models): batch_normalization_41 (BatchNo (None, 157, 128)     512         conv1d_44[0][0]                  
(models): __________________________________________________________________________________________________
(models): activation_41 (Activation)      (None, 157, 128)     0           batch_normalization_41[0][0]     
(models): __________________________________________________________________________________________________
(models): max_pooling1d_4 (MaxPooling1D)  (None, 157, 512)     0           activation_39[0][0]              
(models): __________________________________________________________________________________________________
(models): conv1d_45 (Conv1D)              (None, 157, 512)     66048       activation_41[0][0]              
(models): __________________________________________________________________________________________________
(models): add_13 (Add)                    (None, 157, 512)     0           max_pooling1d_4[0][0]            
(models):                                                                  conv1d_45[0][0]                  
(models): __________________________________________________________________________________________________
(models): global_average_pooling1d (Globa (None, 512)          0           add_13[0][0]                     
(models): __________________________________________________________________________________________________
(models): dropout (Dropout)               (None, 512)          0           global_average_pooling1d[0][0]   
(models): __________________________________________________________________________________________________
(models): dense_64 (Dense)                (None, 256)          131328      dropout[0][0]                    
(models): __________________________________________________________________________________________________
(models): batch_normalization_42 (BatchNo (None, 256)          1024        dense_64[0][0]                   
(models): __________________________________________________________________________________________________
(models): activation_42 (Activation)      (None, 256)          0           batch_normalization_42[0][0]     
(models): __________________________________________________________________________________________________
(models): dense_65 (Dense)                (None, 256)          65792       activation_42[0][0]              
(models): ==================================================================================================
(models): Total params: 1,122,388
(models): Trainable params: 1,113,106
(models): Non-trainable params: 9,282
(models): __________________________________________________________________________________________________
(main): 	Done.
(main): 
(main): Loading GAN.
(main): 	Done.
(main): 
(main): Training GAN.
